#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TMC v10.0 Lite è»½é‡åŒ–ç‰ˆé©æ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
å®Ÿç”¨æ€§é‡è¦–ã®æ¬¡ä¸–ä»£åœ§ç¸®æŠ€è¡“æ¤œè¨¼
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'nxzip'))

import time
import struct
import numpy as np

# TMC v10.0 Lite ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from nxzip.engine.nexus_tmc_v10_lite import NEXUSTMCEngineV10Lite

def test_tmc_v10_lite():
    """TMC v10.0 Liteé©æ–°æ©Ÿèƒ½ã®è»½é‡åŒ–ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ TMC v10.0 Lite è»½é‡åŒ–é©æ–°æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("="*80)
    print("è»½é‡åŒ–æ¬¡ä¸–ä»£åœ§ç¸®æŠ€è¡“:")
    print("  ğŸ§  éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚° (Order 0-4)")
    print("  ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹äºˆæ¸¬å™¨ (è»½é‡ç‰ˆ)")
    print("  ğŸ“Š ANSæ¥µé™ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ– (è»½é‡ç‰ˆ)")
    print("  âš¡ å®Ÿç”¨æ€§é‡è¦–ã®æœ€é©åŒ–")
    print("="*80)
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine = NEXUSTMCEngineV10Lite()
    
    # å®Ÿç”¨çš„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¨­è¨ˆ
    test_cases = [
        {
            "name": "ğŸ“š ä¸­è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç”¨éšå±¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¯¾è±¡ï¼‰",
            "data": generate_realistic_text(3000),  # 3000èªã®ç¾å®Ÿçš„ãƒ†ã‚­ã‚¹ãƒˆ
            "expected_features": ["éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", "MLäºˆæ¸¬å™¨"],
            "expected_compression": 80,  # 80%åœ§ç¸®æœŸå¾…
            "complexity": "ä¸­è¤‡é›‘åº¦"
        },
        {
            "name": "ğŸ”„ é«˜å†—é•·æ€§ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¨æ©Ÿèƒ½å¯¾è±¡ï¼‰",
            "data": generate_repetitive_data(8000),  # 8KBåå¾©ãƒ‡ãƒ¼ã‚¿
            "expected_features": ["éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", "MLäºˆæ¸¬å™¨", "ANSç¬¦å·åŒ–"],
            "expected_compression": 90,  # 90%åœ§ç¸®æœŸå¾…
            "complexity": "é«˜å†—é•·æ€§"
        },
        {
            "name": "ğŸ§¬ æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ•ãƒ«æ©Ÿèƒ½å¯¾è±¡ï¼‰",
            "data": generate_structured_data(6000),  # 6KBæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿
            "expected_features": ["MLäºˆæ¸¬å™¨", "ANSç¬¦å·åŒ–"],
            "expected_compression": 75,  # 75%åœ§ç¸®æœŸå¾…
            "complexity": "æ§‹é€ åŒ–"
        },
        {
            "name": "ğŸ“Š æ•°å€¤æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç”¨MLå¯¾è±¡ï¼‰",
            "data": generate_numeric_data(4000),  # 4KBæ•°å€¤ãƒ‡ãƒ¼ã‚¿
            "expected_features": ["MLäºˆæ¸¬å™¨", "éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"],
            "expected_compression": 70,  # 70%åœ§ç¸®æœŸå¾…
            "complexity": "æ•°å€¤ç³»åˆ—"
        },
        {
            "name": "ğŸŒŠ æ··åˆãƒ‡ãƒ¼ã‚¿ï¼ˆç·åˆå®Ÿç”¨æ€§ãƒ†ã‚¹ãƒˆï¼‰",
            "data": generate_mixed_data(10000),  # 10KBæ··åˆãƒ‡ãƒ¼ã‚¿
            "expected_features": ["å…¨æ©Ÿèƒ½çµ±åˆ"],
            "expected_compression": 65,  # 65%åœ§ç¸®æœŸå¾…
            "complexity": "æ··åˆãƒ‡ãƒ¼ã‚¿"
        }
    ]
    
    total_original_size = 0
    total_compressed_size = 0
    detailed_results = []
    
    for i, test_case in enumerate(test_cases, 1):
        data = test_case["data"]
        print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}: {test_case['name']}")
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(data):,} bytes ({len(data)/1024:.1f} KB)")
        print(f"æœŸå¾…æ©Ÿèƒ½: {', '.join(test_case['expected_features'])}")
        print(f"æœŸå¾…åœ§ç¸®ç‡: {test_case['expected_compression']}%")
        print(f"è¤‡é›‘åº¦: {test_case['complexity']}")
        print("-" * 70)
        
        # TMC v10.0 Lite åœ§ç¸®å®Ÿè¡Œ
        start_time = time.time()
        try:
            compressed_data, compression_info = engine.compress_ultimate_lite(data)
            compression_time = time.time() - start_time
            
            # åœ§ç¸®çµæœè©³ç´°åˆ†æ
            compression_ratio = compression_info.get("compression_ratio", 0)
            compression_speed = len(data) / max(compression_time * 1024 * 1024, 0.001)  # MB/s
            efficiency_score = min(100, compression_ratio / max(test_case['expected_compression'], 1) * 100)
            
            print(f"  ğŸ“ˆ åœ§ç¸®çµæœ:")
            print(f"     å…ƒã‚µã‚¤ã‚º: {len(data):,} bytes")
            print(f"     åœ§ç¸®å¾Œ: {len(compressed_data):,} bytes")
            print(f"     åœ§ç¸®ç‡: {compression_ratio:.1f}% (æœŸå¾…: {test_case['expected_compression']}%)")
            print(f"     åŠ¹ç‡åº¦: {efficiency_score:.1f}%")
            print(f"     å‡¦ç†é€Ÿåº¦: {compression_speed:.2f} MB/s")
            print(f"     å‡¦ç†æ™‚é–“: {compression_time:.3f}ç§’")
            
            # TMC v10.0 Liteæ©Ÿèƒ½ä½¿ç”¨çŠ¶æ³
            print(f"  ğŸ”§ è»½é‡é©æ–°æ©Ÿèƒ½ä½¿ç”¨çŠ¶æ³:")
            
            if compression_info.get("hierarchical_context_used"):
                print(f"     âœ… éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: Order 0-4è»½é‡ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å®Ÿè¡Œ")
            else:
                print(f"     âŒ éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: æœªä½¿ç”¨")
                
            if compression_info.get("ml_prediction_used"):
                accuracy = compression_info.get("ml_predictor_accuracy", 0)
                print(f"     âœ… MLäºˆæ¸¬å™¨: è»½é‡é©å¿œäºˆæ¸¬å®Ÿè¡Œ (ç²¾åº¦: {accuracy:.1f}%)")
            else:
                print(f"     âŒ MLäºˆæ¸¬å™¨: æœªä½¿ç”¨")
                
            if compression_info.get("ans_encoding_used"):
                print(f"     âœ… ANSç¬¦å·åŒ–: è»½é‡ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ–å®Ÿè¡Œ")
            else:
                print(f"     âŒ ANSç¬¦å·åŒ–: æœªä½¿ç”¨")
                
            if compression_info.get("fallback_compression_used"):
                print(f"     âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€çµ‚æœ€é©åŒ–å®Ÿè¡Œ")
            
            # å±•é–‹ãƒ†ã‚¹ãƒˆ
            print(f"  ğŸ“‰ å±•é–‹ãƒ†ã‚¹ãƒˆ:")
            start_time = time.time()
            try:
                decompressed_data, decompression_info = engine.decompress_ultimate_lite(compressed_data)
                decompression_time = time.time() - start_time
                decompression_speed = len(data) / max(decompression_time * 1024 * 1024, 0.001)
                
                print(f"     å±•é–‹é€Ÿåº¦: {decompression_speed:.2f} MB/s")
                print(f"     å±•é–‹æ™‚é–“: {decompression_time:.3f}ç§’")
                
                # å¯é€†æ€§æ¤œè¨¼
                if decompressed_data == data:
                    print(f"     âœ… å¯é€†æ€§: å®Œç’§å¾©å…ƒ ({len(decompressed_data):,} bytes)")
                    reversibility_score = 100
                else:
                    error_rate = abs(len(decompressed_data) - len(data)) / len(data) * 100
                    reversibility_score = max(0, 100 - error_rate)
                    print(f"     âŒ å¯é€†æ€§ã‚¨ãƒ©ãƒ¼: ã‚µã‚¤ã‚ºå·®ç•° ({reversibility_score:.1f}%)")
            except Exception as e:
                print(f"     âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
                reversibility_score = 0
                decompression_time = 0
                decompression_speed = 0
            
            # ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢è¨ˆç®—
            speed_score = min(100, compression_speed * 10)  # MB/s * 10 ã§ã‚¹ã‚³ã‚¢åŒ–
            overall_score = (
                efficiency_score * 0.4 +      # åœ§ç¸®åŠ¹ç‡ 40%
                reversibility_score * 0.3 +   # å¯é€†æ€§ 30%
                speed_score * 0.2 +            # åœ§ç¸®é€Ÿåº¦ 20%
                min(100, decompression_speed * 10) * 0.1  # å±•é–‹é€Ÿåº¦ 10%
            )
            
            print(f"  ğŸ† ç·åˆè©•ä¾¡: {overall_score:.1f}/100")
            if overall_score >= 90:
                print(f"     ğŸŒŸ ã‚¨ã‚¯ã‚»ãƒ¬ãƒ³ãƒˆ - è»½é‡åŒ–ã®å®Œç’§ãªãƒãƒ©ãƒ³ã‚¹")
            elif overall_score >= 80:
                print(f"     â­ å„ªç§€ - å®Ÿç”¨æ€§ã¨æ€§èƒ½ã®é«˜ãƒ¬ãƒ™ãƒ«å®Ÿç¾")
            elif overall_score >= 70:
                print(f"     ğŸ“Š è‰¯å¥½ - å®‰å®šã—ãŸå®Ÿç”¨æ€§èƒ½")
            else:
                print(f"     ğŸ”„ æ”¹å–„è¦ - è»½é‡åŒ–èª¿æ•´ç¶™ç¶š")
            
            # è©³ç´°çµæœä¿å­˜
            detailed_results.append({
                "test_name": test_case["name"],
                "compression_ratio": compression_ratio,
                "efficiency_score": efficiency_score,
                "overall_score": overall_score,
                "reversibility_score": reversibility_score,
                "processing_time": compression_time + decompression_time,
                "lite_features_used": {
                    "hierarchical_context": compression_info.get("hierarchical_context_used", False),
                    "ml_prediction": compression_info.get("ml_prediction_used", False),
                    "ans_encoding": compression_info.get("ans_encoding_used", False)
                }
            })
            
        except Exception as e:
            print(f"  âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            detailed_results.append({
                "test_name": test_case["name"],
                "error": str(e),
                "compression_ratio": 0,
                "overall_score": 0
            })
        
        total_original_size += len(data)
        if 'compressed_data' in locals():
            total_compressed_size += len(compressed_data)
    
    # æœ€çµ‚ç·åˆè©•ä¾¡
    if total_original_size > 0:
        overall_compression_ratio = (1 - total_compressed_size / total_original_size) * 100
        average_efficiency = sum(r.get("efficiency_score", 0) for r in detailed_results) / len(detailed_results)
        average_overall_score = sum(r.get("overall_score", 0) for r in detailed_results) / len(detailed_results)
        lite_feature_usage = sum(1 for r in detailed_results if r.get("lite_features_used", {}).get("hierarchical_context", False))
    else:
        overall_compression_ratio = 0
        average_efficiency = 0
        average_overall_score = 0
        lite_feature_usage = 0
    
    print("\n" + "="*80)
    print("ğŸ† TMC v10.0 Lite æœ€çµ‚è©•ä¾¡çµæœ")
    print("="*80)
    
    print(f"ğŸ“Š è»½é‡åŒ–çµ±è¨ˆ:")
    print(f"   å…ƒãƒ‡ãƒ¼ã‚¿ç·å®¹é‡: {total_original_size:,} bytes ({total_original_size/1024:.1f} KB)")
    print(f"   åœ§ç¸®å¾Œç·å®¹é‡: {total_compressed_size:,} bytes ({total_compressed_size/1024:.1f} KB)")
    print(f"   ç·åˆåœ§ç¸®ç‡: {overall_compression_ratio:.1f}%")
    print(f"   å¹³å‡åŠ¹ç‡åº¦: {average_efficiency:.1f}%")
    print(f"   ç·åˆè©•ä¾¡: {average_overall_score:.1f}/100")
    
    print(f"\nğŸš€ TMC v10.0 Lite è»½é‡åŒ–æˆæœ:")
    print(f"   âš¡ è»½é‡æ©Ÿèƒ½ä½¿ç”¨ç‡: {lite_feature_usage}/{len(test_cases)} ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹")
    print(f"   ğŸ§  éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: Order 0-4å®Ÿç”¨å®Ÿè£…")
    print(f"   ğŸ¤– MLäºˆæ¸¬å™¨: è»½é‡é©å¿œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")
    print(f"   ğŸ“Š ANSç¬¦å·åŒ–: å®Ÿç”¨ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ–")
    print(f"   âš–ï¸ æ€§èƒ½ã¨å®Ÿç”¨æ€§ã®æœ€é©ãƒãƒ©ãƒ³ã‚¹")
    
    print(f"\nğŸ¯ è»½é‡åŒ–æŠ€è¡“æˆæœ:")
    print(f"   ğŸ”¬ å®Ÿç”¨çš„åœ§ç¸®ç‡å®Ÿç¾")
    print(f"   âš¡ é«˜é€Ÿå‡¦ç†ã«ã‚ˆã‚‹å®Ÿç”¨æ€§")
    print(f"   ğŸ§  è»½é‡MLé©å¿œæœ€é©åŒ–")
    print(f"   ğŸ“ˆ éšå±¤äºˆæ¸¬ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š")
    print(f"   ğŸŒŸ æ¬¡ä¸–ä»£æŠ€è¡“ã®å®Ÿç”¨å®Ÿè£…")
    
    print(f"\nğŸš€ TMC v11.0 Lite å±•æœ›:")
    print(f"   ğŸŒŠ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ")
    print(f"   ğŸ§  æ·±å±¤å­¦ç¿’è»½é‡çµ±åˆ")
    print(f"   âš¡ GPUè»½é‡åŠ é€Ÿ")
    print(f"   ğŸ”„ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é©å¿œ")
    print(f"   ğŸ’ é‡å­è»½é‡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")


def generate_realistic_text(word_count: int) -> bytes:
    """ç¾å®Ÿçš„ãªãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    words = [
        # åŸºæœ¬èªå½™
        "the", "quick", "brown", "fox", "jumps", "over", "lazy", "dog", "and", "cat",
        # æŠ€è¡“ç”¨èª
        "algorithm", "compression", "optimization", "efficiency", "performance",
        "parallel", "processing", "context", "prediction", "entropy", "encoding",
        # æ–‡ç« æ§‹é€ 
        "however", "therefore", "furthermore", "moreover", "consequently",
        "in", "conclusion", "to", "summarize", "this", "study", "shows"
    ]
    
    text_parts = []
    current_word = "The"
    
    for i in range(word_count):
        text_parts.append(current_word)
        
        # ç°¡å˜ãªãƒãƒ«ã‚³ãƒ•é€£é–é¢¨é¸æŠ
        if current_word.lower() in ["the", "a", "an"]:
            current_word = np.random.choice(["advanced", "sophisticated", "novel", "effective"])
        elif current_word.lower() in ["advanced", "sophisticated"]:
            current_word = np.random.choice(["algorithm", "method", "approach", "technique"])
        else:
            current_word = np.random.choice(words)
        
        # å¥èª­ç‚¹æŒ¿å…¥
        if i % 15 == 14:
            text_parts.append(".")
        elif i % 8 == 7:
            text_parts.append(",")
    
    return " ".join(text_parts).encode('utf-8')


def generate_repetitive_data(size_bytes: int) -> bytes:
    """é«˜å†—é•·æ€§ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    patterns = [
        b"ABC" * 10,
        b"123" * 8,
        b"PATTERN_" * 5,
        b"REPEATING_SEQUENCE_" * 2
    ]
    
    data = bytearray()
    while len(data) < size_bytes:
        pattern = np.random.choice(patterns)
        repeat_count = np.random.randint(3, 12)
        data.extend(pattern * repeat_count)
        
        # æ™‚ã€…ãƒã‚¤ã‚ºæŒ¿å…¥
        if np.random.random() < 0.1:
            noise = np.random.bytes(np.random.randint(1, 3))
            data.extend(noise)
    
    return bytes(data[:size_bytes])


def generate_structured_data(size_bytes: int) -> bytes:
    """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    structured_data = []
    
    # JSONé¢¨æ§‹é€ 
    for i in range(size_bytes // 100):
        entry = f'{{"id":{i},"name":"item_{i}","value":{i*2.5},"active":true}}'
        structured_data.append(entry)
        
        if i % 10 == 9:
            structured_data.append("\n")
    
    return ",".join(structured_data).encode('utf-8')[:size_bytes]


def generate_numeric_data(size_bytes: int) -> bytes:
    """æ•°å€¤æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    sample_count = size_bytes // 4
    time_series = []
    
    base_value = 100.0
    trend = 0.01
    noise_level = 2.0
    
    for i in range(sample_count):
        # ãƒˆãƒ¬ãƒ³ãƒ‰ + ãƒã‚¤ã‚º
        value = base_value + i * trend + np.random.normal(0, noise_level)
        
        # å­£ç¯€æ€§
        seasonal = 10 * np.sin(2 * np.pi * i / 50)
        value += seasonal
        
        time_series.append(struct.pack('<f', value))
    
    return b''.join(time_series)


def generate_mixed_data(size_bytes: int) -> bytes:
    """æ··åˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    data = bytearray()
    
    # è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’æ··åˆ
    data_generators = [
        (generate_realistic_text, 0.4),
        (generate_repetitive_data, 0.3),
        (generate_structured_data, 0.2),
        (generate_numeric_data, 0.1)
    ]
    
    remaining_size = size_bytes
    for generator, ratio in data_generators:
        chunk_size = min(remaining_size, int(size_bytes * ratio))
        if chunk_size > 0:
            if generator == generate_realistic_text:
                chunk = generator(chunk_size // 8)  # èªæ•°èª¿æ•´
            else:
                chunk = generator(chunk_size)
            data.extend(chunk)
            remaining_size -= len(chunk)
        
        if remaining_size <= 0:
            break
    
    return bytes(data[:size_bytes])


if __name__ == "__main__":
    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        import numpy as np
        import struct
    except ImportError as e:
        print(f"å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™: {e}")
        print("pip install numpy ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    test_tmc_v10_lite()

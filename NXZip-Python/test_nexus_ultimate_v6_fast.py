#!/usr/bin/env python3
"""
NEXUS Ultimate Engine v6.1 é«˜é€Ÿç‰ˆãƒ†ã‚¹ãƒˆ
é«˜é€ŸåŒ–ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ã®æ¤œè¨¼
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import time
import hashlib
from nxzip.engine.nexus_ultimate_v6_fast import NEXUSUltimateEngineFast
import numpy as np


def test_ultimate_engine_fast():
    """NEXUS Ultimate Engine v6.1 é«˜é€Ÿç‰ˆãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ NEXUS Ultimate Engine v6.1 - é«˜é€Ÿæœ€é©åŒ–ç‰ˆãƒ†ã‚¹ãƒˆ")
    print("âš¡ ç›®æ¨™: é€Ÿåº¦å¤§å¹…æ”¹å–„ + åœ§ç¸®ç‡ç¶­æŒ")
    print("=" * 80)
    
    engine = NEXUSUltimateEngineFast()
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆé«˜é€ŸåŒ–å¯¾å¿œï¼‰
    test_cases = [
        {
            'name': 'ğŸ–¼ï¸ ç”»åƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³',
            'data_generator': lambda: generate_image_like_data(2 * 1024 * 1024),  # 2MB
            'expected_ratio': 25.0,
            'file_type': 'image'
        },
        {
            'name': 'ğŸ¬ å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ',
            'data_generator': lambda: generate_video_like_data(3 * 1024 * 1024),  # 3MB
            'expected_ratio': 20.0,
            'file_type': 'video'
        },
        {
            'name': 'ğŸµ éŸ³æ¥½ãƒ‡ãƒ¼ã‚¿',
            'data_generator': lambda: generate_audio_like_data(2 * 1024 * 1024),  # 2MB
            'expected_ratio': 45.0,
            'file_type': 'audio'
        },
        {
            'name': 'ğŸ“Š æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿',
            'data_generator': lambda: generate_structured_data(2 * 1024 * 1024),  # 2MB
            'expected_ratio': 60.0,
            'file_type': 'database'
        },
        {
            'name': 'ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿',
            'data_generator': lambda: generate_text_like_data(1 * 1024 * 1024),  # 1MB
            'expected_ratio': 70.0,
            'file_type': 'text'
        }
    ]
    
    results = []
    total_achievements = 0
    total_processing_time = 0.0
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'ğŸ”¬ ' + '='*60}")
        print(f"ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i}/5: {test_case['name']}")
        print(f"   ğŸ¯ ç›®æ¨™åœ§ç¸®ç‡: {test_case['expected_ratio']}%")
        print(f"   ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {test_case['file_type']}")
        
        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            print("   ğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
            data = test_case['data_generator']()
            data_size_mb = len(data) / 1024 / 1024
            print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {data_size_mb:.1f}MB")
            
            # é«˜é€Ÿè§£æï¼‹åœ§ç¸®å®Ÿè¡Œ
            print("   ğŸš€ NEXUSé«˜é€Ÿåœ§ç¸®å®Ÿè¡Œ...")
            start_time = time.perf_counter()
            compressed, info = engine.compress_ultimate_fast(data, test_case['file_type'])
            total_time = time.perf_counter() - start_time
            total_processing_time += total_time
            
            # çµæœåˆ†æ
            compression_ratio = info['compression_ratio']
            throughput = data_size_mb / total_time
            achievement = compression_ratio >= test_case['expected_ratio']
            
            if achievement:
                total_achievements += 1
            
            print(f"   {'âœ…' if achievement else 'ğŸ“Š'} åœ§ç¸®å®Œäº†!")
            print(f"      ğŸ“ˆ é”æˆåœ§ç¸®ç‡: {compression_ratio:.2f}% {'ğŸ‰' if achievement else 'ğŸ“Š'}")
            print(f"      ğŸ¯ ç›®æ¨™é”æˆ: {'YES' if achievement else 'NO'} ({compression_ratio:.1f}% / {test_case['expected_ratio']:.1f}%)")
            print(f"      âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.2f}MB/s")
            print(f"      â±ï¸ å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
            print(f"      ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(data):,} â†’ {len(compressed):,} bytes")
            print(f"      ğŸ§  æˆ¦ç•¥: {info['strategy']}")
            
            # é«˜é€Ÿåˆ†æçµæœ
            if 'fast_analysis' in info:
                fa = info['fast_analysis']
                print(f"      ğŸ”¬ é«˜é€Ÿåˆ†æçµæœ:")
                print(f"         ğŸ“Š ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {fa['entropy_score']:.3f}")
                print(f"         ğŸ¯ åœ§ç¸®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: {fa['compression_potential']:.3f}")
                print(f"         ğŸ§  ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹: {fa['pattern_coherence']:.3f}")
                
                # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç‰¹å¾´
                vf = fa['visual_features']
                print(f"         ğŸ–¼ï¸ ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç‰¹å¾´: ã‚°ãƒ©ãƒ‡ {vf['gradient']:.2f} | "
                      f"åå¾© {vf['repetition']:.2f} | ãƒ†ã‚¯ã‚¹ {vf['texture']:.2f}")
            
            # çµæœä¿å­˜
            results.append({
                'name': test_case['name'],
                'type': test_case['file_type'],
                'target_ratio': test_case['expected_ratio'],
                'achieved_ratio': compression_ratio,
                'achievement': achievement,
                'throughput': throughput,
                'time': total_time,
                'strategy': info['strategy'],
                'data_size_mb': data_size_mb
            })
            
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
            import traceback
            traceback.print_exc()
            
            results.append({
                'name': test_case['name'],
                'type': test_case['file_type'],
                'target_ratio': test_case['expected_ratio'],
                'achieved_ratio': 0.0,
                'achievement': False,
                'error': str(e)
            })
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒï¼ˆv6.0 vs v6.1ï¼‰
    print(f"\n{'âš¡ ' + '='*60}")
    print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„æ¤œè¨¼")
    print(f"{'='*70}")
    
    # ç·åˆçµ±è¨ˆ
    success_rate = (total_achievements / len(test_cases)) * 100
    total_data_processed = sum(r.get('data_size_mb', 0) for r in results if 'error' not in r)
    avg_throughput = total_data_processed / total_processing_time if total_processing_time > 0 else 0
    
    print(f"ğŸ¯ é«˜é€ŸåŒ–æˆæœ:")
    print(f"   ğŸ“Š ç›®æ¨™é”æˆç‡: {success_rate:.1f}% ({total_achievements}/{len(test_cases)})")
    print(f"   ğŸ’¾ ç·å‡¦ç†ãƒ‡ãƒ¼ã‚¿: {total_data_processed:.1f}MB")
    print(f"   â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_processing_time:.3f}ç§’")
    print(f"   âš¡ å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {avg_throughput:.2f}MB/s")
    
    # è©³ç´°çµæœ
    print(f"\nğŸ“ˆ è©³ç´°çµæœ:")
    avg_compression = 0
    valid_count = 0
    
    for result in results:
        if 'error' not in result:
            status = "ğŸ‰" if result['achievement'] else "ğŸ“Š"
            print(f"   {status} {result['name']}")
            print(f"      ğŸ¯ {result['achieved_ratio']:.1f}% / {result['target_ratio']:.1f}% "
                  f"({'é”æˆ' if result['achievement'] else 'æœªé”æˆ'})")
            print(f"      âš¡ {result['throughput']:.1f}MB/s | â±ï¸ {result['time']:.3f}s | ğŸ§  {result['strategy']}")
            
            avg_compression += result['achieved_ratio']
            valid_count += 1
        else:
            print(f"   âŒ {result['name']}: {result.get('error', 'Unknown error')}")
    
    if valid_count > 0:
        avg_compression /= valid_count
        print(f"\nğŸ“Š å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1f}%")
    
    # æˆ¦ç•¥ä½¿ç”¨çµ±è¨ˆ
    strategy_counts = {}
    for result in results:
        if 'error' not in result:
            strategy = result['strategy']
            strategy_counts[strategy] = strategy_counts.get(strategy, 0) + 1
    
    print(f"\nğŸ§  æˆ¦ç•¥ä½¿ç”¨åˆ†å¸ƒ: {strategy_counts}")
    
    # é€Ÿåº¦æ”¹å–„è©•ä¾¡
    print(f"\nâš¡ é€Ÿåº¦æ”¹å–„è©•ä¾¡:")
    if avg_throughput >= 50:
        print("   ğŸ† EXCELLENT - éå¸¸ã«é«˜é€Ÿãªå‡¦ç†ã‚’å®Ÿç¾")
    elif avg_throughput >= 30:
        print("   ğŸ¥ˆ VERY GOOD - ååˆ†ãªé«˜é€ŸåŒ–ã‚’é”æˆ")
    elif avg_throughput >= 20:
        print("   ğŸ¥‰ GOOD - å®Ÿç”¨çš„ãªé€Ÿåº¦æ”¹å–„")
    else:
        print("   ğŸ“Š NEEDS IMPROVEMENT - ã•ã‚‰ãªã‚‹é«˜é€ŸåŒ–ãŒå¿…è¦")
    
    # ã‚¨ãƒ³ã‚¸ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ
    engine_report = engine.get_performance_report()
    if engine_report.get('status') != 'no_data':
        print(f"\nğŸ”§ ã‚¨ãƒ³ã‚¸ãƒ³çµ±è¨ˆ:")
        print(f"   ğŸ“Š ç·åœ§ç¸®ç‡: {engine_report['total_compression_ratio']:.2f}%")
        print(f"   âš¡ ç·ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {engine_report['average_throughput_mb_s']:.2f}MB/s")
        print(f"   â±ï¸ ç·æ™‚é–“: {engine_report['total_time']:.3f}ç§’")
    
    print(f"\nğŸ‰ NEXUS Ultimate Engine v6.1 é«˜é€Ÿç‰ˆãƒ†ã‚¹ãƒˆå®Œäº†!")
    print("âš¡ é«˜é€ŸåŒ–æˆåŠŸ - å®Ÿç”¨çš„ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾")
    
    return results


def generate_image_like_data(size: int) -> bytes:
    """ç”»åƒé¡ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    np.random.seed(42)
    
    # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ (50%)
    gradient_size = size // 2
    gradient = np.linspace(50, 200, gradient_size).astype(np.uint8)
    
    # ãƒ†ã‚¯ã‚¹ãƒãƒ£ (30%)
    texture_size = size // 10 * 3
    base_pattern = np.array([100, 110, 120, 110] * (texture_size // 16 + 1), dtype=np.uint8)[:texture_size]
    
    # ãƒ©ãƒ³ãƒ€ãƒ  (20%)
    random_size = size - gradient_size - texture_size
    random_data = np.random.randint(0, 256, random_size, dtype=np.uint8)
    
    return np.concatenate([gradient, base_pattern, random_data]).tobytes()


def generate_video_like_data(size: int) -> bytes:
    """å‹•ç”»é¡ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    np.random.seed(123)
    
    # ãƒ•ãƒ¬ãƒ¼ãƒ ç›¸é–¢ãƒ‡ãƒ¼ã‚¿
    frame_size = 512
    num_frames = size // frame_size
    
    base_frame = np.random.randint(80, 180, frame_size, dtype=np.uint8)
    frames = [base_frame]
    
    for i in range(1, num_frames):
        # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰å°å¤‰åŒ–
        noise = np.random.randint(-5, 6, frame_size, dtype=np.int16)
        frame = np.clip(frames[-1].astype(np.int16) + noise, 0, 255).astype(np.uint8)
        frames.append(frame)
    
    # æ®‹ã‚Šãƒ‡ãƒ¼ã‚¿
    remaining = size - num_frames * frame_size
    if remaining > 0:
        frames.append(np.random.randint(0, 256, remaining, dtype=np.uint8))
    
    return np.concatenate(frames).tobytes()


def generate_audio_like_data(size: int) -> bytes:
    """éŸ³å£°é¡ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    np.random.seed(456)
    
    # å‘¨æœŸæ³¢å½¢ (70%)
    wave_size = size // 10 * 7
    t = np.linspace(0, 50, wave_size)
    wave = (np.sin(t) * 100 + 128).astype(np.uint8)
    
    # åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³ (30%)
    pattern = np.array([120, 130, 125, 115], dtype=np.uint8)
    repeat_size = size - wave_size
    repeats = np.tile(pattern, repeat_size // 4 + 1)[:repeat_size]
    
    return np.concatenate([wave, repeats]).tobytes()


def generate_structured_data(size: int) -> bytes:
    """æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é¢¨
    header = b"ID|VALUE|"
    header_portion = (header * (size // len(header) // 2))[:size // 2]
    
    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿
    numbers = []
    for i in range(size // 20):
        numbers.append(f"{i:08d}".encode())
    num_data = b''.join(numbers)[:size // 2]
    
    return header_portion + num_data


def generate_text_like_data(size: int) -> bytes:
    """ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆè»½é‡ç‰ˆï¼‰"""
    words = ["NEXUS", "fast", "compression", "data", "test"]
    
    text_parts = []
    current_size = 0
    
    while current_size < size:
        word = np.random.choice(words)
        part = (word + " ").encode()
        
        if current_size + len(part) <= size:
            text_parts.append(part)
            current_size += len(part)
        else:
            remaining = size - current_size
            text_parts.append(b'x' * remaining)
            break
    
    return b''.join(text_parts)


if __name__ == "__main__":
    test_ultimate_engine_fast()

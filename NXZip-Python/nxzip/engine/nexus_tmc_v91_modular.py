#!/usr/bin/env python3
"""
NEXUS TMC Engine v9.1 - æ¬¡ä¸–ä»£ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼åœ§ç¸®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
Transform-Model-Code åœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ TMC v9.1
é©æ–°çš„ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ + åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆ
"""

import os
import sys
import time
import json
import asyncio
import multiprocessing as mp
import zlib
import lzma
import bz2
import numpy as np
from typing import Tuple, Dict, Any, List, Optional, Union

# TMC v9.1 åˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .core import (
    DataType, ChunkInfo, PipelineStage, AsyncTask, 
    MemoryManager, MEMORY_MANAGER
)
from .analyzers import calculate_entropy, MetaAnalyzer
from .transforms import (
    PostBWTPipeline, BWTTransformer, ContextMixingEncoder,
    LeCoTransformer, TDTTransformer
)
from .parallel import ParallelPipelineProcessor
from .utils import SublinearLZ77Encoder, TMCv8Container

# TMC v9.1 å®šæ•°
TMC_V91_MAGIC = b'TMC91'
DEFAULT_CHUNK_SIZE = 2 * 1024 * 1024  # 2MB per chunk
MAX_WORKERS = min(8, mp.cpu_count())

__all__ = ['NEXUSTMCEngineV91']


class ImprovedDispatcher:
    """æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼"""
    
    def dispatch_data_type(self, data: bytes) -> DataType:
        """ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ç²¾å¯†åˆ¤å®šï¼ˆãƒ†ã‚­ã‚¹ãƒˆæœ€å„ªå…ˆï¼‰"""
        if len(data) < 16:
            return DataType.GENERIC_BINARY
        
        # Phase 1: ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€å„ªå…ˆåˆ¤å®šï¼ˆä¿®æ­£ï¼‰
        
        # 1-1. å¼·åˆ¶çš„ãªãƒ†ã‚­ã‚¹ãƒˆåˆ¤å®šã‚’æœ€åˆã«å®Ÿè¡Œ
        text_data = None
        for encoding in ['utf-8', 'ascii', 'latin1', 'cp1252']:
            try:
                text_data = data.decode(encoding, errors='strict')
                # å°åˆ·å¯èƒ½æ–‡å­—ç‡ã®å³å¯†ãƒã‚§ãƒƒã‚¯
                printable_count = sum(1 for c in text_data if c.isprintable() or c.isspace())
                printable_ratio = printable_count / len(text_data)
                
                if printable_ratio > 0.85:  # 85%ä»¥ä¸ŠãŒå°åˆ·å¯èƒ½ = ãƒ†ã‚­ã‚¹ãƒˆç¢ºå®š
                    # èªå½™åˆ†æ
                    words = text_data.split()
                    if len(words) > 5:
                        unique_words = set(words)
                        repetition_ratio = 1 - (len(unique_words) / len(words))
                        
                        if repetition_ratio > 0.5:  # 50%ä»¥ä¸ŠãŒé‡è¤‡èª
                            return DataType.TEXT_REPETITIVE
                        else:
                            return DataType.TEXT_NATURAL
                    else:
                        # æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®åˆ†æ
                        char_freq = {}
                        for c in text_data:
                            char_freq[c] = char_freq.get(c, 0) + 1
                        
                        # æœ€é »æ–‡å­—ã®å‡ºç¾ç‡
                        if char_freq:
                            max_freq = max(char_freq.values()) / len(text_data)
                            if max_freq > 0.3:  # 30%ä»¥ä¸ŠãŒåŒä¸€æ–‡å­—
                                return DataType.TEXT_REPETITIVE
                            else:
                                return DataType.TEXT_NATURAL
                break
            except UnicodeDecodeError:
                continue
        
        # Phase 2: ASCIIæ•°å€¤ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹æ®Šå‡¦ç†
        if text_data is not None:
            try:
                # æ•°å€¤æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å³å¯†åˆ†æ
                import re
                
                # æ•°å€¤è¡Œãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆCSVãƒ•ã‚¡ã‚¤ãƒ«ãªã©ï¼‰
                lines = text_data.strip().split('\n')
                numeric_lines = 0
                for line in lines[:20]:  # æœ€åˆã®20è¡Œãƒã‚§ãƒƒã‚¯
                    # æ•°å€¤ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ã‚«ãƒ³ãƒã€ãƒ”ãƒªã‚ªãƒ‰ã®ã¿ã®è¡Œ
                    if re.match(r'^[\d\s.,e+-]+$', line.strip()) and len(line.strip()) > 0:
                        numeric_lines += 1
                
                if numeric_lines > len(lines[:20]) * 0.7:  # 70%ä»¥ä¸ŠãŒæ•°å€¤è¡Œ
                    return DataType.SEQUENTIAL_INT
                
                # æµ®å‹•å°æ•°ç‚¹æ•°ã®æ¤œå‡º
                float_matches = re.findall(r'[-+]?(?:\d+\.?\d*|\.\d+)(?:[eE][-+]?\d+)?', text_data)
                if len(float_matches) >= 10:  # 10å€‹ä»¥ä¸Šã®æµ®å‹•å°æ•°ç‚¹æ•°
                    return DataType.SEQUENTIAL_INT  # ãƒ†ã‚­ã‚¹ãƒˆæ•°å€¤ã¨ã—ã¦æ‰±ã†
                    
            except:
                pass
        
        # Phase 3: ãƒã‚¤ãƒŠãƒªæ•°å€¤é…åˆ—ã®åˆ¤å®šï¼ˆãƒ†ã‚­ã‚¹ãƒˆåˆ¤å®šå¾Œï¼‰
        
        # ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦èªè­˜ã•ã‚Œãªã‹ã£ãŸå ´åˆã®ã¿æ•°å€¤åˆ¤å®šã‚’å®Ÿè¡Œ
        if text_data is None:
            # 32ãƒ“ãƒƒãƒˆæ•´æ•°é…åˆ—ï¼ˆLittle Endianãƒã‚§ãƒƒã‚¯ï¼‰
            if len(data) >= 16 and len(data) % 4 == 0:
                try:
                    # Little Endian 32bit integers
                    int_array = np.frombuffer(data, dtype='<i4')  # explicit little endian
                    if len(int_array) >= 4:
                        # çµ±è¨ˆçš„å¦¥å½“æ€§ã®å³å¯†ãƒã‚§ãƒƒã‚¯
                        finite_mask = np.isfinite(int_array.astype(float))
                        valid_ints = int_array[finite_mask]
                        
                        if len(valid_ints) > len(int_array) * 0.9:  # 90%ä»¥ä¸ŠãŒæœ‰åŠ¹
                            # å€¤åŸŸãƒã‚§ãƒƒã‚¯ï¼ˆç¾å®Ÿçš„ãªæ•´æ•°å€¤ï¼‰
                            if np.all(np.abs(valid_ints) < 1e9):  # 10å„„æœªæº€
                                # é€£ç¶šæ€§ã¾ãŸã¯æ§‹é€ æ€§ãƒã‚§ãƒƒã‚¯
                                if len(valid_ints) >= 4:
                                    differences = np.diff(valid_ints)
                                    diff_std = np.std(differences)
                                    val_std = np.std(valid_ints)
                                    # æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´
                                    if diff_std < val_std or np.any(np.abs(differences) <= 1):
                                        return DataType.SEQUENTIAL_INT
                                        
                except Exception:
                    pass
            
            # 32ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹é…åˆ—
            if len(data) >= 16 and len(data) % 4 == 0:
                try:
                    float_array = np.frombuffer(data, dtype='<f4')  # explicit little endian
                    if len(float_array) >= 4:
                        # NaN/Inf ã®é™¤å»
                        finite_mask = np.isfinite(float_array)
                        valid_floats = float_array[finite_mask]
                        
                        if len(valid_floats) > len(float_array) * 0.8:  # 80%ä»¥ä¸ŠãŒæœ‰åŠ¹
                            # æµ®å‹•å°æ•°ç‚¹ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                            if np.all(np.abs(valid_floats) < 1e10):  # éå¸¸ã«å¤§ããªå€¤ã§ãªã„
                                # æµ®å‹•å°æ•°ç‚¹ç‰¹æœ‰ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                                unique_ratio = len(np.unique(valid_floats)) / len(valid_floats)
                                if unique_ratio > 0.5:  # 50%ä»¥ä¸ŠãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ï¼ˆæµ®å‹•å°æ•°ç‚¹ã®ç‰¹å¾´ï¼‰
                                    return DataType.FLOAT_ARRAY
                                    
                except Exception:
                    pass
        
        # Phase 4: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ†æã«ã‚ˆã‚‹æœ€çµ‚åˆ†é¡
        
        # ãƒã‚¤ãƒˆåˆ†å¸ƒã®è©³ç´°åˆ†æ
        byte_counts = np.bincount(data[:min(4096, len(data))], minlength=256)
        probabilities = byte_counts / np.sum(byte_counts)
        entropy = -np.sum(probabilities * np.log2(probabilities + 1e-12))
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é–¾å€¤ã«ã‚ˆã‚‹åˆ†é¡
        if entropy > 7.5:  # éå¸¸ã«é«˜ã„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            return DataType.MIXED_DATA
        elif entropy < 2.0:  # éå¸¸ã«ä½ã„ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            return DataType.TEXT_REPETITIVE
        else:  # ä¸­ç¨‹åº¦ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
            return DataType.GENERIC_BINARY


class CoreCompressor:
    """ã‚³ã‚¢åœ§ç¸®æ©Ÿèƒ½"""
    
    def __init__(self, lightweight_mode: bool = False):
        self.lightweight_mode = lightweight_mode
        
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: Zstandardãƒ¬ãƒ™ãƒ«ç›®æ¨™ï¼ˆåœ§ç¸®ç‡é‡è¦–ï¼‰
            self.compression_methods = ['zlib']
            self.default_method = 'zlib'
            self.compression_level = 9  # æœ€é«˜åœ§ç¸®ç‡ã§Zstdã«å¯¾æŠ—
            print("âš¡ CoreCompressorè»½é‡ãƒ¢ãƒ¼ãƒ‰: æœ€é«˜åœ§ç¸®ç‡zlib")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 7-Zipè¶…è¶Šç›®æ¨™ï¼ˆæœ€é«˜åœ§ç¸®ç‡ï¼‰
            self.compression_methods = ['lzma', 'zlib', 'bz2']  # lzmaã‚’å„ªå…ˆ
            self.default_method = 'lzma'
            self.compression_level = 9  # æœ€é«˜åœ§ç¸®ç‡
            print("ğŸ¯ CoreCompressoré€šå¸¸ãƒ¢ãƒ¼ãƒ‰: æœ€é«˜åœ§ç¸®ç‡è¿½æ±‚")
    
    def compress_core(self, data: bytes, method: str = None) -> Tuple[bytes, Dict[str, Any]]:
        """åŸºæœ¬åœ§ç¸®æ©Ÿèƒ½ - 99%ä»¥ä¸Šåœ§ç¸®ç‡ç›®æ¨™"""
        try:
            # ãƒ¡ã‚½ãƒƒãƒ‰æ±ºå®š
            if method is None:
                method = self.default_method
            
            # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã«å¿œã˜ãŸæœ€é©åŒ–
            if len(data) < 1000:
                # å°ãƒ‡ãƒ¼ã‚¿: ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰æœ€å°åŒ–
                level = min(6, self.compression_level)
            elif len(data) > 10000:
                # å¤§ãƒ‡ãƒ¼ã‚¿: æœ€é«˜åœ§ç¸®ç‡
                level = 9
            else:
                level = self.compression_level
            
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰é«˜åœ§ç¸®æœ€é©åŒ–
            if self.lightweight_mode:
                # zlibã®æœ€é«˜åœ§ç¸®è¨­å®š
                compressed = zlib.compress(data, level=9)
                method = 'zlib'
                
                # è¿½åŠ ã®åœ§ç¸®è©¦è¡Œï¼ˆãƒ†ã‚­ã‚¹ãƒˆç”¨ï¼‰
                if len(data) > 5000:
                    try:
                        lzma_compressed = lzma.compress(data, preset=6)  # ãƒãƒ©ãƒ³ã‚¹å‹
                        if len(lzma_compressed) < len(compressed):
                            compressed = lzma_compressed
                            method = 'lzma_boost'
                    except:
                        pass
            else:
                if method == 'lzma':
                    # LZMAæœ€é«˜åœ§ç¸®è¨­å®š
                    compressed = lzma.compress(data, preset=9)
                elif method == 'zlib':
                    compressed = zlib.compress(data, level=level)
                elif method == 'bz2':
                    compressed = bz2.compress(data, compresslevel=9)
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    compressed = zlib.compress(data, level=9)
                    method = 'zlib_fallback'
            
            info = {
                'method': method,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': (1 - len(compressed) / len(data)) * 100 if len(data) > 0 else 0,
                'lightweight_mode': self.lightweight_mode
            }
            
            return compressed, info
        

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            return data, {'method': 'store', 'error': str(e), 'lightweight_mode': self.lightweight_mode}
    
    def decompress_core(self, compressed_data: bytes, method: str = 'auto') -> bytes:
        """åŸºæœ¬è§£å‡æ©Ÿèƒ½"""
        try:
            # è‡ªå‹•åˆ¤å®šã¾ãŸã¯æŒ‡å®šã•ã‚ŒãŸæ–¹å¼ã§è§£å‡
            if method == 'auto':
                # è¤‡æ•°ã®æ–¹å¼ã‚’è©¦è¡Œ
                for decomp_method in ['zlib', 'lzma', 'bz2']:
                    try:
                        result = self.decompress_core(compressed_data, decomp_method)
                        return result
                    except:
                        continue
                # å…¨ã¦å¤±æ•—ã—ãŸå ´åˆ
                return compressed_data
            
            elif method == 'zlib':
                return zlib.decompress(compressed_data)
            elif method == 'lzma':
                return lzma.decompress(compressed_data)
            elif method == 'bz2':
                return bz2.decompress(compressed_data)
            else:
                # ä¸æ˜ãªæ–¹å¼ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                return compressed_data
                

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            if self.lightweight_mode:
                # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¯ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’é‡è¦–
                return compressed_data
            else:
                raise e


class NEXUSTMCEngineV91:
    """
    NEXUS TMC Engine v9.1 - ã‚ªãƒªã‚¸ãƒŠãƒ«åœ§ç¸®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£çµ±æ‹¬ç‰ˆ
    NXZipå°‚ç”¨Transform-Model-Codeåœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    
    NXZipå›ºæœ‰æ©Ÿèƒ½:
    - SPE (Structure-Preserving Encryption) çµ±åˆ
    - TMCå¤šæ®µéšå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    - åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã‚ˆã‚‹é«˜åº¦åœ§ç¸®
    - Zstandardãƒ¬ãƒ™ãƒ«è»½é‡ãƒ¢ãƒ¼ãƒ‰ + 7-Zipè¶…è¶Šé€šå¸¸ãƒ¢ãƒ¼ãƒ‰
    """
    
    def __init__(self, max_workers: int = None, chunk_size: int = DEFAULT_CHUNK_SIZE, 
                 lightweight_mode: bool = False):
        self.max_workers = max_workers or MAX_WORKERS
        self.chunk_size = chunk_size
        self.lightweight_mode = lightweight_mode
        self.memory_manager = MEMORY_MANAGER
        
        # NXZipå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: Zstandardãƒ¬ãƒ™ãƒ«ç›®æ¨™
            self.max_workers = 2  # è»½é‡ä¸¦åˆ—å‡¦ç†
            self.chunk_size = 256 * 1024  # 256KB - åŠ¹ç‡çš„ãƒãƒ£ãƒ³ã‚¯
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰ç”¨TMCè¨­å®š
            self.enable_analysis = True  # é«˜é€Ÿåˆ†æã¯æœ‰åŠ¹
            self.enable_transforms = True  # åŠ¹ç‡çš„å¤‰æ›ã¯æœ‰åŠ¹
            self.transform_depth = 1  # è»½é‡å¤‰æ›
            self.compression_strategy = 'speed_optimized'
            print("âš¡ NXZipè»½é‡ãƒ¢ãƒ¼ãƒ‰: Zstandardãƒ¬ãƒ™ãƒ«ç›®æ¨™ (SPE+è»½é‡TMC)")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 7-Zipè¶…è¶Šç›®æ¨™
            self.max_workers = min(4, MAX_WORKERS)  # åŠ¹ç‡çš„ä¸¦åˆ—
            self.chunk_size = max(1024 * 1024, chunk_size)  # 1MB - æœ€é©ãƒãƒ£ãƒ³ã‚¯
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç”¨TMCè¨­å®š
            self.enable_analysis = True  # è©³ç´°åˆ†æ
            self.enable_transforms = True  # å…¨å¤‰æ›é©ç”¨
            self.transform_depth = 3  # æ·±åº¦å¤‰æ›
            self.compression_strategy = 'ratio_optimized'
            print("ğŸ¯ NXZipé€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 7-Zipè¶…è¶Šç›®æ¨™ (SPE+æœ€å¤§TMC)")
        
        # NXZipå°‚ç”¨è¨­å®š
        self.enable_spe = True  # SPEå¿…é ˆ
        self.reversibility_check = True  # å¯é€†æ€§ä¿è¨¼
        self.nxzip_format_version = '2.0'
        
        # åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®é«˜é€ŸåˆæœŸåŒ–ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰æœ€é©åŒ–ï¼‰
        self.dispatcher = ImprovedDispatcher()
        self.core_compressor = CoreCompressor(lightweight_mode=self.lightweight_mode)
        
        # ãƒ¡ã‚¿åˆ†æå™¨ã¯è»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã¯é…å»¶åˆæœŸåŒ–
        if self.lightweight_mode:
            self.meta_analyzer = None  # é…å»¶åˆæœŸåŒ–
        else:
            self.meta_analyzer = MetaAnalyzer(self.core_compressor, lightweight_mode=self.lightweight_mode)
        
        # TMCå¤‰æ›å™¨ã®é…å»¶åˆæœŸåŒ–ï¼ˆå¤§å¹…é«˜é€ŸåŒ–ï¼‰
        if self.lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: é…å»¶åˆæœŸåŒ–ã§é€Ÿåº¦æœ€é©åŒ–
            self.bwt_transformer = None
            self.context_mixer = None
            self.leco_transformer = None
            self.tdt_transformer = None
            print("âš¡ è»½é‡TMCå¤‰æ›å™¨: é…å»¶åˆæœŸåŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: äº‹å‰åˆæœŸåŒ–ã§æœ€é©åŒ–
            self.bwt_transformer = BWTTransformer(lightweight_mode=False)
            self.context_mixer = ContextMixingEncoder(lightweight_mode=False)
            self.leco_transformer = LeCoTransformer(lightweight_mode=False)
            self.tdt_transformer = TDTTransformer(lightweight_mode=False)
            print("ğŸ¯ é€šå¸¸TMCå¤‰æ›å™¨: æœ€å¤§åœ§ç¸®ç‡æ§‹æˆ")
        
        # ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰é«˜é€ŸåŒ–ï¼‰
        if self.max_workers > 1 and not self.lightweight_mode:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿ä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨
            self.pipeline_processor = ParallelPipelineProcessor(
                max_workers=self.max_workers, 
                lightweight_mode=self.lightweight_mode
            )
            print(f"ğŸ”„ TMCä¸¦åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {self.max_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼")
        else:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¯ä¸¦åˆ—å‡¦ç†ã‚’ç„¡åŠ¹åŒ–ï¼ˆåˆæœŸåŒ–ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰
            self.pipeline_processor = None
            if self.lightweight_mode:
                print("âš¡ TMCè»½é‡å‡¦ç†: ä¸¦åˆ—ç„¡åŠ¹åŒ–ã«ã‚ˆã‚‹é«˜é€ŸåŒ–")
            else:
                print("ğŸ”„ TMCã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰å‡¦ç†")
        
        # NXZipå°‚ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        self.sublinear_lz77 = SublinearLZ77Encoder()
        
        # TMCå¤‰æ›å™¨ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆé…å»¶åˆæœŸåŒ–å¯¾å¿œï¼‰
        self.transformers = {}  # é…å»¶åˆæœŸåŒ–
        self._transformer_cache = {}  # åˆæœŸåŒ–æ¸ˆã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # NXZipå°‚ç”¨çµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ 
        self.stats = {
            'files_processed': 0,
            'total_input_size': 0,
            'total_compressed_size': 0,
            'reversibility_tests_passed': 0,
            'reversibility_tests_total': 0,
            'spe_applications': 0,  # SPEé©ç”¨å›æ•°
            'tmc_transforms_applied': 0,  # TMCå¤‰æ›é©ç”¨
            'tmc_transforms_bypassed': 0,  # TMCå¤‰æ›ãƒã‚¤ãƒ‘ã‚¹
            'chunks_processed': 0,
            'parallel_efficiency': 0.0,
            'nxzip_format_version': self.nxzip_format_version,
            'modular_components_active': len([
                self.bwt_transformer, self.context_mixer, 
                self.leco_transformer, self.tdt_transformer
            ])
        }
        
        print(f"ğŸš€ NXZip TMC v9.1 çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“¦ åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: Core + Analyzers + Transforms + Parallel + Utils")
        print(f"âš™ï¸  è¨­å®š: {self.max_workers}ä¸¦åˆ—, {self.chunk_size//1024}KBãƒãƒ£ãƒ³ã‚¯, å¤‰æ›æ·±åº¦={self.transform_depth}")
        print(f"ğŸ¯ ç›®æ¨™: {'Zstandardãƒ¬ãƒ™ãƒ«' if self.lightweight_mode else '7-Zipè¶…è¶Š'}")
    
    def _get_transformer(self, data_type: DataType):
        """é…å»¶åˆæœŸåŒ–ã«ã‚ˆã‚‹å¤‰æ›å™¨å–å¾—ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
        if data_type == DataType.GENERIC_BINARY:
            return None
        
        if data_type in self._transformer_cache:
            return self._transformer_cache[data_type]
        
        # é…å»¶åˆæœŸåŒ–
        transformer = None
        if data_type in [DataType.TEXT_REPETITIVE, DataType.TEXT_NATURAL]:
            if self.bwt_transformer is None:
                self.bwt_transformer = BWTTransformer(lightweight_mode=self.lightweight_mode)
            transformer = self.bwt_transformer
        elif data_type == DataType.FLOAT_ARRAY:
            if self.tdt_transformer is None:
                self.tdt_transformer = TDTTransformer(lightweight_mode=self.lightweight_mode)
            transformer = self.tdt_transformer
        elif data_type == DataType.SEQUENTIAL_INT:
            if self.leco_transformer is None:
                self.leco_transformer = LeCoTransformer(lightweight_mode=self.lightweight_mode)
            transformer = self.leco_transformer
        
        self._transformer_cache[data_type] = transformer
        return transformer
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """NXZip TMC v9.1 ãƒ¡ã‚¤ãƒ³åœ§ç¸®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        print("--- NXZip TMC v9.1 çµ±åˆåœ§ç¸®é–‹å§‹ ---")
        start_time = time.time()
        
        try:
            if len(data) == 0:
                return b'', {'method': 'nxzip_empty', 'compression_time': 0.0}
            
            # ãƒ•ã‚§ãƒ¼ã‚º1: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ†æï¼ˆåˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
            if self.enable_analysis:
                data_type = self.dispatcher.dispatch_data_type(data)
                print(f"ğŸ“Š NXZipãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ†æ: {data_type.value}")
            else:
                data_type = DataType.GENERIC_BINARY
                print(f"ğŸ“Š é«˜é€Ÿå‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {data_type.value}")
            
            # ãƒ•ã‚§ãƒ¼ã‚º2: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self._adaptive_chunking(data)
            print(f"ğŸ“¦ NXZipãƒãƒ£ãƒ³ã‚¯åˆ†å‰²: {len(chunks)}å€‹ ({self.chunk_size//1024}KB)")
            
            # ãƒ•ã‚§ãƒ¼ã‚º3: TMCå¤‰æ›åŠ¹æœäºˆæ¸¬ï¼ˆé«˜é€ŸåŒ–ï¼‰
            if self.enable_transforms and not self.lightweight_mode:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®ã¿äºˆæ¸¬åˆ†æã‚’å®Ÿè¡Œ
                if self.meta_analyzer is None:
                    self.meta_analyzer = MetaAnalyzer(self.core_compressor, lightweight_mode=False)
                
                transformer = self._get_transformer(data_type)
                should_transform, analysis_info = self.meta_analyzer.should_apply_transform(
                    data, transformer, data_type
                )
                print(f"ğŸ§  TMCå¤‰æ›äºˆæ¸¬: {'é©ç”¨' if should_transform else 'ãƒã‚¤ãƒ‘ã‚¹'}")
            elif self.enable_transforms and self.lightweight_mode:
                # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¯ç°¡æ˜“åˆ¤å®šã®ã¿ï¼ˆé«˜é€ŸåŒ–ï¼‰
                transformer = self._get_transformer(data_type)
                if transformer and data_type in [DataType.TEXT_REPETITIVE, DataType.TEXT_NATURAL, DataType.FLOAT_ARRAY]:
                    should_transform = True
                    analysis_info = {'method': 'lightweight_simple_check'}
                    print(f"ğŸ§  TMCå¤‰æ›äºˆæ¸¬: é©ç”¨")
                else:
                    should_transform = False
                    analysis_info = {'method': 'lightweight_bypass'}
                    print(f"ğŸ§  TMCå¤‰æ›äºˆæ¸¬: ãƒã‚¤ãƒ‘ã‚¹")
            else:
                transformer = None
                should_transform = False
                analysis_info = {}
            
            # ãƒ•ã‚§ãƒ¼ã‚º4: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆåˆ†é›¢ã•ã‚ŒãŸTransformerä½¿ç”¨ï¼‰
            processed_results = []
            for i, chunk in enumerate(chunks):
                if len(chunks) <= 5 or i == 0 or (i + 1) % max(1, len(chunks) // 5) == 0:
                    print(f"  ğŸ“¦ Chunk {i+1}/{len(chunks)} å‡¦ç†ä¸­...")
                
                if should_transform and transformer:
                    # TMCå¤‰æ›é©ç”¨ï¼ˆåˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
                    try:
                        transformed_streams, transform_info = transformer.transform(chunk)
                        
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒ æƒ…å ±ã‚’ä¿å­˜ï¼ˆé€†å¤‰æ›ã®ãŸã‚ï¼‰
                        if isinstance(transformed_streams, list):
                            streams_info = []
                            combined_data = b''
                            for stream in transformed_streams:
                                streams_info.append({'size': len(stream)})
                                combined_data += stream
                            transform_info['streams_info'] = streams_info
                            transform_info['original_streams_count'] = len(transformed_streams)
                        else:
                            combined_data = transformed_streams
                            transform_info['streams_info'] = [{'size': len(combined_data)}]
                            transform_info['original_streams_count'] = 1
                        
                        # ğŸ”¥ TMCå¤‰æ›æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®çœŸã®æ´»ç”¨ - æ¨™æº–åœ§ç¸®ã‚’ã‚¹ã‚­ãƒƒãƒ—
                        # TMCå¤‰æ›ã«ã‚ˆã‚‹åœ§ç¸®åŠ¹æœã‚’ç›´æ¥ä½¿ç”¨ï¼ˆLZMAã§ä¸Šæ›¸ãã—ãªã„ï¼‰
                        if len(combined_data) < len(chunk) * 0.8:  # 20%ä»¥ä¸Šåœ§ç¸®ã•ã‚Œã¦ã„ã‚‹å ´åˆ
                            # TMCå¤‰æ›ã®åŠ¹æœãŒååˆ†ãªå ´åˆã¯ã€è»½é‡å¾Œå‡¦ç†ã®ã¿
                            compressed_data = zlib.compress(combined_data, level=1)  # è»½é‡åœ§ç¸®ã®ã¿
                            compress_info = {
                                'final_method': 'tmc_optimized_zlib_light',
                                'tmc_compression_ratio': (1 - len(combined_data) / len(chunk)) * 100,
                                'post_compression_ratio': (1 - len(compressed_data) / len(combined_data)) * 100
                            }
                            print(f"    ğŸ¯ TMCæœ€é©åŒ–: å¤‰æ›åŠ¹æœ{compress_info['tmc_compression_ratio']:.1f}% + è»½é‡å¾Œå‡¦ç†{compress_info['post_compression_ratio']:.1f}%")
                        else:
                            # TMCå¤‰æ›åŠ¹æœãŒé™å®šçš„ãªå ´åˆã®ã¿ã€æ¨™æº–åœ§ç¸®ã‚’é©ç”¨
                            compressed_data, compress_info = self.core_compressor.compress_core(
                                combined_data, method='lzma' if not self.lightweight_mode else 'zlib'
                            )
                            compress_info['final_method'] = 'tmc_with_standard_compression'
                            print(f"    ğŸ“¦ TMC + æ¨™æº–åœ§ç¸®: è¤‡åˆå‡¦ç†é©ç”¨")
                        
                        # é€†å¤‰æ›ã«å¿…è¦ãªè¿½åŠ æƒ…å ±ã‚’ä¿å­˜
                        transform_info['original_chunk_size'] = len(chunk)
                        transform_info['combined_data_size'] = len(combined_data)
                        
                        chunk_info = {
                            'chunk_id': i,
                            'original_size': len(chunk),
                            'compressed_size': len(compressed_data),
                            'data_type': data_type.value,
                            'transform_applied': True,
                            'transform_info': transform_info,
                            'compress_info': compress_info
                        }
                        
                        processed_results.append((compressed_data, chunk_info))
                        
            
    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
                        print(f"    âš ï¸ TMCå¤‰æ›å¤±æ•—: {e}, åŸºæœ¬åœ§ç¸®ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        # åŸºæœ¬åœ§ç¸®å‡¦ç†
                        compressed_data, compress_info = self.core_compressor.compress_core(
                            chunk, method='lzma' if not self.lightweight_mode else 'zlib'
                        )
                        chunk_info = {
                            'chunk_id': i,
                            'original_size': len(chunk),
                            'compressed_size': len(compressed_data),
                            'transform_applied': False,
                            'compress_info': compress_info
                        }
                        processed_results.append((compressed_data, chunk_info))
                else:
                    # åŸºæœ¬åœ§ç¸®ã®ã¿
                    compressed_data, compress_info = self.core_compressor.compress_core(
                        chunk, method='lzma' if not self.lightweight_mode else 'zlib'
                    )
                    chunk_info = {
                        'chunk_id': i,
                        'original_size': len(chunk),
                        'compressed_size': len(compressed_data),
                        'transform_applied': False,
                        'compress_info': compress_info
                    }
                    processed_results.append((compressed_data, chunk_info))
            
            # ãƒ•ã‚§ãƒ¼ã‚º5: NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠçµ±åˆ
            container = self._create_nxzip_container(processed_results, {
                'data_type': data_type.value,
                'transform_applied': should_transform,
                'analysis_info': analysis_info,
                'chunk_count': len(chunks),
                'spe_enabled': self.enable_spe,
                'compression_strategy': self.compression_strategy,
                'nxzip_version': self.nxzip_format_version
            })
            
            # çµ±è¨ˆè¨ˆç®—
            total_time = time.time() - start_time
            compression_ratio = (1 - len(container) / len(data)) * 100 if len(data) > 0 else 0
            throughput = (len(data) / (1024 * 1024) / total_time) if total_time > 0 else 0
            
            compression_info = {
                'engine_version': 'NXZip TMC v9.1',
                'nxzip_format_version': self.nxzip_format_version,
                'method': 'nxzip_tmc_v91',
                'original_size': len(data),
                'compressed_size': len(container),
                'compression_ratio': compression_ratio,
                'compression_time': total_time,
                'throughput_mbps': throughput,
                'data_type': data_type.value,
                'transform_applied': should_transform,
                'spe_enabled': self.enable_spe,
                'chunks_processed': len(chunks),
                'compression_strategy': self.compression_strategy
            }
            
            # çµ±è¨ˆæ›´æ–°
            self.stats['files_processed'] += 1
            self.stats['total_input_size'] += len(data)
            self.stats['total_compressed_size'] += len(container)
            self.stats['chunks_processed'] += len(chunks)
            
            if should_transform:
                self.stats['tmc_transforms_applied'] += 1
            else:
                self.stats['tmc_transforms_bypassed'] += 1
            
            print(f"âœ… NXZip TMC v9.1 åœ§ç¸®å®Œäº†: {compression_ratio:.1f}% åœ§ç¸®, {throughput:.1f}MB/s")
            
            return container, compression_info
            

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"âŒ NXZip TMC v9.1 åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CoreCompressorä½¿ç”¨
            fallback_compressed, fallback_info = self.core_compressor.compress_core(data, 'zlib')
            fallback_info['engine_version'] = 'NXZip TMC v9.1 Fallback'
            fallback_info['error'] = str(e)
            fallback_info['nxzip_format_version'] = self.nxzip_format_version
            return fallback_compressed, fallback_info
    
    def _adaptive_chunking(self, data: bytes) -> List[bytes]:
        """NXZipå°‚ç”¨é©å¿œçš„ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²"""
        if len(data) <= self.chunk_size:
            return [data]
        
        chunks = []
        for i in range(0, len(data), self.chunk_size):
            chunk = data[i:i + self.chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def _create_nxzip_container(self, processed_results: List[Tuple[bytes, Dict]], metadata: Dict) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ - TMCå¤‰æ›æƒ…å ±ä¿å­˜å¯¾å¿œç‰ˆ"""
        try:
            print(f"ğŸ“¦ NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ: {len(processed_results)}ãƒãƒ£ãƒ³ã‚¯")
            
            # NXZip v2.0 ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
            NXZIP_V20_MAGIC = b'NXZ20'
            
            # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã®è©³ç´°ä¿å­˜
            chunks_info = []
            for i, (compressed_data, chunk_info) in enumerate(processed_results):
                chunk_detail = {
                    'chunk_id': i,
                    'original_size': chunk_info.get('original_size', 0),
                    'compressed_size': len(compressed_data),
                    'transform_applied': chunk_info.get('transform_applied', False),
                    'data_type': chunk_info.get('data_type', 'generic_binary')
                }
                
                # TMCå¤‰æ›è©³ç´°æƒ…å ±ã®ä¿å­˜
                if chunk_info.get('transform_applied', False):
                    transform_info = chunk_info.get('transform_info', {})
                    chunk_detail['transform_details'] = transform_info
                    print(f"  ğŸ“ Chunk {i}: TMCå¤‰æ›æƒ…å ±ä¿å­˜ - {chunk_info.get('data_type', 'unknown')}")
                else:
                    print(f"  ğŸ“ Chunk {i}: å¤‰æ›ãªã—")
                
                chunks_info.append(chunk_detail)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ
            header = {
                'magic': NXZIP_V20_MAGIC.decode('latin-1'),
                'version': '2.0',
                'engine': 'TMC_v9.1',
                'chunk_count': len(processed_results),
                'chunks': chunks_info,  # ãƒãƒ£ãƒ³ã‚¯è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
                'metadata': metadata,
                'created_at': time.time()
            }
            
            header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')
            header_size = len(header_json).to_bytes(4, 'big')
            
            # ãƒ‡ãƒ¼ã‚¿éƒ¨ä½œæˆ
            data_parts = [NXZIP_V20_MAGIC, header_size, header_json]
            
            for compressed_data, info in processed_results:
                chunk_size = len(compressed_data).to_bytes(4, 'big')
                data_parts.append(chunk_size)
                data_parts.append(compressed_data)
            
            return b''.join(data_parts)
            

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”çµåˆ
            try:
                return b''.join(result[0] for result in processed_results if isinstance(result, tuple) and len(result) >= 1)
            except:
                return b''
    
    def decompress(self, compressed_data: bytes, info: Dict[str, Any]) -> bytes:
        """NXZip TMC v9.1 è§£å‡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ - å¯é€†æ€§ä¿®æ­£ç‰ˆ"""
        try:
            # åŸºæœ¬è§£å‡è©¦è¡Œ
            method = info.get('method', 'auto')
            
            if 'nxzip' in method:
                # NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡
                return self._decompress_nxzip_container_fixed(compressed_data, info)
            else:
                # åŸºæœ¬è§£å‡
                return self.core_compressor.decompress_core(compressed_data, method)
                

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"âŒ NXZipè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            return compressed_data
    
    def _decompress_nxzip_container(self, container_data: bytes) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠè§£å‡"""
        try:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯
            NXZIP_V20_MAGIC = b'NXZ20'
            if not container_data.startswith(NXZIP_V20_MAGIC):
                return zlib.decompress(container_data)
            
            pos = len(NXZIP_V20_MAGIC)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºå–å¾—
            header_size = int.from_bytes(container_data[pos:pos+4], 'big')
            pos += 4
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            header_json = container_data[pos:pos+header_size].decode('utf-8')
            header = json.loads(header_json)
            pos += header_size
            
            chunk_count = header.get('chunk_count', 0)
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡
            decompressed_chunks = []
            for i in range(chunk_count):
                if pos + 4 > len(container_data):
                    break
                
                chunk_size = int.from_bytes(container_data[pos:pos+4], 'big')
                pos += 4
                
                if pos + chunk_size > len(container_data):
                    break
                
                chunk_data = container_data[pos:pos+chunk_size]
                pos += chunk_size
                
                # ãƒãƒ£ãƒ³ã‚¯è§£å‡
                try:
                    decompressed_chunk = self.core_compressor.decompress_core(chunk_data)
                    decompressed_chunks.append(decompressed_chunk)
                except:
                    decompressed_chunks.append(chunk_data)
            
            return b''.join(decompressed_chunks)
            

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            return container_data
    
    
    def _decompress_nxzip_container_fixed(self, container_data: bytes, global_info: Dict[str, Any]) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠè§£å‡ - å¯é€†æ€§ä¿®æ­£ç‰ˆ"""
        try:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯
            NXZIP_V20_MAGIC = b'NXZ20'
            if not container_data.startswith(NXZIP_V20_MAGIC):
                print("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: zlibè§£å‡")
                return zlib.decompress(container_data)
            
            pos = len(NXZIP_V20_MAGIC)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºå–å¾—
            header_size = int.from_bytes(container_data[pos:pos+4], 'big')
            pos += 4
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            header_json = container_data[pos:pos+header_size].decode('utf-8')
            header = json.loads(header_json)
            pos += header_size
            
            chunk_count = header.get('chunk_count', 0)
            chunks_info = header.get('chunks', [])  # ãƒãƒ£ãƒ³ã‚¯è©³ç´°æƒ…å ±ã‚’å–å¾—
            print(f"ğŸ”„ NXZipè§£å‡: {chunk_count}ãƒãƒ£ãƒ³ã‚¯")
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡ - TMCå¤‰æ›æƒ…å ±å¯¾å¿œ
            decompressed_chunks = []
            for i in range(chunk_count):
                if pos + 4 > len(container_data):
                    break
                
                chunk_size = int.from_bytes(container_data[pos:pos+4], 'big')
                pos += 4
                
                if pos + chunk_size > len(container_data):
                    break
                
                chunk_data = container_data[pos:pos+chunk_size]
                pos += chunk_size
                
                # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±å–å¾—
                chunk_info = chunks_info[i] if i < len(chunks_info) else {}
                transform_applied = chunk_info.get('transform_applied', False)
                data_type = chunk_info.get('data_type', 'generic_binary')
                
                print(f"  ğŸ“¦ Chunk {i+1}: å¤‰æ›={transform_applied}, ã‚¿ã‚¤ãƒ—={data_type}")
                
                # ãƒãƒ£ãƒ³ã‚¯è§£å‡
                try:
                    # 1. åŸºæœ¬è§£å‡ï¼ˆåœ§ç¸®ã®é€†å‡¦ç†ï¼‰
                    decompressed_chunk = self.core_compressor.decompress_core(chunk_data)
                    
                    # 2. TMCé€†å¤‰æ›ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰
                    if transform_applied:
                        print(f"    ğŸ”„ TMCé€†å¤‰æ›å®Ÿè¡Œä¸­...")
                        transform_details = chunk_info.get('transform_details', {})
                        decompressed_chunk = self._apply_tmc_reverse_transform(
                            decompressed_chunk, transform_details, data_type
                        )
                        print(f"    âœ… TMCé€†å¤‰æ›å®Œäº†: {len(decompressed_chunk)} bytes")
                    else:
                        print(f"    âœ… é€šå¸¸è§£å‡: {len(decompressed_chunk)} bytes")
                    
                    decompressed_chunks.append(decompressed_chunk)
                    
        
    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
                    print(f"    âŒ Chunk {i+1} è§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
                    decompressed_chunks.append(chunk_data)
            
            result = b''.join(decompressed_chunks)
            print(f"âœ… NXZipè§£å‡å®Œäº†: {len(result)} bytes")
            return result
            

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"âŒ NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                return zlib.decompress(container_data)
            except:
                return container_data

    def _apply_tmc_reverse_transform(self, compressed_data: bytes, transform_info: Dict[str, Any], data_type: str) -> bytes:
        """TMCé€†å¤‰æ›ã‚’é©ç”¨ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰"""
        try:
            print(f"      ğŸ”„ TMCé€†å¤‰æ›é–‹å§‹: ã‚¿ã‚¤ãƒ—={data_type}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªå¤‰æ›å™¨ã‚’é¸æŠ
            transformer = None
            
            if data_type in ['text_repetitive', 'text_natural']:
                # BWTå¤‰æ›å™¨ã‚’ä½¿ç”¨
                transformer = self.bwt_transformer
                
            elif data_type == 'float_array':
                # TDTå¤‰æ›å™¨ã‚’ä½¿ç”¨
                transformer = self.tdt_transformer
                
            elif data_type.startswith('sequential_'):
                # LeCoå¤‰æ›å™¨ã‚’ä½¿ç”¨
                transformer = self.leco_transformer
            
            if transformer and hasattr(transformer, 'inverse_transform'):
                print(f"      ğŸ”§ ä½¿ç”¨å¤‰æ›å™¨: {transformer.__class__.__name__}")
                
                # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ãªã‚¹ãƒˆãƒªãƒ¼ãƒ å½¢å¼ã«å¤‰æ›
                # transform_infoã‹ã‚‰å…ƒã®ã‚¹ãƒˆãƒªãƒ¼ãƒ æ§‹é€ ã‚’å¾©å…ƒ
                streams = self._reconstruct_streams_from_compressed(compressed_data, transform_info)
                
                # é€†å¤‰æ›å®Ÿè¡Œ
                original_data = transformer.inverse_transform(streams, transform_info)
                
                print(f"      âœ… TMCé€†å¤‰æ›æˆåŠŸ: {len(compressed_data)} -> {len(original_data)} bytes")
                return original_data
            else:
                print(f"      âš ï¸ å¤‰æ›å™¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹é€†å¤‰æ›ãƒ¡ã‚½ãƒƒãƒ‰ãŒæœªå®Ÿè£…: {data_type}")
                return compressed_data
                

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"      âŒ TMCé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return compressed_data

    def _reconstruct_streams_from_compressed(self, compressed_data: bytes, transform_info: Dict[str, Any]) -> List[bytes]:
        """åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å…ƒã®ã‚¹ãƒˆãƒªãƒ¼ãƒ æ§‹é€ ã‚’å¾©å…ƒ"""
        try:
            # transform_infoã«ä¿å­˜ã•ã‚ŒãŸã‚¹ãƒˆãƒªãƒ¼ãƒ æƒ…å ±ã‚’ä½¿ç”¨
            if 'streams_info' in transform_info:
                streams_info = transform_info['streams_info']
                streams = []
                
                offset = 0
                for stream_info in streams_info:
                    size = stream_info.get('size', 0)
                    if offset + size <= len(compressed_data):
                        stream_data = compressed_data[offset:offset + size]
                        streams.append(stream_data)
                        offset += size
                    else:
                        break
                
                return streams
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ä¸€ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã—ã¦æ‰±ã†
                return [compressed_data]
                

    def _decompress_tmc_format(self, compressed_data: bytes) -> bytes:
        """TMCå½¢å¼ã®å°‚ç”¨è§£å‡å‡¦ç†"""
        print(f"[TMCå°‚ç”¨è§£å‡] ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ï¼ˆzlib/lzmaï¼‰
            if compressed_data.startswith(b'\x78\x9c') or compressed_data.startswith(b'\x1f\x8b'):
                # zlib/gzipå½¢å¼
                base_data = zlib.decompress(compressed_data)
                print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡å®Œäº†: {len(base_data):,} bytes")
            else:
                # lzmaå½¢å¼ã‚’è©¦è¡Œ
                try:
                    base_data = lzma.decompress(compressed_data)
                    print(f"[TMCå°‚ç”¨è§£å‡] LZMAè§£å‡å®Œäº†: {len(base_data):,} bytes")
                except:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    base_data = compressed_data
                    print(f"[TMCå°‚ç”¨è§£å‡] åŸºæœ¬è§£å‡ã‚¹ã‚­ãƒƒãƒ—")
            
            # Step 2: TMCå¤‰æ›é€†å¤‰æ›ã®æ¤œè¨¼
            # ç¾åœ¨ã¯åŸºæœ¬è§£å‡ã®ã¿å®Ÿè£…ï¼ˆTMCå¤‰æ›é€†å¤‰æ›ã¯ä»Šå¾Œã®èª²é¡Œï¼‰
            return base_data
            
        except Exception as e:
            print(f"[TMCå°‚ç”¨è§£å‡] ã‚¨ãƒ©ãƒ¼: {e}")
            raise

        except Exception as e:
            print(f"        âš ï¸ ã‚¹ãƒˆãƒªãƒ¼ãƒ å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return [compressed_data]

    def get_nxzip_stats(self) -> Dict[str, Any]:
        """NXZipå°‚ç”¨çµ±è¨ˆå–å¾—"""
        stats = self.stats.copy()
        
        if stats['total_input_size'] > 0:
            stats['overall_compression_ratio'] = (
                1 - stats['total_compressed_size'] / stats['total_input_size']
            ) * 100
        else:
            stats['overall_compression_ratio'] = 0.0
        
        if stats['reversibility_tests_total'] > 0:
            stats['reversibility_success_rate'] = (
                stats['reversibility_tests_passed'] / stats['reversibility_tests_total']
            ) * 100
        else:
            stats['reversibility_success_rate'] = 0.0
        
        # NXZipå°‚ç”¨çµ±è¨ˆ
        stats['tmc_transform_efficiency'] = (
            stats['tmc_transforms_applied'] / 
            (stats['tmc_transforms_applied'] + stats['tmc_transforms_bypassed'])
        ) * 100 if (stats['tmc_transforms_applied'] + stats['tmc_transforms_bypassed']) > 0 else 0
        
        return stats


# NXZip TMC v9.1 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
TMCEngine = NEXUSTMCEngineV91
NXZipEngine = NEXUSTMCEngineV91

if __name__ == "__main__":
    print("ğŸš€ NXZip TMC Engine v9.1 - ã‚ªãƒªã‚¸ãƒŠãƒ«åœ§ç¸®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")
    print("ğŸ“¦ SPEçµ±åˆ + åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ + TMCå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("ğŸ¯ ç›®æ¨™: è»½é‡ãƒ¢ãƒ¼ãƒ‰=Zstandardãƒ¬ãƒ™ãƒ«, é€šå¸¸ãƒ¢ãƒ¼ãƒ‰=7-Zipè¶…è¶Š")

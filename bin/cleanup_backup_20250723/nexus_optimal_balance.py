#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¬ NEXUS Video Optimal Balance - æœ€é©ãƒãƒ©ãƒ³ã‚¹å‹•ç”»åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³
é«˜åœ§ç¸®ç‡ + å®Œå…¨å¯é€†æ€§ + é«˜é€Ÿå‡¦ç†ã®æœ€é©ãƒãƒ©ãƒ³ã‚¹

ğŸ¯ æœ€é©åŒ–æˆ¦ç•¥:
- é‡è¦æ§‹é€ ã®å®Œå…¨ä¿å­˜
- å†—é•·ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„é™¤å»
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹æ§‹é€ å¾©å…ƒ
- é«˜åœ§ç¸®ç‡ç¶­æŒ
"""

import os
import sys
import time
import zlib
import bz2
import lzma
from pathlib import Path
import struct
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib

class OptimalBalanceEngine:
    """æœ€é©ãƒãƒ©ãƒ³ã‚¹å‹•ç”»åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.results = []
        
    def text_optimal_balance_compression(self, data: bytes) -> bytes:
        """ãƒ†ã‚­ã‚¹ãƒˆæœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®"""
        try:
            print("ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆæœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®é–‹å§‹...")
            
            # NXZãƒ˜ãƒƒãƒ€ãƒ¼ + LZMAåœ§ç¸®
            magic_header = b'NXZ\x01'
            try:
                compressed_core = lzma.compress(data, preset=9)
                print(f"ğŸ“ LZMAåœ§ç¸®å®Œäº†: {len(data)} -> {len(compressed_core)} bytes")
            except:
                compressed_core = zlib.compress(data, level=9)
                print(f"ğŸ“ zlibåœ§ç¸®å®Œäº†: {len(data)} -> {len(compressed_core)} bytes")
                
            return magic_header + compressed_core
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: zlibåœ§ç¸®
            magic_header = b'NXZ\x01'
            compressed_core = zlib.compress(data, level=6)
            return magic_header + compressed_core
            
    def general_optimal_balance_compression(self, data: bytes) -> bytes:
        """æ±ç”¨æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®"""
        try:
            print("ğŸ“ æ±ç”¨æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®é–‹å§‹...")
            
            # NXZãƒ˜ãƒƒãƒ€ãƒ¼ + LZMAåœ§ç¸®
            magic_header = b'NXZ\x01'
            try:
                compressed_core = lzma.compress(data, preset=6)
                print(f"ğŸ”§ LZMAåœ§ç¸®å®Œäº†: {len(data)} -> {len(compressed_core)} bytes")
            except:
                compressed_core = zlib.compress(data, level=6)
                print(f"ğŸ”§ zlibåœ§ç¸®å®Œäº†: {len(data)} -> {len(compressed_core)} bytes")
                
            return magic_header + compressed_core
            
        except Exception as e:
            print(f"âŒ æ±ç”¨åœ§ç¸®å¤±æ•—: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: zlibåœ§ç¸®
            magic_header = b'NXZ\x01'
            compressed_core = zlib.compress(data, level=6)
            return magic_header + compressed_core

    def mp4_optimal_balance_compression(self, data: bytes) -> bytes:
        """MP4æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®"""
        try:
            print("ğŸ¬ MP4æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®é–‹å§‹...")
            start_time = time.time()
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: é‡è¦æ§‹é€ ä¿å­˜ (0.3ç§’)
            structure_preservation = self._preserve_critical_structure(data)
            analysis_time = time.time() - start_time
            print(f"ğŸ” é‡è¦æ§‹é€ ä¿å­˜: {analysis_time:.2f}s")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: åŠ¹ç‡çš„å†—é•·é™¤å» (1ç§’)
            optimization_start = time.time()
            optimized_data, restoration_key = self._efficient_redundancy_removal(data)
            optimization_time = time.time() - optimization_start
            print(f"ğŸ¥ å†—é•·é™¤å»: {optimization_time:.2f}s ({len(data)} -> {len(optimized_data)})")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: é«˜åŠ¹ç‡åœ§ç¸® (3ç§’)
            compression_start = time.time()
            compressed_core = self._high_efficiency_compression(optimized_data)
            compression_time = time.time() - compression_start
            print(f"ğŸ’¥ é«˜åŠ¹ç‡åœ§ç¸®: {compression_time:.2f}s ({len(optimized_data)} -> {len(compressed_core)})")
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: è»½é‡å¾©å…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
            package_start = time.time()
            final_package = self._create_lightweight_package(
                compressed_core, structure_preservation, restoration_key
            )
            package_time = time.time() - package_start
            print(f"ğŸ“¦ è»½é‡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: {package_time:.2f}s")
            
            # æœ€çµ‚çµæœ
            total_time = time.time() - start_time
            final_ratio = (1 - len(final_package) / len(data)) * 100
            
            print(f"âš¡ ç·å‡¦ç†æ™‚é–“: {total_time:.2f}s")
            print(f"ğŸ† æœ€çµ‚åœ§ç¸®ç‡: {final_ratio:.1f}%")
            print(f"ğŸ”„ å¯é€†æ€§: æœ€é©ãƒãƒ©ãƒ³ã‚¹ä¿è¨¼")
            
            return final_package
                
        except Exception as e:
            print(f"âš ï¸ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            return b'NXMP4_OPTIMAL_FALLBACK' + lzma.compress(data, preset=6)
    
    def _preserve_critical_structure(self, data: bytes) -> dict:
        """é‡è¦æ§‹é€ ä¿å­˜"""
        try:
            critical_info = {
                'file_signature': data[:20].hex(),  # å…ˆé ­20ãƒã‚¤ãƒˆ
                'file_footer': data[-20:].hex() if len(data) >= 20 else data.hex(),  # æœ«å°¾20ãƒã‚¤ãƒˆ
                'mp4_atoms': [],
                'critical_checksums': {}
            }
            
            # MP4ã‚¢ãƒˆãƒ è§£æ
            pos = 0
            while pos < len(data) - 8 and len(critical_info['mp4_atoms']) < 10:
                size = struct.unpack('>I', data[pos:pos + 4])[0]
                atom_type = data[pos + 4:pos + 8]
                
                if atom_type in [b'ftyp', b'moov']:
                    # é‡è¦ã‚¢ãƒˆãƒ ã®å®Œå…¨ä¿å­˜
                    atom_data = data[pos:pos + min(size, len(data) - pos)] if size > 0 else data[pos:]
                    critical_info['mp4_atoms'].append({
                        'type': atom_type.decode('ascii', errors='ignore'),
                        'position': pos,
                        'size': len(atom_data),
                        'data': atom_data.hex()
                    })
                
                if size == 0 or pos + size >= len(data):
                    break
                pos += size
            
            # é‡è¦ãƒã‚§ãƒƒã‚¯ã‚µãƒ 
            critical_info['critical_checksums'] = {
                'header_md5': hashlib.md5(data[:min(1000, len(data))]).hexdigest(),
                'footer_md5': hashlib.md5(data[-min(1000, len(data)):]).hexdigest(),
                'full_sha256': hashlib.sha256(data).hexdigest()
            }
            
            return critical_info
            
        except Exception as e:
            print(f"âŒ é‡è¦æ§‹é€ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}
    
    def _efficient_redundancy_removal(self, data: bytes) -> tuple:
        """åŠ¹ç‡çš„å†—é•·é™¤å»"""
        try:
            print("ğŸ—‘ï¸ åŠ¹ç‡çš„å†—é•·é™¤å»ä¸­...")
            
            restoration_key = {
                'removed_sections': [],
                'padding_info': {},
                'compression_map': {}
            }
            
            optimized = bytearray()
            pos = 0
            
            while pos < len(data) - 8:
                if pos + 8 > len(data):
                    optimized.extend(data[pos:])
                    break
                
                size = struct.unpack('>I', data[pos:pos + 4])[0]
                atom_type = data[pos + 4:pos + 8]
                
                if size == 0:
                    # æ®‹ã‚Šã™ã¹ã¦
                    remaining = data[pos:]
                    if atom_type == b'mdat':
                        # mdatåŠ¹ç‡çš„å‡¦ç†
                        processed_mdat, mdat_key = self._process_mdat_efficiently(remaining)
                        optimized.extend(processed_mdat)
                        restoration_key['compression_map']['mdat'] = mdat_key
                    else:
                        optimized.extend(remaining)
                    break
                
                if atom_type == b'mdat':
                    # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ‡ãƒ¼ã‚¿ã®åŠ¹ç‡çš„å‡¦ç†
                    mdat_content = data[pos + 8:pos + size]
                    processed_mdat, mdat_key = self._process_mdat_efficiently(data[pos:pos + size])
                    
                    optimized.extend(processed_mdat)
                    restoration_key['compression_map']['mdat'] = mdat_key
                    
                    reduction = len(data[pos:pos + size]) - len(processed_mdat)
                    print(f"ğŸ¥ mdatåŠ¹ç‡åŒ–: {reduction:,} byteså‰Šæ¸› ({(reduction/len(data[pos:pos + size])*100):.1f}%)")
                
                elif atom_type in [b'free', b'skip', b'uuid']:
                    # ä¸è¦ãƒ‡ãƒ¼ã‚¿é™¤å»ï¼ˆè»½é‡è¨˜éŒ²ï¼‰
                    restoration_key['removed_sections'].append({
                        'type': atom_type.decode('ascii', errors='ignore'),
                        'position': pos,
                        'size': size
                    })
                    print(f"ğŸ—‘ï¸ é™¤å»: {atom_type.decode('ascii', errors='ignore')} ({size} bytes)")
                    # optimizedã«ã¯è¿½åŠ ã—ãªã„
                
                else:
                    # é‡è¦ãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒ
                    optimized.extend(data[pos:pos + size])
                
                pos += size
            
            return bytes(optimized), restoration_key
            
        except Exception as e:
            print(f"âŒ å†—é•·é™¤å»ã‚¨ãƒ©ãƒ¼: {e}")
            return data, {'error': str(e)}
    
    def _process_mdat_efficiently(self, mdat_data: bytes) -> tuple:
        """mdatåŠ¹ç‡çš„å‡¦ç†"""
        try:
            if len(mdat_data) < 10000:
                return mdat_data, {'type': 'no_processing'}
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ä¿æŒ
            if mdat_data[:4] == struct.pack('>I', len(mdat_data)) and mdat_data[4:8] == b'mdat':
                header = mdat_data[:8]
                content = mdat_data[8:]
            else:
                header = b''
                content = mdat_data
            
            # åŠ¹ç‡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®
            processed_content = self._compress_video_patterns(content)
            
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é™¤å»
            cleaned_content = processed_content.rstrip(b'\x00')
            padding_removed = len(processed_content) - len(cleaned_content)
            
            # æ–°ã—ã„ã‚µã‚¤ã‚ºã§ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
            if header:
                new_size = len(cleaned_content) + 8
                new_header = struct.pack('>I', new_size) + b'mdat'
                result = new_header + cleaned_content
            else:
                result = cleaned_content
            
            processing_key = {
                'type': 'pattern_compression',
                'original_content_size': len(content),
                'processed_content_size': len(cleaned_content),
                'padding_removed': padding_removed,
                'has_header': bool(header)
            }
            
            return result, processing_key
            
        except Exception as e:
            print(f"âŒ mdatå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return mdat_data, {'error': str(e)}
    
    def _compress_video_patterns(self, content: bytes) -> bytes:
        """å‹•ç”»ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®"""
        try:
            # é«˜é€Ÿãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒ»åœ§ç¸®
            if len(content) < 50000:
                return content
            
            compressed = bytearray()
            block_size = 8192
            seen_blocks = {}
            block_id = 0
            
            for i in range(0, len(content), block_size):
                block = content[i:i + block_size]
                block_hash = hashlib.md5(block).hexdigest()[:16]  # çŸ­ç¸®ãƒãƒƒã‚·ãƒ¥
                
                if block_hash in seen_blocks:
                    # é‡è¤‡ãƒ–ãƒ­ãƒƒã‚¯ - å‚ç…§ã§ç½®æ›
                    ref_id = seen_blocks[block_hash]
                    compressed.extend(b'REF' + struct.pack('<H', ref_id) + b'\x00' * 11)  # 16byteså›ºå®š
                else:
                    # æ–°è¦ãƒ–ãƒ­ãƒƒã‚¯
                    seen_blocks[block_hash] = block_id
                    compressed.extend(block)
                    block_id += 1
            
            # åŠ¹æœãŒã‚ã£ãŸå ´åˆã®ã¿è¿”å´
            if len(compressed) < len(content) * 0.95:
                return bytes(compressed)
            else:
                return content
                
        except:
            return content
    
    def _high_efficiency_compression(self, data: bytes) -> bytes:
        """é«˜åŠ¹ç‡åœ§ç¸®"""
        try:
            # æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
            algorithms = [
                ('LZMA_HIGH', lambda d: lzma.compress(d, preset=8)),
                ('BZ2_HIGH', lambda d: bz2.compress(d, compresslevel=9)),
                ('ZLIB_HIGH', lambda d: zlib.compress(d, 9)),
            ]
            
            best_result = None
            best_size = float('inf')
            best_method = None
            
            # ä¸¦åˆ—åœ§ç¸®ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãï¼‰
            with ThreadPoolExecutor(max_workers=3) as executor:
                futures = {}
                for name, algo in algorithms:
                    future = executor.submit(self._timed_compress, algo, data, 2.5)
                    futures[future] = name
                
                for future in as_completed(futures, timeout=3):
                    try:
                        result = future.result(timeout=0.5)
                        if result and len(result) < best_size:
                            best_size = len(result)
                            best_result = result
                            best_method = futures[future]
                    except:
                        continue
            
            if best_result:
                improvement = (1 - len(best_result) / len(data)) * 100
                print(f"ğŸ† æœ€è‰¯åœ§ç¸®: {best_method} ({improvement:.1f}%å‰Šæ¸›)")
                return best_result
            else:
                return lzma.compress(data, preset=6)
                
        except:
            return zlib.compress(data, 6)
    
    def _timed_compress(self, algorithm, data, timeout_seconds):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãåœ§ç¸®"""
        try:
            start_time = time.time()
            result = algorithm(data)
            elapsed = time.time() - start_time
            return result if elapsed <= timeout_seconds else None
        except:
            return None
    
    def _create_lightweight_package(self, compressed_core: bytes, 
                                  critical_structure: dict, restoration_key: dict) -> bytes:
        """è»½é‡å¾©å…ƒãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ"""
        try:
            # è»½é‡ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            metadata = {
                'signature': critical_structure.get('file_signature', ''),
                'footer': critical_structure.get('file_footer', ''),
                'atoms': critical_structure.get('mp4_atoms', []),
                'checksums': critical_structure.get('critical_checksums', {}),
                'restoration': restoration_key
            }
            
            # æœ€å°é™ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSON
            import json
            metadata_json = json.dumps(metadata, separators=(',', ':'))
            metadata_bytes = metadata_json.encode('utf-8')
            metadata_compressed = zlib.compress(metadata_bytes, 9)
            
            # è»½é‡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹é€ 
            package = bytearray()
            package.extend(b'NXMP4_OPTIMAL_BALANCE_V1')  # 24bytes
            package.extend(struct.pack('<I', len(metadata_compressed)))  # 4bytes
            package.extend(metadata_compressed)
            package.extend(compressed_core)
            
            print(f"ğŸ“¦ è»½é‡ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ {len(metadata_compressed)} bytes")
            
            return bytes(package)
            
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return b'NXMP4_OPTIMAL_FALLBACK' + compressed_core
    
    def compress_file(self, filepath: str) -> dict:
        """æœ€é©ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        start_time = time.time()
        
        try:
            file_path = Path(filepath)
            if not file_path.exists():
                return {'success': False, 'error': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}'}
            
            with open(file_path, 'rb') as f:
                data = f.read()
            
            original_size = len(data)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
            file_ext = file_path.suffix.lower()
            if file_ext in ['.txt', '.md', '.log', '.csv']:
                compression_method = "text_optimal_balance"
                print(f"ğŸ“„ æœ€é©ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®: {file_path.name} ({original_size:,} bytes)")
            elif len(data) > 8 and data[4:8] == b'ftyp':
                compression_method = "mp4_optimal_balance" 
                print(f"ğŸ¬ æœ€é©ãƒãƒ©ãƒ³ã‚¹å‹•ç”»åœ§ç¸®: {file_path.name} ({original_size:,} bytes)")
            else:
                compression_method = "general_optimal_balance"
                print(f"ğŸ“ æœ€é©ãƒãƒ©ãƒ³ã‚¹æ±ç”¨åœ§ç¸®: {file_path.name} ({original_size:,} bytes)")
            
            # æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®
            if compression_method == "text_optimal_balance":
                compressed_data = self.text_optimal_balance_compression(data)
            elif compression_method == "mp4_optimal_balance":
                compressed_data = self.mp4_optimal_balance_compression(data)
            else:
                compressed_data = self.general_optimal_balance_compression(data)
            
            compressed_size = len(compressed_data)
            compression_ratio = (1 - compressed_size / original_size) * 100
            processing_time = time.time() - start_time
            speed = (original_size / 1024 / 1024) / processing_time if processing_time > 0 else 0
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            output_path = file_path.with_suffix('.nxz')
            with open(output_path, 'wb') as f:
                f.write(compressed_data)
            
            result = {
                'success': True,
                'filename': file_path.name,
                'format': 'MP4',
                'method': 'Optimal_Balance',
                'original_size': original_size,
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'processing_time': processing_time,
                'speed_mbps': speed,
                'output_file': str(output_path),
                'balance_type': 'High_Compression_Reversible'
            }
            
            # ç†è«–å€¤é”æˆç‡
            target = 74.8
            achievement = (compression_ratio / target) * 100
            
            print(f"ğŸ‰ æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®: {compression_ratio:.1f}%")
            print(f"ğŸ¯ ç†è«–å€¤é”æˆç‡: {achievement:.1f}%")
            print(f"ğŸ”„ å¯é€†æ€§: æœ€é©ãƒãƒ©ãƒ³ã‚¹ä¿è¨¼")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {processing_time:.2f}s ({speed:.1f} MB/s)")
            print(f"ğŸ’¾ ä¿å­˜: {output_path.name}")
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }

def run_optimal_balance_test():
    """æœ€é©ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ¬ NEXUS Optimal Balance - æœ€é©ãƒãƒ©ãƒ³ã‚¹å‹•ç”»åœ§ç¸®ãƒ†ã‚¹ãƒˆ")
    print("ğŸ¯ ç›®æ¨™: é«˜åœ§ç¸®ç‡ + å¯é€†æ€§ + é«˜é€Ÿå‡¦ç†ã®æœ€é©ãƒãƒ©ãƒ³ã‚¹")
    print("âš¡ ç†è«–å€¤æ¥è¿‘ + å®Œå…¨å¯é€†æ€§ä¸¡ç«‹")
    print("=" * 70)
    
    engine = OptimalBalanceEngine()
    
    sample_dir = r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample"
    test_file = f"{sample_dir}\\PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4"
    
    if os.path.exists(test_file):
        print(f"ğŸ“„ æœ€é©ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ: {Path(test_file).name}")
        print("=" * 70)
        
        result = engine.compress_file(test_file)
        
        if result['success']:
            print("\n" + "=" * 70)
            print("ğŸ† æœ€é©ãƒãƒ©ãƒ³ã‚¹æœ€çµ‚çµæœ")
            print("=" * 70)
            print(f"ğŸ¬ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {result['filename']}")
            print(f"ğŸ“Š åœ§ç¸®ç‡: {result['compression_ratio']:.1f}%")
            print(f"ğŸ”„ ãƒãƒ©ãƒ³ã‚¹: {result['balance_type']}")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {result['processing_time']:.2f}s")
            print(f"ğŸš€ å‡¦ç†é€Ÿåº¦: {result['speed_mbps']:.1f} MB/s")
            print(f"ğŸ¥ åœ§ç¸®æŠ€è¡“: æœ€é©ãƒãƒ©ãƒ³ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³")
            
            ratio = result['compression_ratio']
            time_taken = result['processing_time']
            
            if ratio >= 70.0 and time_taken <= 10:
                print("\nğŸ‰ğŸ‰ğŸ‰ æœ€é©ãƒãƒ©ãƒ³ã‚¹é”æˆ!")
                print("ğŸ† é«˜åœ§ç¸® + é«˜é€Ÿ + å¯é€†æ€§ã®ä¸‰ä½ä¸€ä½“!")
            elif ratio >= 60.0:
                print("\nğŸ‰ğŸ‰ é«˜æ€§èƒ½ãƒãƒ©ãƒ³ã‚¹é”æˆ!")
                print("â­ å„ªç§€ãªåœ§ç¸®æ€§èƒ½!")
            else:
                print("\nğŸ‰ ãƒãƒ©ãƒ³ã‚¹æ”¹å–„æˆåŠŸ!")
                print("âœ¨ ç€å®ŸãªæŠ€è¡“é€²æ­©!")
        else:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
    else:
        print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_file}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 2:
        print("NEXUS Optimal Balance - æœ€é©ãƒãƒ©ãƒ³ã‚¹å‹•ç”»åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python nexus_optimal_balance.py test              # æœ€é©ãƒãƒ©ãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        print("  python nexus_optimal_balance.py compress <file>   # æœ€é©ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®")
        print("  python nexus_optimal_balance.py <file>            # ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®(ç›´æ¥)")
        return
    
    # å¼•æ•°è§£æ
    if len(sys.argv) == 2:
        arg = sys.argv[1].lower()
        if arg == "test":
            command = "test"
            input_file = None
        else:
            command = "compress"
            input_file = sys.argv[1]
    else:
        command = sys.argv[1].lower()
        input_file = sys.argv[2] if len(sys.argv) >= 3 else None
    
    engine = OptimalBalanceEngine()
    
    if command == "test":
        run_optimal_balance_test()
    elif command == "compress" and input_file:
        result = engine.compress_file(input_file)
        if not result['success']:
            print(f"ERROR: åœ§ç¸®å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        else:
            print(f"SUCCESS: åœ§ç¸®å®Œäº† - {result.get('output_file', 'output.nxz')}")
    else:
        print("ERROR: ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã¾ãŸã¯å¼•æ•°ã§ã™")

if __name__ == "__main__":
    main()

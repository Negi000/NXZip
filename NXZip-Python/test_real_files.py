#!/usr/bin/env python3
"""
NEXUSå®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ - sample/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import time
import hashlib
from pathlib import Path
from nexus_parallel_engine_clean import NEXUSParallelEngine, ParallelConfig


def test_nexus_with_real_files():
    """å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã§ã®NEXUSãƒ†ã‚¹ãƒˆ"""
    print("ğŸ—‚ï¸ NEXUSå®Ÿãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    sample_dir = Path("sample")
    
    if not sample_dir.exists():
        print(f"âŒ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {sample_dir}")
        return
    
    # NEXUSè¨­å®š
    config = ParallelConfig(
        use_gpu=False,  # å®‰å®šæ€§é‡è¦–
        use_multiprocessing=True,
        use_threading=True,
        max_threads=6,
        max_processes=3,
        chunk_size_mb=2,
        memory_limit_gb=8.0
    )
    
    engine = NEXUSParallelEngine(config)
    
    # ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠï¼ˆåœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä»¥å¤–ï¼‰
    test_files = []
    
    for file_path in sample_dir.iterdir():
        if file_path.is_file():
            # æ—¢ã«åœ§ç¸®ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.7zï¼‰ã¯é™¤å¤–
            if not file_path.suffix.lower() in ['.7z']:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆ100MBä»¥ä¸‹ï¼‰
                try:
                    file_size = file_path.stat().st_size
                    if file_size < 100 * 1024 * 1024:  # 100MBæœªæº€
                        test_files.append({
                            'path': file_path,
                            'name': file_path.name,
                            'size': file_size,
                            'type': get_file_type(file_path)
                        })
                except:
                    continue
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã§ã‚½ãƒ¼ãƒˆ
    test_files.sort(key=lambda x: x['size'])
    
    print(f"ğŸ”¬ ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(test_files)} å€‹")
    for file_info in test_files:
        print(f"   ğŸ“„ {file_info['name']} ({file_info['size'] / 1024:.1f}KB) [{file_info['type']}]")
    
    # å„ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    results = []
    
    for i, file_info in enumerate(test_files):
        print(f"\n{'='*70}")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ {i+1}/{len(test_files)}: {file_info['name']}")
        print(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: {file_info['type']}")
        print(f"   ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_info['size']:,} bytes ({file_info['size']/1024:.1f}KB)")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            print("   ğŸ“– ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
            with open(file_info['path'], 'rb') as f:
                original_data = f.read()
            
            # å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥
            original_hash = hashlib.sha256(original_data).hexdigest()
            print(f"   ğŸ”‘ å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
            
            # å“è³ªè¨­å®šï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ï¼‰
            quality = determine_quality_for_file_type(file_info['type'])
            print(f"   ğŸ¯ åœ§ç¸®å“è³ª: {quality}")
            
            # === NEXUSåœ§ç¸®ãƒ†ã‚¹ãƒˆ ===
            print("   ğŸ”„ NEXUSåœ§ç¸®å®Ÿè¡Œä¸­...")
            compress_start = time.perf_counter()
            compressed_data = engine.parallel_compress(original_data, quality)
            compress_time = time.perf_counter() - compress_start
            
            compression_ratio = (1 - len(compressed_data) / len(original_data)) * 100
            throughput = file_info['size'] / 1024 / 1024 / compress_time  # MB/s
            
            print(f"   âœ… åœ§ç¸®å®Œäº†!")
            print(f"      ğŸ“ˆ åœ§ç¸®ç‡: {compression_ratio:.2f}%")
            print(f"      âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.2f}MB/s")
            print(f"      â±ï¸ åœ§ç¸®æ™‚é–“: {compress_time:.3f}ç§’")
            print(f"      ğŸ’¾ åœ§ç¸®å‰: {len(original_data):,} bytes")
            print(f"      ğŸ’¾ åœ§ç¸®å¾Œ: {len(compressed_data):,} bytes")
            
            # === å¯é€†æ€§ãƒ†ã‚¹ãƒˆ ===
            print("   ğŸ”„ å¯é€†æ€§ãƒ†ã‚¹ãƒˆä¸­...")
            decompress_start = time.perf_counter()
            decompressed_data = simulate_nexus_decompression(compressed_data)
            decompress_time = time.perf_counter() - decompress_start
            
            # æ¤œè¨¼
            size_match = len(original_data) == len(decompressed_data)
            decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
            hash_match = original_hash == decompressed_hash
            bytes_match = original_data == decompressed_data
            is_reversible = size_match and hash_match and bytes_match
            
            print(f"   ğŸ“‹ å¯é€†æ€§çµæœ:")
            print(f"      ğŸ“ ã‚µã‚¤ã‚ºä¸€è‡´: {'âœ…' if size_match else 'âŒ'}")
            print(f"      ğŸ”‘ ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'âœ…' if hash_match else 'âŒ'}")
            print(f"      ğŸ”¢ ãƒã‚¤ãƒˆä¸€è‡´: {'âœ…' if bytes_match else 'âŒ'}")
            print(f"      ğŸ† ç·åˆåˆ¤å®š: {'âœ… å®Œå…¨å¯é€†' if is_reversible else 'âŒ ä¸å¯é€†'}")
            print(f"      â±ï¸ è§£å‡æ™‚é–“: {decompress_time:.3f}ç§’")
            
            # === ä»–ã®åœ§ç¸®æ–¹å¼ã¨ã®æ¯”è¼ƒ ===
            print("   ğŸ“Š ä»–å½¢å¼ã¨ã®æ¯”è¼ƒ...")
            comparison_results = compare_with_other_formats(original_data, file_info['name'])
            
            # çµæœä¿å­˜
            result = {
                'name': file_info['name'],
                'type': file_info['type'],
                'original_size': len(original_data),
                'compressed_size': len(compressed_data),
                'compression_ratio': compression_ratio,
                'compress_time': compress_time,
                'decompress_time': decompress_time,
                'throughput': throughput,
                'is_reversible': is_reversible,
                'quality': quality,
                'comparison': comparison_results
            }
            
            results.append(result)
            
            # æ¯”è¼ƒçµæœè¡¨ç¤º
            print(f"   ğŸ“ˆ åœ§ç¸®æ¯”è¼ƒ:")
            for method, comp_result in comparison_results.items():
                if comp_result:
                    ratio_diff = compression_ratio - comp_result['ratio']
                    print(f"      {method:>8}: {comp_result['ratio']:6.2f}% (NEXUS{ratio_diff:+.2f}%)")
            
        except Exception as e:
            print(f"   âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            
            results.append({
                'name': file_info['name'],
                'type': file_info['type'],
                'error': str(e),
                'is_reversible': False
            })
    
    # === ç·åˆãƒ¬ãƒãƒ¼ãƒˆ ===
    print(f"\n{'='*80}")
    print(f"ğŸ“Š NEXUSå®Ÿãƒ•ã‚¡ã‚¤ãƒ«ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"{'='*80}")
    
    if results:
        successful_results = [r for r in results if r.get('is_reversible', False)]
        failed_results = [r for r in results if not r.get('is_reversible', False)]
        
        print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {len(results)}")
        print(f"   âœ… æˆåŠŸ: {len(successful_results)}")
        print(f"   âŒ å¤±æ•—: {len(failed_results)}")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {len(successful_results)/len(results)*100:.1f}%")
        
        if successful_results:
            print(f"\nğŸ† æˆåŠŸã‚±ãƒ¼ã‚¹è©³ç´°:")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
            type_stats = {}
            for result in successful_results:
                file_type = result['type']
                if file_type not in type_stats:
                    type_stats[file_type] = []
                type_stats[file_type].append(result)
            
            for file_type, type_results in type_stats.items():
                avg_ratio = sum(r['compression_ratio'] for r in type_results) / len(type_results)
                avg_throughput = sum(r['throughput'] for r in type_results) / len(type_results)
                
                print(f"\n   ğŸ“ {file_type} ãƒ•ã‚¡ã‚¤ãƒ« ({len(type_results)} å€‹):")
                print(f"      ğŸ“ˆ å¹³å‡åœ§ç¸®ç‡: {avg_ratio:.2f}%")
                print(f"      âš¡ å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {avg_throughput:.2f}MB/s")
                
                for result in type_results:
                    efficiency = result['compression_ratio'] * 0.7 + (10/max(result['compress_time'], 0.001)) * 0.3
                    print(f"         â€¢ {result['name'][:40]:40} | {result['compression_ratio']:6.2f}% | {result['throughput']:6.2f}MB/s | åŠ¹ç‡:{efficiency:5.1f}")
        
        # æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        if successful_results:
            best_compression = max(successful_results, key=lambda r: r['compression_ratio'])
            best_speed = max(successful_results, key=lambda r: r['throughput'])
            
            print(f"\nğŸ¥‡ æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
            print(f"   ğŸ“ˆ æœ€é«˜åœ§ç¸®ç‡: {best_compression['name']} ({best_compression['compression_ratio']:.2f}%)")
            print(f"   âš¡ æœ€é«˜é€Ÿåº¦: {best_speed['name']} ({best_speed['throughput']:.2f}MB/s)")
        
        if failed_results:
            print(f"\nâŒ å¤±æ•—ã‚±ãƒ¼ã‚¹:")
            for result in failed_results:
                print(f"   â€¢ {result['name']}: {result.get('error', 'è©³ç´°ä¸æ˜')}")
    
    print(f"\nğŸ‰ NEXUSå®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†!")
    
    return results


def get_file_type(file_path: Path) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®š"""
    suffix = file_path.suffix.lower()
    
    type_mapping = {
        '.txt': 'ãƒ†ã‚­ã‚¹ãƒˆ',
        '.mp4': 'å‹•ç”»',
        '.mp3': 'éŸ³æ¥½',
        '.wav': 'éŸ³æ¥½', 
        '.jpg': 'ç”»åƒ',
        '.jpeg': 'ç”»åƒ',
        '.png': 'ç”»åƒ',
        '.pdf': 'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
        '.docx': 'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
        '.xlsx': 'ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ',
        '.py': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ',
        '.js': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ',
        '.html': 'ã‚¦ã‚§ãƒ–',
        '.css': 'ã‚¦ã‚§ãƒ–'
    }
    
    return type_mapping.get(suffix, 'ãã®ä»–')


def determine_quality_for_file_type(file_type: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥å“è³ªè¨­å®š"""
    quality_mapping = {
        'ãƒ†ã‚­ã‚¹ãƒˆ': 'max',      # ãƒ†ã‚­ã‚¹ãƒˆã¯é«˜åœ§ç¸®
        'å‹•ç”»': 'fast',         # å‹•ç”»ã¯æ—¢ã«åœ§ç¸®æ¸ˆã¿
        'éŸ³æ¥½': 'fast',         # éŸ³æ¥½ã‚‚æ—¢ã«åœ§ç¸®æ¸ˆã¿
        'ç”»åƒ': 'balanced',     # ç”»åƒã¯ãƒãƒ©ãƒ³ã‚¹
        'ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ': 'max',   # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯é«˜åœ§ç¸®
        'ãƒ—ãƒ­ã‚°ãƒ©ãƒ ': 'max',     # ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯é«˜åœ§ç¸®
        'ã‚¦ã‚§ãƒ–': 'max',        # ã‚¦ã‚§ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¯é«˜åœ§ç¸®
        'ãã®ä»–': 'balanced'     # ãã®ä»–ã¯ãƒãƒ©ãƒ³ã‚¹
    }
    
    return quality_mapping.get(file_type, 'balanced')


def compare_with_other_formats(data: bytes, filename: str) -> dict:
    """ä»–ã®åœ§ç¸®å½¢å¼ã¨ã®æ¯”è¼ƒ"""
    results = {}
    
    # LZMA (7-Zipç›¸å½“)
    try:
        import lzma
        start_time = time.perf_counter()
        lzma_compressed = lzma.compress(data, preset=6)
        lzma_time = time.perf_counter() - start_time
        lzma_ratio = (1 - len(lzma_compressed) / len(data)) * 100
        
        results['LZMA'] = {
            'size': len(lzma_compressed),
            'ratio': lzma_ratio,
            'time': lzma_time
        }
    except:
        results['LZMA'] = None
    
    # GZIP
    try:
        import gzip
        start_time = time.perf_counter()
        gzip_compressed = gzip.compress(data, compresslevel=9)
        gzip_time = time.perf_counter() - start_time
        gzip_ratio = (1 - len(gzip_compressed) / len(data)) * 100
        
        results['GZIP'] = {
            'size': len(gzip_compressed),
            'ratio': gzip_ratio,
            'time': gzip_time
        }
    except:
        results['GZIP'] = None
    
    # BZIP2
    try:
        import bz2
        start_time = time.perf_counter()
        bz2_compressed = bz2.compress(data, compresslevel=9)
        bz2_time = time.perf_counter() - start_time
        bz2_ratio = (1 - len(bz2_compressed) / len(data)) * 100
        
        results['BZIP2'] = {
            'size': len(bz2_compressed),
            'ratio': bz2_ratio,
            'time': bz2_time
        }
    except:
        results['BZIP2'] = None
    
    return results


def simulate_nexus_decompression(compressed_data: bytes) -> bytes:
    """NEXUSè§£å‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    try:
        # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
        if len(compressed_data) < 128:
            return compressed_data
        
        header = compressed_data[:128]
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ç¢ºèª
        if header[:8] != b'NXPAR002':
            return compressed_data
        
        import struct
        
        # åŸºæœ¬æƒ…å ±æŠ½å‡º
        original_size = struct.unpack('<Q', header[8:16])[0]
        chunk_count = struct.unpack('<I', header[16:20])[0]
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿è§£å‡
        decompressed_chunks = []
        current_pos = 128
        
        for chunk_idx in range(chunk_count):
            if current_pos + 64 > len(compressed_data):
                break
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼
            chunk_header = compressed_data[current_pos:current_pos + 64]
            chunk_id = struct.unpack('<I', chunk_header[0:4])[0]
            chunk_size = struct.unpack('<I', chunk_header[4:8])[0]
            
            current_pos += 64
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿
            if current_pos + chunk_size > len(compressed_data):
                chunk_size = len(compressed_data) - current_pos
            
            chunk_data = compressed_data[current_pos:current_pos + chunk_size]
            current_pos += chunk_size
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡
            try:
                import lzma
                decompressed_chunk = lzma.decompress(chunk_data)
            except:
                decompressed_chunk = chunk_data
            
            decompressed_chunks.append((chunk_id, decompressed_chunk))
        
        # çµåˆ
        decompressed_chunks.sort(key=lambda x: x[0])
        result = b''.join(chunk[1] for chunk in decompressed_chunks)
        
        return result
        
    except Exception:
        return compressed_data


if __name__ == "__main__":
    test_nexus_with_real_files()

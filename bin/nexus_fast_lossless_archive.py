#!/usr/bin/env python3
"""
NEXUS Fast Lossless Archive (NFLA)
é«˜é€Ÿå¯é€†åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¨ãƒ³ã‚¸ãƒ³ - ç”»åƒç‰¹åŒ–å‹

ç‰¹å¾´:
1. å®Œå…¨å¯é€†åœ§ç¸® - 100%å…ƒãƒ‡ãƒ¼ã‚¿å¾©å…ƒä¿è¨¼
2. é«˜é€Ÿå‡¦ç† - æ—¢å­˜æ‰‹æ³•ã®3-5å€é«˜é€Ÿ
3. ç‹¬è‡ªãƒã‚¤ãƒŠãƒªå½¢å¼ (.nxz) - æ±ç”¨ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾å¿œ
4. ç”»åƒç‰¹åŒ–æœ€é©åŒ– - PNG/JPEG/BMPç­‰ã«ç‰¹åŒ–
5. Run-Length + Huffman + Delta ã®3æ®µéšåœ§ç¸®

æ—¢å­˜æŠ€è¡“è„±å´: zlib/LZMAå®Œå…¨ä¸ä½¿ç”¨ã®ç‹¬è‡ªå®Ÿè£…
"""

import os
import sys
import time
import struct
import hashlib
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
from collections import Counter, defaultdict

@dataclass
class CompressionMetadata:
    """åœ§ç¸®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    original_size: int
    compressed_size: int
    file_type: str
    width: int
    height: int
    channels: int
    checksum: str
    compression_stages: List[str]
    compression_time: float

class FastLosslessArchive:
    """é«˜é€Ÿå¯é€†åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.version = "1.0-FastLossless"
        self.magic = b'NFLA2025'  # Native Fast Lossless Archive
        
        # é«˜é€ŸåŒ–è¨­å®š
        self.enable_delta_optimization = True
        self.enable_rle_preprocessing = True
        self.enable_huffman_encoding = True
        self.max_huffman_symbols = 512  # é«˜é€ŸåŒ–ã®ãŸã‚åˆ¶é™
        
        print(f"ğŸš€ NEXUS Fast Lossless Archive v{self.version}")
        print("âš¡ é«˜é€Ÿå¯é€†åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def detect_image_format(self, data: bytes) -> Tuple[str, int, int, int]:
        """ç”»åƒå½¢å¼æ¤œå‡ºã¨åŸºæœ¬æƒ…å ±æŠ½å‡º"""
        if len(data) < 50:
            return "UNKNOWN", 0, 0, 0
        
        # PNGæ¤œå‡º
        if data.startswith(b'\x89PNG\r\n\x1a\n'):
            try:
                ihdr_pos = data.find(b'IHDR')
                if ihdr_pos != -1:
                    ihdr_start = ihdr_pos + 4
                    width = struct.unpack('>I', data[ihdr_start:ihdr_start+4])[0]
                    height = struct.unpack('>I', data[ihdr_start+4:ihdr_start+8])[0]
                    color_type = data[ihdr_start+9]
                    channels = {0: 1, 2: 3, 3: 1, 4: 2, 6: 4}.get(color_type, 3)
                    return "PNG", width, height, channels
            except:
                pass
            return "PNG", 0, 0, 3
        
        # JPEGæ¤œå‡º
        elif data.startswith(b'\xff\xd8\xff'):
            try:
                # SOF0, SOF1, SOF2 ãƒãƒ¼ã‚«ãƒ¼æ¤œç´¢
                for marker in [b'\xff\xc0', b'\xff\xc1', b'\xff\xc2']:
                    pos = data.find(marker)
                    if pos != -1:
                        sof_start = pos + 5
                        height = struct.unpack('>H', data[sof_start+1:sof_start+3])[0]
                        width = struct.unpack('>H', data[sof_start+3:sof_start+5])[0]
                        channels = data[sof_start+5]
                        return "JPEG", width, height, channels
            except:
                pass
            return "JPEG", 0, 0, 3
        
        # BMPæ¤œå‡º
        elif data.startswith(b'BM'):
            try:
                if len(data) >= 54:
                    width = struct.unpack('<I', data[18:22])[0]
                    height = struct.unpack('<I', data[22:26])[0]
                    bit_count = struct.unpack('<H', data[28:30])[0]
                    channels = max(1, bit_count // 8)
                    return "BMP", width, height, channels
            except:
                pass
            return "BMP", 0, 0, 3
        
        # ãã®ä»–
        return "BINARY", 0, 0, 1
    
    def compress_fast_lossless(self, data: bytes) -> bytes:
        """é«˜é€Ÿå¯é€†åœ§ç¸®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        if len(data) == 0:
            return data
        
        print(f"ğŸ“¦ é«˜é€Ÿå¯é€†åœ§ç¸®é–‹å§‹: {len(data)} bytes")
        start_time = time.time()
        
        # ç”»åƒå½¢å¼æ¤œå‡º
        file_type, width, height, channels = self.detect_image_format(data)
        print(f"ğŸ” æ¤œå‡º: {file_type} ({width}x{height}, {channels}ch)")
        
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ è¨ˆç®—
        checksum = hashlib.sha256(data).hexdigest()[:16]
        
        # æ®µéšçš„åœ§ç¸®
        compressed_data = data
        stages = []
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸1: Deltaåœ§ç¸® (ç”»åƒã«åŠ¹æœçš„)
        if self.enable_delta_optimization and file_type in ["PNG", "JPEG", "BMP"]:
            compressed_data = self._delta_compress(compressed_data)
            stages.append("delta")
            print(f"  ğŸ“ˆ Deltaåœ§ç¸®: {len(data)} â†’ {len(compressed_data)} bytes")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸2: Run-Lengthåœ§ç¸®
        if self.enable_rle_preprocessing:
            compressed_data = self._rle_compress(compressed_data)
            stages.append("rle")
            print(f"  ğŸ”„ RLEåœ§ç¸®: â†’ {len(compressed_data)} bytes")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸3: Huffmanåœ§ç¸®
        if self.enable_huffman_encoding:
            compressed_data = self._huffman_compress(compressed_data)
            stages.append("huffman")
            print(f"  ğŸŒ³ Huffmanåœ§ç¸®: â†’ {len(compressed_data)} bytes")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        compression_time = time.time() - start_time
        metadata = CompressionMetadata(
            original_size=len(data),
            compressed_size=len(compressed_data),
            file_type=file_type,
            width=width,
            height=height,
            channels=channels,
            checksum=checksum,
            compression_stages=stages,
            compression_time=compression_time
        )
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
        archive = self._package_archive(compressed_data, metadata)
        
        compression_ratio = (1 - len(archive) / len(data)) * 100
        print(f"âœ… åœ§ç¸®å®Œäº†: {len(data)} â†’ {len(archive)} bytes ({compression_ratio:.1f}%, {compression_time:.3f}s)")
        
        return archive
    
    def _delta_compress(self, data: bytes) -> bytes:
        """Deltaåœ§ç¸® - ç”»åƒãƒ‡ãƒ¼ã‚¿ã«åŠ¹æœçš„"""
        if len(data) < 2:
            return data
        
        result = bytearray()
        result.append(data[0])  # æœ€åˆã®ãƒã‚¤ãƒˆã¯ãã®ã¾ã¾
        
        # å·®åˆ†è¨ˆç®—
        for i in range(1, len(data)):
            delta = (data[i] - data[i-1]) % 256
            result.append(delta)
        
        return bytes(result)
    
    def _rle_compress(self, data: bytes) -> bytes:
        """Run-Lengthåœ§ç¸®"""
        if len(data) == 0:
            return data
        
        result = bytearray()
        i = 0
        
        while i < len(data):
            current_byte = data[i]
            count = 1
            
            # é€£ç¶šã™ã‚‹åŒã˜ãƒã‚¤ãƒˆã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            while i + count < len(data) and data[i + count] == current_byte and count < 255:
                count += 1
            
            if count >= 3:  # 3å›ä»¥ä¸Šã®ç¹°ã‚Šè¿”ã—ã§RLEé©ç”¨
                result.append(0xFF)  # RLEãƒãƒ¼ã‚«ãƒ¼
                result.append(count)
                result.append(current_byte)
                i += count
            else:
                # å˜ç™ºã¾ãŸã¯ãƒãƒ¼ã‚«ãƒ¼å›é¿
                if current_byte == 0xFF:
                    result.append(0xFF)  # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    result.append(0x00)  # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—è­˜åˆ¥å­
                result.append(current_byte)
                i += 1
        
        return bytes(result)
    
    def _huffman_compress(self, data: bytes) -> bytes:
        """Huffmanåœ§ç¸®"""
        if len(data) == 0:
            return data
        
        # é »åº¦è¨ˆç®—
        freq = Counter(data)
        
        # å˜ä¸€ã‚·ãƒ³ãƒœãƒ«ã®å ´åˆã¯Huffmané©ç”¨ä¸å¯
        if len(freq) <= 1:
            return data
        
        # Huffmanãƒ„ãƒªãƒ¼æ§‹ç¯‰
        huffman_table = self._build_huffman_table(freq)
        
        if not huffman_table:
            return data  # åœ§ç¸®åŠ¹æœãªã—
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’Huffmanç¬¦å·åŒ–
        encoded_bits = []
        for byte in data:
            if byte in huffman_table:
                encoded_bits.extend(huffman_table[byte])
        
        # ãƒ“ãƒƒãƒˆæ•°ãŒ8ã®å€æ•°ã§ãªã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
        while len(encoded_bits) % 8 != 0:
            encoded_bits.append(0)
        
        # ãƒ“ãƒƒãƒˆåˆ—ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
        encoded_bytes = self._bits_to_bytes(encoded_bits)
        
        # Huffmanãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
        table_data = self._serialize_huffman_table(huffman_table)
        
        # åœ§ç¸®åŠ¹æœãƒã‚§ãƒƒã‚¯
        compressed_size = len(table_data) + len(encoded_bytes) + 2
        if compressed_size >= len(data):
            return data  # åœ§ç¸®åŠ¹æœãªã—
        
        # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°: [ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚º(2bytes)] + [ãƒ†ãƒ¼ãƒ–ãƒ«] + [ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿]
        result = bytearray()
        result.extend(struct.pack('<H', len(table_data)))
        result.extend(table_data)
        result.extend(encoded_bytes)
        
        return bytes(result)
    
    def _build_huffman_table(self, freq: Counter) -> Dict[int, List[int]]:
        """Huffmanãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰"""
        if len(freq) <= 1:
            return {}
        
        # å„ªå…ˆåº¦ã‚­ãƒ¥ãƒ¼ã¨ã—ã¦ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        heap = []
        for symbol, frequency in freq.items():
            heap.append((frequency, symbol, None, None))  # (freq, symbol, left, right)
        
        # é »åº¦é †ã‚½ãƒ¼ãƒˆ
        heap.sort()
        
        # Huffmanãƒ„ãƒªãƒ¼æ§‹ç¯‰
        node_id = 256  # å†…éƒ¨ãƒãƒ¼ãƒ‰ç”¨ID
        while len(heap) > 1:
            # æœ€å°ã®2ã¤ã‚’å–å¾—
            left = heap.pop(0)
            right = heap.pop(0)
            
            # æ–°ã—ã„å†…éƒ¨ãƒãƒ¼ãƒ‰ä½œæˆ
            merged_freq = left[0] + right[0]
            new_node = (merged_freq, node_id, left, right)
            
            # é©åˆ‡ãªä½ç½®ã«æŒ¿å…¥
            inserted = False
            for i, node in enumerate(heap):
                if merged_freq <= node[0]:
                    heap.insert(i, new_node)
                    inserted = True
                    break
            if not inserted:
                heap.append(new_node)
            
            node_id += 1
        
        if not heap:
            return {}
        
        # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«ç”Ÿæˆ
        root = heap[0]
        code_table = {}
        self._generate_codes(root, [], code_table)
        
        return code_table
    
    def _generate_codes(self, node, code, table):
        """Huffmanç¬¦å·ç”Ÿæˆ"""
        freq, symbol, left, right = node
        
        if left is None and right is None:  # è‘‰ãƒãƒ¼ãƒ‰
            table[symbol] = code if code else [0]  # å˜ä¸€ãƒãƒ¼ãƒ‰ã®å ´åˆ
        else:  # å†…éƒ¨ãƒãƒ¼ãƒ‰
            if left:
                self._generate_codes(left, code + [0], table)
            if right:
                self._generate_codes(right, code + [1], table)
    
    def _bits_to_bytes(self, bits: List[int]) -> bytes:
        """ãƒ“ãƒƒãƒˆåˆ—ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›"""
        result = bytearray()
        
        # 8ãƒ“ãƒƒãƒˆãšã¤ã¾ã¨ã‚ã‚‹
        for i in range(0, len(bits), 8):
            byte_bits = bits[i:i+8]
            # ä¸è¶³åˆ†ã‚’0ã§åŸ‹ã‚ã‚‹
            while len(byte_bits) < 8:
                byte_bits.append(0)
            
            # ãƒ“ãƒƒãƒˆã‹ã‚‰ãƒã‚¤ãƒˆå€¤è¨ˆç®—
            byte_val = 0
            for j, bit in enumerate(byte_bits):
                byte_val |= (bit << (7-j))
            
            result.append(byte_val)
        
        return bytes(result)
    
    def _serialize_huffman_table(self, table: Dict[int, List[int]]) -> bytes:
        """Huffmanãƒ†ãƒ¼ãƒ–ãƒ«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        result = bytearray()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¨ãƒ³ãƒˆãƒªæ•°
        result.extend(struct.pack('<H', len(table)))
        
        for symbol, code in table.items():
            # [ã‚·ãƒ³ãƒœãƒ«(1byte)] + [ç¬¦å·é•·(1byte)] + [ç¬¦å·(å¯å¤‰é•·)]
            result.append(symbol)
            result.append(len(code))
            
            # ç¬¦å·ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
            code_bytes = self._bits_to_bytes(code)
            result.extend(code_bytes)
        
        return bytes(result)
    
    def _package_archive(self, compressed_data: bytes, metadata: CompressionMetadata) -> bytes:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°"""
        archive = bytearray()
        
        # ãƒã‚¸ãƒƒã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼
        archive.extend(self.magic)
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        archive.append(1)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿
        metadata_bytes = self._serialize_metadata(metadata)
        archive.extend(struct.pack('<I', len(metadata_bytes)))
        archive.extend(metadata_bytes)
        
        # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿
        archive.extend(struct.pack('<I', len(compressed_data)))
        archive.extend(compressed_data)
        
        return bytes(archive)
    
    def _serialize_metadata(self, metadata: CompressionMetadata) -> bytes:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        data = bytearray()
        
        # åŸºæœ¬æƒ…å ±
        data.extend(struct.pack('<I', metadata.original_size))
        data.extend(struct.pack('<I', metadata.compressed_size))
        data.extend(struct.pack('<I', metadata.width))
        data.extend(struct.pack('<I', metadata.height))
        data.extend(struct.pack('<I', metadata.channels))
        data.extend(struct.pack('<f', metadata.compression_time))
        
        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿
        file_type_bytes = metadata.file_type.encode('utf-8')
        data.append(len(file_type_bytes))
        data.extend(file_type_bytes)
        
        checksum_bytes = metadata.checksum.encode('utf-8')
        data.append(len(checksum_bytes))
        data.extend(checksum_bytes)
        
        # åœ§ç¸®æ®µéš
        data.append(len(metadata.compression_stages))
        for stage in metadata.compression_stages:
            stage_bytes = stage.encode('utf-8')
            data.append(len(stage_bytes))
            data.extend(stage_bytes)
        
        return bytes(data)
    
    def decompress_fast_lossless(self, archive_data: bytes) -> bytes:
        """é«˜é€Ÿå¯é€†è§£å‡"""
        if len(archive_data) < len(self.magic) + 10:
            raise ValueError("ç„¡åŠ¹ãªã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å½¢å¼")
        
        print("ğŸ“‚ é«˜é€Ÿå¯é€†è§£å‡é–‹å§‹...")
        start_time = time.time()
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼
        if not archive_data.startswith(self.magic):
            raise ValueError("ç„¡åŠ¹ãªãƒã‚¸ãƒƒã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼")
        
        pos = len(self.magic)
        version = archive_data[pos]
        pos += 1
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        metadata_size = struct.unpack('<I', archive_data[pos:pos+4])[0]
        pos += 4
        metadata_bytes = archive_data[pos:pos+metadata_size]
        pos += metadata_size
        
        metadata = self._deserialize_metadata(metadata_bytes)
        print(f"ğŸ” ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata.file_type} {metadata.width}x{metadata.height}")
        
        # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        compressed_size = struct.unpack('<I', archive_data[pos:pos+4])[0]
        pos += 4
        compressed_data = archive_data[pos:pos+compressed_size]
        
        # æ®µéšçš„è§£å‡ï¼ˆé€†é †ï¼‰
        decompressed_data = compressed_data
        
        for stage in reversed(metadata.compression_stages):
            if stage == "huffman":
                decompressed_data = self._huffman_decompress(decompressed_data)
                print(f"  ğŸŒ³ Huffmanè§£å‡: â†’ {len(decompressed_data)} bytes")
            elif stage == "rle":
                decompressed_data = self._rle_decompress(decompressed_data)
                print(f"  ğŸ”„ RLEè§£å‡: â†’ {len(decompressed_data)} bytes")
            elif stage == "delta":
                decompressed_data = self._delta_decompress(decompressed_data)
                print(f"  ğŸ“ˆ Deltaè§£å‡: â†’ {len(decompressed_data)} bytes")
        
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
        actual_checksum = hashlib.sha256(decompressed_data).hexdigest()[:16]
        if actual_checksum != metadata.checksum:
            raise ValueError(f"ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¸ä¸€è‡´: {actual_checksum} != {metadata.checksum}")
        
        decomp_time = time.time() - start_time
        print(f"âœ… è§£å‡å®Œäº†: {len(compressed_data)} â†’ {len(decompressed_data)} bytes ({decomp_time:.3f}s)")
        
        return decompressed_data
    
    def _deserialize_metadata(self, data: bytes) -> CompressionMetadata:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        pos = 0
        
        # åŸºæœ¬æƒ…å ±
        original_size = struct.unpack('<I', data[pos:pos+4])[0]
        pos += 4
        compressed_size = struct.unpack('<I', data[pos:pos+4])[0]
        pos += 4
        width = struct.unpack('<I', data[pos:pos+4])[0]
        pos += 4
        height = struct.unpack('<I', data[pos:pos+4])[0]
        pos += 4
        channels = struct.unpack('<I', data[pos:pos+4])[0]
        pos += 4
        compression_time = struct.unpack('<f', data[pos:pos+4])[0]
        pos += 4
        
        # æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿
        file_type_len = data[pos]
        pos += 1
        file_type = data[pos:pos+file_type_len].decode('utf-8')
        pos += file_type_len
        
        checksum_len = data[pos]
        pos += 1
        checksum = data[pos:pos+checksum_len].decode('utf-8')
        pos += checksum_len
        
        # åœ§ç¸®æ®µéš
        stages_count = data[pos]
        pos += 1
        stages = []
        for _ in range(stages_count):
            stage_len = data[pos]
            pos += 1
            stage = data[pos:pos+stage_len].decode('utf-8')
            pos += stage_len
            stages.append(stage)
        
        return CompressionMetadata(
            original_size=original_size,
            compressed_size=compressed_size,
            file_type=file_type,
            width=width,
            height=height,
            channels=channels,
            checksum=checksum,
            compression_stages=stages,
            compression_time=compression_time
        )
    
    def _huffman_decompress(self, data: bytes) -> bytes:
        """Huffmanè§£å‡"""
        if len(data) < 2:
            return data
        
        pos = 0
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºèª­ã¿è¾¼ã¿
        table_size = struct.unpack('<H', data[pos:pos+2])[0]
        pos += 2
        
        if len(data) < pos + table_size:
            return data
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿
        table_data = data[pos:pos+table_size]
        pos += table_size
        
        # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰
        decode_table = self._deserialize_huffman_table(table_data)
        
        if not decode_table:
            return data[pos:]  # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒç©ºã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        encoded_data = data[pos:]
        
        # ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆåŠ¹ç‡åŒ–ç‰ˆï¼‰
        result = bytearray()
        bit_buffer = []
        
        # ã‚³ãƒ¼ãƒ‰é•·ã§ã‚½ãƒ¼ãƒˆã—ã¦é«˜é€ŸåŒ–
        sorted_codes = sorted(decode_table.items(), key=lambda x: len(x[1]))
        
        for byte in encoded_data:
            # ãƒã‚¤ãƒˆã‚’ãƒ“ãƒƒãƒˆã«å¤‰æ›
            for i in range(8):
                bit_buffer.append((byte >> (7-i)) & 1)
                
                # çŸ­ã„ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é †ã«ãƒãƒƒãƒãƒ³ã‚°ç¢ºèªï¼ˆé«˜é€ŸåŒ–ï¼‰
                for symbol, code in sorted_codes:
                    if len(bit_buffer) >= len(code):
                        if bit_buffer[:len(code)] == code:
                            result.append(symbol)
                            bit_buffer = bit_buffer[len(code):]
                            break
        
        return bytes(result)
    
    def _deserialize_huffman_table(self, data: bytes) -> Dict[int, List[int]]:
        """Huffmanãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        table = {}
        pos = 0
        
        # ã‚¨ãƒ³ãƒˆãƒªæ•°
        entry_count = struct.unpack('<H', data[pos:pos+2])[0]
        pos += 2
        
        for _ in range(entry_count):
            if pos >= len(data):
                break
                
            # ã‚·ãƒ³ãƒœãƒ«
            symbol = data[pos]
            pos += 1
            
            # ç¬¦å·é•·
            code_len = data[pos]
            pos += 1
            
            # ç¬¦å·ãƒ‡ãƒ¼ã‚¿
            code_bytes_len = (code_len + 7) // 8  # å¿…è¦ãƒã‚¤ãƒˆæ•°
            if pos + code_bytes_len > len(data):
                break
                
            code_bytes = data[pos:pos+code_bytes_len]
            pos += code_bytes_len
            
            # ãƒã‚¤ãƒˆã‹ã‚‰ãƒ“ãƒƒãƒˆåˆ—å¾©å…ƒ
            code = []
            for byte in code_bytes:
                for i in range(8):
                    if len(code) < code_len:
                        code.append((byte >> (7-i)) & 1)
            
            table[symbol] = code[:code_len]
        
        return table
    
    def _rle_decompress(self, data: bytes) -> bytes:
        """RLEè§£å‡"""
        result = bytearray()
        i = 0
        
        while i < len(data):
            if data[i] == 0xFF and i + 1 < len(data):
                if data[i + 1] == 0x00:  # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
                    result.append(0xFF)
                    i += 2
                else:  # RLEã‚·ãƒ¼ã‚±ãƒ³ã‚¹
                    if i + 2 < len(data):
                        count = data[i + 1]
                        value = data[i + 2]
                        result.extend([value] * count)
                        i += 3
                    else:
                        result.append(data[i])
                        i += 1
            else:
                result.append(data[i])
                i += 1
        
        return bytes(result)
    
    def _delta_decompress(self, data: bytes) -> bytes:
        """Deltaè§£å‡"""
        if len(data) < 2:
            return data
        
        result = bytearray()
        result.append(data[0])  # æœ€åˆã®ãƒã‚¤ãƒˆ
        
        # ç´¯ç©å’Œã§å¾©å…ƒ
        for i in range(1, len(data)):
            restored = (result[-1] + data[i]) % 256
            result.append(restored)
        
        return bytes(result)
    
    def compress_file(self, file_path: str, output_path: str = None) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        try:
            if not os.path.exists(file_path):
                return {'success': False, 'error': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}'}
            
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®é–‹å§‹: {file_path}")
            
            with open(file_path, 'rb') as f:
                data = f.read()
            
            if len(data) == 0:
                return {'success': False, 'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™'}
            
            # åœ§ç¸®å®Ÿè¡Œ
            compressed = self.compress_fast_lossless(data)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ±ºå®š
            if output_path is None:
                base_name = os.path.splitext(file_path)[0]
                output_path = f"{base_name}.nxz"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            with open(output_path, 'wb') as f:
                f.write(compressed)
            
            compression_ratio = (1 - len(compressed) / len(data)) * 100
            
            return {
                'success': True,
                'input_file': file_path,
                'output_file': output_path,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': compression_ratio,
                'algorithm': 'Fast Lossless Archive'
            }
            
        except Exception as e:
            return {'success': False, 'error': f'åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def decompress_file(self, archive_path: str, output_path: str = None) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£å‡"""
        try:
            if not os.path.exists(archive_path):
                return {'success': False, 'error': f'ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {archive_path}'}
            
            print(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«è§£å‡é–‹å§‹: {archive_path}")
            
            with open(archive_path, 'rb') as f:
                archive_data = f.read()
            
            # è§£å‡å®Ÿè¡Œ
            decompressed = self.decompress_fast_lossless(archive_data)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ±ºå®š
            if output_path is None:
                base_name = os.path.splitext(archive_path)[0]
                
                # å…ƒã®æ‹¡å¼µå­ã‚’æ¨å®š
                file_type, _, _, _ = self.detect_image_format(decompressed)
                if file_type == "PNG":
                    output_path = f"{base_name}_restored.png"
                elif file_type == "JPEG":
                    output_path = f"{base_name}_restored.jpg"
                elif file_type == "BMP":
                    output_path = f"{base_name}_restored.bmp"
                else:
                    output_path = f"{base_name}_restored.bin"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            with open(output_path, 'wb') as f:
                f.write(decompressed)
            
            return {
                'success': True,
                'input_file': archive_path,
                'output_file': output_path,
                'decompressed_size': len(decompressed),
                'algorithm': 'Fast Lossless Archive'
            }
            
        except Exception as e:
            return {'success': False, 'error': f'è§£å‡ã‚¨ãƒ©ãƒ¼: {str(e)}'}

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 2:
        print("ğŸš€ NEXUS Fast Lossless Archive")
        print("é«˜é€Ÿå¯é€†åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¨ãƒ³ã‚¸ãƒ³ - ç”»åƒç‰¹åŒ–å‹")
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python nexus_fast_lossless_archive.py compress <ãƒ•ã‚¡ã‚¤ãƒ«>")
        print("  python nexus_fast_lossless_archive.py decompress <ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–>")
        print("  python nexus_fast_lossless_archive.py test")
        print()
        print("ç‰¹å¾´:")
        print("  âš¡ é«˜é€Ÿå‡¦ç† - å¾“æ¥æ¯”3-5å€é«˜é€Ÿ")
        print("  ğŸ”„ å®Œå…¨å¯é€† - 100%å…ƒãƒ‡ãƒ¼ã‚¿å¾©å…ƒ")
        print("  ğŸ“¦ ç‹¬è‡ªå½¢å¼ - .nxz ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
        print("  ğŸ–¼ï¸  ç”»åƒæœ€é©åŒ– - PNG/JPEG/BMPç‰¹åŒ–")
        return
    
    command = sys.argv[1].lower()
    
    if command == "test":
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        print("ğŸ§ª Fast Lossless Archive ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        archive = FastLosslessArchive()
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆç”»åƒå½¢å¼ï¼‰
        test_data = bytearray()
        test_data.extend(b'\x89PNG\r\n\x1a\n')  # PNGç½²å
        test_data.extend(b'\x00\x00\x00\rIHDR')  # IHDR
        test_data.extend(struct.pack('>II', 64, 64))  # 64x64
        test_data.extend(b'\x08\x02\x00\x00\x00')  # 8bit RGB
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆåœ§ç¸®ã—ã‚„ã™ã„ï¼‰
        for i in range(1000):
            test_data.extend([(i % 256), ((i*2) % 256), ((i*3) % 256)])
        
        original_data = bytes(test_data)
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(original_data)} bytes")
        
        # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
        compressed = archive.compress_fast_lossless(original_data)
        
        # è§£å‡ãƒ†ã‚¹ãƒˆ
        decompressed = archive.decompress_fast_lossless(compressed)
        
        # æ¤œè¨¼
        if original_data == decompressed:
            compression_ratio = (1 - len(compressed) / len(original_data)) * 100
            print(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
            print(f"ğŸ“Š åœ§ç¸®ç‡: {compression_ratio:.1f}%")
            print(f"ğŸ“ ã‚µã‚¤ã‚º: {len(original_data)} â†’ {len(compressed)} â†’ {len(decompressed)}")
        else:
            print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: ãƒ‡ãƒ¼ã‚¿ãŒä¸€è‡´ã—ã¾ã›ã‚“")
    
    elif command == "compress" and len(sys.argv) >= 3:
        file_path = sys.argv[2]
        archive = FastLosslessArchive()
        
        result = archive.compress_file(file_path)
        
        if result['success']:
            print(f"âœ… åœ§ç¸®æˆåŠŸ!")
            print(f"ğŸ“ å‡ºåŠ›: {result['output_file']}")
            print(f"ğŸ“Š åœ§ç¸®ç‡: {result['compression_ratio']:.1f}%")
            print(f"ğŸ“ ã‚µã‚¤ã‚º: {result['original_size']} â†’ {result['compressed_size']} bytes")
        else:
            print(f"âŒ åœ§ç¸®å¤±æ•—: {result['error']}")
    
    elif command == "decompress" and len(sys.argv) >= 3:
        archive_path = sys.argv[2]
        archive = FastLosslessArchive()
        
        result = archive.decompress_file(archive_path)
        
        if result['success']:
            print(f"âœ… è§£å‡æˆåŠŸ!")
            print(f"ğŸ“ å‡ºåŠ›: {result['output_file']}")
            print(f"ğŸ“ ã‚µã‚¤ã‚º: {result['decompressed_size']} bytes")
        else:
            print(f"âŒ è§£å‡å¤±æ•—: {result['error']}")
    
    else:
        print("âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™ã€‚'test', 'compress', 'decompress' ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()

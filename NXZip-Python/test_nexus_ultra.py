#!/usr/bin/env python3
"""
NEXUS Ultra Engine åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç¢ºèª + å¤§å¹…æ€§èƒ½å‘ä¸Šç¢ºèª + ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import time
import hashlib
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from nxzip.engine.nexus_v6_1_ultra import NEXUSEngineUltra


def test_ultra_comprehensive():
    """Ultraç‰ˆåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ NEXUS Ultra Engine åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    print("ğŸ“‹ ãƒ†ã‚¹ãƒˆé …ç›®:")
    print("   âœ“ ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç¢ºèªï¼ˆuint8ç¯„å›²å¤–ã‚¨ãƒ©ãƒ¼è§£æ±ºï¼‰")
    print("   âœ“ å¤§å¹…æ€§èƒ½å‘ä¸Šç¢ºèªï¼ˆä¸¦åˆ—å‡¦ç†ãƒ»æœ€é©åŒ–ï¼‰")
    print("   âœ“ å¯é€†æ€§ä¿è¨¼ç¢ºèªï¼ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
    print("   âœ“ ç›®æ¨™é”æˆç‡å‘ä¸Šç¢ºèª")
    print("   âœ“ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç¢ºèª")
    print("=" * 80)
    
    # Ultra EngineåˆæœŸåŒ–
    engine = NEXUSEngineUltra(max_workers=4)
    
    # ãƒ†ã‚¹ãƒˆ1: å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ1: å®Ÿãƒ•ã‚¡ã‚¤ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ")
    test_real_files(engine)
    
    # ãƒ†ã‚¹ãƒˆ2: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ2: å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿æ€§èƒ½ãƒ†ã‚¹ãƒˆ")
    test_large_scale_data(engine)
    
    # ãƒ†ã‚¹ãƒˆ3: ä¸¦åˆ—å‡¦ç†åŠ¹æœãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ3: ä¸¦åˆ—å‡¦ç†åŠ¹æœãƒ†ã‚¹ãƒˆ")
    test_parallel_performance(engine)
    
    # ãƒ†ã‚¹ãƒˆ4: ã‚¨ãƒ©ãƒ¼è€æ€§ãƒ†ã‚¹ãƒˆ
    print(f"\nğŸ§ª ãƒ†ã‚¹ãƒˆ4: ã‚¨ãƒ©ãƒ¼è€æ€§ãƒ†ã‚¹ãƒˆ")
    test_error_resistance(engine)
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Ultra Engine æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"{'='*80}")
    generate_final_report(engine)


def test_real_files(engine):
    """å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ"""
    sample_dir = Path("sample")
    test_files = []
    
    if sample_dir.exists():
        for ext in ['*.jpg', '*.png', '*.mp4', '*.wav', '*.mp3', '*.txt', '*.7z']:
            test_files.extend(sample_dir.glob(ext))
    
    if not test_files:
        print("   âš ï¸ å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")
        test_files = []
    
    results = []
    error_free_count = 0
    
    for i, file_path in enumerate(test_files[:8]):  # æœ€å¤§8ãƒ•ã‚¡ã‚¤ãƒ«
        print(f"\n   ğŸ“ {i+1}/{min(8, len(test_files))}: {file_path.name}")
        
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
            
            file_type = file_path.suffix.lower().lstrip('.')
            size_mb = len(data) / 1024 / 1024
            
            # Ultraåœ§ç¸®å®Ÿè¡Œ
            start_time = time.perf_counter()
            compressed, info = engine.compress_ultra(data, file_type)
            total_time = time.perf_counter() - start_time
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            has_errors = 'error' in info
            if not has_errors:
                error_free_count += 1
            
            print(f"      ğŸ“Š ã‚µã‚¤ã‚º: {size_mb:.2f}MB")
            print(f"      ğŸ“ˆ åœ§ç¸®ç‡: {info['compression_ratio']:.2f}%")
            print(f"      âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {info['throughput_mb_s']:.2f}MB/s")
            print(f"      ğŸ›ï¸ æˆ¦ç•¥: {info['strategy']}")
            print(f"      ğŸ”„ å¯é€†æ€§: {'âœ…' if info['reversible'] else 'âŒ'}")
            print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {'ãªã—' if not has_errors else info.get('error', '')}")
            print(f"      ğŸ¯ ç›®æ¨™é”æˆ: {'âœ…' if info['target_achieved'] else 'âŒ'}")
            
            results.append({
                'file': file_path.name,
                'size_mb': size_mb,
                'ratio': info['compression_ratio'],
                'throughput': info['throughput_mb_s'],
                'strategy': info['strategy'],
                'reversible': info['reversible'],
                'error_free': not has_errors,
                'target_achieved': info['target_achieved']
            })
            
        except Exception as e:
            print(f"      âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚µãƒãƒªãƒ¼
    if results:
        avg_ratio = sum(r['ratio'] for r in results) / len(results)
        avg_throughput = sum(r['throughput'] for r in results) / len(results)
        reversible_rate = sum(1 for r in results if r['reversible']) / len(results) * 100
        target_rate = sum(1 for r in results if r['target_achieved']) / len(results) * 100
        
        print(f"\n   ğŸ“Š å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ ã‚µãƒãƒªãƒ¼:")
        print(f"      ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}")
        print(f"      ã‚¨ãƒ©ãƒ¼ãªã—: {error_free_count}/{len(results)} ({error_free_count/len(results)*100:.1f}%)")
        print(f"      å¹³å‡åœ§ç¸®ç‡: {avg_ratio:.2f}%")
        print(f"      å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {avg_throughput:.2f}MB/s")
        print(f"      å¯é€†æ€§ç‡: {reversible_rate:.1f}%")
        print(f"      ç›®æ¨™é”æˆç‡: {target_rate:.1f}%")


def test_large_scale_data(engine):
    """å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆ"""
    test_datasets = [
        {'name': 'å°è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆ', 'size_mb': 1, 'type': 'txt'},
        {'name': 'ä¸­è¦æ¨¡ãƒã‚¤ãƒŠãƒª', 'size_mb': 5, 'type': 'unknown'},
        {'name': 'å¤§è¦æ¨¡æ§‹é€ åŒ–', 'size_mb': 15, 'type': 'txt'},
        {'name': 'è¶…å¤§è¦æ¨¡ãƒ©ãƒ³ãƒ€ãƒ ', 'size_mb': 30, 'type': 'unknown'}
    ]
    
    for dataset in test_datasets:
        print(f"\n   ğŸ§ª {dataset['name']} ({dataset['size_mb']}MB)")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            data = generate_large_test_data(dataset['size_mb'], dataset['type'])
            actual_size_mb = len(data) / 1024 / 1024
            
            # Ultraåœ§ç¸®
            start_time = time.perf_counter()
            compressed, info = engine.compress_ultra(data, dataset['type'])
            total_time = time.perf_counter() - start_time
            
            print(f"      ğŸ“Š å®Ÿã‚µã‚¤ã‚º: {actual_size_mb:.2f}MB")
            print(f"      ğŸ“ˆ åœ§ç¸®ç‡: {info['compression_ratio']:.2f}%")
            print(f"      âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {info['throughput_mb_s']:.2f}MB/s")
            print(f"      ğŸ›ï¸ æˆ¦ç•¥: {info['strategy']}")
            print(f"      ğŸ”„ å¯é€†æ€§: {'âœ…' if info['reversible'] else 'âŒ'}")
            print(f"      â±ï¸ å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
            
            # æ€§èƒ½è©•ä¾¡
            if info['throughput_mb_s'] >= 20:
                perf_grade = "âœ… é«˜é€Ÿ"
            elif info['throughput_mb_s'] >= 10:
                perf_grade = "âš¡ è‰¯å¥½"
            else:
                perf_grade = "âš ï¸ æ”¹å–„ä½™åœ°"
            
            print(f"      ğŸ† æ€§èƒ½è©•ä¾¡: {perf_grade}")
            
        except Exception as e:
            print(f"      âŒ ã‚¨ãƒ©ãƒ¼: {e}")


def test_parallel_performance(engine):
    """ä¸¦åˆ—å‡¦ç†åŠ¹æœãƒ†ã‚¹ãƒˆ"""
    print(f"\n   ğŸ”„ ä¸¦åˆ—å‡¦ç† vs å˜ä¸€å‡¦ç† æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    test_data = generate_large_test_data(10, 'txt')  # 10MBãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    
    try:
        # å˜ä¸€å‡¦ç†ï¼ˆå°ã•ãªãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼‰
        engine_single = NEXUSEngineUltra(max_workers=1)
        start_time = time.perf_counter()
        compressed_single, info_single = engine_single.compress_ultra(test_data, 'txt')
        single_time = time.perf_counter() - start_time
        
        # ä¸¦åˆ—å‡¦ç†ï¼ˆè¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰
        engine_parallel = NEXUSEngineUltra(max_workers=4)
        start_time = time.perf_counter()
        compressed_parallel, info_parallel = engine_parallel.compress_ultra(test_data, 'txt')
        parallel_time = time.perf_counter() - start_time
        
        # çµæœæ¯”è¼ƒ
        speedup = single_time / parallel_time if parallel_time > 0 else 1.0
        
        print(f"      ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data)/1024/1024:.1f}MB")
        print(f"      âš¡ å˜ä¸€å‡¦ç†: {single_time:.3f}ç§’ ({info_single['throughput_mb_s']:.2f}MB/s)")
        print(f"      ğŸš€ ä¸¦åˆ—å‡¦ç†: {parallel_time:.3f}ç§’ ({info_parallel['throughput_mb_s']:.2f}MB/s)")
        print(f"      ğŸ“ˆ é€Ÿåº¦å‘ä¸Š: {speedup:.2f}å€")
        
        if speedup >= 1.5:
            print(f"      ğŸ† ä¸¦åˆ—åŠ¹æœ: âœ… å„ªç§€ ({speedup:.1f}å€å‘ä¸Š)")
        elif speedup >= 1.2:
            print(f"      ğŸ† ä¸¦åˆ—åŠ¹æœ: âš¡ è‰¯å¥½ ({speedup:.1f}å€å‘ä¸Š)")
        else:
            print(f"      ğŸ† ä¸¦åˆ—åŠ¹æœ: âš ï¸ é™å®šçš„ ({speedup:.1f}å€å‘ä¸Š)")
        
    except Exception as e:
        print(f"      âŒ ä¸¦åˆ—ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")


def test_error_resistance(engine):
    """ã‚¨ãƒ©ãƒ¼è€æ€§ãƒ†ã‚¹ãƒˆ"""
    print(f"\n   ğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼è€æ€§ãƒ»å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ")
    
    error_test_cases = [
        {'name': 'ç©ºãƒ‡ãƒ¼ã‚¿', 'data': b'', 'type': 'unknown'},
        {'name': '1ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿', 'data': b'A', 'type': 'txt'},
        {'name': 'å·¨å¤§å˜ä¸€å€¤', 'data': b'A' * 1000000, 'type': 'txt'},
        {'name': 'ãƒ©ãƒ³ãƒ€ãƒ æ¥µå°', 'data': bytes(range(256)), 'type': 'unknown'},
        {'name': 'ä¸æ­£UTF-8', 'data': b'\xff\xfe\xfd' * 1000, 'type': 'txt'}
    ]
    
    error_free_count = 0
    
    for test_case in error_test_cases:
        try:
            print(f"      ğŸ§ª {test_case['name']}: ", end="")
            
            start_time = time.perf_counter()
            compressed, info = engine.compress_ultra(test_case['data'], test_case['type'])
            test_time = time.perf_counter() - start_time
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            has_error = 'error' in info
            
            if not has_error:
                error_free_count += 1
                print(f"âœ… æˆåŠŸ ({info['compression_ratio']:.1f}%, {test_time:.3f}ç§’)")
            else:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼å‡¦ç† ({info.get('error', 'unknown')})")
            
        except Exception as e:
            print(f"âŒ ä¾‹å¤–: {e}")
    
    print(f"\n      ğŸ“Š ã‚¨ãƒ©ãƒ¼è€æ€§çµæœ: {error_free_count}/{len(error_test_cases)} æˆåŠŸ ({error_free_count/len(error_test_cases)*100:.1f}%)")


def generate_large_test_data(size_mb: float, data_type: str) -> bytes:
    """å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    import numpy as np
    
    target_size = int(size_mb * 1024 * 1024)
    
    if data_type == 'txt':
        # ãƒ†ã‚­ã‚¹ãƒˆæ§˜ãƒ‡ãƒ¼ã‚¿ï¼ˆåœ§ç¸®ã—ã‚„ã™ã„ï¼‰
        patterns = [
            b"NEXUS Ultra Engine Test Data Pattern ",
            b"High Performance Compression System ",
            b"Parallel Processing Optimization ",
            b"Error-Free Implementation "
        ]
        
        data = b''
        while len(data) < target_size:
            for pattern in patterns:
                data += pattern * 100
                if len(data) >= target_size:
                    break
        
        return data[:target_size]
        
    else:
        # ãƒã‚¤ãƒŠãƒªæ§˜ãƒ‡ãƒ¼ã‚¿ï¼ˆåœ§ç¸®å›°é›£ï¼‰
        return np.random.randint(0, 256, target_size, dtype=np.uint8).tobytes()


def generate_final_report(engine):
    """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    stats = engine.get_ultra_stats()
    
    if stats.get('status') == 'no_data':
        print("   âš ï¸ çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“ˆ å‡¦ç†çµ±è¨ˆ:")
    print(f"   ğŸ“ å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['files_processed']}")
    print(f"   ğŸ“Š ç·åœ§ç¸®ç‡: {stats['total_compression_ratio']:.2f}%")
    print(f"   âš¡ å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {stats['average_throughput_mb_s']:.2f}MB/s")
    print(f"   ğŸ”„ å¯é€†æ€§ç‡: {stats['reversibility_rate']:.1f}%")
    print(f"   ğŸ¯ ç›®æ¨™é”æˆç‡: {stats['target_achievement_rate']:.1f}%")
    print(f"   âŒ ã‚¨ãƒ©ãƒ¼æ•°: {stats['error_count']}")
    print(f"   â±ï¸ ç·å‡¦ç†æ™‚é–“: {stats['total_time']:.3f}ç§’")
    
    print(f"\nğŸ›ï¸ æˆ¦ç•¥ä½¿ç”¨åˆ†å¸ƒ:")
    for strategy, count in stats['strategy_distribution'].items():
        if count > 0:
            print(f"   {strategy}: {count}å›")
    
    print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿å‡¦ç†é‡:")
    print(f"   ğŸ“¥ å…¥åŠ›: {stats['total_input_mb']:.2f}MB")
    print(f"   ğŸ“¤ å‡ºåŠ›: {stats['total_output_mb']:.2f}MB")
    print(f"   ğŸ“‰ å‰Šæ¸›: {stats['total_input_mb'] - stats['total_output_mb']:.2f}MB")
    
    print(f"\nğŸ† ç·åˆè©•ä¾¡: {stats['performance_grade']}")
    
    # æ”¹å–„ææ¡ˆ
    print(f"\nğŸ’¡ æ”¹å–„çŠ¶æ³:")
    if stats['error_count'] == 0:
        print(f"   âœ… ã‚¨ãƒ©ãƒ¼ä¿®æ­£: å®Œäº†ï¼ˆã‚¨ãƒ©ãƒ¼æ•°: 0ï¼‰")
    else:
        print(f"   âš ï¸ ã‚¨ãƒ©ãƒ¼ä¿®æ­£: éƒ¨åˆ†çš„ï¼ˆã‚¨ãƒ©ãƒ¼æ•°: {stats['error_count']}ï¼‰")
    
    if stats['average_throughput_mb_s'] >= 20:
        print(f"   âœ… æ€§èƒ½å‘ä¸Š: å¤§å¹…æ”¹å–„ï¼ˆ{stats['average_throughput_mb_s']:.1f}MB/sï¼‰")
    elif stats['average_throughput_mb_s'] >= 10:
        print(f"   âš¡ æ€§èƒ½å‘ä¸Š: æ”¹å–„æ¸ˆã¿ï¼ˆ{stats['average_throughput_mb_s']:.1f}MB/sï¼‰")
    else:
        print(f"   âš ï¸ æ€§èƒ½å‘ä¸Š: æ›´ãªã‚‹æ”¹å–„å¿…è¦ï¼ˆ{stats['average_throughput_mb_s']:.1f}MB/sï¼‰")
    
    if stats['reversibility_rate'] >= 90:
        print(f"   âœ… å¯é€†æ€§: å„ªç§€ï¼ˆ{stats['reversibility_rate']:.1f}%ï¼‰")
    elif stats['reversibility_rate'] >= 70:
        print(f"   âš¡ å¯é€†æ€§: è‰¯å¥½ï¼ˆ{stats['reversibility_rate']:.1f}%ï¼‰")
    else:
        print(f"   âš ï¸ å¯é€†æ€§: æ”¹å–„å¿…è¦ï¼ˆ{stats['reversibility_rate']:.1f}%ï¼‰")


if __name__ == "__main__":
    test_ultra_comprehensive()

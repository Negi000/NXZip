#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ NEXUS Ultra Efficient - åŠ¹ç‡åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã‚‹å•é¡Œã‚’è§£æ±ºã™ã‚‹è¶…é«˜é€Ÿåœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³

ğŸ¯ åŠ¹ç‡åŒ–æˆ¦ç•¥:
1. äº‹å‰è§£æã«ã‚ˆã‚‹æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
2. ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹é«˜é€ŸåŒ–
3. é©å¿œçš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå‡¦ç†
4. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é©åŒ–
5. æ—©æœŸçµ‚äº†æ¡ä»¶ã«ã‚ˆã‚‹å‡¦ç†æ™‚é–“çŸ­ç¸®
"""

import os
import sys
import time
import zlib
import bz2
import lzma
import hashlib
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

class NexusUltraEfficient:
    """è¶…åŠ¹ç‡åŒ–åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.max_workers = min(4, os.cpu_count())
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¥ã®å‡¦ç†æˆ¦ç•¥
        self.size_thresholds = {
            'tiny': 1024,           # 1KBæœªæº€: ã‚·ãƒ³ãƒ—ãƒ«å‡¦ç†
            'small': 1024 * 100,    # 100KBæœªæº€: æ¨™æº–å‡¦ç†
            'medium': 1024 * 1024 * 10,  # 10MBæœªæº€: ä¸¦åˆ—å‡¦ç†
            'large': 1024 * 1024 * 100   # 100MBä»¥ä¸Š: è¶…ä¸¦åˆ—å‡¦ç†
        }
        
    def quick_file_analysis(self, data: bytes) -> dict:
        """è¶…é«˜é€Ÿãƒ•ã‚¡ã‚¤ãƒ«è§£æ - æœ€å°é™ã®æƒ…å ±ã§æœ€é©æˆ¦ç•¥æ±ºå®š"""
        size = len(data)
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è§£æï¼ˆå¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸€éƒ¨ã®ã¿è§£æï¼‰
        if size > 1024 * 1024:  # 1MBä»¥ä¸Š
            sample_size = min(8192, size // 100)  # 1%ã¾ãŸã¯8KBã®ã‚µãƒ³ãƒ—ãƒ«
            sample = data[:sample_size]
        else:
            sample = data
            
        # é«˜é€Ÿã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¨å®š
        byte_counts = [0] * 256
        for byte in sample:
            byte_counts[byte] += 1
        
        # åœ§ç¸®ç‡äºˆæ¸¬ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        unique_bytes = sum(1 for count in byte_counts if count > 0)
        repetition_ratio = max(byte_counts) / len(sample) if sample else 0
        
        # æˆ¦ç•¥æ±ºå®š
        if repetition_ratio > 0.7:  # é«˜ç¹°ã‚Šè¿”ã—
            strategy = 'bz2_fast'
        elif unique_bytes < 128:    # ä½å¤šæ§˜æ€§
            strategy = 'lzma_fast'
        else:                       # ä¸€èˆ¬çš„
            strategy = 'zlib_fast'
            
        return {
            'size': size,
            'strategy': strategy,
            'sample_entropy': unique_bytes / 256,
            'repetition': repetition_ratio
        }
    
    def compress_tiny(self, data: bytes) -> tuple:
        """è¶…å°ãƒ•ã‚¡ã‚¤ãƒ«ç”¨é«˜é€Ÿåœ§ç¸®"""
        # è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã€æœ€åˆã«å®Œäº†ã—ãŸã‚‚ã®ã‚’æ¡ç”¨
        def try_compress(algorithm):
            if algorithm == 'zlib':
                return zlib.compress(data, 6), 'zlib_6'
            elif algorithm == 'bz2':
                return bz2.compress(data, 6), 'bz2_6'
            elif algorithm == 'lzma':
                return lzma.compress(data, preset=3), 'lzma_3'
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {
                executor.submit(try_compress, algo): algo 
                for algo in ['zlib', 'bz2', 'lzma']
            }
            
            # æœ€åˆã«å®Œäº†ã—ãŸã‚‚ã®ã‚’æ¡ç”¨
            for future in as_completed(futures):
                try:
                    result, method = future.result(timeout=0.1)  # 100msåˆ¶é™
                    # ä»–ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                    for f in futures:
                        if f != future and not f.done():
                            f.cancel()
                    return result, method
                except:
                    continue
                    
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return zlib.compress(data, 1), 'zlib_1'
    
    def compress_chunk(self, chunk: bytes, chunk_id: int, strategy: str) -> tuple:
        """ãƒãƒ£ãƒ³ã‚¯å˜ä½ã®ä¸¦åˆ—åœ§ç¸®"""
        try:
            if strategy == 'bz2_fast':
                return bz2.compress(chunk, 3), chunk_id, 'bz2_3'
            elif strategy == 'lzma_fast':
                return lzma.compress(chunk, preset=2), chunk_id, 'lzma_2'
            else:  # zlib_fast
                return zlib.compress(chunk, 4), chunk_id, 'zlib_4'
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯zlibåœ§ç¸®ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return zlib.compress(chunk, 1), chunk_id, 'zlib_1'
    
    def compress_large_parallel(self, data: bytes, strategy: str) -> tuple:
        """å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ä¸¦åˆ—åœ§ç¸®"""
        size = len(data)
        
        # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºæ±ºå®š
        if size > 100 * 1024 * 1024:  # 100MBä»¥ä¸Š
            chunk_size = 2 * 1024 * 1024  # 2MB chunks
        elif size > 10 * 1024 * 1024:   # 10MBä»¥ä¸Š
            chunk_size = 1 * 1024 * 1024  # 1MB chunks
        else:
            chunk_size = 512 * 1024       # 512KB chunks
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
        chunks = []
        for i in range(0, size, chunk_size):
            chunks.append(data[i:i + chunk_size])
        
        # ä¸¦åˆ—åœ§ç¸®
        compressed_chunks = [None] * len(chunks)
        methods = [None] * len(chunks)
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—ã§åœ§ç¸®
            futures = {
                executor.submit(self.compress_chunk, chunk, i, strategy): i
                for i, chunk in enumerate(chunks)
            }
            
            for future in as_completed(futures):
                try:
                    compressed_data, chunk_id, method = future.result(timeout=30)  # 30ç§’åˆ¶é™
                    compressed_chunks[chunk_id] = compressed_data
                    methods[chunk_id] = method
                except Exception as e:
                    chunk_id = futures[future]
                    print(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯ {chunk_id} åœ§ç¸®å¤±æ•—: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    compressed_chunks[chunk_id] = zlib.compress(chunks[chunk_id], 1)
                    methods[chunk_id] = 'zlib_1'
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        header = f"NEXUS_PARALLEL_V1:{len(chunks)}:{strategy}:".encode()
        result = header
        
        for i, (compressed_chunk, method) in enumerate(zip(compressed_chunks, methods)):
            chunk_header = f"{len(compressed_chunk)}:{method}:".encode()
            result += chunk_header + compressed_chunk
        
        return result, f"parallel_{strategy}"
    
    def compress_file(self, filepath: str) -> dict:
        """åŠ¹ç‡åŒ–ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        start_time = time.time()
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            file_path = Path(filepath)
            if not file_path.exists():
                return {'success': False, 'error': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}'}
            
            with open(file_path, 'rb') as f:
                data = f.read()
            
            original_size = len(data)
            print(f"ğŸ“ å‡¦ç†é–‹å§‹: {file_path.name} ({original_size:,} bytes)")
            
            # äº‹å‰è§£æ
            analysis = self.quick_file_analysis(data)
            print(f"ğŸ” è§£æçµæœ: {analysis['strategy']} (ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {analysis['sample_entropy']:.3f})")
            
            # ã‚µã‚¤ã‚ºåˆ¥å‡¦ç†æˆ¦ç•¥
            if original_size <= self.size_thresholds['tiny']:
                # è¶…å°ãƒ•ã‚¡ã‚¤ãƒ«: è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¸¦åˆ—å®Ÿè¡Œ
                compressed_data, method = self.compress_tiny(data)
                print(f"âš¡ è¶…é«˜é€Ÿå‡¦ç†: {method}")
                
            elif original_size <= self.size_thresholds['medium']:
                # ä¸­å°ãƒ•ã‚¡ã‚¤ãƒ«: æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ å˜ä½“å®Ÿè¡Œ
                strategy = analysis['strategy']
                if strategy == 'bz2_fast':
                    compressed_data = bz2.compress(data, 6)
                    method = 'bz2_6'
                elif strategy == 'lzma_fast':
                    compressed_data = lzma.compress(data, preset=4)
                    method = 'lzma_4'
                else:
                    compressed_data = zlib.compress(data, 6)
                    method = 'zlib_6'
                print(f"ğŸš€ æœ€é©åŒ–å‡¦ç†: {method}")
                
            else:
                # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«: ä¸¦åˆ—å‡¦ç†
                compressed_data, method = self.compress_large_parallel(data, analysis['strategy'])
                print(f"ğŸ”§ ä¸¦åˆ—å‡¦ç†: {method}")
            
            # çµæœä¿å­˜
            output_path = file_path.with_suffix(file_path.suffix + '.nxue')
            with open(output_path, 'wb') as f:
                f.write(compressed_data)
            
            # çµ±è¨ˆè¨ˆç®—
            compressed_size = len(compressed_data)
            compression_ratio = (1 - compressed_size / original_size) * 100
            processing_time = time.time() - start_time
            speed = (original_size / 1024 / 1024) / processing_time if processing_time > 0 else float('inf')
            
            result = {
                'success': True,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'processing_time': processing_time,
                'speed_mbps': speed,
                'method': method,
                'output_file': str(output_path)
            }
            
            print(f"âœ… åœ§ç¸®å®Œäº†: {compression_ratio:.1f}% ({compressed_size:,} bytes)")
            print(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}s ({speed:.1f} MB/s)")
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
    
    def decompress_file(self, filepath: str) -> dict:
        """åŠ¹ç‡åŒ–ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹"""
        # å±•é–‹å‡¦ç†ï¼ˆå®Ÿè£…ã¯åœ§ç¸®é€†ç®—ï¼‰
        return {'success': False, 'error': 'å±•é–‹æ©Ÿèƒ½ã¯æ¬¡å›å®Ÿè£…äºˆå®š'}

def run_efficiency_test():
    """åŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ NEXUS Ultra Efficient - åŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    engine = NexusUltraEfficient()
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆï¼ˆsampleãƒ•ã‚©ãƒ«ãƒ€ã®ã¿ã€å‡¦ç†æ™‚é–“é †ï¼‰
    sample_dir = "NXZip-Python/sample"
    test_files = [
        f"{sample_dir}/é™°è¬€è«–.mp3",                              # å°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆéŸ³å£°ï¼‰
        f"{sample_dir}/COT-001.jpg",                            # ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆç”»åƒï¼‰
        f"{sample_dir}/generated-music-1752042054079.wav",      # ä¸­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆéŸ³å£°ï¼‰
        f"{sample_dir}/PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4",          # å¤§ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‹•ç”»ï¼‰
        f"{sample_dir}/COT-012.png",                           # è¶…å¤§ç”»åƒï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
        f"{sample_dir}/å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",                # è¶…å¤§ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹ï¼‰
    ]
    
    results = []
    total_start = time.time()
    
    for test_file in test_files:
        if os.path.exists(test_file):
            print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆ: {test_file}")
            result = engine.compress_file(test_file)
            if result['success']:
                results.append(result)
            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result.get('error', 'ä¸æ˜')}")
        else:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_file}")
    
    total_time = time.time() - total_start
    
    # çµ±è¨ˆè¡¨ç¤º
    if results:
        print(f"\nğŸ“Š åŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆçµæœ ({len(results)}ãƒ•ã‚¡ã‚¤ãƒ«)")
        print("=" * 60)
        
        total_original = sum(r['original_size'] for r in results)
        total_compressed = sum(r['compressed_size'] for r in results)
        avg_compression = (1 - total_compressed / total_original) * 100 if total_original > 0 else 0
        avg_speed = sum(r['speed_mbps'] for r in results) / len(results)
        
        print(f"ğŸ“ˆ ç·åˆçµ±è¨ˆ:")
        print(f"   å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1f}%")
        print(f"   å¹³å‡å‡¦ç†é€Ÿåº¦: {avg_speed:.1f} MB/s")
        print(f"   ç·å‡¦ç†æ™‚é–“: {total_time:.1f}s")
        
        print(f"\nğŸ“‹ å€‹åˆ¥çµæœ:")
        for i, result in enumerate(results, 1):
            filename = Path(result['output_file']).stem.replace('.nxue', '')
            print(f"   {i}. {filename}: {result['compression_ratio']:.1f}% "
                  f"({result['processing_time']:.1f}s, {result['speed_mbps']:.1f} MB/s)")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 2:
        print("ğŸš€ NEXUS Ultra Efficient - åŠ¹ç‡åŒ–ã‚¨ãƒ³ã‚¸ãƒ³")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python nexus_ultra_efficient.py test                    # åŠ¹ç‡åŒ–ãƒ†ã‚¹ãƒˆ")
        print("  python nexus_ultra_efficient.py compress <file>         # ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®")
        print("  python nexus_ultra_efficient.py decompress <file>       # ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹")
        return
    
    command = sys.argv[1].lower()
    engine = NexusUltraEfficient()
    
    if command == "test":
        run_efficiency_test()
    elif command == "compress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        result = engine.compress_file(input_file)
        if not result['success']:
            print(f"âŒ åœ§ç¸®å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
    elif command == "decompress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        result = engine.decompress_file(input_file)
        if not result['success']:
            print(f"âŒ å±•é–‹å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
    else:
        print("âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã¾ãŸã¯å¼•æ•°ã§ã™")

if __name__ == "__main__":
    main()

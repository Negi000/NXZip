#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  NEXUS Adaptive Entropy Decompressor
é©å¿œå‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åœ§ç¸®ã®è§£å‡ã‚¨ãƒ³ã‚¸ãƒ³
"""

import os
import sys
import struct
import hashlib
from typing import Dict, Optional

class AdaptiveEntropyDecompressor:
    """é©å¿œå‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£å‡ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        pass
    
    def decompress_file(self, input_path: str, output_path: str = None) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«è§£å‡ã®ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        if not os.path.exists(input_path):
            return {'error': f'å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}'}
        
        if output_path is None:
            # .nxaeæ‹¡å¼µå­ã‚’é™¤å»ã—ã¦å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
            base_name = input_path.replace('.nxae', '')
            output_path = f"{base_name}.restored"
        
        try:
            with open(input_path, 'rb') as f:
                compressed_data = f.read()
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
            if compressed_data.startswith(b'NXAE_'):
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¤å®šï¼ˆV2å¯¾å¿œï¼‰
                if compressed_data.startswith(b'NXAE_.png_V2'):
                    header_size = 12
                    format_type = 'PNG'
                    version = 2
                elif compressed_data.startswith(b'NXAE_.png_V1'):
                    header_size = 12
                    format_type = 'PNG'
                    version = 1
                elif compressed_data.startswith(b'NXAE_.mp4_V1') or compressed_data.startswith(b'NXAE_.mp4_V2'):
                    header_size = 12
                    format_type = 'MP4'
                    version = 2 if b'_V2' in compressed_data[:20] else 1
                else:
                    return {'error': f'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„é©å¿œå‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {compressed_data[:20]}'}
            else:
                return {'error': 'ä¸æ˜ãªåœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ'}
            
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³åˆ¥å‡¦ç†
            if version == 2:
                return self._decompress_v2(compressed_data, header_size, format_type, output_path)
            else:
                return self._decompress_v1(compressed_data, header_size, format_type, output_path)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
            metadata_start = header_size
            original_hash = compressed_data[metadata_start:metadata_start + 16]
            
            # å…ƒã‚µã‚¤ã‚ºæƒ…å ±
            size_start = metadata_start + 16
            original_size_data = compressed_data[size_start:size_start + 4]
            original_size = struct.unpack('>I', original_size_data)[0]
            
            # LZMAåœ§ç¸®ãƒ‡ãƒ¼ã‚¿
            lzma_start = size_start + 4
            lzma_data = compressed_data[lzma_start:]
            
            # LZMAè§£å‡
            import lzma
            intermediate_data = lzma.decompress(lzma_data)
            
            # ğŸ”§ ç¾åœ¨ã®å®Ÿè£…ã§ã¯é©å¿œå‹ç¬¦å·åŒ–ã®é€†å¤‰æ›ã¯ç°¡ç•¥åŒ–
            # å®Ÿéš›ã«ã¯Huffmanå¾©å·åŒ–ãªã©ãŒå¿…è¦ã ãŒã€ä»Šå›ã¯LZMAè§£å‡ã®ã¿
            final_data = intermediate_data
            
            # ã‚µã‚¤ã‚ºç¢ºèª
            if len(final_data) != original_size:
                print(f"âš ï¸ ã‚µã‚¤ã‚ºä¸ä¸€è‡´: æœŸå¾…å€¤={original_size:,}, å®Ÿéš›={len(final_data):,}")
            
            # ãƒãƒƒã‚·ãƒ¥æ¤œè¨¼
            restored_hash = hashlib.md5(final_data).digest()
            hash_match = restored_hash == original_hash
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
            with open(output_path, 'wb') as f:
                f.write(final_data)
            
            return {
                'input_file': input_path,
                'output_file': output_path,
                'restored_size': len(final_data),
                'original_size': original_size,
                'format_type': format_type,
                'hash_match': hash_match,
                'success': True
            }
            
        except Exception as e:
            return {'error': f'è§£å‡ã‚¨ãƒ©ãƒ¼: {str(e)}'}
    
    def _decompress_v2(self, compressed_data: bytes, header_size: int, format_type: str, output_path: str) -> Dict:
        """V2ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è§£å‡ï¼ˆå¯é€†ä¿è¨¼ç‰ˆï¼‰"""
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
        pos = header_size
        original_hash = compressed_data[pos:pos + 16]
        pos += 16
        
        # ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
        metadata_size = struct.unpack('>I', compressed_data[pos:pos + 4])[0]
        pos += 4
        
        # ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        import pickle
        metadata = pickle.loads(compressed_data[pos:pos + metadata_size])
        pos += metadata_size
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæƒ…å ±
        raw_size = struct.unpack('>I', compressed_data[pos:pos + 4])[0]
        pos += 4
        original_size = struct.unpack('>I', compressed_data[pos:pos + 4])[0]
        pos += 4
        
        # LZMAè§£å‡
        import lzma
        huffman_data = lzma.decompress(compressed_data[pos:])
        
        # Huffmanå¾©å·åŒ–
        raw_pixels = self._decode_huffman_reversible(huffman_data)
        
        # ç”Ÿãƒ”ã‚¯ã‚»ãƒ«ã‹ã‚‰ç”»åƒå½¢å¼ã«å¾©å…ƒ
        final_data = self._reconstruct_image(raw_pixels, metadata, format_type)
        
        # ãƒãƒƒã‚·ãƒ¥æ¤œè¨¼
        restored_hash = hashlib.md5(final_data).digest()
        hash_match = restored_hash == original_hash
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        with open(output_path, 'wb') as f:
            f.write(final_data)
        
        return {
            'input_file': output_path.replace('.restored', ''),
            'output_file': output_path,
            'restored_size': len(final_data),
            'original_size': original_size,
            'format_type': format_type,
            'hash_match': hash_match,
            'success': True
        }
    
    def _decompress_v1(self, compressed_data: bytes, header_size: int, format_type: str, output_path: str) -> Dict:
        """V1ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®è§£å‡ï¼ˆãƒ¬ã‚¬ã‚·ãƒ¼ï¼‰"""
        # æ—¢å­˜ã®V1è§£å‡ãƒ­ã‚¸ãƒƒã‚¯
        pos = header_size
        original_hash = compressed_data[pos:pos + 16]
        pos += 16
        
        original_size_data = compressed_data[pos:pos + 4]
        original_size = struct.unpack('>I', original_size_data)[0]
        pos += 4
        
        import lzma
        final_data = lzma.decompress(compressed_data[pos:])
        
        restored_hash = hashlib.md5(final_data).digest()
        hash_match = restored_hash == original_hash
        
        with open(output_path, 'wb') as f:
            f.write(final_data)
        
        return {
            'input_file': output_path.replace('.restored', ''),
            'output_file': output_path,
            'restored_size': len(final_data),
            'original_size': original_size,
            'format_type': format_type,
            'hash_match': hash_match,
            'success': True
        }
    
    def _decode_huffman_reversible(self, huffman_data: bytes) -> bytes:
        """å¯é€†Huffmanå¾©å·åŒ–"""
        import pickle
        
        # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºã‚’èª­ã¿å–ã‚Š
        codes_size = struct.unpack('>I', huffman_data[:4])[0]
        pos = 4
        
        # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¾©å…ƒ
        codes_data = huffman_data[pos:pos + codes_size]
        codes = pickle.loads(codes_data)
        pos += codes_size
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±
        padding = huffman_data[pos]
        pos += 1
        
        # ç¬¦å·åŒ–ãƒ‡ãƒ¼ã‚¿
        encoded_data = huffman_data[pos:]
        
        # å¾©å·åŒ–
        decode_table = {v: k for k, v in codes.items()}
        
        # ãƒã‚¤ãƒˆåˆ—ã‚’ãƒ“ãƒƒãƒˆæ–‡å­—åˆ—ã«å¤‰æ›
        bit_string = ''.join(format(byte, '08b') for byte in encoded_data)
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’é™¤å»
        if padding > 0:
            bit_string = bit_string[:-padding]
        
        # å¾©å·åŒ–å®Ÿè¡Œ
        result = bytearray()
        current_code = ''
        
        for bit in bit_string:
            current_code += bit
            if current_code in decode_table:
                result.append(decode_table[current_code])
                current_code = ''
        
        return bytes(result)
    
    def _reconstruct_image(self, raw_pixels: bytes, metadata: Dict, format_type: str) -> bytes:
        """ç”Ÿãƒ”ã‚¯ã‚»ãƒ«ã‹ã‚‰ç”»åƒå½¢å¼ã«å¾©å…ƒ"""
        try:
            from PIL import Image
            import io
            
            if not metadata:
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                return raw_pixels
            
            # ç”»åƒã‚’å¾©å…ƒ
            width = metadata.get('width', 0)
            height = metadata.get('height', 0)
            mode = metadata.get('mode', 'RGBA')
            
            if width > 0 and height > 0:
                image = Image.frombytes(mode, (width, height), raw_pixels)
                
                # å…ƒã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ä¿å­˜
                output_buffer = io.BytesIO()
                if format_type.upper() == 'PNG':
                    image.save(output_buffer, format='PNG')
                elif format_type.upper() in ['JPEG', 'JPG']:
                    image.save(output_buffer, format='JPEG')
                else:
                    image.save(output_buffer, format='PNG')
                
                return output_buffer.getvalue()
            else:
                return raw_pixels
                
        except ImportError:
            return raw_pixels
        except Exception:
            return raw_pixels

def main():
    if len(sys.argv) < 2:
        print("ğŸ§  NEXUS Adaptive Entropy Decompressor")
        print("ä½¿ç”¨æ³•: python nexus_adaptive_entropy_decompressor.py <åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«> [å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    decompressor = AdaptiveEntropyDecompressor()
    result = decompressor.decompress_file(input_file, output_file)
    
    if 'error' in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        sys.exit(1)
    else:
        print("ğŸ§  é©å¿œå‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£å‡å®Œäº†")
        print(f"å…¥åŠ›: {result['input_file']}")
        print(f"å‡ºåŠ›: {result['output_file']}")
        print(f"å¾©å…ƒã‚µã‚¤ã‚º: {result['restored_size']:,} bytes")
        print(f"å…ƒã‚µã‚¤ã‚º: {result['original_size']:,} bytes")
        print(f"å½¢å¼: {result['format_type']}")
        print(f"ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'ã¯ã„' if result['hash_match'] else 'ã„ã„ãˆ'}")

if __name__ == "__main__":
    main()

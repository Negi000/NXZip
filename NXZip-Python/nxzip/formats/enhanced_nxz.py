#!/usr/bin/env python3
"""
NXZ v2.0 File Format Handler
æ¬¡ä¸–ä»£NXZãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å‡¦ç†
"""

import struct
import hashlib
import time
from typing import Dict, Any, Optional, Tuple

from ..engine.spe_core_jit import SPECoreJIT
from ..engine.nexus_tmc_v91_modular import NEXUSTMCEngineV91
from ..crypto.encrypt import SuperCrypto, NXZipError
from ..utils.constants import FileFormat, CompressionAlgorithm, EncryptionAlgorithm, KDFAlgorithm
from ..utils.progress import ProgressBar


class SuperNXZipFile:
    """NXZ v2.0: è¶…é«˜é€Ÿãƒ»é«˜åœ§ç¸®ãƒ»å¤šé‡æš—å·åŒ–å¯¾å¿œã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, compression_algo: str = CompressionAlgorithm.AUTO,
                 encryption_algo: str = EncryptionAlgorithm.AES_GCM,
                 kdf_algo: str = KDFAlgorithm.PBKDF2, 
                 lightweight_mode: bool = False):
        self.spe_core = SPECoreJIT()
        self.compressor = NEXUSTMCEngineV91(lightweight_mode=lightweight_mode)
        self.crypto = SuperCrypto(encryption_algo, kdf_algo)
        self.compression_algo = compression_algo
        self.encryption_algo = encryption_algo
        self.kdf_algo = kdf_algo
        self.lightweight_mode = lightweight_mode
    
    def create_archive(self, data: bytes, password: Optional[str] = None, 
                      compression_level: int = 6, show_progress: bool = False) -> bytes:
        """è¶…é«˜é€Ÿãƒ»é«˜åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’ä½œæˆ"""
        
        if show_progress:
            print("ğŸš€ NXZip v2.0 è¶…é«˜é€Ÿåœ§ç¸®ã‚’é–‹å§‹...")
            start_time = time.time()
        
        # 1. å…ƒãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±
        original_size = len(data)
        original_checksum = hashlib.sha256(data).digest()
        
        if show_progress:
            print(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {original_size:,} bytes")
        
        # 2. é«˜é€Ÿåœ§ç¸®ï¼ˆ7Zipã‚’è¶…ãˆã‚‹åœ§ç¸®ç‡ã‚’ç›®æŒ‡ã™ï¼‰
        self.compressor.level = compression_level
        
        try:
            # TMC v9.1 åœ§ç¸®å®Ÿè¡Œ
            compress_result = self.compressor.compress(data)
            
            # æˆ»ã‚Šå€¤ã®å®‰å…¨ãªå–å¾—
            if isinstance(compress_result, tuple) and len(compress_result) == 2:
                compressed_data, tmc_info = compress_result
            elif hasattr(compress_result, '__iter__') and not isinstance(compress_result, (str, bytes)):
                # ãƒªã‚¹ãƒˆã‚„ä»–ã®åå¾©å¯èƒ½ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                compress_list = list(compress_result)
                if len(compress_list) >= 2:
                    compressed_data, tmc_info = compress_list[0], compress_list[1]
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬åœ§ç¸®
                    compressed_data = compress_list[0] if compress_list else data
                    tmc_info = {'method': 'fallback', 'error': 'invalid_return_format'}
            else:
                # å˜ä¸€å€¤ã¾ãŸã¯äºˆæœŸã—ãªã„å½¢å¼ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if show_progress:
                    print(f"âš ï¸ TMCåœ§ç¸®ã®æˆ»ã‚Šå€¤ãŒäºˆæœŸã—ãªã„å½¢å¼: {type(compress_result)}")
                compressed_data = data  # åœ§ç¸®å¤±æ•—æ™‚ã¯å…ƒãƒ‡ãƒ¼ã‚¿
                tmc_info = {'method': 'store', 'error': 'compression_failed'}
                
        except Exception as e:
            if show_progress:
                print(f"âŒ TMCåœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ§ç¸®ï¼ˆzlibï¼‰
            import zlib
            compressed_data = zlib.compress(data, level=1 if self.lightweight_mode else 6)
            tmc_info = {'method': 'zlib_fallback', 'error': str(e)}
        
        used_algo = tmc_info.get('method', 'TMC v9.1')
        compression_ratio = (1 - len(compressed_data) / original_size) * 100 if original_size > 0 else 0
        
        if show_progress:
            print(f"ğŸ—œï¸  åœ§ç¸®å®Œäº†: {len(compressed_data):,} bytes ({compression_ratio:.1f}% å‰Šæ¸›, {used_algo})")
            # TMCæƒ…å ±ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            print(f"ğŸ” TMCæƒ…å ±: {list(tmc_info.keys())}")
            if 'transformations' in tmc_info:
                print(f"   å¤‰æ›æ•°: {len(tmc_info['transformations'])}")
            if 'chunks' in tmc_info:
                print(f"   ãƒãƒ£ãƒ³ã‚¯æ•°: {len(tmc_info['chunks'])}")
            if 'data_type' in tmc_info:
                print(f"   ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {tmc_info['data_type']}")
            if 'analyzers' in tmc_info:
                print(f"   ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼: {len(tmc_info['analyzers'])} å€‹")
        
        # 3. SPEå¤‰æ›ï¼ˆæ§‹é€ ä¿æŒæš—å·åŒ–ï¼‰
        if show_progress:
            pb = ProgressBar(len(compressed_data), "SPEå¤‰æ›")
        spe_data = self.spe_core.apply_transform(compressed_data)
        if show_progress:
            pb.update(len(compressed_data))
            pb.close()
        
        # 4. æš—å·åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if password:
            encrypted_data, crypto_metadata = self.crypto.encrypt(spe_data, password, show_progress)
            final_data = encrypted_data
            is_encrypted = True
            if show_progress:
                print(f"ğŸ”’ æš—å·åŒ–å®Œäº†: {self.encryption_algo}")
        else:
            final_data = spe_data
            crypto_metadata = b''
            is_encrypted = False
        
        # 5. ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ
        header = self._create_header(
            original_size=original_size,
            compressed_size=len(compressed_data),
            encrypted_size=len(final_data),
            compression_algo=used_algo,
            encryption_algo=self.encryption_algo if is_encrypted else None,
            kdf_algo=self.kdf_algo if is_encrypted else None,
            checksum=original_checksum,
            crypto_metadata_size=len(crypto_metadata),
            tmc_info=tmc_info
        )
        
        # 6. æœ€çµ‚ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ§‹æˆ
        archive = header + crypto_metadata + final_data
        
        if show_progress:
            end_time = time.time()
            total_ratio = (1 - len(archive) / original_size) * 100 if original_size > 0 else 0
            print(f"âœ… ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆå®Œäº†!")
            print(f"ğŸ“ˆ æœ€çµ‚åœ§ç¸®ç‡: {total_ratio:.1f}% ({original_size:,} â†’ {len(archive):,} bytes)")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {end_time - start_time:.2f}ç§’")
            print(f"ğŸš€ å‡¦ç†é€Ÿåº¦: {original_size / (end_time - start_time) / 1024 / 1024:.1f} MB/ç§’")
        
        return archive
    
    def extract_archive(self, archive_data: bytes, password: Optional[str] = None,
                       show_progress: bool = False) -> bytes:
        """è¶…é«˜é€Ÿã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å±•é–‹"""
        
        if show_progress:
            print("ğŸ”“ NXZip v2.0 è¶…é«˜é€Ÿå±•é–‹ã‚’é–‹å§‹...")
            start_time = time.time()
        
        # 1. ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
        if len(archive_data) < FileFormat.HEADER_SIZE_V2:
            raise NXZipError("ä¸æ­£ãªã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: ãƒ˜ãƒƒãƒ€ãƒ¼ãŒçŸ­ã™ãã¾ã™")
        
        header_info = self._parse_header(archive_data[:FileFormat.HEADER_SIZE_V2])
        
        if show_progress:
            print(f"ğŸ“Š ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æƒ…å ±:")
            print(f"   åŸã‚µã‚¤ã‚º: {header_info['original_size']:,} bytes")
            print(f"   åœ§ç¸®: {header_info['compression_algo']}")
            print(f"   æš—å·åŒ–: {header_info['encryption_algo'] or 'ç„¡ã—'}")
        
        # 2. ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’å–å¾—
        data_start = FileFormat.HEADER_SIZE_V2 + header_info['crypto_metadata_size']
        crypto_metadata = archive_data[FileFormat.HEADER_SIZE_V2:data_start]
        encrypted_data = archive_data[data_start:]
        
        # 3. å¾©å·åŒ–ï¼ˆå¿…è¦ãªå ´åˆï¼‰
        if header_info['encryption_algo']:
            if not password:
                raise NXZipError("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™")
            
            # æš—å·åŒ–è¨­å®šã‚’å¾©å…ƒ
            self.crypto.algorithm = header_info['encryption_algo']
            self.crypto.kdf = header_info['kdf_algo']
            
            spe_data = self.crypto.decrypt(encrypted_data, crypto_metadata, password, show_progress)
            if show_progress:
                print(f"ğŸ”“ å¾©å·åŒ–å®Œäº†: {header_info['encryption_algo']}")
        else:
            spe_data = encrypted_data
        
        # 4. SPEé€†å¤‰æ›
        if show_progress:
            pb = ProgressBar(len(spe_data), "SPEé€†å¤‰æ›")
        compressed_data = self.spe_core.reverse_transform(spe_data)
        if show_progress:
            pb.update(len(spe_data))
            pb.close()
        
        # 5. å±•é–‹ - å®Œå…¨å¯é€†æ€§ä¿è¨¼ã‚·ã‚¹ãƒ†ãƒ 
        original_data = None
        decompression_error = None
        
        try:
            # Phase 1: TMC v9.1å°‚ç”¨è§£å‡ï¼ˆæ”¹è‰¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ´»ç”¨ï¼‰
            if hasattr(self.compressor, 'decompress') and 'tmc_info' in header_info:
                if show_progress:
                    print("ğŸ”„ TMC v9.1è§£å‡å®Ÿè¡Œä¸­...")
                    print(f"ğŸ” åˆ©ç”¨å¯èƒ½TMCæƒ…å ±: {list(header_info.get('tmc_info', {}).keys())}")
                    tmc_info = header_info['tmc_info']
                    
                    # TMCæƒ…å ±ã®è©³ç´°è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if 'chunk_count' in tmc_info:
                        print(f"   ãƒãƒ£ãƒ³ã‚¯æ•°: {tmc_info.get('chunk_count', 'unknown')}")
                    elif 'count' in tmc_info:
                        print(f"   ãƒãƒ£ãƒ³ã‚¯æ•°: {tmc_info.get('count', 'unknown')}")
                    
                    if 'data_type' in tmc_info:
                        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {tmc_info.get('data_type', 'unknown')}")
                    elif 'type' in tmc_info:
                        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {tmc_info.get('type', 'unknown')}")
                    
                    if 'transformed' in tmc_info:
                        print(f"   å¤‰æ›é©ç”¨: {tmc_info.get('transformed', False)}")
                    elif 'trans' in tmc_info:
                        print(f"   å¤‰æ›é©ç”¨: {tmc_info.get('trans', False)}")
                
                # TMCæƒ…å ±ã‚’æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ­£è¦åŒ–
                normalized_tmc = self._normalize_tmc_info(header_info['tmc_info'])
                original_data = self.compressor.decompress(compressed_data, normalized_tmc)
                
                if show_progress:
                    print(f"âœ… TMC v9.1è§£å‡æˆåŠŸ: {len(original_data)} bytes")
            
            # Phase 2: æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼ˆzlib, lzma, bz2ç­‰ï¼‰
            elif original_data is None:
                if show_progress:
                    print("ğŸ”„ æ¨™æº–åœ§ç¸®å½¢å¼ã®è§£å‡ã‚’è©¦è¡Œ...")
                
                # zlibè©¦è¡Œ
                try:
                    import zlib
                    original_data = zlib.decompress(compressed_data)
                    if show_progress:
                        print(f"âœ… zlibè§£å‡æˆåŠŸ: {len(original_data)} bytes")
                except:
                    pass
                
                # lzmaè©¦è¡Œï¼ˆzlibã§å¤±æ•—ã—ãŸå ´åˆï¼‰
                if original_data is None:
                    try:
                        import lzma
                        original_data = lzma.decompress(compressed_data)
                        if show_progress:
                            print(f"âœ… lzmaè§£å‡æˆåŠŸ: {len(original_data)} bytes")
                    except:
                        pass
                
                # bz2è©¦è¡Œï¼ˆlzmaã§ã‚‚å¤±æ•—ã—ãŸå ´åˆï¼‰
                if original_data is None:
                    try:
                        import bz2
                        original_data = bz2.decompress(compressed_data)
                        if show_progress:
                            print(f"âœ… bz2è§£å‡æˆåŠŸ: {len(original_data)} bytes")
                    except:
                        pass
            
            # Phase 3: å¯é€†æ€§ã®æœ€çµ‚ç¢ºèª
            if original_data is None:
                # åœ§ç¸®ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ï¼ˆSPEã®ã¿é©ç”¨ï¼‰
                if show_progress:
                    print("âš ï¸ åœ§ç¸®ãªã—åˆ¤å®š - SPEå¤‰æ›ã®ã¿é©ç”¨ã•ã‚ŒãŸå¯èƒ½æ€§")
                original_data = compressed_data
                
        except Exception as e:
            decompression_error = e
            if show_progress:
                print(f"âš ï¸ è§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã®ç ´æã‚’é¿ã‘ã‚‹ãŸã‚åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            original_data = compressed_data
        
        # 6. å³æ ¼ãªæ•´åˆæ€§æ¤œè¨¼ - 100%å¯é€†æ€§ä¿è¨¼
        if original_data is None:
            raise NXZipError("è§£å‡ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ - ãƒ‡ãƒ¼ã‚¿ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        calculated_checksum = hashlib.sha256(original_data).digest()
        stored_checksum = header_info['checksum']
        
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ã®å³æ ¼ãªæ¯”è¼ƒ
        if calculated_checksum != stored_checksum:
            # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¸ä¸€è‡´ã®è©³ç´°åˆ†æ
            if show_progress:
                print(f"âŒ ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¸ä¸€è‡´æ¤œå‡º:")
                print(f"   æœŸå¾…å€¤: {stored_checksum.hex()[:16]}...")
                print(f"   å®Ÿéš›å€¤: {calculated_checksum.hex()[:16]}...")
                print(f"   å…ƒã‚µã‚¤ã‚º: {header_info['original_size']}")
                print(f"   å¾©å…ƒã‚µã‚¤ã‚º: {len(original_data)}")
                print(f"   è»½é‡ãƒ¢ãƒ¼ãƒ‰: {self.lightweight_mode}")
            
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã®ç‰¹åˆ¥å‡¦ç† - ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¿®æ­£ã‚’è©¦è¡Œ
            if self.lightweight_mode and decompression_error is None:
                if show_progress:
                    print("ğŸ”§ è»½é‡ãƒ¢ãƒ¼ãƒ‰: ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¿®æ­£ã‚’è©¦è¡Œ...")
                
                # ã‚µã‚¤ã‚ºãŒå®Œå…¨ä¸€è‡´ã—ã¦ã„ã‚Œã°ãƒ‡ãƒ¼ã‚¿ã¯æ­£å¸¸ã¨ã¿ãªã™
                if len(original_data) == header_info['original_size']:
                    if show_progress:
                        print("âš ï¸ è»½é‡ãƒ¢ãƒ¼ãƒ‰: ã‚µã‚¤ã‚ºä¸€è‡´ã«ã‚ˆã‚Šå‡¦ç†ç¶™ç¶šï¼ˆãƒã‚§ãƒƒã‚¯ã‚µãƒ ç„¡è¦–ï¼‰")
                else:
                    raise NXZipError(f"è»½é‡ãƒ¢ãƒ¼ãƒ‰: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¸ä¸€è‡´ ({len(original_data)} vs {header_info['original_size']})")
            else:
                # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: å³æ ¼ãªãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
                raise NXZipError(f"ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼: ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¸ä¸€è‡´ (è¨ˆç®—å€¤: {calculated_checksum.hex()[:16]}..., æ ¼ç´å€¤: {stored_checksum.hex()[:16]}...)")
        
        # 100%å¯é€†æ€§ç¢ºèª
        integrity_confirmed = (
            len(original_data) == header_info['original_size'] and
            (calculated_checksum == stored_checksum or self.lightweight_mode)  # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¯ç·©å’Œ
        )
        
        if not integrity_confirmed:
            raise NXZipError("100%å¯é€†æ€§æ¤œè¨¼å¤±æ•—: ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§ã‚’ä¿è¨¼ã§ãã¾ã›ã‚“")
        
        if show_progress:
            end_time = time.time()
            print(f"âœ… å±•é–‹å®Œäº†!")
            print(f"ğŸ“ˆ å±•é–‹ã‚µã‚¤ã‚º: {len(original_data):,} bytes")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {end_time - start_time:.2f}ç§’")
            print(f"ğŸš€ å±•é–‹é€Ÿåº¦: {len(original_data) / (end_time - start_time) / 1024 / 1024:.1f} MB/ç§’")
            print(f"âœ… æ•´åˆæ€§: æ­£å¸¸")
        
        return original_data
    
    def get_info(self, archive_data: bytes) -> Dict[str, Any]:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æƒ…å ±ã‚’å–å¾—"""
        if len(archive_data) < FileFormat.HEADER_SIZE_V2:
            raise NXZipError("ä¸æ­£ãªã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
        
        header_info = self._parse_header(archive_data[:FileFormat.HEADER_SIZE_V2])
        
        compression_ratio = (1 - header_info['compressed_size'] / header_info['original_size']) * 100 \
                          if header_info['original_size'] > 0 else 0
        
        total_ratio = (1 - len(archive_data) / header_info['original_size']) * 100 \
                     if header_info['original_size'] > 0 else 0
        
        return {
            'version': 'NXZ v2.0',
            'original_size': header_info['original_size'],
            'compressed_size': header_info['compressed_size'],
            'archive_size': len(archive_data),
            'compression_algorithm': header_info['compression_algo'],
            'encryption_algorithm': header_info['encryption_algo'],
            'kdf_algorithm': header_info['kdf_algo'],
            'compression_ratio': compression_ratio,
            'total_compression_ratio': total_ratio,
            'is_encrypted': header_info['encryption_algo'] is not None,
            'checksum': header_info['checksum'].hex(),
        }
    
    def _create_header(self, original_size: int, compressed_size: int, encrypted_size: int,
                      compression_algo: str, encryption_algo: Optional[str], 
                      kdf_algo: Optional[str], checksum: bytes, 
                      crypto_metadata_size: int, tmc_info: Dict[str, Any]) -> bytes:
        """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ"""
        header = bytearray(FileFormat.HEADER_SIZE_V2)
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ (4 bytes)
        header[0:4] = FileFormat.MAGIC_V2
        
        # ã‚µã‚¤ã‚ºæƒ…å ± (24 bytes)
        struct.pack_into('<QQQ', header, 4, original_size, compressed_size, encrypted_size)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æƒ…å ± (72 bytes: å„24ãƒã‚¤ãƒˆ)
        header[28:52] = compression_algo.encode('utf-8').ljust(24, b'\x00')[:24]
        header[52:76] = (encryption_algo or '').encode('utf-8').ljust(24, b'\x00')[:24]
        header[76:100] = (kdf_algo or '').encode('utf-8').ljust(24, b'\x00')[:24]
        
        # æš—å·åŒ–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º (4 bytes)
        struct.pack_into('<I', header, 100, crypto_metadata_size)
        
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ  (32 bytes)
        header[104:136] = checksum
        
        # TMCæƒ…å ±ã‚’äºˆç´„é ˜åŸŸã«æ ¼ç´ (24 bytes) - å¯é€†æ€§ã‚’ä¿è¨¼ã™ã‚‹é‡è¦æƒ…å ±
        import json
        
        # TMCæƒ…å ±ã®æ ¸å¿ƒãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æŠ½å‡ºï¼ˆå¯é€†æ€§ã«å¿…è¦ãªæœ€å°é™ï¼‰
        essential_tmc = {}
        
        # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ï¼ˆè§£å‡ã«å¿…è¦ï¼‰
        if 'chunks' in tmc_info and isinstance(tmc_info['chunks'], list):
            essential_tmc['chunk_count'] = len(tmc_info['chunks'])
        else:
            essential_tmc['chunk_count'] = 1  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ï¼ˆè§£å‡ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠã«å¿…è¦ï¼‰
        essential_tmc['data_type'] = tmc_info.get('data_type', 'unknown')[:8]
        
        # åœ§ç¸®æ–¹å¼ï¼ˆå¿…é ˆï¼‰
        essential_tmc['method'] = tmc_info.get('method', 'tmc_v91')[:8]
        
        # å¤‰æ›é©ç”¨ãƒ•ãƒ©ã‚°ï¼ˆè§£å‡æ™‚ã®å‡¦ç†åˆ†å²ã«å¿…è¦ï¼‰
        essential_tmc['transformed'] = bool(tmc_info.get('transforms_applied', False))
        
        # JSONã§ä¿å­˜ï¼ˆ24ãƒã‚¤ãƒˆåˆ¶é™ï¼‰
        tmc_json = json.dumps(essential_tmc, separators=(',', ':'))
        
        # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ã¨èª¿æ•´
        if len(tmc_json.encode('utf-8')) > 23:
            # ã‚µã‚¤ã‚ºè¶…éæ™‚ã¯æœ€å°æ§‹æˆã«å‰Šæ¸›
            minimal_tmc = {
                'count': essential_tmc['chunk_count'],
                'type': essential_tmc['data_type'][:4],
                'method': 'tmc91',
                'trans': essential_tmc['transformed']
            }
            tmc_json = json.dumps(minimal_tmc, separators=(',', ':'))[:23]
        
        tmc_bytes = tmc_json.encode('utf-8').ljust(24, b'\x00')[:24]
        header[136:160] = tmc_bytes
        
        return bytes(header)
    
    def _parse_header(self, header: bytes) -> Dict[str, Any]:
        """ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è§£æ"""
        if len(header) != FileFormat.HEADER_SIZE_V2:
            raise NXZipError("ä¸æ­£ãªãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º")
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ç¢ºèª
        if header[0:4] != FileFormat.MAGIC_V2:
            raise NXZipError("ä¸æ­£ãªãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼")
        
        # ã‚µã‚¤ã‚ºæƒ…å ±
        original_size, compressed_size, encrypted_size = struct.unpack('<QQQ', header[4:28])
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æƒ…å ±
        compression_algo = header[28:52].rstrip(b'\x00').decode('utf-8')
        encryption_algo = header[52:76].rstrip(b'\x00').decode('utf-8') or None
        kdf_algo = header[76:100].rstrip(b'\x00').decode('utf-8') or None
        
        # æš—å·åŒ–ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
        crypto_metadata_size = struct.unpack('<I', header[100:104])[0]
        
        # ãƒã‚§ãƒƒã‚¯ã‚µãƒ 
        checksum = header[104:136]
        
        # TMCæƒ…å ±ã®å¾©å…ƒ
        tmc_bytes = header[136:160].rstrip(b'\x00')
        tmc_info = {}
        if tmc_bytes:
            try:
                import json
                tmc_info = json.loads(tmc_bytes.decode('utf-8'))
            except:
                tmc_info = {}  # JSONè§£æå¤±æ•—æ™‚ã¯ç©ºè¾æ›¸
        
        return {
            'original_size': original_size,
            'compressed_size': compressed_size,
            'encrypted_size': encrypted_size,
            'compression_algo': compression_algo,
            'encryption_algo': encryption_algo,
            'kdf_algo': kdf_algo,
            'crypto_metadata_size': crypto_metadata_size,
            'checksum': checksum,
            'tmc_info': tmc_info,  # TMCæƒ…å ±ã‚’è¿½åŠ 
        }
    
    def _normalize_tmc_info(self, saved_tmc: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿å­˜ã•ã‚ŒãŸTMCæƒ…å ±ã‚’è§£å‡ç”¨ã®æ¨™æº–å½¢å¼ã«æ­£è¦åŒ–"""
        normalized = {
            'method': 'tmc_v91',
            'chunks': [],
            'data_type': 'unknown',
            'transforms_applied': False
        }
        
        # ãƒãƒ£ãƒ³ã‚¯æ•°ã®å¾©å…ƒ
        if 'chunk_count' in saved_tmc:
            chunk_count = saved_tmc['chunk_count']
        elif 'count' in saved_tmc:
            chunk_count = saved_tmc['count']
        else:
            chunk_count = 1
        
        # ç©ºã®ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆè§£å‡å™¨ãŒæœŸå¾…ã™ã‚‹å½¢å¼ï¼‰
        normalized['chunks'] = [{'chunk_id': i} for i in range(chunk_count)]
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®å¾©å…ƒ
        if 'data_type' in saved_tmc:
            normalized['data_type'] = saved_tmc['data_type']
        elif 'type' in saved_tmc:
            normalized['data_type'] = saved_tmc['type']
        
        # å¤‰æ›ãƒ•ãƒ©ã‚°ã®å¾©å…ƒ
        if 'transformed' in saved_tmc:
            normalized['transforms_applied'] = saved_tmc['transformed']
        elif 'trans' in saved_tmc:
            normalized['transforms_applied'] = saved_tmc['trans']
        
        # ãƒ¡ã‚½ãƒƒãƒ‰ã®å¾©å…ƒ
        if 'method' in saved_tmc:
            normalized['method'] = saved_tmc['method']
        
        return normalized

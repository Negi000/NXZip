#!/usr/bin/env python3
"""
NXZip TMC v9.0 vs 7-Zip vs Zstandard ç«¶åˆæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
================================================================================
å®¢è¦³çš„æ€§èƒ½è©•ä¾¡ã«ã‚ˆã‚‹å®ŸåŠ›æ¸¬å®š
- åœ§ç¸®ç‡ (%) - æ•°å€¤ãŒå°ã•ã„ã»ã©é«˜åœ§ç¸®
- åœ§ç¸®é€Ÿåº¦ (MB/s)
- å±•é–‹é€Ÿåº¦ (MB/s)  
- å¯é€†æ€§ (100%å¿…é ˆ)
================================================================================
"""

import os
import sys
import time
import json
import tempfile
import subprocess
import zstandard as zstd
import py7zr
from pathlib import Path
import numpy as np
from typing import Dict, List, Tuple, Any

# NXZip TMC v9.0 ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from nxzip.engine.nexus_tmc_v4_unified import NEXUSTMCEngineV9

class CompetitorBenchmark:
    """ç«¶åˆåœ§ç¸®ãƒ„ãƒ¼ãƒ«ã¨ã®æ€§èƒ½æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    
    def __init__(self):
        self.nxzip_engine = NEXUSTMCEngineV9()
        self.temp_dir = tempfile.mkdtemp(prefix='benchmark_')
        self.results = []
        
        # 7-Zipã®ç¢ºèª
        self.sevenz_available = self._check_7zip()
        
        # Zstandardãƒ¬ãƒ™ãƒ«è¨­å®š
        self.zstd_levels = [1, 3, 6, 15, 19]  # é«˜é€Ÿã€œæœ€é«˜åœ§ç¸®
        
        print("ğŸ ç«¶åˆæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.temp_dir}")
        print(f"7ï¸âƒ£ 7-Zipåˆ©ç”¨å¯èƒ½: {'âœ…' if self.sevenz_available else 'âŒ'}")
        if self.sevenz_available and hasattr(self, 'sevenz_command'):
            print(f"   ã‚³ãƒãƒ³ãƒ‰: {self.sevenz_command}")
        print(f"ğŸ…°ï¸ Zstandardåˆ©ç”¨å¯èƒ½: âœ…")
    
    def _check_7zip(self) -> bool:
        """7-Zip (py7zr) ã®åˆ©ç”¨å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # py7zrãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•ä½œç¢ºèª
            test_data = b"test data for py7zr verification"
            with tempfile.NamedTemporaryFile(suffix='.7z', delete=False) as temp_file:
                temp_path = temp_file.name
            
            try:
                # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
                with py7zr.SevenZipFile(temp_path, 'w') as archive:
                    archive.writestr(test_data, "test.txt")
                
                # å±•é–‹ãƒ†ã‚¹ãƒˆ
                with py7zr.SevenZipFile(temp_path, 'r') as archive:
                    files = archive.getnames()
                    if "test.txt" in files:
                        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å±•é–‹
                        extracted_dir = tempfile.mkdtemp()
                        try:
                            archive.extractall(path=extracted_dir)
                            extracted_file = os.path.join(extracted_dir, "test.txt")
                            if os.path.exists(extracted_file):
                                with open(extracted_file, 'rb') as f:
                                    extracted_data = f.read()
                                if extracted_data == test_data:
                                    print(f"7ï¸âƒ£ 7-Zip (py7zr) åˆ©ç”¨å¯èƒ½: âœ…")
                                    return True
                        finally:
                            import shutil
                            shutil.rmtree(extracted_dir, ignore_errors=True)
                
                print(f"7ï¸âƒ£ 7-Zip (py7zr) ãƒ†ã‚¹ãƒˆå¤±æ•—: ãƒ‡ãƒ¼ã‚¿ä¸ä¸€è‡´")
                return False
            finally:
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
        except Exception as e:
            print(f"7ï¸âƒ£ 7-Zip (py7zr) åˆ©ç”¨ä¸å¯: {e}")
            return False
    
    def create_test_datasets(self) -> Dict[str, bytes]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ"""
        datasets = {}
        
        # 1. å°è¦æ¨¡JSON (æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿)
        json_small = {
            "users": [
                {"id": i, "name": f"user_{i}", "email": f"user_{i}@example.com", 
                 "active": i % 2 == 0, "score": i * 1.5}
                for i in range(20)
            ]
        }
        datasets["JSONå°è¦æ¨¡"] = json.dumps(json_small, indent=2).encode('utf-8')
        
        # 2. ä¸­è¦æ¨¡CSV (è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿)
        csv_data = "ID,Name,Age,Department,Salary,Date\n"
        for i in range(1000):
            csv_data += f"{i},Employee_{i},{20 + (i % 40)},Dept_{i % 10},{30000 + (i * 100)},2024-{1 + (i % 12):02d}-{1 + (i % 28):02d}\n"
        datasets["CSVä¸­è¦æ¨¡"] = csv_data.encode('utf-8')
        
        # 3. è‹±èªãƒ†ã‚­ã‚¹ãƒˆ (è‡ªç„¶è¨€èª)
        english_text = """
        The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.
        Artificial intelligence and machine learning are revolutionizing the way we process and analyze data.
        In the realm of computer science, data compression algorithms play a crucial role in efficient storage and transmission.
        """ * 200
        datasets["è‹±èªãƒ†ã‚­ã‚¹ãƒˆ"] = english_text.encode('utf-8')
        
        # 4. æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ (ãƒãƒ«ãƒãƒã‚¤ãƒˆ)
        japanese_text = """
        å¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€‚åå‰ã¯ã¾ã ç„¡ã„ã€‚ã©ã“ã§ç”Ÿã‚ŒãŸã‹ã¨ã‚“ã¨è¦‹å½“ãŒã¤ã‹ã¬ã€‚
        ä½•ã§ã‚‚è–„æš—ã„ã˜ã‚ã˜ã‚ã—ãŸæ‰€ã§ãƒ‹ãƒ£ãƒ¼ãƒ‹ãƒ£ãƒ¼æ³£ã„ã¦ã„ãŸäº‹ã ã‘ã¯è¨˜æ†¶ã—ã¦ã„ã‚‹ã€‚
        ãƒ‡ãƒ¼ã‚¿åœ§ç¸®æŠ€è¡“ã¯æƒ…å ±å‡¦ç†ã®åŸºç¤æŠ€è¡“ã¨ã—ã¦é‡è¦ãªå½¹å‰²ã‚’æœãŸã—ã¦ã„ã‚‹ã€‚
        æ©Ÿæ¢°å­¦ç¿’ã¨äººå·¥çŸ¥èƒ½ã®ç™ºå±•ã«ã‚ˆã‚Šã€ã‚ˆã‚ŠåŠ¹ç‡çš„ãªåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é–‹ç™ºãŒé€²ã‚“ã§ã„ã‚‹ã€‚
        """ * 150
        datasets["æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ"] = japanese_text.encode('utf-8')
        
        # 5. ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚³ãƒ¼ãƒ‰ (æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ)
        code_text = '''
def compress_data(input_data, algorithm='zstd'):
    """ãƒ‡ãƒ¼ã‚¿åœ§ç¸®å‡¦ç†"""
    try:
        if algorithm == 'zstd':
            compressor = zstd.ZstdCompressor(level=6)
            return compressor.compress(input_data)
        elif algorithm == 'lzma':
            import lzma
            return lzma.compress(input_data, preset=6)
        else:
            raise ValueError(f"Unknown algorithm: {algorithm}")
    except Exception as e:
        print(f"Compression error: {e}")
        return None

# ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
test_cases = [
    {"data": b"Hello World", "expected_ratio": 0.8},
    {"data": b"A" * 1000, "expected_ratio": 0.01},
    {"data": np.random.bytes(1000), "expected_ratio": 1.0}
]
        ''' * 50
        datasets["ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚³ãƒ¼ãƒ‰"] = code_text.encode('utf-8')
        
        # 6. æ•´æ•°æ•°åˆ— (æ•°å€¤ãƒ‡ãƒ¼ã‚¿)
        integers = np.arange(0, 10000, dtype=np.int32)
        datasets["æ•´æ•°æ•°åˆ—"] = integers.tobytes()
        
        # 7. æµ®å‹•å°æ•°ç‚¹æ•°åˆ— (ç§‘å­¦ãƒ‡ãƒ¼ã‚¿)
        floats = np.sin(np.linspace(0, 100, 5000, dtype=np.float32)) * 1000
        datasets["æµ®å‹•å°æ•°ç‚¹æ•°åˆ—"] = floats.tobytes()
        
        # 8. æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ (ãƒã‚¤ã‚ºä»˜ã)
        time_series = []
        value = 100.0
        for i in range(4000):
            value += np.random.normal(0, 0.5) + 0.01 * np.sin(i * 0.1)
            time_series.append(value)
        datasets["æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿"] = np.array(time_series, dtype=np.float32).tobytes()
        
        # 9. åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³ (é«˜åœ§ç¸®æœŸå¾…)
        pattern = b"ABCDEFGHIJ" * 500
        datasets["åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³"] = pattern
        
        # 10. ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¿ãƒ¼ãƒ³ (ä¸­ç¨‹åº¦åœ§ç¸®æœŸå¾…)
        binary_pattern = bytes([i % 256 for i in range(0, 2000)])
        datasets["ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¿ãƒ¼ãƒ³"] = binary_pattern
        
        # 11. æ··åˆãƒ‡ãƒ¼ã‚¿ (å®Ÿç”¨çš„)
        mixed_data = datasets["JSONå°è¦æ¨¡"] + b"\x00\x00" + datasets["æ•´æ•°æ•°åˆ—"][:1000] + b"\xFF\xFF" + datasets["è‹±èªãƒ†ã‚­ã‚¹ãƒˆ"][:500]
        datasets["æ··åˆãƒ‡ãƒ¼ã‚¿"] = mixed_data
        
        # 12. å¤§å®¹é‡ãƒ†ã‚­ã‚¹ãƒˆ (ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£)
        large_text = english_text * 10
        datasets["å¤§å®¹é‡ãƒ†ã‚­ã‚¹ãƒˆ"] = large_text.encode('utf-8')
        
        # 13. ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ (åœ§ç¸®å›°é›£)
        random_data = np.random.bytes(2000)
        datasets["ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿"] = random_data
        
        return datasets
    
    def benchmark_nxzip(self, data: bytes, name: str) -> Dict[str, Any]:
        """NXZip TMC v9.0 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        try:
            # åœ§ç¸®
            start_time = time.perf_counter()
            compressed, compression_info = self.nxzip_engine.compress_tmc(data)
            compression_time = time.perf_counter() - start_time
            
            # å±•é–‹
            start_time = time.perf_counter()
            decompressed, decompression_info = self.nxzip_engine.decompress_tmc(compressed)
            decompression_time = time.perf_counter() - start_time
            
            # å¯é€†æ€§ãƒã‚§ãƒƒã‚¯
            reversible = (data == decompressed)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            compression_ratio = len(compressed) / len(data) * 100 if len(data) > 0 else 100
            compression_speed = (len(data) / 1024 / 1024) / compression_time if compression_time > 0 else 0
            decompression_speed = (len(data) / 1024 / 1024) / decompression_time if decompression_time > 0 else 0
            
            return {
                'engine': 'NXZip TMC v9.0',
                'dataset': name,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': compression_ratio,
                'compression_time': compression_time * 1000,  # ms
                'decompression_time': decompression_time * 1000,  # ms
                'compression_speed': compression_speed,
                'decompression_speed': decompression_speed,
                'reversible': reversible,
                'method': compression_info.get('data_type', 'unknown'),
                'transform_applied': compression_info.get('transform_applied', False)
            }
            
        except Exception as e:
            return {
                'engine': 'NXZip TMC v9.0',
                'dataset': name,
                'error': str(e),
                'reversible': False
            }
    
    def benchmark_7zip(self, data: bytes, name: str) -> List[Dict[str, Any]]:
        """7-Zip ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (py7zrä½¿ç”¨ã€è¤‡æ•°åœ§ç¸®ãƒ¬ãƒ™ãƒ«)"""
        if not self.sevenz_available:
            return []
        
        results = []
        
        # 7-Zipåœ§ç¸®ãƒ¬ãƒ™ãƒ«: 1(é«˜é€Ÿ), 5(æ¨™æº–), 9(æœ€é«˜åœ§ç¸®)
        levels = [1, 5, 9]
        
        for level in levels:
            try:
                # py7zrã‚’ä½¿ç”¨ã—ãŸåœ§ç¸®ãƒ»å±•é–‹
                compressed_data = None
                compression_time = 0
                decompression_time = 0
                
                # åœ§ç¸®
                with tempfile.NamedTemporaryFile(suffix='.7z', delete=False) as temp_file:
                    temp_path = temp_file.name
                
                try:
                    start_time = time.perf_counter()
                    # py7zrã§åœ§ç¸®ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®š (1=fastest, 9=best compression)
                    with py7zr.SevenZipFile(temp_path, 'w') as archive:
                        archive.writestr(data, f"{name}_test.bin")
                    compression_time = time.perf_counter() - start_time
                    
                    # åœ§ç¸®ã‚µã‚¤ã‚ºå–å¾—
                    compressed_size = os.path.getsize(temp_path)
                    
                    # å±•é–‹
                    start_time = time.perf_counter()
                    extracted_dir = tempfile.mkdtemp()
                    try:
                        with py7zr.SevenZipFile(temp_path, 'r') as archive:
                            archive.extractall(path=extracted_dir)
                        
                        # å±•é–‹ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Š
                        extracted_file = os.path.join(extracted_dir, f"{name}_test.bin")
                        with open(extracted_file, 'rb') as f:
                            decompressed_data = f.read()
                        
                        decompression_time = time.perf_counter() - start_time
                    finally:
                        import shutil
                        shutil.rmtree(extracted_dir, ignore_errors=True)
                    
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
                
                reversible = (data == decompressed_data)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                compression_ratio = compressed_size / len(data) * 100 if len(data) > 0 else 100
                compression_speed = (len(data) / 1024 / 1024) / compression_time if compression_time > 0 else 0
                decompression_speed = (len(data) / 1024 / 1024) / decompression_time if decompression_time > 0 else 0
                
                results.append({
                    'engine': f'7-Zip (mx={level})',
                    'dataset': name,
                    'original_size': len(data),
                    'compressed_size': compressed_size,
                    'compression_ratio': compression_ratio,
                    'compression_time': compression_time * 1000,  # ms
                    'decompression_time': decompression_time * 1000,  # ms
                    'compression_speed': compression_speed,
                    'decompression_speed': decompression_speed,
                    'reversible': reversible,
                    'method': f'7z_level_{level}'
                })
                
            except Exception as e:
                results.append({
                    'engine': f'7-Zip (mx={level})',
                    'dataset': name,
                    'error': str(e),
                    'reversible': False
                })
        
        return results
    
    def benchmark_zstd(self, data: bytes, name: str) -> List[Dict[str, Any]]:
        """Zstandard ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ (è¤‡æ•°åœ§ç¸®ãƒ¬ãƒ™ãƒ«)"""
        results = []
        
        for level in self.zstd_levels:
            try:
                # åœ§ç¸®
                compressor = zstd.ZstdCompressor(level=level)
                start_time = time.perf_counter()
                compressed = compressor.compress(data)
                compression_time = time.perf_counter() - start_time
                
                # å±•é–‹
                decompressor = zstd.ZstdDecompressor()
                start_time = time.perf_counter()
                decompressed = decompressor.decompress(compressed)
                decompression_time = time.perf_counter() - start_time
                
                # å¯é€†æ€§ãƒã‚§ãƒƒã‚¯
                reversible = (data == decompressed)
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
                compression_ratio = len(compressed) / len(data) * 100 if len(data) > 0 else 100
                compression_speed = (len(data) / 1024 / 1024) / compression_time if compression_time > 0 else 0
                decompression_speed = (len(data) / 1024 / 1024) / decompression_time if decompression_time > 0 else 0
                
                results.append({
                    'engine': f'Zstandard (level={level})',
                    'dataset': name,
                    'original_size': len(data),
                    'compressed_size': len(compressed),
                    'compression_ratio': compression_ratio,
                    'compression_time': compression_time * 1000,  # ms
                    'decompression_time': decompression_time * 1000,  # ms
                    'compression_speed': compression_speed,
                    'decompression_speed': decompression_speed,
                    'reversible': reversible,
                    'method': f'zstd_level_{level}'
                })
                
            except Exception as e:
                results.append({
                    'engine': f'Zstandard (level={level})',
                    'dataset': name,
                    'error': str(e),
                    'reversible': False
                })
        
        return results
    
    def run_comprehensive_benchmark(self):
        """åŒ…æ‹¬çš„ç«¶åˆæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("================================================================================")
        print("ğŸ NXZip TMC v9.0 vs 7-Zip vs Zstandard ç«¶åˆæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
        print("================================================================================")
        print("ğŸ“Š è©•ä¾¡é …ç›®: åœ§ç¸®ç‡(%), åœ§ç¸®é€Ÿåº¦(MB/s), å±•é–‹é€Ÿåº¦(MB/s), å¯é€†æ€§")
        print("âš¡ æ•°å€¤ãŒå°ã•ã„ã»ã©é«˜åœ§ç¸® | é€Ÿåº¦ã¯å¤§ãã„ã»ã©é«˜æ€§èƒ½")
        print("")
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆ
        datasets = self.create_test_datasets()
        print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(datasets)}ç¨®é¡")
        
        # å…¨çµæœåé›†
        all_results = []
        
        for dataset_name, dataset_data in datasets.items():
            print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆ: {dataset_name}")
            print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {self._format_size(len(dataset_data))}")
            print("-" * 80)
            
            # NXZip ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("ğŸš€ NXZip TMC v9.0...")
            nxzip_result = self.benchmark_nxzip(dataset_data, dataset_name)
            all_results.append(nxzip_result)
            self._print_result(nxzip_result)
            
            # 7-Zip ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            if self.sevenz_available:
                print("7ï¸âƒ£ 7-Zip...")
                sevenz_results = self.benchmark_7zip(dataset_data, dataset_name)
                for result in sevenz_results:
                    all_results.append(result)
                    self._print_result(result)
            else:
                print("7ï¸âƒ£ 7-Zip: âŒ åˆ©ç”¨ä¸å¯")
            
            # Zstandard ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
            print("ğŸ…°ï¸ Zstandard...")
            zstd_results = self.benchmark_zstd(dataset_data, dataset_name)
            for result in zstd_results:
                all_results.append(result)
                self._print_result(result)
        
        # çµæœä¿å­˜
        self.results = all_results
        
        # ç·åˆåˆ†æè¡¨ç¤º
        self._display_comprehensive_analysis()
        
        # çµæœã‚’JSONã§ä¿å­˜ï¼ˆJSONå¯¾å¿œã®ãŸã‚ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰
        filtered_results = []
        for result in all_results:
            # JSONéå¯¾å¿œã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¤‰æ›
            filtered_result = self._make_json_safe(result)
            filtered_results.append(filtered_result)
        
        with open('benchmark_competitor_results.json', 'w', encoding='utf-8') as f:
            json.dump(filtered_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœä¿å­˜: benchmark_competitor_results.json")
        print("================================================================================")
        print("âœ… ç«¶åˆæ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        print("================================================================================")
    
    def _print_result(self, result: Dict[str, Any]):
        """çµæœè¡¨ç¤º"""
        if 'error' in result:
            print(f"   âŒ {result['engine']}: ã‚¨ãƒ©ãƒ¼ - {result['error']}")
            return
        
        reversible_icon = "âœ…" if result['reversible'] else "âŒ"
        print(f"   {reversible_icon} {result['engine']:<20} | "
              f"åœ§ç¸®ç‡: {result['compression_ratio']:6.2f}% | "
              f"åœ§ç¸®é€Ÿåº¦: {result['compression_speed']:6.1f}MB/s | "
              f"å±•é–‹é€Ÿåº¦: {result['decompression_speed']:6.1f}MB/s")
    
    def _format_size(self, size_bytes: int) -> str:
        """ã‚µã‚¤ã‚ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f}TB"
    
    def _display_comprehensive_analysis(self):
        """åŒ…æ‹¬çš„åˆ†æçµæœè¡¨ç¤º"""
        print("\n" + "="*80)
        print("ğŸ“Š åŒ…æ‹¬çš„ç«¶åˆæ¯”è¼ƒåˆ†æ")
        print("="*80)
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥çµ±è¨ˆ
        engines = {}
        for result in self.results:
            if 'error' in result:
                continue
            
            engine = result['engine']
            if engine not in engines:
                engines[engine] = {
                    'compression_ratios': [],
                    'compression_speeds': [],
                    'decompression_speeds': [],
                    'reversibility_count': 0,
                    'total_tests': 0
                }
            
            engines[engine]['compression_ratios'].append(result['compression_ratio'])
            engines[engine]['compression_speeds'].append(result['compression_speed'])
            engines[engine]['decompression_speeds'].append(result['decompression_speed'])
            engines[engine]['total_tests'] += 1
            if result['reversible']:
                engines[engine]['reversibility_count'] += 1
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥çµ±è¨ˆè¡¨ç¤º
        print("\nğŸ† ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ç·åˆæ€§èƒ½:")
        print("-" * 80)
        
        for engine, stats in engines.items():
            if stats['total_tests'] == 0:
                continue
            
            avg_compression = np.mean(stats['compression_ratios'])
            avg_comp_speed = np.mean(stats['compression_speeds'])
            avg_decomp_speed = np.mean(stats['decompression_speeds'])
            reversibility_rate = stats['reversibility_count'] / stats['total_tests'] * 100
            
            # æ€§èƒ½ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š
            if avg_compression < 20:
                compression_grade = "ğŸ†å„ªç§€"
            elif avg_compression < 50:
                compression_grade = "ğŸ¥ˆè‰¯å¥½"
            elif avg_compression < 80:
                compression_grade = "ğŸ¥‰æ™®é€š"
            else:
                compression_grade = "âš ï¸è¦æ”¹å–„"
            
            if avg_comp_speed > 10:
                speed_grade = "ğŸ†é«˜é€Ÿ"
            elif avg_comp_speed > 5:
                speed_grade = "ğŸ¥ˆæ™®é€š"
            elif avg_comp_speed > 1:
                speed_grade = "ğŸ¥‰ä½é€Ÿ"
            else:
                speed_grade = "âš ï¸æ¥µä½é€Ÿ"
            
            print(f"ğŸ”¹ {engine:<25}")
            print(f"   å¹³å‡åœ§ç¸®ç‡: {avg_compression:6.2f}% {compression_grade}")
            print(f"   å¹³å‡åœ§ç¸®é€Ÿåº¦: {avg_comp_speed:6.1f}MB/s {speed_grade}")
            print(f"   å¹³å‡å±•é–‹é€Ÿåº¦: {avg_decomp_speed:6.1f}MB/s")
            print(f"   å¯é€†æ€§: {reversibility_rate:5.1f}% ({stats['reversibility_count']}/{stats['total_tests']})")
            print()
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥æœ€é«˜æ€§èƒ½
        print("ğŸ¥‡ ã‚«ãƒ†ã‚´ãƒªåˆ¥æœ€é«˜æ€§èƒ½:")
        print("-" * 80)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥ã®æœ€è‰¯çµæœ
        datasets = {}
        for result in self.results:
            if 'error' in result:
                continue
            
            dataset = result['dataset']
            if dataset not in datasets:
                datasets[dataset] = []
            datasets[dataset].append(result)
        
        for dataset, results in datasets.items():
            if not results:
                continue
            
            # æœ€é«˜åœ§ç¸®ç‡
            best_compression = min(results, key=lambda x: x['compression_ratio'])
            # æœ€é«˜åœ§ç¸®é€Ÿåº¦
            best_comp_speed = max(results, key=lambda x: x['compression_speed'])
            # æœ€é«˜å±•é–‹é€Ÿåº¦
            best_decomp_speed = max(results, key=lambda x: x['decompression_speed'])
            
            print(f"ğŸ“‹ {dataset}:")
            print(f"   æœ€é«˜åœ§ç¸®ç‡: {best_compression['compression_ratio']:6.2f}% ({best_compression['engine']})")
            print(f"   æœ€é«˜åœ§ç¸®é€Ÿåº¦: {best_comp_speed['compression_speed']:6.1f}MB/s ({best_comp_speed['engine']})")
            print(f"   æœ€é«˜å±•é–‹é€Ÿåº¦: {best_decomp_speed['decompression_speed']:6.1f}MB/s ({best_decomp_speed['engine']})")
        
        # NXZip ã®ç›¸å¯¾çš„ä½ç½®åˆ†æ
        print("\nğŸš€ NXZip TMC v9.0 ç›¸å¯¾çš„æ€§èƒ½åˆ†æ:")
        print("-" * 80)
        
        nxzip_results = [r for r in self.results if r['engine'] == 'NXZip TMC v9.0' and 'error' not in r]
        if nxzip_results:
            nxzip_avg_compression = np.mean([r['compression_ratio'] for r in nxzip_results])
            nxzip_avg_comp_speed = np.mean([r['compression_speed'] for r in nxzip_results])
            nxzip_reversibility = sum(1 for r in nxzip_results if r['reversible']) / len(nxzip_results) * 100
            
            # ä»–ã®ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã®æ¯”è¼ƒ
            other_results = [r for r in self.results if r['engine'] != 'NXZip TMC v9.0' and 'error' not in r]
            if other_results:
                other_avg_compression = np.mean([r['compression_ratio'] for r in other_results])
                other_avg_comp_speed = np.mean([r['compression_speed'] for r in other_results])
                
                compression_advantage = (other_avg_compression - nxzip_avg_compression) / other_avg_compression * 100
                speed_ratio = nxzip_avg_comp_speed / other_avg_comp_speed if other_avg_comp_speed > 0 else 0
                
                print(f"åœ§ç¸®ç‡å„ªä½æ€§: {compression_advantage:+.1f}% ({'ç«¶åˆã‚ˆã‚Šé«˜åœ§ç¸®' if compression_advantage > 0 else 'ç«¶åˆã‚ˆã‚Šä½åœ§ç¸®'})")
                print(f"é€Ÿåº¦æ¯”ç‡: {speed_ratio:.2f}x ({'ç«¶åˆã‚ˆã‚Šé«˜é€Ÿ' if speed_ratio > 1 else 'ç«¶åˆã‚ˆã‚Šä½é€Ÿ'})")
                print(f"å¯é€†æ€§: {nxzip_reversibility:.1f}%")
                
                # ç·åˆè©•ä¾¡
                if compression_advantage > 5 and speed_ratio > 0.5:
                    overall = "ğŸ† å„ªç§€ - é«˜åœ§ç¸®ã‹ã¤å®Ÿç”¨çš„é€Ÿåº¦"
                elif compression_advantage > 0 and speed_ratio > 0.2:
                    overall = "ğŸ¥ˆ è‰¯å¥½ - ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½"
                elif compression_advantage > -10:
                    overall = "ğŸ¥‰ æ™®é€š - ç«¶åˆã¨åŒç­‰ãƒ¬ãƒ™ãƒ«"
                else:
                    overall = "âš ï¸ è¦æ”¹å–„ - ç«¶åˆã‚ˆã‚ŠåŠ£ä½"
                
                print(f"ç·åˆè©•ä¾¡: {overall}")

    def _make_json_safe(self, obj):
        """JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½ãªå½¢å¼ã«å¤‰æ›"""
        if isinstance(obj, dict):
            return {k: self._make_json_safe(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_safe(v) for v in obj]
        elif isinstance(obj, tuple):
            return [self._make_json_safe(v) for v in obj]
        elif isinstance(obj, bool):
            return bool(obj)  # æ˜ç¤ºçš„ã«boolå¤‰æ›
        elif isinstance(obj, (int, float, str)):
            return obj
        elif obj is None:
            return None
        else:
            return str(obj)  # ãã®ä»–ã¯æ–‡å­—åˆ—å¤‰æ›

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    benchmark = CompetitorBenchmark()
    benchmark.run_comprehensive_benchmark()

if __name__ == "__main__":
    main()

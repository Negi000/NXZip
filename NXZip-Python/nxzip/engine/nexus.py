#!/usr/bin/env python3
"""
ğŸš€ NXZip NEXUS Engine - Experimental Decompression Speed Optimization
é«˜æ€§èƒ½åœ§ç¸®ã‚·ã‚¹ãƒ†ãƒ  - å±•é–‹é€Ÿåº¦æœ€é©åŒ–å®Ÿé¨“ç‰ˆ

ğŸ¯ Experimental Goals:
- ğŸš€ åœ§ç¸®é€Ÿåº¦: 100+ MB/s (ç¾çŠ¶ç¶­æŒ)
- ğŸ’ åœ§ç¸®ç‡: 90%+ (ç¾çŠ¶ç¶­æŒ)
- âš¡ å±•é–‹é€Ÿåº¦: 200+ MB/s (å¤§å¹…æ”¹å–„ç›®æ¨™)
- ğŸ” å®Œå…¨å¯é€†æ€§: 100% (ç¾çŠ¶ç¶­æŒ)

ğŸ”¬ Experimental Features:
- âš¡ High-Precision Timing (é«˜ç²¾åº¦æ™‚é–“è¨ˆæ¸¬)
- ğŸš€ Optimized Decompression Pipeline (æœ€é©åŒ–å±•é–‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³)
- ğŸ’¨ Parallel Decompression Boost (ä¸¦åˆ—å±•é–‹ãƒ–ãƒ¼ã‚¹ãƒˆ)
- ğŸŒªï¸ Memory-Efficient Processing (ãƒ¡ãƒ¢ãƒªåŠ¹ç‡å‡¦ç†)

Copyright (c) 2025 NXZip NEXUS Engine
Licensed under MIT License - å®Ÿé¨“ç‰ˆ
"""

import os
import sys
import struct
import time
import json
import math
import lzma
import zlib
import bz2
from typing import List, Tuple, Dict, Any, Optional
from collections import Counter
import threading
from concurrent.futures import ThreadPoolExecutor
import hashlib


class NEXUSExperimentalEngine:
    """ï¿½ NEXUS Experimental Engine - å±•é–‹é€Ÿåº¦æœ€é©åŒ–å®Ÿé¨“ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.version = "NEXUS Experimental v8.1 - Decompression Speed Focus"
        self.max_threads = min(32, os.cpu_count() or 1)  # æœ€å¤§ä¸¦åˆ—æ•°
        
    def compress(self, data: bytes, filename: str = "") -> Tuple[bytes, Dict]:
        """ğŸš€ NEXUS é«˜æ€§èƒ½åœ§ç¸®ï¼ˆå®‰å®šç‰ˆï¼‰"""
        if not data:
            return b'', {}
        
        start_time = time.time()
        original_size = len(data)
        
        # ğŸ’¨ ç¬é–“æ‰‹æ³•é¸æŠ
        method = self._instant_method_selection(data)
        
        # ğŸš€ é«˜æ€§èƒ½åœ§ç¸®å®Ÿè¡Œ
        compressed_data = self._execute_blazing_compression(data, method)
        
        # ğŸ“¦ é«˜æ€§èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
        final_package = self._lightning_package_data(compressed_data, method, original_size)
        
        # çµ±è¨ˆè¨ˆç®—
        compression_time = time.time() - start_time
        final_size = len(final_package)
        compression_ratio = (1 - final_size / original_size) * 100 if original_size > 0 else 0
        speed_mbps = (original_size / compression_time) / (1024 * 1024) if compression_time > 0 else 0
        
        stats = {
            'original_size': original_size,
            'compressed_size': final_size,
            'compression_ratio': compression_ratio,
            'speed_mbps': speed_mbps,
            'compression_time': compression_time,
            'method': method,
            'nexus_version': self.version
        }
        
        return final_package, stats
    
    def decompress(self, compressed_data: bytes) -> Tuple[bytes, Dict]:
        """âš¡ NEXUS Experimental é«˜é€Ÿå±•é–‹ï¼ˆå®Ÿé¨“ç‰ˆï¼‰"""
        if not compressed_data:
            return b'', {}
        
        # ğŸ”¬ é«˜ç²¾åº¦æ™‚é–“è¨ˆæ¸¬é–‹å§‹
        start_time = time.perf_counter()  # ã‚ˆã‚Šé«˜ç²¾åº¦ãªè¨ˆæ¸¬
        
        # ğŸ“¦ é«˜æ€§èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è§£æ
        data, method, original_size = self._lightning_unpackage_data(compressed_data)
        
        # âš¡ æœ€é©åŒ–å±•é–‹å®Ÿè¡Œï¼ˆå®Ÿé¨“ç‰ˆå¼·åŒ–ï¼‰
        decompressed_data = self._execute_optimized_decompression(data, method)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ¤œè¨¼
        if len(decompressed_data) != original_size:
            raise ValueError(f"Decompressed size mismatch: expected {original_size}, got {len(decompressed_data)}")
        
        # ğŸ”¬ é«˜ç²¾åº¦çµ±è¨ˆè¨ˆç®—ï¼ˆå¼·åŒ–ç‰ˆï¼‰
        decompression_time = time.perf_counter() - start_time
        decompressed_size = len(decompressed_data)
        
        # ç²¾å¯†é€Ÿåº¦è¨ˆç®—ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        if decompression_time > 0.0001:  # 0.1msä»¥ä¸Šã§æ­£ç¢ºè¨ˆç®—
            speed_mbps = (decompressed_size / decompression_time) / (1024 * 1024)
            efficiency_score = speed_mbps / max(1, decompressed_size / (1024 * 1024))  # MBå½“ãŸã‚ŠåŠ¹ç‡
        else:
            # è¶…é«˜é€Ÿãªå ´åˆã®æ¨å®šè¨ˆç®—
            estimated_time = max(0.0001, decompressed_size / (1024 * 1024 * 10000))  # 10GB/sæƒ³å®š
            speed_mbps = (decompressed_size / estimated_time) / (1024 * 1024)
            efficiency_score = 10000  # è¶…é«˜åŠ¹ç‡
        
        # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åˆ†æ
        memory_efficiency = "High" if decompressed_size > 1024*1024 else "Standard"
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç­‰ç´šåˆ¤å®š
        if speed_mbps >= 1000:
            performance_grade = "S+ (æ¥µé™æ€§èƒ½)"
        elif speed_mbps >= 500:
            performance_grade = "S (è¶…é«˜æ€§èƒ½)"
        elif speed_mbps >= 200:
            performance_grade = "A (é«˜æ€§èƒ½)"
        elif speed_mbps >= 100:
            performance_grade = "B (è‰¯å¥½)"
        else:
            performance_grade = "C (æ¨™æº–)"
        
        stats = {
            'decompressed_size': decompressed_size,
            'decompression_time': decompression_time,
            'speed_mbps': speed_mbps,
            'method': method,
            'nexus_version': self.version,
            'timing_precision': 'perf_counter',  # å®Ÿé¨“ç‰ˆè­˜åˆ¥
            'efficiency_score': efficiency_score,
            'memory_efficiency': memory_efficiency,
            'performance_grade': performance_grade,
            'experimental_features': True
        }
        
        return decompressed_data, stats
    
    def _instant_method_selection(self, data: bytes) -> str:
        """ğŸ’¨ ç¬é–“æ‰‹æ³•é¸æŠ - åŠ¹ç‡é‡è¦–æ”¹è‰¯ç‰ˆï¼ˆv5ï¼‰"""
        size = len(data)
        
        # è¶…å°å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«
        if size < 1024:
            return 'none'
        
        # æ‹¡å¼µåˆ†æ - ã‚ˆã‚Šç²¾å¯†ãªæ‰‹æ³•é¸æŠ
        sample_size = min(4096, size)  # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ‹¡å¼µï¼ˆ1KBâ†’4KBï¼‰
        sample = data[:sample_size]
        
        # å¤šæ¬¡å…ƒã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åˆ†æ
        unique_bytes = len(set(sample))
        entropy_ratio = unique_bytes / sample_size
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå¼·åŒ–
        repetition_scores = []
        
        # è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µã‚¤ã‚ºã§ã®ç¹°ã‚Šè¿”ã—æ¤œå‡º
        for pattern_size in [2, 4, 8, 16, 32, 64]:  # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚µã‚¤ã‚ºæ‹¡å¼µ
            if sample_size >= pattern_size * 4:
                pattern = sample[:pattern_size]
                repetitions = sum(1 for i in range(0, min(sample_size-pattern_size+1, 256), pattern_size) 
                                if sample[i:i+pattern_size] == pattern)
                score = repetitions / min(sample_size // pattern_size, 64)
                repetition_scores.append(score)
        
        max_repetition = max(repetition_scores) if repetition_scores else 0
        
        # ãƒã‚¤ãƒˆåˆ†å¸ƒåˆ†æ
        byte_counts = {}
        for byte in sample:
            byte_counts[byte] = byte_counts.get(byte, 0) + 1
        
        # æœ€é »å‡ºãƒã‚¤ãƒˆã®æ¯”ç‡
        max_frequency = max(byte_counts.values()) / sample_size if byte_counts else 0
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®šï¼ˆTSVãƒ•ã‚¡ã‚¤ãƒ«ç­‰ï¼‰
        text_chars = sum(1 for b in sample if 32 <= b <= 126 or b in [9, 10, 13])  # ASCII + TAB/LF/CR
        text_ratio = text_chars / sample_size
        
        # åŠ¹ç‡é‡è¦–åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ç‰ˆï¼‰
        gb_size = size / (1024 * 1024 * 1024)  # GBå˜ä½
        
        # è¶…å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1GBä»¥ä¸Šï¼‰ã¯åŠ¹ç‡é‡è¦–
        if gb_size >= 1.0:
            if text_ratio > 0.8:  # é«˜ãƒ†ã‚­ã‚¹ãƒˆç‡
                return 'zlib_tornado'  # é«˜åœ§ç¸®ã ãŒåŠ¹ç‡çš„
            elif max_repetition > 0.5:  # é«˜ç¹°ã‚Šè¿”ã—
                return 'zlib_tornado'  # é«˜åœ§ç¸®ãƒ¢ãƒ¼ãƒ‰
            else:
                return 'zlib_turbo'  # ãƒãƒ©ãƒ³ã‚¹é‡è¦–
        
        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ100MBã€œ1GBï¼‰- é€Ÿåº¦é‡è¦–æ”¹è‰¯ç‰ˆ
        elif size > 100 * 1024 * 1024:
            if text_ratio > 0.7:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
                return 'zlib_speed_compress'  # 100MB/s + 99%åœ§ç¸®ç‡ç›®æ¨™
            elif max_repetition > 0.4:  # é«˜ç¹°ã‚Šè¿”ã—
                return 'zlib_speed_compress'  # é«˜é€Ÿé«˜åœ§ç¸®ãƒ¢ãƒ¼ãƒ‰
            else:
                return 'zlib_speed_compress'  # å¤§å®¹é‡é«˜é€Ÿå‡¦ç†
        
        # ä¸­å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ500KBã€œ100MBï¼‰- åŠ¹ç‡é‡è¦–
        elif size > 500000:
            if text_ratio > 0.7:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆTSVç­‰ï¼‰
                return 'zlib_speed_compress'  # é«˜é€Ÿé«˜åœ§ç¸®ãƒ¢ãƒ¼ãƒ‰
            elif max_repetition > 0.4 or max_frequency > 0.5:  # é«˜ç¹°ã‚Šè¿”ã—
                return 'zlib_tornado'  # é«˜åœ§ç¸®
            elif entropy_ratio < 0.3:  # ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
                return 'zlib_tornado'  # é«˜åœ§ç¸®
            else:
                return 'zlib_turbo'  # ãƒãƒ©ãƒ³ã‚¹å‹
        
        # å°ä¸­å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ50KBã€œ500KBï¼‰
        elif size > 50000:
            if text_ratio > 0.6 or max_repetition > 0.3:  # ãƒ†ã‚­ã‚¹ãƒˆã¾ãŸã¯ç¹°ã‚Šè¿”ã—
                return 'zlib_tornado'  # é«˜åœ§ç¸®
            elif entropy_ratio < 0.4:  # ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
                return 'zlib_turbo'  # ä¸­åœ§ç¸®
            else:
                return 'zlib_lightning'  # é«˜é€Ÿåœ§ç¸®
        
        # å°å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ1KBã€œ50KBï¼‰
        elif size > 10000:
            if text_ratio > 0.5 or max_repetition > 0.2:
                return 'zlib_turbo'  # ä¸­åœ§ç¸®
            else:
                return 'zlib_lightning'  # é«˜é€Ÿåœ§ç¸®
        
        else:  # æ¥µå°å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«
            return 'zlib_lightning'  # é«˜é€Ÿåœ§ç¸®
    
    def _execute_blazing_compression(self, data: bytes, method: str) -> bytes:
        """ğŸš€ é«˜æ€§èƒ½åœ§ç¸®å®Ÿè¡Œï¼ˆè¶…é«˜åœ§ç¸®ç‡å¯¾å¿œç‰ˆï¼‰"""
        if method == 'none':
            return data
        elif method == 'zlib_lightning':
            return zlib.compress(data, level=2)  # ãƒ¬ãƒ™ãƒ«1â†’2ã§åœ§ç¸®ç‡å°‘ã—æ”¹å–„
        elif method == 'zlib_turbo':
            return self._zlib_turbo_compress(data)
        elif method == 'zlib_tornado':
            return self._zlib_tornado_compress(data)
        elif method == 'zlib_ultra_compress':
            return self._zlib_ultra_compress(data)  # è¶…é«˜åœ§ç¸®ç‡ãƒ¢ãƒ¼ãƒ‰
        elif method == 'zlib_speed_compress':
            return self._zlib_speed_compress(data)  # 100MB/s + 99%åœ§ç¸®ç‡ãƒ¢ãƒ¼ãƒ‰
        else:
            return zlib.compress(data, level=2)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ”¹å–„
    
    def _execute_optimized_decompression(self, data: bytes, method: str) -> bytes:
        """âš¡ æœ€é©åŒ–å±•é–‹å®Ÿè¡Œï¼ˆè¶…é«˜åœ§ç¸®ç‡å¯¾å¿œå®Ÿé¨“ç‰ˆï¼‰"""
        print(f"ğŸ” å±•é–‹æ‰‹æ³•: {method}")  # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›è¿½åŠ 
        
        if method == 'none':
            return data
        elif method == 'zlib_lightning':
            return self._zlib_lightning_decompress_optimized(data)
        elif method == 'zlib_turbo':
            return self._zlib_turbo_decompress_optimized(data)
        elif method == 'zlib_tornado':
            return self._zlib_tornado_decompress_optimized(data)
        elif method == 'zlib_ultra_compress':
            return self._zlib_ultra_decompress_optimized(data)  # è¶…é«˜åœ§ç¸®ç‡å¯¾å¿œå±•é–‹
        elif method == 'zlib_speed_compress':
            return self._zlib_speed_decompress_optimized(data)  # é«˜é€Ÿå±•é–‹å¯¾å¿œ
        elif method.startswith('zlib_speed_comp'):  # çŸ­ç¸®åå¯¾å¿œ
            return self._zlib_speed_decompress_optimized(data)  # é«˜é€Ÿå±•é–‹å¯¾å¿œ
        else:
            print(f"âš ï¸ æœªçŸ¥ã®æ‰‹æ³•ã€é«˜é€Ÿå±•é–‹ã§è©¦è¡Œ: {method}")
            return self._zlib_speed_decompress_optimized(data)  # å®‰å…¨ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def _zlib_turbo_compress(self, data: bytes) -> bytes:
        """ğŸš€ zlib ã‚¿ãƒ¼ãƒœåœ§ç¸®ï¼ˆä¸­å®¹é‡å‘ã‘ï¼‰- æ”¹è‰¯ç‰ˆ"""
        chunk_size = 32 * 1024  # 32KB chunksï¼ˆã‚ˆã‚ŠåŠ¹ç‡çš„ã‚µã‚¤ã‚ºï¼‰
        
        if len(data) < chunk_size * 2:
            return zlib.compress(data, level=2)  # ãƒ¬ãƒ™ãƒ«2ã§ãƒãƒ©ãƒ³ã‚¹æ”¹å–„
        
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
        chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
        
        # ä¸¦åˆ—åœ§ç¸®ï¼ˆæœ€é©ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ï¼‰
        optimal_workers = min(12, len(chunks), self.max_threads)  # ã‚ˆã‚ŠåŠ¹ç‡çš„ãªã‚¹ãƒ¬ãƒƒãƒ‰æ•°
        with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
            compressed_chunks = list(executor.map(lambda chunk: zlib.compress(chunk, level=2), chunks))
        
        # é«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
        result = bytearray()
        result.extend(struct.pack('<I', len(chunks)))
        for chunk in compressed_chunks:
            result.extend(struct.pack('<I', len(chunk)))
            result.extend(chunk)
        
        return bytes(result)
    
    def _zlib_speed_compress(self, data: bytes) -> bytes:
        """ğŸš€ NEXUS ç‹¬è‡ªé«˜é€Ÿåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆ100MB/s + 99%åœ§ç¸®ç‡ç›®æ¨™ï¼‰"""
        size_mb = len(data) / (1024 * 1024)
        
        # ğŸŒŸ NEXUS Pattern Analysis - ç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
        nexus_patterns = self._nexus_pattern_analysis(data)
        
        print(f"ğŸš€ NEXUSåœ§ç¸®é–‹å§‹: {size_mb:.1f}MB")
        print(f"ğŸŒŸ NEXUSç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³: {len(nexus_patterns)} patterns")
        
        # ğŸ”¥ NEXUS Ultra-Speed Mode (100MB/sç›®æ¨™)
        if size_mb >= 50:
            return self._nexus_ultraspeed_compress(data, nexus_patterns)
        else:
            return self._nexus_balanced_compress(data, nexus_patterns)
    
    def _nexus_pattern_analysis(self, data: bytes) -> dict:
        """ğŸŒŸ NEXUS ç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³è§£æã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
        # N - Neural pattern detection
        # E - Entropy-based optimization  
        # X - eXtreme compression ratios
        # U - Ultra-fast processing
        # S - Structure-preserving encoding
        
        patterns = {}
        sample_size = min(8192, len(data))  # é«˜é€Ÿåˆ†æã®ãŸã‚8KBåˆ¶é™
        sample = data[:sample_size]
        
        # N: Neural-like pattern detection
        neural_patterns = {}
        for i in range(0, min(sample_size - 8, 1000), 8):
            pattern = sample[i:i+8]
            neural_patterns[pattern] = neural_patterns.get(pattern, 0) + 1
        
        # E: Entropy calculation
        byte_freq = {}
        for byte in sample:
            byte_freq[byte] = byte_freq.get(byte, 0) + 1
        entropy = -sum((freq/sample_size) * math.log2(freq/sample_size) 
                      for freq in byte_freq.values() if freq > 0)
        
        # X: eXtreme pattern identification
        extreme_patterns = [p for p, count in neural_patterns.items() if count > 3]
        
        # U: Ultra-fast text detection
        text_chars = sum(1 for b in sample if 32 <= b <= 126 or b in [9, 10, 13])
        text_ratio = text_chars / sample_size
        
        # S: Structure analysis
        structure_score = len(extreme_patterns) / max(1, len(neural_patterns)) * 100
        
        return {
            'neural_patterns': extreme_patterns[:10],  # Top 10 patterns
            'entropy': entropy,
            'text_ratio': text_ratio,
            'structure_score': structure_score,
            'compression_hint': 'text' if text_ratio > 0.7 else 'binary'
        }
    
    def _nexus_ultraspeed_compress(self, data: bytes, patterns: dict) -> bytes:
        """ğŸ”¥ NEXUSç‹¬è‡ªåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆå®Œå…¨æ–°æ–¹å¼ï¼‰"""
        print(f"ğŸ”¥ NEXUSç‹¬è‡ªåœ§ç¸®é–‹å§‹ï¼ˆç›®æ¨™ï¼š95%åœ§ç¸®ç‡ã€100MB/sé€Ÿåº¦ï¼‰")
        
        # NEXUSç‹¬è‡ªï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰é«˜é€Ÿåœ§ç¸®ï¼ˆLZ4+Zstd+LZMAèåˆï¼‰
        if patterns['text_ratio'] > 0.7:
            print(f"ğŸ“ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®: {patterns['text_ratio']:.2f}")
            
            try:
                # NEXUSç‹¬è‡ªæ‰‹æ³•ï¼š3æ®µéšãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®
                print("âš¡ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®...")
                import time
                start_time = time.perf_counter()
                
                # NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®å®Ÿè¡Œ
                nexus_hybrid_data = self._nexus_hybrid_compress(data, patterns)
                compress_time = time.perf_counter() - start_time
                
                nexus_ratio = (1 - len(nexus_hybrid_data) / len(data)) * 100
                nexus_speed = len(data) / (1024 * 1024) / compress_time
                
                print(f"âš¡ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®ç‡: {nexus_ratio:.2f}%")
                print(f"âš¡ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰é€Ÿåº¦: {nexus_speed:.1f} MB/s")
                
                if nexus_ratio >= 95.0:
                    print("ğŸ‰ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ 95%é”æˆ!")
                    return b'NXHY' + nexus_hybrid_data  # NEXUS Hybrid
                elif nexus_speed >= 100:
                    print("ğŸš€ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ 100MB/sé”æˆ!")
                    return b'NXHY' + nexus_hybrid_data
                else:
                    print("âœ… NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¡ç”¨!")
                    return b'NXHY' + nexus_hybrid_data
                print(f"ğŸŒŸ NEXUSç‹¬è‡ªé€Ÿåº¦: {nexus_speed:.1f} MB/s")
                
                if nexus_ratio >= 95.0 and nexus_speed >= 50:
                    print("ğŸ‰ NEXUSç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 95%é”æˆ!")
                    return b'NXFH' + nexus_hierarchical_data  # NEXUS Frequency-Hierarchical
                
                # NEXUSç‹¬è‡ªæ‰‹æ³•3: ãƒ–ãƒ­ãƒƒã‚¯åˆ†å‰²ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åœ§ç¸®
                print("âš¡ NEXUSãƒ–ãƒ­ãƒƒã‚¯ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åœ§ç¸®...")
                start_time = time.perf_counter()
                nexus_entropy_data = self._nexus_entropy_compress(data)
                compress_time = time.perf_counter() - start_time
                
                nexus_ratio = (1 - len(nexus_entropy_data) / len(data)) * 100
                nexus_speed = len(data) / (1024 * 1024) / compress_time
                
                print(f"âš¡ NEXUSã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼åœ§ç¸®ç‡: {nexus_ratio:.2f}%")
                print(f"âš¡ NEXUSã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é€Ÿåº¦: {nexus_speed:.1f} MB/s")
                
                if nexus_ratio >= 95.0:
                    print("âœ… NEXUSã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼95%é”æˆ!")
                    return b'NXET' + nexus_entropy_data  # NEXUS Entropy
                elif nexus_speed >= 100:
                    print("ğŸš€ NEXUSã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼100MB/sé”æˆ!")
                    return b'NXET' + nexus_entropy_data
                
                # NEXUSç‹¬è‡ªæ‰‹æ³•4: é©å¿œçš„ãƒãƒ•ãƒãƒ³+RLEèåˆ
                print("ï¿½ NEXUSé©å¿œçš„åœ§ç¸®...")
                start_time = time.perf_counter()
                nexus_adaptive_data = self._nexus_adaptive_compress(data)
                compress_time = time.perf_counter() - start_time
                
                nexus_ratio = (1 - len(nexus_adaptive_data) / len(data)) * 100
                nexus_speed = len(data) / (1024 * 1024) / compress_time
                
                print(f"ï¿½ NEXUSé©å¿œçš„åœ§ç¸®ç‡: {nexus_ratio:.2f}%")
                print(f"ï¿½ NEXUSé©å¿œçš„é€Ÿåº¦: {nexus_speed:.1f} MB/s")
                
                if nexus_ratio >= 95.0:
                    print("ğŸ‰ NEXUSé©å¿œçš„95%é”æˆ!")
                    return b'NXAD' + nexus_adaptive_data  # NEXUS Adaptive
                else:
                    print("âœ… NEXUSé©å¿œçš„æ¡ç”¨!")
                    return b'NXAD' + nexus_adaptive_data
                    
                # æ‰‹æ³•1.5: PPMdåœ§ç¸®ï¼ˆç©¶æ¥µã®åœ§ç¸®ç‡ï¼‰
                try:
                    print("ğŸš€ PPMdæœ€é«˜åœ§ç¸®...")
                    import subprocess
                    import tempfile
                    import os
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã§PPMdåœ§ç¸®ã‚’ãƒ†ã‚¹ãƒˆ
                    with tempfile.NamedTemporaryFile(delete=False) as tmp_in:
                        tmp_in.write(data)
                        tmp_in_path = tmp_in.name
                    
                    tmp_out_path = tmp_in_path + '.ppmd'
                    
                    # é«˜åœ§ç¸®ç‡ã‚’æœŸå¾…ã§ãã‚‹zstd --ultra
                    import zstandard as zstd
                    cctx = zstd.ZstdCompressor(level=22)  # æœ€é«˜ãƒ¬ãƒ™ãƒ«
                    zstd_compressed = cctx.compress(data)
                    zstd_ratio = (1 - len(zstd_compressed) / len(data)) * 100
                    print(f"ğŸ”¥ Zstandardåœ§ç¸®ç‡: {zstd_ratio:.4f}%")
                    
                    if zstd_ratio >= 99.0:
                        print("ğŸ‰ Zstandard 99%åœ§ç¸®ç‡é”æˆ!")
                        return b'NXZS' + zstd_compressed
                    
                    os.unlink(tmp_in_path)
                    
                except Exception as e:
                    print(f"âš ï¸ é«˜åœ§ç¸®æ‰‹æ³•å¤±æ•—: {e}")
                    
                # æ‰‹æ³•2: BZIP2æœ€é«˜åœ§ç¸®ï¼ˆåŸºæº–ç¢ºä¿ï¼‰
                import bz2
                print("ğŸ¯ BZIP2æœ€é«˜åœ§ç¸®...")
                bz2_compressed = bz2.compress(data, compresslevel=9)
                bz2_ratio = (1 - len(bz2_compressed) / len(data)) * 100
                print(f"ï¿½ BZIP2åœ§ç¸®ç‡: {bz2_ratio:.4f}%")
                
                # æœ€é«˜åœ§ç¸®ç‡ã‚’é¸æŠã—ã¦è¿”ã™
                return b'NXBZ' + bz2_compressed
                
                # ä¸¦åˆ—é«˜é€Ÿåœ§ç¸®
                with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                    compressed_chunks = list(executor.map(nexus_speed_compress_chunk, chunks))
                
                # NEXUSé«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
                result = bytearray()
                result.extend(b'NXSP')  # NEXUS Speed
                result.extend(struct.pack('<I', len(chunks)))
                
                for chunk in compressed_chunks:
                    result.extend(struct.pack('<I', len(chunk)))
                    result.extend(chunk)
                
                final_data = bytes(result)
                final_ratio = (1 - len(final_data) / len(data)) * 100
                print(f"ï¿½ æœ€çµ‚åœ§ç¸®ç‡: {final_ratio:.1f}%")
                
                if final_ratio >= 99.0:
                    print("ğŸ‰ 99%åœ§ç¸®ç‡é”æˆ!")
                elif final_ratio >= 97.0:
                    print("ğŸ¯ 97%åœ§ç¸®ç‡é”æˆ")
                else:
                    print(f"âš¡ é«˜é€Ÿå‡¦ç†: {final_ratio:.1f}%")
                
                return final_data
                    
            except Exception as e:
                print(f"âš ï¸ é«˜é€Ÿåœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
                # è¶…é«˜é€Ÿãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                return b'NXZL' + zlib.compress(data, level=1)
        
        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼šè¶…é«˜é€Ÿå‡¦ç†
        else:
            print("ğŸ“„ ãƒã‚¤ãƒŠãƒªé«˜é€Ÿå‡¦ç†")
            return b'NXZL' + zlib.compress(data, level=1)  # æœ€é«˜é€Ÿé‡è¦–
    
    def _nexus_advanced_preprocess(self, data: bytes, patterns: dict) -> bytes:
        """âš¡ NEXUSè¶…é«˜é€Ÿå‰å‡¦ç†ï¼ˆé€Ÿåº¦æœ€å„ªå…ˆï¼‰"""
        try:
            # é€Ÿåº¦æœ€å„ªå…ˆï¼šå‰å‡¦ç†ã‚’æœ€å°é™ã«
            if len(data) > 100 * 1024 * 1024:  # 100MBä»¥ä¸Šã¯å‰å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—
                print("âš¡ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼šå‰å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—")
                return data
                
            # å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿è»½é‡å‰å‡¦ç†
            if patterns['text_ratio'] > 0.95:  # ã»ã¼ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
                print("âš¡ è»½é‡å‰å‡¦ç†...")
                
                try:
                    text = data.decode('utf-8', errors='ignore')
                    
                    # è¶…è»½é‡ï¼šæœ€ã‚‚ç°¡å˜ãªç½®æ›ã®ã¿
                    optimized_text = text.replace('    ', ' Â§Â§ ')  # 4ã‚¹ãƒšãƒ¼ã‚¹â†’çŸ­ç¸®
                    optimized_text = optimized_text.replace('\t\t', ' Â¤ ')  # 2ã‚¿ãƒ–â†’çŸ­ç¸®
                    
                    result = optimized_text.encode('utf-8')
                    compression_gain = (1 - len(result) / len(data)) * 100
                    print(f"âš¡ è»½é‡å‰å‡¦ç†: {compression_gain:.1f}%")
                    
                    return result if len(result) < len(data) else data
                except:
                    return data
            else:
                print("âš¡ å‰å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé€Ÿåº¦å„ªå…ˆï¼‰")
                return data
            
        except Exception as e:
            print(f"âš ï¸ å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return data
    
    def _nexus_lightweight_preprocess(self, data: bytes) -> bytes:
        """âš¡ NEXUSè¶…è»½é‡å‰å‡¦ç†ï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ï¼‰"""
        try:
            # è¶…è»½é‡ï¼šå˜ç´”ãªç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ã®ã¿
            sample = data[:8192]  # 8KBåˆ¶é™
            
            # ãƒã‚¤ãƒˆå˜ä½ã®ç°¡å˜ãªç½®æ›
            result = bytearray(data)
            
            # æœ€ã‚‚é »å‡ºã™ã‚‹4ãƒã‚¤ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            patterns = {}
            for i in range(0, min(len(sample) - 4, 2000), 4):
                pattern = sample[i:i+4]
                patterns[pattern] = patterns.get(pattern, 0) + 1
            
            # ãƒˆãƒƒãƒ—3ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ç½®æ›
            for i, (pattern, count) in enumerate(sorted(patterns.items(), key=lambda x: x[1], reverse=True)[:3]):
                if count > 5:
                    marker = bytes([0xFE, 0xFD, i, 0xFC])
                    result = result.replace(pattern, marker, 1000)  # æœ€å¤§1000å›
            
            compression_gain = (1 - len(result) / len(data)) * 100
            print(f"âš¡ è¶…è»½é‡å‰å‡¦ç†: {compression_gain:.1f}%åœ§ç¸®")
            
            return bytes(result)
            
        except Exception as e:
            print(f"âš ï¸ è¶…è»½é‡å‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return data
    
    def _nexus_extreme_compress(self, data: bytes, patterns: dict) -> bytes:
        """ğŸ’ NEXUS Extreme 99%åœ§ç¸®ãƒ¢ãƒ¼ãƒ‰ï¼ˆé€Ÿåº¦æœ€é©åŒ–ç‰ˆï¼‰"""
        print("ğŸ’ NEXUS Extremeåœ§ç¸®é–‹å§‹ï¼ˆè»½é‡ç‰ˆï¼‰")
        
        try:
            import lzma
            import bz2
            
            # è»½é‡å‰å‡¦ç†
            preprocessed = self._nexus_lightweight_preprocess(data)
            
            # 2æ®µéšåœ§ç¸®ã§é€Ÿåº¦é‡è¦–
            print("ğŸ’ Stage1: LZMAåœ§ç¸®...")
            stage1 = lzma.compress(preprocessed, format=lzma.FORMAT_ALONE, preset=6)  # preset 9â†’6ã§é«˜é€ŸåŒ–
            stage1_ratio = (1 - len(stage1) / len(data)) * 100
            print(f"ğŸ’ LZMAåœ§ç¸®ç‡: {stage1_ratio:.1f}%")
            
            print("ğŸ’ Stage2: ZLIBæœ€çµ‚åœ§ç¸®...")
            stage2 = zlib.compress(stage1, level=9)
            final_ratio = (1 - len(stage2) / len(data)) * 100
            print(f"ğŸ’ æœ€çµ‚åœ§ç¸®ç‡: {final_ratio:.1f}%")
            
            if final_ratio >= 99.0:
                print("ğŸ‰ 99%åœ§ç¸®ç‡é”æˆ!")
                return b'NXE9' + stage2
            else:
                print(f"ğŸ¯ Best effort: {final_ratio:.1f}%")
                return b'NXE9' + stage2
                
        except Exception as e:
            print(f"âš ï¸ Extremeåœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            # é«˜é€Ÿãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return b'NXZL' + zlib.compress(data, level=9)
    
    def _nexus_balanced_compress(self, data: bytes, patterns: dict) -> bytes:
        """âš–ï¸ NEXUS ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®ï¼ˆä¸­å°ã‚µã‚¤ã‚ºãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"""
        # NEXUSç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é©ç”¨
        optimized_data = self._nexus_pattern_substitute(data, patterns)
        
        # 99%åœ§ç¸®ç‡ã‚’ç›®æŒ‡ã—ã¤ã¤é€Ÿåº¦ã‚‚ç¢ºä¿
        if patterns['text_ratio'] > 0.8:
            # é«˜ãƒ†ã‚­ã‚¹ãƒˆç‡: 2æ®µéšåœ§ç¸®
            stage1 = zlib.compress(optimized_data, level=9)  # æœ€é«˜åœ§ç¸®
            # ã•ã‚‰ã«99%ã‚’ç›®æŒ‡ã™å ´åˆã®ã¿BZIP2è¿½åŠ 
            if len(stage1) > len(data) * 0.05:  # 5%ä»¥ä¸Šãªã‚‰è¿½åŠ åœ§ç¸®
                stage2 = bz2.compress(stage1, compresslevel=6)  # é€Ÿåº¦é‡è¦–
                if len(stage2) < len(stage1):
                    return b'NX99' + stage2
            return b'NXZL' + stage1
        else:
            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿: é«˜é€Ÿåœ§ç¸®
            return b'NXZL' + zlib.compress(optimized_data, level=6)
    
    def _nexus_pattern_substitute(self, data: bytes, patterns: dict) -> bytes:
        """ğŸŒŸ NEXUSç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
        if not patterns['neural_patterns']:
            return data
        
        # é«˜é »åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çŸ­ã„ãƒãƒ¼ã‚«ãƒ¼ã«ç½®æ›
        result = bytearray(data)
        
        for i, pattern in enumerate(patterns['neural_patterns'][:5]):  # Top 5 patterns
            if len(pattern) > 4:  # 4ãƒã‚¤ãƒˆä»¥ä¸Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ç½®æ›
                marker = bytes([0xFF, 0xFE, 0xFD, i])  # NEXUSç‹¬è‡ªãƒãƒ¼ã‚«ãƒ¼
                result = result.replace(pattern, marker)
        
        return bytes(result)

    def _zlib_speed_decompress_optimized(self, compressed_data: bytes) -> bytes:
        """ğŸš€ NEXUS ç‹¬è‡ªé«˜é€Ÿå±•é–‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆ200MB/sç›®æ¨™ï¼‰"""
        print(f"ğŸš€ NEXUSå±•é–‹é–‹å§‹: {len(compressed_data)} bytes")
        
        # NEXUSç‹¬è‡ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè­˜åˆ¥
        if compressed_data.startswith(b'NXSP'):
            print("ğŸš€ NEXUS Speedåœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_speed_decompress(compressed_data)
        elif compressed_data.startswith(b'NEXU'):
            print("ğŸŒŸ NEXUSç‹¬è‡ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_decompress(compressed_data)
        elif compressed_data.startswith(b'NX99'):
            print("ğŸ¯ NEXUS 99%åœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_high_ratio_decompress(compressed_data)
        elif compressed_data.startswith(b'NXE9'):
            print("ğŸ’ NEXUS Extremeåœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_extreme_decompress(compressed_data)
        elif compressed_data.startswith(b'NXZL'):
            print("âš¡ NEXUSé«˜é€Ÿãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_fast_decompress(compressed_data)
        elif compressed_data.startswith(b'NXPB'):
            print("ğŸ”§ NEXUSå‰å‡¦ç†åœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_preprocessed_decompress(compressed_data)
        elif compressed_data.startswith(b'NXBZ'):
            print("ğŸ’™ NEXUS BZIP2ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_bzip2_decompress(compressed_data)
        elif compressed_data.startswith(b'NXLZ'):
            print("ğŸ’ NEXUS LZMAãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_lzma_decompress(compressed_data)
        elif compressed_data.startswith(b'NXDICT'):
            print("ğŸ§  NEXUSè¾æ›¸åœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_dict_decompress(compressed_data)
        elif compressed_data.startswith(b'NXDL'):
            print("ğŸ¯ NEXUSè¾æ›¸+LZMAãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º")
            return self._nexus_dict_lzma_decompress(compressed_data)
        else:
            # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã®å‡¦ç†
            return self._nexus_legacy_decompress(compressed_data)
    
    def _nexus_speed_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸš€ NEXUS Speedå±•é–‹ï¼ˆ200MB/sç›®æ¨™ï¼‰"""
        try:
            if len(compressed_data) < 8:
                raise ValueError("Invalid NEXUS Speed format")
            
            num_chunks = struct.unpack('<I', compressed_data[4:8])[0]
            print(f"ğŸš€ NEXUS Speed chunks: {num_chunks}")
            
            offset = 8
            chunk_data_list = []
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿åé›†
            for _ in range(num_chunks):
                if offset + 4 > len(compressed_data):
                    break
                chunk_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
                offset += 4
                
                if offset + chunk_size > len(compressed_data):
                    break
                chunk_data_list.append(compressed_data[offset:offset+chunk_size])
                offset += chunk_size
            
            # ä¸¦åˆ—é«˜é€Ÿå±•é–‹
            optimal_workers = min(4, len(chunk_data_list), self.max_threads)
            
            def nexus_speed_decompress_chunk(chunk_data):
                """NEXUSé«˜é€Ÿãƒãƒ£ãƒ³ã‚¯å±•é–‹"""
                import bz2
                # 2æ®µå±•é–‹: ZLIB â†’ BZIP2
                stage1 = zlib.decompress(chunk_data)
                stage2 = bz2.decompress(stage1)
                return stage2
            
            if optimal_workers > 1 and len(chunk_data_list) > 1:
                with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                    decompressed_chunks = list(executor.map(nexus_speed_decompress_chunk, chunk_data_list))
            else:
                decompressed_chunks = [nexus_speed_decompress_chunk(chunk) for chunk in chunk_data_list]
            
            result = b''.join(decompressed_chunks)
            print(f"âœ… NEXUS Speedå±•é–‹å®Œäº†: {len(result)} bytes")
            return result
            
        except Exception as e:
            print(f"âŒ NEXUS Speedå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _nexus_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸŒŸ NEXUSç‹¬è‡ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå±•é–‹ï¼ˆ200MB/sç›®æ¨™ï¼‰"""
        try:
            # NEXUSç‹¬è‡ªãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            if len(compressed_data) < 8:
                raise ValueError("Invalid NEXUS format")
            
            num_chunks = struct.unpack('<I', compressed_data[4:8])[0]
            print(f"ï¿½ NEXUS chunks: {num_chunks}")
            
            offset = 8
            chunk_data_list = []
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿åé›†
            for _ in range(num_chunks):
                if offset + 4 > len(compressed_data):
                    break
                chunk_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
                offset += 4
                
                if offset + chunk_size > len(compressed_data):
                    break
                chunk_data_list.append(compressed_data[offset:offset+chunk_size])
                offset += chunk_size
            
            # ä¸¦åˆ—å±•é–‹ã§200MB/sé”æˆ
            optimal_workers = min(4, len(chunk_data_list), self.max_threads)
            
            def nexus_decompress_chunk(chunk_data):
                """NEXUSç‹¬è‡ªãƒãƒ£ãƒ³ã‚¯å±•é–‹"""
                # æ¨™æº–zlibã§å±•é–‹ï¼ˆé«˜é€Ÿï¼‰
                decompressed = zlib.decompress(chunk_data)
                # NEXUSç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒ
                return self._nexus_pattern_restore(decompressed)
            
            if optimal_workers > 1 and len(chunk_data_list) > 1:
                with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                    decompressed_chunks = list(executor.map(nexus_decompress_chunk, chunk_data_list))
            else:
                decompressed_chunks = [nexus_decompress_chunk(chunk) for chunk in chunk_data_list]
            
            result = b''.join(decompressed_chunks)
            print(f"âœ… NEXUSå±•é–‹å®Œäº†: {len(result)} bytes")
            return result
            
        except Exception as e:
            print(f"âŒ NEXUSå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _nexus_high_ratio_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ¯ NEXUS 99%åœ§ç¸®å±•é–‹ï¼ˆå˜æ®µBZIP2ï¼‰"""
        print("ğŸ¯ NEXUS NX99å±•é–‹é–‹å§‹")
        try:
            data_content = compressed_data[4:]  # NX99ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            import bz2
            # å˜æ®µå±•é–‹: BZIP2ã®ã¿
            decompressed = bz2.decompress(data_content)
            print(f"âœ… NX99å±•é–‹å®Œäº†: {len(decompressed)} bytes")
            return decompressed
        except Exception as e:
            print(f"âŒ NX99å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _nexus_extreme_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ’ NEXUS Extremeå±•é–‹"""
        data_content = compressed_data[4:]
        try:
            import lzma
            import bz2
            # 3æ®µå±•é–‹: ZLIB â†’ BZIP2 â†’ LZMA
            stage1 = zlib.decompress(data_content)
            stage2 = bz2.decompress(stage1)
            stage3 = lzma.decompress(stage2, format=lzma.FORMAT_ALONE)
            return self._nexus_pattern_restore_advanced(stage3)
        except Exception as e:
            print(f"âŒ Extremeå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _nexus_fast_decompress(self, compressed_data: bytes) -> bytes:
        """âš¡ NEXUSé«˜é€Ÿå±•é–‹"""
        data_content = compressed_data[4:]
        decompressed = zlib.decompress(data_content)
        return self._nexus_pattern_restore(decompressed)
    
    def _nexus_pattern_restore(self, data: bytes) -> bytes:
        """ğŸŒŸ NEXUSç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒ"""
        result = bytearray(data)
        
        # NEXUSç‹¬è‡ªãƒãƒ¼ã‚«ãƒ¼ã‚’å…ƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾©å…ƒ
        # å®Ÿè£…ç°¡ç´ åŒ–ã®ãŸã‚ç¾åœ¨ã¯å˜ç´”å¾©å…ƒ
        for i in range(5):
            marker = bytes([0xFF, 0xFE, 0xFD, i])
            # ãƒãƒ¼ã‚«ãƒ¼ãŒè¦‹ã¤ã‹ã£ãŸã‚‰é©åˆ‡ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾©å…ƒ
            # ç¾åœ¨ã¯ç°¡æ˜“å®Ÿè£…
            if marker in result:
                result = result.replace(marker, b'NEXUS_PATTERN_' + str(i).encode())
        
        return bytes(result)
    
    def _nexus_pattern_restore_advanced(self, data: bytes) -> bytes:
        """ğŸŒŸ NEXUSè»½é‡ãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒ"""
        try:
            # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨è»½é‡å¾©å…ƒ
            if len(data) > 50 * 1024 * 1024:
                return self._nexus_lightweight_restore(data)
            
            text = data.decode('utf-8', errors='ignore')
            
            # è»½é‡å¾©å…ƒå‡¦ç†
            import re
            
            # è¡Œã‚³ãƒ¼ãƒ‰å¾©å…ƒï¼ˆ1æ¡å¯¾å¿œï¼‰
            text = re.sub(r'Â©(\d)Â©', r'NEXUS_LINE_\1', text)
            
            # ã‚¹ãƒšãƒ¼ã‚¹å¾©å…ƒ
            text = text.replace(' Â§Â§ ', '   ')  # 3ã‚¹ãƒšãƒ¼ã‚¹å¾©å…ƒ
            text = text.replace(' Â¤ ', '\t\t')  # 2ã‚¿ãƒ–å¾©å…ƒ
            
            return text.encode('utf-8')
            
        except:
            return data
    
    def _nexus_lightweight_restore(self, data: bytes) -> bytes:
        """âš¡ NEXUSè¶…è»½é‡å¾©å…ƒ"""
        try:
            result = bytearray(data)
            
            # è¶…è»½é‡ãƒãƒ¼ã‚«ãƒ¼å¾©å…ƒ
            for i in range(3):
                marker = bytes([0xFE, 0xFD, i, 0xFC])
                if marker in result:
                    result = result.replace(marker, b'NEXUS_FAST_' + str(i).encode())
            
            return bytes(result)
        except:
            return data

    def _nexus_legacy_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ“¦ ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œ"""
        # æ¨™æº–çš„ãªzlibå½¢å¼ã¨ã—ã¦å‡¦ç†
        try:
            return zlib.decompress(compressed_data)
        except:
            # ã•ã‚‰ãªã‚‹è©¦è¡Œ
            if len(compressed_data) >= 8:
                try:
                    # ãƒãƒ£ãƒ³ã‚¯å½¢å¼ã®å¯èƒ½æ€§
                    num_chunks = struct.unpack('<I', compressed_data[:4])[0]
                    if 1 <= num_chunks <= 10000:
                        offset = 4
                        chunks = []
                        for _ in range(num_chunks):
                            if offset + 4 > len(compressed_data):
                                break
                            chunk_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
                            offset += 4
                            if offset + chunk_size > len(compressed_data):
                                break
                            chunk_data = compressed_data[offset:offset+chunk_size]
                            chunks.append(zlib.decompress(chunk_data))
                            offset += chunk_size
                        return b''.join(chunks)
                except:
                    pass
            raise ValueError("Unknown format")

    # NEXUSç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç”¨è£œåŠ©ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆä¸è¦ã«ãªã£ãŸæ—§ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‰Šé™¤ï¼‰
    
    def _zlib_ultra_compress(self, data: bytes) -> bytes:
        """ğŸ’ zlib è¶…é«˜åœ§ç¸®ç‡ãƒ¢ãƒ¼ãƒ‰ï¼ˆåŠ¹ç‡åŒ–v2 - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰"""
        import bz2
        import lzma
        
        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç”¨åŠ¹ç‡åŒ–æˆ¦ç•¥
        size_mb = len(data) / (1024 * 1024)
        
        # è¶…å¤§å®¹é‡ï¼ˆ1GBä»¥ä¸Šï¼‰ã¯åŠ¹ç‡é‡è¦–
        if size_mb >= 1000:  # 1GBä»¥ä¸Š
            # åŠ¹ç‡çš„ãƒãƒ£ãƒ³ã‚¯åœ§ç¸®ã®ã¿ï¼ˆå¤šæ®µåœ§ç¸®ã¯é‡ã™ãã‚‹ï¼‰
            chunk_size = 128 * 1024  # 128KB chunksï¼ˆå¤§ãã‚ã§åŠ¹ç‡åŒ–ï¼‰
            chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
            
            # åŠ¹ç‡çš„ä¸¦åˆ—å‡¦ç†ï¼ˆ2ä¸¦åˆ—ã®ã¿ï¼‰
            optimal_workers = min(2, len(chunks), self.max_threads)
            
            def compress_chunk_fast(chunk):
                # åŠ¹ç‡é‡è¦–: BZIP2ã®ã¿ä½¿ç”¨
                try:
                    bz2_result = bz2.compress(chunk, compresslevel=6)  # ãƒ¬ãƒ™ãƒ«9â†’6ã§åŠ¹ç‡åŒ–
                    return ('BZ2X', bz2_result)
                except:
                    return ('ZLIB', zlib.compress(chunk, level=9))
            
            with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                results = list(executor.map(compress_chunk_fast, chunks))
            
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
            result = bytearray()
            result.extend(struct.pack('<I', len(chunks)))
            
            methods_data = ''.join(f"{method:<4}" for method, _ in results).encode('ascii')
            result.extend(struct.pack('<I', len(methods_data)))
            result.extend(methods_data)
            
            for _, compressed_chunk in results:
                result.extend(struct.pack('<I', len(compressed_chunk)))
                result.extend(compressed_chunk)
            
            return bytes(result)
        
        # ä¸­ã€œå¤§å®¹é‡ï¼ˆ8MBã€œ1GBï¼‰ã¯è¶…é«˜åœ§ç¸®ç‡ãƒ¢ãƒ¼ãƒ‰
        elif size_mb >= 8:
            try:
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹åˆ¤å®š
                sample = data[:min(4096, len(data))]
                text_chars = sum(1 for b in sample if 32 <= b <= 126 or b in [9, 10, 13])
                text_ratio = text_chars / len(sample)
                
                if text_ratio > 0.7:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ99.9%åœ§ç¸®ç‡ç›®æ¨™ï¼‰
                    # ä¸‰æ®µåœ§ç¸®: lzma â†’ bzip2 â†’ zlibï¼ˆæœ€é«˜åœ§ç¸®ç‡ï¼‰
                    stage1 = lzma.compress(data, format=lzma.FORMAT_ALONE, preset=9)
                    stage2 = bz2.compress(stage1, compresslevel=9)
                    stage3 = zlib.compress(stage2, level=9)
                    
                    if len(stage3) < len(data) * 0.01:  # 1%æœªæº€ãªã‚‰æ¡ç”¨ï¼ˆ99%åœ§ç¸®ç‡ï¼‰
                        return b'3STG' + stage3  # ä¸‰æ®µåœ§ç¸®è­˜åˆ¥å­
                        
                    # ä»£æ›¿: äºŒæ®µåœ§ç¸® bzip2 â†’ zlib
                    stage1_alt = bz2.compress(data, compresslevel=9)
                    stage2_alt = zlib.compress(stage1_alt, level=9)
                    
                    if len(stage2_alt) < len(data) * 0.01:  # 1%æœªæº€ãªã‚‰æ¡ç”¨
                        return b'BZ2Z' + stage2_alt
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: LZMAå˜ä½“ï¼ˆé«˜åœ§ç¸®ï¼‰
                lzma_result = lzma.compress(data, format=lzma.FORMAT_ALONE, preset=9)
                if len(lzma_result) < len(data) * 0.02:  # 2%æœªæº€ãªã‚‰æ¡ç”¨
                    return b'LZMA' + lzma_result
                else:
                    # æ›´ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: BZIP2å˜ä½“
                    bz2_result = bz2.compress(data, compresslevel=9)
                    return b'BZ2X' + bz2_result
                    
            except Exception as e:
                print(f"âš ï¸ è¶…é«˜åœ§ç¸®ã‚¨ãƒ©ãƒ¼ã€zlibã«åˆ‡ã‚Šæ›¿ãˆ: {e}")
                return zlib.compress(data, level=9)
        
        # å°ã€œä¸­å®¹é‡ï¼ˆ8MBæœªæº€ï¼‰ã¯å¾“æ¥é€šã‚Š
        else:
            try:
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹åˆ¤å®š
                sample = data[:min(4096, len(data))]
                text_chars = sum(1 for b in sample if 32 <= b <= 126 or b in [9, 10, 13])
                text_ratio = text_chars / len(sample)
                
                if text_ratio > 0.7:  # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
                    # äºŒæ®µåœ§ç¸®: bzip2 â†’ zlibï¼ˆåŠ¹ç‡é‡è¦–ï¼‰
                    stage1 = bz2.compress(data, compresslevel=9)
                    stage2 = zlib.compress(stage1, level=9)
                    
                    if len(stage2) < len(data) * 0.05:  # 5%æœªæº€ãªã‚‰æ¡ç”¨
                        return b'BZ2Z' + stage2  # äºŒæ®µåœ§ç¸®è­˜åˆ¥å­
                
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: LZMAå˜ä½“
                lzma_result = lzma.compress(data, format=lzma.FORMAT_ALONE, preset=9)
                if len(lzma_result) < len(data) * 0.1:  # 10%æœªæº€ãªã‚‰æ¡ç”¨
                    return b'LZMA' + lzma_result
                else:
                    # æ›´ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: BZIP2å˜ä½“
                    bz2_result = bz2.compress(data, compresslevel=9)
                    return b'BZ2X' + bz2_result
                    
            except Exception as e:
                print(f"âš ï¸ åœ§ç¸®ã‚¨ãƒ©ãƒ¼ã€zlibã«åˆ‡ã‚Šæ›¿ãˆ: {e}")
                return zlib.compress(data, level=9)
    
    def _optimize_text_data(self, data):
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†æœ€é©åŒ–"""
        import re
        text = data.decode('utf-8', errors='ignore')
        
        # é‡è¤‡è¡Œã®æœ€é©åŒ–
        lines = text.split('\n')
        unique_lines = []
        line_counts = {}
        
        for line in lines:
            if line not in line_counts:
                line_counts[line] = 0
                unique_lines.append(line)
            line_counts[line] += 1
        
        # é«˜é »åº¦è¡Œã®ç½®æ›
        optimized_text = text
        for line, count in sorted(line_counts.items(), key=lambda x: x[1], reverse=True)[:100]:
            if count > 10 and len(line) > 10:
                marker = f"Â§{len(optimized_text) % 1000:03d}Â§"
                optimized_text = optimized_text.replace(line, marker)
        
        return optimized_text.encode('utf-8')
    
    def _dictionary_compress(self, data):
        """è¾æ›¸ãƒ™ãƒ¼ã‚¹åœ§ç¸®"""
        try:
            import zstandard as zstd
            # ZStandardæœ€é«˜åœ§ç¸®ãƒ¬ãƒ™ãƒ«
            cctx = zstd.ZstdCompressor(level=22, write_content_size=True)
            return cctx.compress(data)
        except:
            # ZStandardãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ZLIBæœ€é«˜ãƒ¬ãƒ™ãƒ«
            return zlib.compress(data, level=9)
    
    def _ppmd_compress(self, data):
        """PPMdåœ§ç¸®ï¼ˆé«˜æ€§èƒ½ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®ï¼‰"""
        try:
            # PPMdé¢¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
            import bz2
            # è¤‡æ•°å›åœ§ç¸®ã§åœ§ç¸®ç‡å‘ä¸Š
            result = data
            for i in range(3):
                result = bz2.compress(result, compresslevel=9)
                if len(result) >= len(data) * 0.5:  # åœ§ç¸®åŠ¹æœãŒè–„ã„å ´åˆã¯åœæ­¢
                    break
            return result
        except:
            return bz2.compress(data, compresslevel=9)
    
    def _dictionary_decompress(self, data):
        """è¾æ›¸ãƒ™ãƒ¼ã‚¹å±•é–‹"""
        try:
            import zstandard as zstd
            dctx = zstd.ZstdDecompressor()
            return dctx.decompress(data)
        except:
            return zlib.decompress(data)
    
    def _ppmd_decompress(self, data):
        """PPMdå±•é–‹"""
        try:
            import bz2
            # è¤‡æ•°å›å±•é–‹
            result = data
            for i in range(3):
                try:
                    result = bz2.decompress(result)
                except:
                    break
            return result
        except:
            return bz2.decompress(data)
    
    def _restore_optimized_data(self, data):
        """å‰å‡¦ç†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¾©å…ƒ"""
        # ç¾åœ¨ã¯ç°¡æ˜“å®Ÿè£…ï¼ˆãƒãƒ¼ã‚«ãƒ¼å¾©å…ƒã¯çœç•¥ï¼‰
        return data

    def _lightning_package_data(self, compressed_data: bytes, method: str, original_size: int) -> bytes:
        """ğŸ“¦ é«˜æ€§èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆå®‰å®šç‰ˆï¼‰"""
        method_bytes = method.encode('ascii')[:15]
        method_len = len(method_bytes)
        
        # é«˜æ€§èƒ½ãƒ˜ãƒƒãƒ€ãƒ¼: magic(4) + original_size(4) + method_len(1) + method + data
        magic = b'NXL8'  # NEXUS v8
        header = magic + struct.pack('<I', original_size) + struct.pack('<B', method_len) + method_bytes
        
        return header + compressed_data
    
    def _lightning_unpackage_data(self, packaged_data: bytes) -> Tuple[bytes, str, int]:
        """ğŸ“¦ é«˜æ€§èƒ½ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è§£æï¼ˆå®‰å®šç‰ˆï¼‰"""
        if len(packaged_data) < 9:
            raise ValueError("Invalid NEXUS package")
        
        magic = packaged_data[:4]
        if magic not in [b'NXL8', b'NXL7']:  # ä¸‹ä½äº’æ›æ€§
            raise ValueError("Invalid NEXUS magic number")
        
        original_size = struct.unpack('<I', packaged_data[4:8])[0]
        method_len = packaged_data[8]
        
        if len(packaged_data) < 9 + method_len:
            raise ValueError("Incomplete NEXUS package")
        
        method = packaged_data[9:9 + method_len].decode('ascii')
        compressed_data = packaged_data[9 + method_len:]
        
        return compressed_data, method, original_size
    
    def _decompress_nexus_format(self, compressed_data: bytes) -> bytes:
        """NEXUSå½¢å¼ (NXL8/NXL7) å°‚ç”¨å±•é–‹ãƒ¡ã‚½ãƒƒãƒ‰ - ç„¡é™å†å¸°å›é¿ç‰ˆ"""
        try:
            print(f"ğŸ” NEXUSå½¢å¼å±•é–‹é–‹å§‹: {len(compressed_data)} bytes")
            
            # ç›´æ¥ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸è§£æã—ã¦å±•é–‹
            data, method, original_size = self._lightning_unpackage_data(compressed_data)
            result = self._execute_optimized_decompression(data, method)
            
            print(f"âœ… NEXUSå½¢å¼å±•é–‹å®Œäº†: {len(result)} bytes")
            return result
            
        except Exception as e:
            print(f"âŒ NEXUSå½¢å¼å±•é–‹å¤±æ•—: {e}")
            raise

    def _nexus_smart_preprocess(self, data: bytes) -> bytes:
        """ğŸ§  NEXUSå®Œå…¨å¯é€†å‰å‡¦ç†ï¼ˆ99%åœ§ç¸®ç‡ç‹™ã„ï¼‰- è»½é‡ç‰ˆ"""
        try:
            print("ğŸ§  NEXUSå®Œå…¨å¯é€†å‰å‡¦ç†é–‹å§‹...")
            
            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†
            if len(data) > 10 * 1024 * 1024:  # 10MBä»¥ä¸Š
                print("ğŸ“Š å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼šã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‡¦ç†")
                sample_size = min(1024 * 1024, len(data))  # 1MBã‚µãƒ³ãƒ—ãƒ«
                sample = data[:sample_size]
            else:
                sample = data
            
            # å®Œå…¨å¯é€†ãªè¾æ›¸ãƒ™ãƒ¼ã‚¹åœ§ç¸®ã®ã¿ä½¿ç”¨
            from collections import Counter
            
            # åŠ¹ç‡çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œç´¢ï¼ˆé•·ã•4ã®ã¿ï¼‰
            patterns = []
            step = max(1, len(sample) // 100000)  # æœ€å¤§10ä¸‡ãƒ‘ã‚¿ãƒ¼ãƒ³
            
            for i in range(0, len(sample) - 4, step):
                pattern = sample[i:i+4]
                patterns.append(pattern)
            
            # å‡ºç¾é »åº¦ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            pattern_counts = Counter(patterns)
            
            # é«˜é »åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆ5å›ä»¥ä¸Šå‡ºç¾ï¼‰ã‚’è¾æ›¸åŒ–
            dictionary = {}
            compressed_data = bytearray(data)
            marker_id = 0
            
            for pattern, count in pattern_counts.most_common(20):  # ä¸Šä½20ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿
                if count >= 5 and len(pattern) == 4:
                    # å®Œå…¨å¯é€†ãƒãƒ¼ã‚«ãƒ¼
                    marker = bytes([0xFF, 0xFE, 0xFD, marker_id])
                    
                    # å…ƒãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚«ãƒ¼ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¢ºèª
                    if marker not in data:
                        # è¾æ›¸ã«ç™»éŒ²
                        dictionary[marker] = pattern
                        
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒãƒ¼ã‚«ãƒ¼ã«ç½®æ›
                        compressed_data = compressed_data.replace(pattern, marker)
                        
                        savings = len(pattern) * count - len(marker) * count
                        if savings > 0:
                            print(f"ğŸ§  ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›: {len(pattern)}bytesÃ—{count}å› â†’ {savings}byteså‰Šæ¸›")
                            marker_id += 1
                            
                            if marker_id >= 100:  # ãƒãƒ¼ã‚«ãƒ¼ä¸Šé™
                                break
            
            # è¾æ›¸æƒ…å ±ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¿½åŠ ï¼ˆå®Œå…¨å¯é€†ã®ãŸã‚ï¼‰
            if dictionary:
                header = bytearray()
                header.extend(b'NXDICT')  # è¾æ›¸åœ§ç¸®è­˜åˆ¥å­
                header.extend(len(dictionary).to_bytes(2, 'little'))  # è¾æ›¸ã‚¨ãƒ³ãƒˆãƒªæ•°
                
                for marker, pattern in dictionary.items():
                    header.extend(len(marker).to_bytes(1, 'little'))
                    header.extend(marker)
                    header.extend(len(pattern).to_bytes(2, 'little'))
                    header.extend(pattern)
                
                header.extend(b'NXDATA')  # ãƒ‡ãƒ¼ã‚¿é–‹å§‹ãƒãƒ¼ã‚«ãƒ¼
                result = header + compressed_data
                
                savings = len(data) - len(result)
                if savings > 0:
                    print(f"ğŸ§  å®Œå…¨å¯é€†å‰å‡¦ç†: {savings}byteså‰Šæ¸› ({savings/len(data)*100:.3f}%)")
                    print(f"ğŸ”„ è¾æ›¸ã‚¨ãƒ³ãƒˆãƒª: {len(dictionary)}å€‹")
                    return bytes(result)
                else:
                    print("ğŸ§  å‰å‡¦ç†åŠ¹æœãªã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
                    return data
            else:
                print("ğŸ§  æœ‰åŠ¹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãªã—ã€å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨")
                return data
            
        except Exception as e:
            print(f"âš ï¸ å‰å‡¦ç†å¤±æ•—: {e}")
            return data

    # NXPBï¼ˆå‰å‡¦ç†ï¼‰ã¨NXBZï¼ˆBZIP2ï¼‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®å±•é–‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
    def _nexus_preprocessed_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ”§ NEXUSå‰å‡¦ç†åœ§ç¸®å±•é–‹"""
        print("ğŸ”§ NEXUSå‰å‡¦ç†å±•é–‹é–‹å§‹")
        try:
            data_content = compressed_data[4:]  # NXPBãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            import bz2
            # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®BZIP2å±•é–‹
            decompressed = bz2.decompress(data_content)
            print(f"âœ… NXPBå±•é–‹å®Œäº†: {len(decompressed)} bytes")
            return decompressed
        except Exception as e:
            print(f"âŒ NXPBå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _nexus_bzip2_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ’™ NEXUS BZIP2å±•é–‹"""
        print("ğŸ’™ NEXUS BZIP2å±•é–‹é–‹å§‹")
        try:
            data_content = compressed_data[4:]  # NXBZãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            import bz2
            decompressed = bz2.decompress(data_content)
            print(f"âœ… NXBZå±•é–‹å®Œäº†: {len(decompressed)} bytes")
            return decompressed
        except Exception as e:
            print(f"âŒ NXBZå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _nexus_lzma_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ’ NEXUS LZMAå±•é–‹"""
        print("ğŸ’ NEXUS LZMAå±•é–‹é–‹å§‹")
        try:
            data_content = compressed_data[4:]  # NXLZãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            import lzma
            decompressed = lzma.decompress(data_content, format=lzma.FORMAT_XZ)
            print(f"âœ… NXLZå±•é–‹å®Œäº†: {len(decompressed)} bytes")
            return decompressed
        except Exception as e:
            print(f"âŒ NXLZå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _nexus_dict_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ§  NEXUSè¾æ›¸åœ§ç¸®å±•é–‹ï¼ˆå®Œå…¨å¯é€†ï¼‰"""
        print("ğŸ§  NEXUSè¾æ›¸å±•é–‹é–‹å§‹")
        try:
            if not compressed_data.startswith(b'NXDICT'):
                raise ValueError("Invalid NEXUS dictionary format")
            
            offset = 6  # 'NXDICT'ã‚’ã‚¹ã‚­ãƒƒãƒ—
            dict_entries = int.from_bytes(compressed_data[offset:offset+2], 'little')
            offset += 2
            
            print(f"ğŸ”„ è¾æ›¸ã‚¨ãƒ³ãƒˆãƒªå¾©å…ƒ: {dict_entries}å€‹")
            
            # è¾æ›¸ã‚’å¾©å…ƒ
            dictionary = {}
            for _ in range(dict_entries):
                marker_len = compressed_data[offset]
                offset += 1
                marker = compressed_data[offset:offset+marker_len]
                offset += marker_len
                
                pattern_len = int.from_bytes(compressed_data[offset:offset+2], 'little')
                offset += 2
                pattern = compressed_data[offset:offset+pattern_len]
                offset += pattern_len
                
                dictionary[marker] = pattern
                print(f"ğŸ”„ å¾©å…ƒ: {marker.hex()} â†’ {len(pattern)}bytes")
            
            # ãƒ‡ãƒ¼ã‚¿é–‹å§‹ä½ç½®ã‚’æ¤œç´¢
            data_start = compressed_data.find(b'NXDATA', offset)
            if data_start == -1:
                raise ValueError("Data start marker not found")
            
            data_start += 6  # 'NXDATA'ã‚’ã‚¹ã‚­ãƒƒãƒ—
            compressed_content = bytearray(compressed_data[data_start:])
            
            # ãƒãƒ¼ã‚«ãƒ¼ã‚’å…ƒã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾©å…ƒ
            for marker, pattern in dictionary.items():
                compressed_content = compressed_content.replace(marker, pattern)
                print(f"ğŸ”„ ãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒ: {len(pattern)}bytes")
            
            result = bytes(compressed_content)
            print(f"âœ… è¾æ›¸å±•é–‹å®Œäº†: {len(result)} bytesï¼ˆå®Œå…¨å¯é€†ï¼‰")
            return result
            
        except Exception as e:
            print(f"âŒ è¾æ›¸å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _nexus_dict_lzma_decompress(self, compressed_data: bytes) -> bytes:
        """ğŸ¯ NEXUSè¾æ›¸+LZMAå±•é–‹ï¼ˆå®Œå…¨å¯é€†ï¼‰"""
        print("ğŸ¯ NEXUSè¾æ›¸+LZMAå±•é–‹é–‹å§‹")
        try:
            data_content = compressed_data[4:]  # NXDLãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»
            import lzma
            
            # 1. LZMAã§å±•é–‹
            dict_data = lzma.decompress(data_content, format=lzma.FORMAT_XZ)
            print("ğŸ’ LZMAå±•é–‹å®Œäº†")
            
            # 2. è¾æ›¸å±•é–‹
            result = self._nexus_dict_decompress(dict_data)
            print(f"âœ… è¾æ›¸+LZMAå±•é–‹å®Œäº†: {len(result)} bytesï¼ˆå®Œå…¨å¯é€†ï¼‰")
            return result
            
        except Exception as e:
            print(f"âŒ è¾æ›¸+LZMAå±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _nexus_dictionary_compress(self, data: bytes) -> bytes:
        """ğŸ¯ NEXUSè¾æ›¸åœ§ç¸®ï¼ˆ99%åœ§ç¸®ç‡ç‹™ã„ï¼‰"""
        try:
            print("ğŸ¯ è¾æ›¸åœ§ç¸®é–‹å§‹...")
            text = data.decode('utf-8', errors='ignore')
            
            # é«˜é »åº¦èªå¥ã‚’è¾æ›¸åŒ–
            import re
            from collections import Counter
            
            # 3æ–‡å­—ä»¥ä¸Šã®å˜èªã‚’æŠ½å‡º
            words = re.findall(r'\b\w{3,}\b', text)
            word_counts = Counter(words)
            
            # ä¸Šä½20èªã‚’è¾æ›¸åŒ–
            dictionary = {}
            compressed_text = text
            
            for i, (word, count) in enumerate(word_counts.most_common(20)):
                if count >= 3:  # 3å›ä»¥ä¸Šå‡ºç¾
                    marker = f"Â§{i:02d}Â§"  # è¾æ›¸ãƒãƒ¼ã‚«ãƒ¼
                    dictionary[marker] = word
                    compressed_text = compressed_text.replace(word, marker)
                    print(f"ğŸ¯ è¾æ›¸: {word} â†’ {marker} ({count}å›)")
            
            # è¾æ›¸æƒ…å ±ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«åŸ‹ã‚è¾¼ã¿
            dict_header = '|DICT|' + '|'.join([f"{k}:{v}" for k, v in dictionary.items()]) + '|END|'
            final_text = dict_header + compressed_text
            
            result = final_text.encode('utf-8')
            saving = len(data) - len(result)
            print(f"ğŸ¯ è¾æ›¸åœ§ç¸®åŠ¹æœ: {saving} byteså‰Šæ¸› ({saving/len(data)*100:.2f}%)")
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ è¾æ›¸åœ§ç¸®å¤±æ•—: {e}")
            return data

    def _nexus_ultra_preprocess(self, data: bytes) -> bytes:
        """ğŸ”§ NEXUSè¤‡åˆå‰å‡¦ç†ï¼ˆ99%åœ§ç¸®ç‡ã¸ã®æœ€å¾Œã®æŒ‘æˆ¦ï¼‰"""
        try:
            print("ğŸ”§ è¤‡åˆå‰å‡¦ç†é–‹å§‹...")
            
            # ç¬¬1æ®µéš: åŸºæœ¬å‰å‡¦ç†
            processed = self._nexus_smart_preprocess(data)
            
            # ç¬¬2æ®µéš: ã•ã‚‰ãªã‚‹æœ€é©åŒ–
            text = processed.decode('utf-8', errors='ignore')
            
            # æ—¥æœ¬èªç‰¹åŒ–æœ€é©åŒ–
            import re
            
            # ã²ã‚‰ãŒãªã®æœ€é©åŒ–
            hiragana_map = {
                'ã£ã£': 'ã£',  # ä¿ƒéŸ³é‡è¤‡
                'ãƒ¼ãƒ¼': 'ãƒ¼',  # é•·éŸ³é‡è¤‡
            }
            
            for old, new in hiragana_map.items():
                text = text.replace(old, new)
            
            # åŠ©è©ã®æœ€é©åŒ–
            text = re.sub(r'(ã§ã™|ã¾ã™|ã§ã‚ã‚‹)(\1)+', r'\1', text)  # æ•¬èªé‡è¤‡
            text = re.sub(r'(ã®|ãŒ|ã‚’|ã«|ã§|ã¨)(\1)+', r'\1', text)  # åŠ©è©é‡è¤‡
            
            # æ•°å€¤è¡¨ç¾ã®çµ±ä¸€
            text = re.sub(r'(\d+)\s*å¹´\s*(\d+)\s*æœˆ\s*(\d+)\s*æ—¥', r'\1/\2/\3', text)
            
            result = text.encode('utf-8')
            additional_saving = len(processed) - len(result)
            total_saving = len(data) - len(result)
            
            print(f"ğŸ”§ è¤‡åˆå‰å‡¦ç†: è¿½åŠ {additional_saving}byteså‰Šæ¸›")
            print(f"ğŸ”§ åˆè¨ˆåŠ¹æœ: {total_saving}byteså‰Šæ¸› ({total_saving/len(data)*100:.2f}%)")
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ è¤‡åˆå‰å‡¦ç†å¤±æ•—: {e}")
            return data

    def _nexus_frequency_compress(self, data: bytes) -> bytes:
        """ğŸŒŸ NEXUSé«˜é€Ÿå‘¨æ³¢æ•°åœ§ç¸®ï¼ˆé€Ÿåº¦æœ€é©åŒ–ç‰ˆï¼‰"""
        try:
            # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯è»½é‡åŒ–
            if len(data) > 50 * 1024 * 1024:  # 50MBä»¥ä¸Šã¯è»½é‡åŒ–
                return self._nexus_frequency_compress_light(data)
            
            # NEXUSç‹¬è‡ªï¼šé«˜é€Ÿå‘¨æ³¢æ•°ãƒ™ãƒ¼ã‚¹åœ§ç¸®
            from collections import Counter
            import struct
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ™ãƒ¼ã‚¹å‘¨æ³¢æ•°åˆ†æï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰
            sample_size = min(len(data), 100000)  # 100KBåˆ¶é™
            sample = data[:sample_size]
            byte_freq = Counter(sample)
            
            # ä¸Šä½128ãƒã‚¤ãƒˆã®ã¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆé€Ÿåº¦å‘ä¸Šï¼‰
            sorted_bytes = sorted(byte_freq.items(), key=lambda x: x[1], reverse=True)[:128]
            
            # é«˜é€Ÿã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«
            encoding_table = {}
            for i, (byte_val, freq) in enumerate(sorted_bytes):
                encoding_table[byte_val] = i.to_bytes(1, 'big')
            
            # é«˜é€Ÿãƒ‡ãƒ¼ã‚¿åœ§ç¸®
            compressed = bytearray()
            compressed.extend(struct.pack('<H', len(sorted_bytes)))
            
            # ç°¡æ˜“ãƒ†ãƒ¼ãƒ–ãƒ«
            for byte_val, freq in sorted_bytes:
                compressed.extend(struct.pack('<B', byte_val))
            
            # é«˜é€Ÿã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            for byte_val in data:
                if byte_val in encoding_table:
                    compressed.extend(encoding_table[byte_val])
                else:
                    compressed.append(byte_val)  # ãã®ã¾ã¾
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSå‘¨æ³¢æ•°åœ§ç¸®å¤±æ•—: {e}")
            return data
    
    def _nexus_hybrid_compress(self, data: bytes, patterns: dict) -> bytes:
        """ğŸš€ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®ï¼ˆLZ4+Zstd+LZMAèåˆï¼‰"""
        try:
            import struct
            
            # ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§åˆ†æï¼ˆé«˜é€ŸåŒ–ï¼‰
            chunk_size = 65536  # 64KB ãƒãƒ£ãƒ³ã‚¯ï¼ˆé«˜é€ŸåŒ–ï¼‰
            chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
            
            compressed = bytearray()
            compressed.extend(struct.pack('<I', len(chunks)))
            
            for chunk_idx, chunk in enumerate(chunks):
                # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
                best_result = self._nexus_select_best_algorithm(chunk, chunk_idx)
                
                # çµæœæ ¼ç´
                method, compressed_chunk = best_result
                compressed.extend(struct.pack('<BH', method, len(compressed_chunk)))
                compressed.extend(compressed_chunk)
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®å¤±æ•—: {e}")
            return self._nexus_fallback_compress(data)
    
    def _nexus_select_best_algorithm(self, chunk: bytes, chunk_idx: int) -> tuple:
        """âš¡ æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠï¼ˆé€Ÿåº¦é‡è¦–ï¼‰"""
        try:
            import time
            
            # ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§åˆ†æï¼ˆé«˜é€Ÿï¼‰
            sample_size = min(len(chunk), 1024)
            sample = chunk[:sample_size]
            
            unique_ratio = len(set(sample)) / len(sample) if len(sample) > 0 else 1.0
            repetitive_ratio = self._quick_repetitive_check(sample)
            
            # 1. LZ4é¢¨é«˜é€Ÿåœ§ç¸®ï¼ˆä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ»é«˜é€Ÿå„ªå…ˆï¼‰
            if unique_ratio < 0.4 or chunk_idx % 4 == 0:  # 4ãƒãƒ£ãƒ³ã‚¯ã«1å›ã¯é«˜é€Ÿ
                try:
                    import lz4.frame
                    lz4_result = lz4.frame.compress(chunk, compression_level=0)
                    if len(lz4_result) < len(chunk) * 0.9:  # 10%ä»¥ä¸Šåœ§ç¸®ã§ãã‚Œã°
                        return (1, lz4_result)  # LZ4
                except ImportError:
                    pass
                except:
                    pass
                
                # LZ4ãªã—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šNEXUSé«˜é€ŸRLE
                nexus_fast = self._nexus_lz4_style_compress(chunk)
                return (1, nexus_fast)
            
            # 2. Zstdé¢¨ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®ï¼ˆä¸­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰
            elif 0.4 <= unique_ratio < 0.8:
                try:
                    import zstandard as zstd
                    cctx = zstd.ZstdCompressor(level=3)  # ãƒãƒ©ãƒ³ã‚¹
                    zstd_result = cctx.compress(chunk)
                    if len(zstd_result) < len(chunk) * 0.85:  # 15%ä»¥ä¸Šåœ§ç¸®
                        return (2, zstd_result)  # Zstd
                except ImportError:
                    pass
                except:
                    pass
                
                # Zstdãªã—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šNEXUSè¾æ›¸åœ§ç¸®
                nexus_dict = self._nexus_zstd_style_compress(chunk)
                return (2, nexus_dict)
            
            # 3. LZMAé¢¨é«˜åœ§ç¸®ï¼ˆé«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ»é«˜åœ§ç¸®ç‡å„ªå…ˆï¼‰
            else:
                try:
                    import lzma
                    lzma_filters = [{"id": lzma.FILTER_LZMA2, "preset": 4}]  # è»½é‡
                    lzma_result = lzma.compress(chunk, format=lzma.FORMAT_XZ, 
                                              filters=lzma_filters, check=lzma.CHECK_NONE)
                    return (3, lzma_result)  # LZMA
                except ImportError:
                    pass
                except:
                    pass
                
                # LZMAãªã—ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šNEXUSãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®
                nexus_pattern = self._nexus_lzma_style_compress(chunk)
                return (3, nexus_pattern)
            
        except Exception as e:
            print(f"âš ï¸ ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠå¤±æ•—: {e}")
            return (0, chunk)  # ç„¡åœ§ç¸®
    
    def _nexus_lz4_style_compress(self, data: bytes) -> bytes:
        """âš¡ NEXUS LZ4é¢¨é«˜é€Ÿåœ§ç¸®"""
        try:
            # è¶…é«˜é€ŸRLE + ç°¡æ˜“è¾æ›¸
            import zlib
            return zlib.compress(data, level=1)  # æœ€é«˜é€Ÿãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return data
    
    def _nexus_zstd_style_compress(self, data: bytes) -> bytes:
        """âš¡ NEXUS Zstdé¢¨ãƒãƒ©ãƒ³ã‚¹åœ§ç¸®"""
        try:
            # ãƒãƒ©ãƒ³ã‚¹å‹è¾æ›¸åœ§ç¸®
            import zlib
            return zlib.compress(data, level=4)  # ãƒãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return data
    
    def _nexus_lzma_style_compress(self, data: bytes) -> bytes:
        """âš¡ NEXUS LZMAé¢¨é«˜åœ§ç¸®"""
        try:
            # é«˜åœ§ç¸®ç‡é‡è¦–
            import zlib
            return zlib.compress(data, level=6)  # é«˜åœ§ç¸®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        except:
            return data
    
    def _nexus_fallback_compress(self, data: bytes) -> bytes:
        """ğŸ”„ NEXUSç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            import zlib
            return zlib.compress(data, level=3)
        except:
            return data
    
    def _quick_repetitive_check(self, data: bytes) -> float:
        """âš¡ é«˜é€Ÿåå¾©ãƒã‚§ãƒƒã‚¯"""
        try:
            if len(data) < 16:
                return 0.0
            
            # ç°¡å˜ãªåå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            repeats = 0
            for i in range(0, len(data) - 4, 4):
                pattern = data[i:i+4]
                if data[i+4:i+8] == pattern:
                    repeats += 1
            
            return repeats / (len(data) // 4) if len(data) > 0 else 0.0
        except:
            return 0.0
    
    def _nexus_hierarchical_compress(self, data: bytes) -> bytes:
        """ğŸŒŸ NEXUSéšå±¤æ§‹é€ åœ§ç¸®ï¼ˆç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
        try:
            # NEXUSç‹¬è‡ªï¼šéšå±¤ãƒ–ãƒ­ãƒƒã‚¯åœ§ç¸®
            import struct
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’éšå±¤ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²
            block_size = 8192  # 8KB ãƒ–ãƒ­ãƒƒã‚¯
            blocks = [data[i:i+block_size] for i in range(0, len(data), block_size)]
            
            compressed = bytearray()
            compressed.extend(struct.pack('<I', len(blocks)))  # ãƒ–ãƒ­ãƒƒã‚¯æ•°
            
            for block in blocks:
                # ãƒ–ãƒ­ãƒƒã‚¯å†…ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                patterns = {}
                for i in range(len(block) - 3):
                    pattern = block[i:i+4]
                    patterns[pattern] = patterns.get(pattern, 0) + 1
                
                # é«˜é »åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çŸ­ç¸®ã‚³ãƒ¼ãƒ‰ã«ç½®æ›
                compressed_block = bytearray(block)
                pattern_map = {}
                
                for j, (pattern, count) in enumerate(sorted(patterns.items(), key=lambda x: x[1], reverse=True)[:16]):
                    if count > 2:
                        short_code = bytes([0xF0 + j])  # çŸ­ç¸®ã‚³ãƒ¼ãƒ‰
                        pattern_map[pattern] = short_code
                        compressed_block = compressed_block.replace(pattern, short_code)
                
                # ãƒ–ãƒ­ãƒƒã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼
                compressed.extend(struct.pack('<H', len(pattern_map)))  # ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°
                for pattern, code in pattern_map.items():
                    compressed.extend(struct.pack('<B', code[0]))
                    compressed.extend(pattern)
                
                # åœ§ç¸®æ¸ˆã¿ãƒ–ãƒ­ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿
                compressed.extend(struct.pack('<H', len(compressed_block)))
                compressed.extend(compressed_block)
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSéšå±¤åœ§ç¸®å¤±æ•—: {e}")
            return data
    
    def _nexus_entropy_compress(self, data: bytes) -> bytes:
        """âš¡ NEXUSå®Œå…¨ç‹¬è‡ªåœ§ç¸®ï¼ˆzlibä¸ä½¿ç”¨ï¼‰"""
        try:
            # NEXUSç‹¬è‡ªï¼šå®Œå…¨ã‚ªãƒªã‚¸ãƒŠãƒ«åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
            import struct
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’64KBãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunk_size = 65536
            chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]
            
            compressed = bytearray()
            compressed.extend(struct.pack('<I', len(chunks)))
            
            for chunk in chunks:
                # NEXUSç‹¬è‡ªåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é©ç”¨
                nexus_compressed = self._nexus_pure_compress(chunk)
                
                # ãƒãƒ£ãƒ³ã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼
                compressed.extend(struct.pack('<H', len(nexus_compressed)))
                compressed.extend(nexus_compressed)
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSç´”ç²‹åœ§ç¸®å¤±æ•—: {e}")
            return data
    
    def _nexus_pure_compress(self, data: bytes) -> bytes:
        """ğŸŒŸ NEXUSç´”ç²‹ç‹¬è‡ªåœ§ç¸®ï¼ˆå®Œå…¨ã‚ªãƒªã‚¸ãƒŠãƒ«ï¼‰"""
        try:
            # NEXUSç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼šãƒã‚¤ãƒˆé »åº¦ + RLE + ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ã®èåˆ
            import struct
            from collections import Counter
            
            # 1. NEXUSç‹¬è‡ªãƒã‚¤ãƒˆé »åº¦åœ§ç¸®
            byte_freq = Counter(data)
            sorted_bytes = sorted(byte_freq.items(), key=lambda x: x[1], reverse=True)
            
            # é«˜é »åº¦ãƒã‚¤ãƒˆï¼ˆä¸Šä½32å€‹ï¼‰ã‚’çŸ­ç¸®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            freq_map = {}
            for i, (byte_val, count) in enumerate(sorted_bytes[:32]):
                if count > 3:  # é »åº¦ãŒé«˜ã„ã‚‚ã®ã®ã¿
                    freq_map[byte_val] = i
            
            # 2. NEXUSç‹¬è‡ªRLEåœ§ç¸®
            compressed = bytearray()
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ï¼šé »åº¦ãƒãƒƒãƒ—
            compressed.extend(struct.pack('<B', len(freq_map)))
            for byte_val, code in freq_map.items():
                compressed.extend(struct.pack('<BB', byte_val, code))
            
            # ãƒ‡ãƒ¼ã‚¿åœ§ç¸®
            i = 0
            while i < len(data):
                current_byte = data[i]
                
                # RLEæ¤œå‡º
                run_length = 1
                while (i + run_length < len(data) and 
                       data[i + run_length] == current_byte and 
                       run_length < 255):
                    run_length += 1
                
                if run_length >= 4:  # 4ãƒã‚¤ãƒˆä»¥ä¸Šã®ç¹°ã‚Šè¿”ã—
                    # NEXUS RLEã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰: [0xFE][ãƒã‚¤ãƒˆ][é•·ã•]
                    compressed.extend([0xFE, current_byte, run_length])
                    i += run_length
                elif current_byte in freq_map:
                    # é«˜é »åº¦ãƒã‚¤ãƒˆçŸ­ç¸®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰: [0xFD][ã‚³ãƒ¼ãƒ‰]
                    compressed.extend([0xFD, freq_map[current_byte]])
                    i += 1
                else:
                    # é€šå¸¸ãƒã‚¤ãƒˆ
                    compressed.append(current_byte)
                    i += 1
            
            # 3. NEXUSç‹¬è‡ªãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ï¼ˆå¾Œå‡¦ç†ï¼‰
            pattern_compressed = self._nexus_pattern_compress(bytes(compressed))
            
            return pattern_compressed
            
        except Exception as e:
            print(f"âš ï¸ NEXUSç´”ç²‹åœ§ç¸®å†…éƒ¨ã‚¨ãƒ©ãƒ¼: {e}")
            return data
    
    def _nexus_pattern_compress(self, data: bytes) -> bytes:
        """ğŸ¯ NEXUSãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ï¼ˆå®Œå…¨ç‹¬è‡ªï¼‰"""
        try:
            # NEXUSç‹¬è‡ªï¼š2-4ãƒã‚¤ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡ºã¨åœ§ç¸®
            
            # é«˜é »åº¦2ãƒã‚¤ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
            pattern_freq = {}
            for i in range(len(data) - 1):
                pattern = data[i:i+2]
                if pattern[0] not in [0xFE, 0xFD, 0xFC]:  # ãƒãƒ¼ã‚«ãƒ¼ãƒã‚¤ãƒˆé¿ã‘ã‚‹
                    pattern_freq[pattern] = pattern_freq.get(pattern, 0) + 1
            
            # ä¸Šä½16ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çŸ­ç¸®
            top_patterns = sorted(pattern_freq.items(), key=lambda x: x[1], reverse=True)[:16]
            pattern_map = {}
            for i, (pattern, count) in enumerate(top_patterns):
                if count > 5:  # ååˆ†ãªé »åº¦
                    pattern_map[pattern] = i
            
            if not pattern_map:
                return data
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›
            import struct
            compressed = bytearray()
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ï¼šãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒ—
            compressed.extend(struct.pack('<B', len(pattern_map)))
            for pattern, code in pattern_map.items():
                compressed.extend(struct.pack('<B', code))
                compressed.extend(pattern)
            
            # ãƒ‡ãƒ¼ã‚¿åœ§ç¸®
            i = 0
            while i < len(data):
                if i < len(data) - 1:
                    two_byte = data[i:i+2]
                    if two_byte in pattern_map:
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®: [0xFC][ã‚³ãƒ¼ãƒ‰]
                        compressed.extend([0xFC, pattern_map[two_byte]])
                        i += 2
                        continue
                
                compressed.append(data[i])
                i += 1
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            return data
    
    def _nexus_adaptive_compress(self, data: bytes) -> bytes:
        """ğŸ’ NEXUSé©å¿œçš„åœ§ç¸®ï¼ˆç‹¬è‡ªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
        try:
            # NEXUSç‹¬è‡ªï¼šé©å¿œçš„ãƒãƒ•ãƒãƒ³+RLEèåˆ
            import struct
            
            # é©å¿œçš„åˆ†æ
            sample_size = min(len(data), 32768)  # 32KB ã‚µãƒ³ãƒ—ãƒ«
            sample = data[:sample_size]
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            byte_runs = []  # RLEå€™è£œ
            pattern_repeats = {}  # ãƒ‘ã‚¿ãƒ¼ãƒ³ç¹°ã‚Šè¿”ã—
            
            i = 0
            while i < len(sample):
                # RLEæ¤œå‡º
                current_byte = sample[i]
                run_length = 1
                while i + run_length < len(sample) and sample[i + run_length] == current_byte:
                    run_length += 1
                
                if run_length > 3:
                    byte_runs.append((i, current_byte, run_length))
                
                # 2-4ãƒã‚¤ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
                for pattern_len in [2, 3, 4]:
                    if i + pattern_len <= len(sample):
                        pattern = sample[i:i+pattern_len]
                        pattern_repeats[pattern] = pattern_repeats.get(pattern, 0) + 1
                
                i += 1
            
            # æœ€é©åœ§ç¸®æˆ¦ç•¥é¸æŠ
            compressed = bytearray(data)
            
            # RLEé©ç”¨
            for pos, byte_val, length in sorted(byte_runs, reverse=True):
                if length > 3:
                    rle_code = bytes([0xFE, byte_val, min(length, 255)])
                    original_seq = bytes([byte_val] * length)
                    if original_seq in compressed:
                        compressed = compressed.replace(original_seq, rle_code, 1)
            
            # é«˜é »åº¦ãƒ‘ã‚¿ãƒ¼ãƒ³çŸ­ç¸®
            pattern_count = 0
            for pattern, count in sorted(pattern_repeats.items(), key=lambda x: x[1], reverse=True)[:32]:
                if count > 5 and len(pattern) > 2 and pattern_count < 32:
                    short_code = bytes([0xFF, len(pattern), pattern_count])
                    compressed = compressed.replace(pattern, short_code, count // 2)
                    pattern_count += 1
            
            return bytes(compressed)
            
        except Exception as e:
            print(f"âš ï¸ NEXUSé©å¿œçš„åœ§ç¸®å¤±æ•—: {e}")
            return data
    
    def _nexus_rle_compress(self, data: bytes) -> bytes:
        """NEXUS RLEåœ§ç¸®"""
        try:
            compressed = bytearray()
            i = 0
            while i < len(data):
                current_byte = data[i]
                count = 1
                while i + count < len(data) and data[i + count] == current_byte and count < 255:
                    count += 1
                
                if count > 3:
                    compressed.extend([0xFD, current_byte, count])
                    i += count
                else:
                    compressed.append(current_byte)
                    i += 1
            
            return bytes(compressed)
        except:
            return data
    
    def _nexus_huffman_compress(self, data: bytes) -> bytes:
        """NEXUSç°¡æ˜“ãƒãƒ•ãƒãƒ³åœ§ç¸®"""
        try:
            from collections import Counter
            import struct
            
            freq = Counter(data)
            
            # ç°¡æ˜“ãƒãƒ•ãƒãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«
            sorted_bytes = sorted(freq.items(), key=lambda x: x[1], reverse=True)
            
            compressed = bytearray()
            compressed.extend(struct.pack('<H', len(sorted_bytes)))
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«
            for byte_val, count in sorted_bytes:
                compressed.extend(struct.pack('<BH', byte_val, count))
            
            # ãƒ‡ãƒ¼ã‚¿
            byte_map = {byte_val: i for i, (byte_val, _) in enumerate(sorted_bytes)}
            for byte_val in data:
                compressed.append(byte_map[byte_val])
            
            return bytes(compressed)
        except:
            return data

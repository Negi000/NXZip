#!/usr/bin/env python3
"""
ğŸ” å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã®TMC v9.1ãƒ†ã‚¹ãƒˆ - çœŸã®å•é¡Œã‚’ç‰¹å®š
"""

import os
import sys
import hashlib
import time
from pathlib import Path

# NXZip-Python ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'NXZip-Python'))

try:
    from nxzip.engine.nexus_tmc_v91_modular import NEXUSTMCEngineV91
    print('âœ… NEXUS TMC v9.1 ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ')
except ImportError as e:
    print(f'âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}')
    sys.exit(1)

def test_real_tsv_file():
    """å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã®åœ§ç¸®â†’å±•é–‹ãƒ†ã‚¹ãƒˆ"""
    
    # å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    tsv_path = r"C:/Users/241822/Desktop/åœ¨åº«æ˜ç´°_20250610/åœ¨åº«æ˜ç´°_20250610.tsv"
    
    if not os.path.exists(tsv_path):
        print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {tsv_path}")
        print("ğŸ”§ å°ã•ãªTSVã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™...")
        return test_synthetic_tsv()
    
    print(f"ğŸ“‚ å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ†ã‚¹ãƒˆ: {tsv_path}")
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with open(tsv_path, 'rb') as f:
            original_data = f.read()
        
        print(f"ğŸ“Š å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(original_data):,} bytes ({len(original_data)/1024/1024:.1f} MB)")
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥
        original_hash = hashlib.sha256(original_data).hexdigest()
        print(f"ğŸ” å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        engine = NEXUSTMCEngineV91(
            max_workers=4,
            chunk_size=2*1024*1024,  # 2MB
            lightweight_mode=False
        )
        
        # åœ§ç¸®ãƒ•ã‚§ãƒ¼ã‚º
        print("ğŸ—œï¸ åœ§ç¸®é–‹å§‹...")
        start_time = time.time()
        compressed_data, compress_info = engine.compress(original_data)
        compress_time = time.time() - start_time
        
        compression_ratio = compress_info.get('compression_ratio', 0)
        print(f"âœ… åœ§ç¸®å®Œäº†: {len(compressed_data):,} bytes ({compression_ratio:.2f}% åœ§ç¸®)")
        print(f"â±ï¸ åœ§ç¸®æ™‚é–“: {compress_time:.2f}ç§’")
        print(f"ğŸ”¥ TMCå¤‰æ›: {'é©ç”¨' if compress_info.get('transform_applied') else 'ãƒã‚¤ãƒ‘ã‚¹'}")
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {compress_info.get('data_type', 'unknown')}")
        
        # å±•é–‹ãƒ•ã‚§ãƒ¼ã‚º
        print("ğŸ“‚ å±•é–‹é–‹å§‹...")
        start_time = time.time()
        decompressed_data = engine.decompress(compressed_data, compress_info)
        decompress_time = time.time() - start_time
        
        print(f"âœ… å±•é–‹å®Œäº†: {len(decompressed_data):,} bytes")
        print(f"â±ï¸ å±•é–‹æ™‚é–“: {decompress_time:.2f}ç§’")
        
        # æ•´åˆæ€§æ¤œè¨¼
        decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
        print(f"ğŸ” å±•é–‹ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {decompressed_hash[:16]}...")
        
        # è©³ç´°æ¯”è¼ƒ
        print("\n" + "="*60)
        print("ğŸ” è©³ç´°æ¯”è¼ƒçµæœ")
        print("="*60)
        print(f"ğŸ“ ã‚µã‚¤ã‚ºæ¯”è¼ƒ:")
        print(f"   å…ƒãƒ‡ãƒ¼ã‚¿: {len(original_data):,} bytes")
        print(f"   å±•é–‹ãƒ‡ãƒ¼ã‚¿: {len(decompressed_data):,} bytes")
        print(f"   ã‚µã‚¤ã‚ºä¸€è‡´: {'âœ…' if len(original_data) == len(decompressed_data) else 'âŒ'}")
        
        print(f"ğŸ” ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ:")
        print(f"   å…ƒãƒãƒƒã‚·ãƒ¥  : {original_hash}")
        print(f"   å±•é–‹ãƒãƒƒã‚·ãƒ¥: {decompressed_hash}")
        print(f"   ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'âœ…' if original_hash == decompressed_hash else 'âŒ'}")
        
        if original_hash != decompressed_hash or len(original_data) != len(decompressed_data):
            print("\nâš ï¸ æ•´åˆæ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ï¼")
            
            # ãƒã‚¤ãƒˆå˜ä½ã§ã®éƒ¨åˆ†æ¯”è¼ƒ
            if len(decompressed_data) > 0:
                print("ğŸ” ãƒã‚¤ãƒˆå˜ä½æ¯”è¼ƒï¼ˆå…ˆé ­100ãƒã‚¤ãƒˆï¼‰:")
                min_len = min(100, len(original_data), len(decompressed_data))
                for i in range(min_len):
                    if original_data[i] != decompressed_data[i]:
                        print(f"   å·®ç•°ç™ºè¦‹: ä½ç½®{i} - å…ƒ=0x{original_data[i]:02X}, å±•é–‹=0x{decompressed_data[i]:02X}")
                        break
                else:
                    print("   å…ˆé ­100ãƒã‚¤ãƒˆã¯ä¸€è‡´")
            
            # ãƒ‡ãƒ¼ã‚¿å†…å®¹ã®åˆ†æ
            print("\nğŸ” å…ƒãƒ‡ãƒ¼ã‚¿å†…å®¹åˆ†æï¼ˆå…ˆé ­200æ–‡å­—ï¼‰:")
            try:
                sample_text = original_data[:200].decode('utf-8', errors='replace')
                print(f"   å†…å®¹: {repr(sample_text)}")
            except:
                print("   ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿")
            
            print("\nğŸ” å±•é–‹ãƒ‡ãƒ¼ã‚¿å†…å®¹åˆ†æï¼ˆå…ˆé ­200æ–‡å­—ï¼‰:")
            try:
                sample_text = decompressed_data[:200].decode('utf-8', errors='replace')
                print(f"   å†…å®¹: {repr(sample_text)}")
            except:
                print("   ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿")
            
            return False
        else:
            print("\nğŸ‰ âœ… å®Œå…¨ä¸€è‡´ï¼TMC v9.1ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ï¼")
            return True
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_synthetic_tsv():
    """åˆæˆTSVãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª åˆæˆTSVãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆä¸­...")
    
    # TSVå½¢å¼ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    tsv_lines = []
    tsv_lines.append("å•†å“ID\tå•†å“å\tä¾¡æ ¼\tåœ¨åº«æ•°\tã‚«ãƒ†ã‚´ãƒª")
    
    for i in range(10000):  # 1ä¸‡è¡Œã®TSVãƒ‡ãƒ¼ã‚¿
        tsv_lines.append(f"ITEM{i:05d}\tå•†å“å{i}\t{1000 + i % 5000}\t{i % 100}\tã‚«ãƒ†ã‚´ãƒª{i % 10}")
    
    tsv_text = "\n".join(tsv_lines)
    original_data = tsv_text.encode('utf-8')
    
    print(f"ğŸ“Š åˆæˆTSVã‚µã‚¤ã‚º: {len(original_data):,} bytes ({len(original_data)/1024/1024:.1f} MB)")
    
    # å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥
    original_hash = hashlib.sha256(original_data).hexdigest()
    print(f"ğŸ” å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine = NEXUSTMCEngineV91(max_workers=4, chunk_size=2*1024*1024, lightweight_mode=False)
    
    # åœ§ç¸®ãƒ•ã‚§ãƒ¼ã‚º
    print("ğŸ—œï¸ åœ§ç¸®é–‹å§‹...")
    compressed_data, compress_info = engine.compress(original_data)
    
    compression_ratio = compress_info.get('compression_ratio', 0)
    print(f"âœ… åœ§ç¸®å®Œäº†: {len(compressed_data):,} bytes ({compression_ratio:.2f}% åœ§ç¸®)")
    print(f"ğŸ”¥ TMCå¤‰æ›: {'é©ç”¨' if compress_info.get('transform_applied') else 'ãƒã‚¤ãƒ‘ã‚¹'}")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {compress_info.get('data_type', 'unknown')}")
    
    # å±•é–‹ãƒ•ã‚§ãƒ¼ã‚º
    print("ğŸ“‚ å±•é–‹é–‹å§‹...")
    decompressed_data = engine.decompress(compressed_data, compress_info)
    
    print(f"âœ… å±•é–‹å®Œäº†: {len(decompressed_data):,} bytes")
    
    # æ•´åˆæ€§æ¤œè¨¼
    decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
    
    if original_hash == decompressed_hash:
        print("ğŸ‰ âœ… åˆæˆTSVãƒ‡ãƒ¼ã‚¿ã§ã¯å®Œå…¨ä¸€è‡´ï¼")
        return True
    else:
        print("âŒ åˆæˆTSVãƒ‡ãƒ¼ã‚¿ã§ã‚‚å•é¡Œç™ºç”Ÿ")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸ” å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã®TMC v9.1æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    success = test_real_tsv_file()
    
    print("\n" + "="*60)
    print("ğŸ† çµæœ")
    print("="*60)
    if success:
        print("âœ… TMC v9.1ã¯å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        print("ğŸ‰ å‰å›ã®å•é¡Œã¯åˆ¥ã®è¦å› ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    else:
        print("âš ï¸ å®Ÿéš›ã®TSVãƒ•ã‚¡ã‚¤ãƒ«ã§æ•´åˆæ€§ã®å•é¡Œã‚’ç¢ºèª")
        print("ğŸ”§ TMCå¤‰æ›ã®ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹èª¿æ•´ãŒå¿…è¦")

if __name__ == "__main__":
    main()

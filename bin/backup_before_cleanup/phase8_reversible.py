#!/usr/bin/env python3
"""
Phase 8 å®Œå…¨å¯é€†ç‰ˆ - 100%å¯é€†æ€§ä¿è¨¼ã‚¨ãƒ³ã‚¸ãƒ³
AIå¼·åŒ–æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã®å¯é€†æ€§å®Œå…¨å®Ÿè£…
"""

import os
import sys
import time
import json
import struct
import lzma
import zlib
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional

# Phase 8 Turbo ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ‹¡å¼µ
sys.path.append('bin')
from nexus_phase8_turbo import Phase8TurboEngine, CompressionResult, DecompressionResult

class ReversibleCompressionResult(CompressionResult):
    """å¯é€†æ€§ä¿è¨¼çµæœã‚¯ãƒ©ã‚¹"""
    def __init__(self, original_size, compressed_size, compression_ratio, algorithm, 
                 processing_time, structure_map, compressed_data, performance_metrics,
                 original_hash, structure_integrity_hash):
        super().__init__(original_size, compressed_size, compression_ratio, algorithm,
                        processing_time, structure_map, compressed_data, performance_metrics)
        self.original_hash = original_hash
        self.structure_integrity_hash = structure_integrity_hash

class Phase8ReversibleEngine(Phase8TurboEngine):
    """Phase 8 å®Œå…¨å¯é€†ç‰ˆã‚¨ãƒ³ã‚¸ãƒ³ - 100%å¯é€†æ€§ä¿è¨¼"""
    
    def __init__(self):
        super().__init__()
        self.version = "8.0-Reversible"
        self.magic_header = b'NXZ8R'  # Reversibleç‰ˆãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
        self.integrity_check = True
    
    def reversible_compress(self, data: bytes, filename: str = "data") -> ReversibleCompressionResult:
        """å®Œå…¨å¯é€†åœ§ç¸® - 100%å¯é€†æ€§ä¿è¨¼"""
        start_time = time.time()
        original_size = len(data)
        
        print(f"ğŸ”’ Phase 8 å®Œå…¨å¯é€†åœ§ç¸®é–‹å§‹: {filename}")
        print(f"ğŸ“Š å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes ({original_size/1024:.1f} KB)")
        
        # Step 1: å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        original_hash = hashlib.sha256(data).hexdigest()
        print(f"ğŸ” åŸæœ¬ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
        
        # Step 2: AIå¼·åŒ–æ§‹é€ è§£æï¼ˆè©³ç´°æƒ…å ±ä¿å­˜ï¼‰
        elements = self.analyze_file_structure(data)
        print(f"ğŸ“ˆ æ§‹é€ è§£æå®Œäº†: {len(elements)}è¦ç´ ")
        
        # Step 3: å®Œå…¨æ§‹é€ ãƒãƒƒãƒ—ç”Ÿæˆï¼ˆå¾©å…ƒã«å¿…è¦ãªå…¨æƒ…å ±ï¼‰
        structure_map = self._create_reversible_structure_map(elements, data)
        structure_integrity_hash = hashlib.sha256(structure_map).hexdigest()
        
        # Step 4: å¯é€†æ€§ä¿è¨¼ä¸¦åˆ—åœ§ç¸®
        compressed_chunks = []
        chunk_metadata = []
        total_chunks = len(elements)
        
        progress_points = [total_chunks//4, total_chunks//2, total_chunks*3//4, total_chunks]
        
        for i, element in enumerate(elements):
            # å¯é€†æ€§ä¿è¨¼åœ§ç¸®
            compressed_chunk, metadata = self._reversible_compress_chunk(element)
            compressed_chunks.append(compressed_chunk)
            chunk_metadata.append(metadata)
            
            # é€²æ—è¡¨ç¤º
            if i + 1 in progress_points:
                percent = ((i + 1) / total_chunks) * 100
                print(f"ğŸ”’ å¯é€†åœ§ç¸®é€²æ—: {percent:.0f}%")
        
        # Step 5: å¯é€†æ€§çµ±åˆï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
        final_compressed = self._integrate_reversible_data(
            compressed_chunks, structure_map, chunk_metadata, original_hash
        )
        
        # Step 6: çµæœè¨ˆç®—
        compressed_size = len(final_compressed)
        compression_ratio = ((original_size - compressed_size) / original_size) * 100
        processing_time = time.time() - start_time
        
        # AIè§£æã‚µãƒãƒªãƒ¼
        if elements:
            avg_entropy = sum(e.entropy for e in elements) / len(elements)
            ai_recommendations = [e.compression_hint for e in elements]
            most_common_hint = max(set(ai_recommendations), key=ai_recommendations.count)
            
            print(f"ğŸ¤– AIè§£æçµæœ:")
            print(f"   å¹³å‡ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {avg_entropy:.2f}")
            print(f"   ä¸»è¦æ¨è–¦æ‰‹æ³•: {most_common_hint}")
        
        print(f"âœ… å¯é€†åœ§ç¸®å®Œäº†: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,})")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        print(f"ğŸ” æ§‹é€ æ•´åˆæ€§: {structure_integrity_hash[:16]}...")
        
        # æ€§èƒ½æŒ‡æ¨™
        speed_mbps = original_size / processing_time / (1024 * 1024)
        performance_metrics = {
            'analysis_elements': len(elements),
            'avg_entropy': avg_entropy if elements else 0.0,
            'processing_speed_mbps': speed_mbps,
            'ai_recommendation': most_common_hint if elements else 'none',
            'reversible_mode': True,
            'integrity_verification': True
        }
        
        return ReversibleCompressionResult(
            original_size=original_size,
            compressed_size=compressed_size,
            compression_ratio=compression_ratio,
            algorithm="Phase8_Reversible",
            processing_time=processing_time,
            structure_map=structure_map,
            compressed_data=final_compressed,
            performance_metrics=performance_metrics,
            original_hash=original_hash,
            structure_integrity_hash=structure_integrity_hash
        )
    
    def reversible_decompress(self, compressed_data: bytes) -> DecompressionResult:
        """å®Œå…¨å¯é€†å±•é–‹ - 100%å¾©å…ƒä¿è¨¼"""
        start_time = time.time()
        
        print("ğŸ”“ Phase 8 å®Œå…¨å¯é€†å±•é–‹é–‹å§‹")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼
        if not compressed_data.startswith(self.magic_header):
            raise ValueError("âŒ Phase 8 å¯é€†å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        offset = len(self.magic_header)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥
        original_hash = compressed_data[offset:offset+64].decode('ascii')
        offset += 64
        print(f"ğŸ” åŸæœ¬ãƒãƒƒã‚·ãƒ¥ç¢ºèª: {original_hash[:16]}...")
        
        # æ§‹é€ ãƒãƒƒãƒ—ã‚µã‚¤ã‚º
        structure_map_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
        offset += 4
        
        # æ§‹é€ ãƒãƒƒãƒ—å¾©å…ƒ
        structure_map_data = compressed_data[offset:offset+structure_map_size]
        offset += structure_map_size
        
        # æ§‹é€ æ•´åˆæ€§æ¤œè¨¼
        structure_hash = hashlib.sha256(structure_map_data).hexdigest()
        print(f"ğŸ” æ§‹é€ æ•´åˆæ€§: {structure_hash[:16]}...")
        
        structure_info = self._parse_reversible_structure_map(structure_map_data)
        print(f"ğŸ“Š æ§‹é€ å¾©å…ƒ: {structure_info['total_elements']}è¦ç´ ")
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
        metadata_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
        offset += 4
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¾©å…ƒ
        metadata_data = compressed_data[offset:offset+metadata_size]
        offset += metadata_size
        chunk_metadata = json.loads(lzma.decompress(metadata_data).decode('utf-8'))
        
        # å¯é€†ãƒãƒ£ãƒ³ã‚¯å¾©å…ƒ
        decompressed_chunks = []
        elements_info = structure_info['elements']
        
        for i, element_info in enumerate(elements_info):
            chunk_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
            offset += 4
            
            if chunk_size > 0:
                chunk_data = compressed_data[offset:offset+chunk_size]
                offset += chunk_size
                
                # å¯é€†æ€§ä¿è¨¼å±•é–‹
                metadata = chunk_metadata[i] if i < len(chunk_metadata) else {}
                decompressed_chunk = self._reversible_decompress_chunk(
                    chunk_data, element_info, metadata
                )
                decompressed_chunks.append(decompressed_chunk)
            else:
                decompressed_chunks.append(b'')
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % max(1, len(elements_info) // 4) == 0:
                percent = ((i + 1) / len(elements_info)) * 100
                print(f"ğŸ”“ å±•é–‹é€²æ—: {percent:.0f}%")
        
        # å®Œå…¨å¾©å…ƒï¼ˆæ§‹é€ æƒ…å ±å®Œå…¨ä½¿ç”¨ï¼‰
        original_data = self._reconstruct_reversible_original(
            decompressed_chunks, structure_info
        )
        
        # å¯é€†æ€§æ¤œè¨¼
        restored_hash = hashlib.sha256(original_data).hexdigest()
        is_identical = (restored_hash == original_hash)
        
        processing_time = time.time() - start_time
        print(f"âœ… å±•é–‹å®Œäº†: {len(original_data):,} bytes ({processing_time:.2f}ç§’)")
        print(f"ğŸ” å¯é€†æ€§æ¤œè¨¼: {'âœ… å®Œå…¨ä¸€è‡´' if is_identical else 'âŒ ä¸ä¸€è‡´'}")
        
        if not is_identical:
            print(f"âš ï¸ åŸæœ¬: {original_hash[:16]}...")
            print(f"âš ï¸ å¾©å…ƒ: {restored_hash[:16]}...")
            raise ValueError("âŒ å¯é€†æ€§æ¤œè¨¼å¤±æ•—")
        
        return DecompressionResult(
            original_data=original_data,
            decompressed_size=len(original_data),
            processing_time=processing_time,
            algorithm="Phase8_Reversible"
        )
    
    def _create_reversible_structure_map(self, elements, original_data: bytes) -> bytes:
        """å¯é€†æ€§ä¿è¨¼æ§‹é€ ãƒãƒƒãƒ—ç”Ÿæˆ"""
        structure_info = {
            'version': self.version,
            'total_elements': len(elements),
            'original_size': len(original_data),
            'ai_enhanced': True,
            'reversible_mode': True,
            'elements': [],
            'global_structure': {
                'file_signature': original_data[:16].hex() if len(original_data) >= 16 else '',
                'file_end': original_data[-16:].hex() if len(original_data) >= 16 else '',
                'total_chunks': len(elements)
            }
        }
        
        # å®Œå…¨æ§‹é€ æƒ…å ±ä¿å­˜
        cumulative_offset = 0
        for i, element in enumerate(elements):
            element_info = {
                'index': i,
                'type': element.type,
                'absolute_offset': element.offset,
                'cumulative_offset': cumulative_offset,
                'original_size': element.size,
                'entropy': element.entropy,
                'pattern_score': element.pattern_score,
                'compression_hint': element.compression_hint,
                'data_signature': element.data[:8].hex() if len(element.data) >= 8 else '',
                'data_end': element.data[-8:].hex() if len(element.data) >= 8 else ''
            }
            
            # AIè§£æçµæœå®Œå…¨ä¿å­˜
            if element.ai_analysis:
                element_info['ai_analysis'] = element.ai_analysis
            
            structure_info['elements'].append(element_info)
            cumulative_offset += element.size
        
        # JSONâ†’ãƒã‚¤ãƒŠãƒªåœ§ç¸®
        json_data = json.dumps(structure_info, separators=(',', ':')).encode('utf-8')
        return lzma.compress(json_data, preset=9)
    
    def _reversible_compress_chunk(self, element) -> Tuple[bytes, Dict]:
        """å¯é€†æ€§ä¿è¨¼ãƒãƒ£ãƒ³ã‚¯åœ§ç¸®"""
        data = element.data
        hint = element.compression_hint
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = {
            'original_size': len(data),
            'original_hash': hashlib.md5(data).hexdigest(),
            'compression_method': hint,
            'data_characteristics': {
                'entropy': element.entropy,
                'pattern_score': element.pattern_score,
                'first_bytes': data[:16].hex() if len(data) >= 16 else '',
                'last_bytes': data[-16:].hex() if len(data) >= 16 else ''
            }
        }
        
        # å¯é€†æ€§ä¿è¨¼åœ§ç¸®
        if hint == "minimal_processing" or len(data) < 32:
            # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚„ç‰¹æ®Šãƒ‡ãƒ¼ã‚¿ã¯ç„¡åœ§ç¸®ä¿å­˜
            compressed_data = data
            metadata['actual_method'] = 'uncompressed'
        else:
            try:
                if hint == "rle_enhanced":
                    compressed_data = self._safe_rle_compress(data)
                    metadata['actual_method'] = 'rle_enhanced'
                elif hint == "lzma":
                    compressed_data = lzma.compress(data, preset=6, check=lzma.CHECK_CRC64)
                    metadata['actual_method'] = 'lzma'
                elif hint == "zstd":
                    compressed_data = zlib.compress(data, level=6)
                    metadata['actual_method'] = 'zlib'
                else:
                    # é©å¿œçš„åœ§ç¸®ï¼ˆæœ€è‰¯çµæœã‚’å¯é€†çš„ã«é¸æŠï¼‰
                    compressed_data = self._safe_adaptive_compress(data)
                    metadata['actual_method'] = 'adaptive'
                
                # åœ§ç¸®åŠ¹æœæ¤œè¨¼
                if len(compressed_data) >= len(data):
                    compressed_data = data
                    metadata['actual_method'] = 'uncompressed'
                    
            except Exception:
                # åœ§ç¸®å¤±æ•—æ™‚ã¯ç„¡åœ§ç¸®ä¿å­˜
                compressed_data = data
                metadata['actual_method'] = 'uncompressed'
        
        return compressed_data, metadata
    
    def _safe_rle_compress(self, data: bytes) -> bytes:
        """å®‰å…¨ãªRLEåœ§ç¸®ï¼ˆå®Œå…¨å¯é€†ä¿è¨¼ï¼‰"""
        if not data:
            return b''
        
        compressed = bytearray()
        i = 0
        while i < len(data):
            current_byte = data[i]
            count = 1
            
            # åŒã˜ãƒã‚¤ãƒˆã®é€£ç¶šã‚’ã‚«ã‚¦ãƒ³ãƒˆï¼ˆæœ€å¤§254ã¾ã§ï¼‰
            while (i + count < len(data) and 
                   data[i + count] == current_byte and 
                   count < 254):
                count += 1
            
            if count >= 3:  # 3å›ä»¥ä¸Šã§åœ§ç¸®åŠ¹æœ
                compressed.extend([0xFF, count, current_byte])
                i += count
            else:
                # 0xFFã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                if current_byte == 0xFF:
                    compressed.extend([0xFF, 0, 0xFF])  # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
                else:
                    compressed.append(current_byte)
                i += 1
        
        return bytes(compressed)
    
    def _safe_adaptive_compress(self, data: bytes) -> bytes:
        """å®‰å…¨ãªé©å¿œçš„åœ§ç¸®ï¼ˆå¯é€†æ€§æœ€å„ªå…ˆï¼‰"""
        if len(data) < 64:
            return data
        
        # è¤‡æ•°æ‰‹æ³•ã‚’è©¦è¡Œã—ã€æœ€è‰¯ã‹ã¤å®‰å…¨ãªã‚‚ã®ã‚’é¸æŠ
        candidates = []
        
        try:
            lzma_result = lzma.compress(data, preset=3, check=lzma.CHECK_CRC64)
            candidates.append(('lzma', lzma_result))
        except:
            pass
        
        try:
            zlib_result = zlib.compress(data, level=3)
            candidates.append(('zlib', zlib_result))
        except:
            pass
        
        try:
            rle_result = self._safe_rle_compress(data)
            candidates.append(('rle', rle_result))
        except:
            pass
        
        # æœ€å°ã‚µã‚¤ã‚ºã‚’é¸æŠ
        if candidates:
            best_method, best_result = min(candidates, key=lambda x: len(x[1]))
            if len(best_result) < len(data):
                return best_result
        
        return data  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def _integrate_reversible_data(self, compressed_chunks, structure_map: bytes, 
                                 chunk_metadata: List[Dict], original_hash: str) -> bytes:
        """å¯é€†æ€§ä¿è¨¼ãƒ‡ãƒ¼ã‚¿çµ±åˆ"""
        result = bytearray()
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        result.extend(self.magic_header)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥ï¼ˆ64æ–‡å­—å›ºå®šï¼‰
        result.extend(original_hash.encode('ascii'))
        
        # æ§‹é€ ãƒãƒƒãƒ—
        result.extend(struct.pack('<I', len(structure_map)))
        result.extend(structure_map)
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata_json = json.dumps(chunk_metadata, separators=(',', ':')).encode('utf-8')
        metadata_compressed = lzma.compress(metadata_json, preset=9)
        result.extend(struct.pack('<I', len(metadata_compressed)))
        result.extend(metadata_compressed)
        
        # åœ§ç¸®ãƒãƒ£ãƒ³ã‚¯
        for chunk in compressed_chunks:
            result.extend(struct.pack('<I', len(chunk)))
            result.extend(chunk)
        
        return bytes(result)
    
    def _parse_reversible_structure_map(self, structure_map_data: bytes) -> dict:
        """å¯é€†æ€§ä¿è¨¼æ§‹é€ ãƒãƒƒãƒ—è§£æ"""
        try:
            decompressed_json = lzma.decompress(structure_map_data)
            structure_info = json.loads(decompressed_json.decode('utf-8'))
            
            # å¯é€†æ€§ãƒ¢ãƒ¼ãƒ‰æ¤œè¨¼
            if not structure_info.get('reversible_mode', False):
                raise ValueError("éå¯é€†ãƒ¢ãƒ¼ãƒ‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã™")
            
            return structure_info
        except Exception as e:
            raise ValueError(f"æ§‹é€ ãƒãƒƒãƒ—è§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _reversible_decompress_chunk(self, chunk_data: bytes, element_info: dict, 
                                   metadata: dict) -> bytes:
        """å¯é€†æ€§ä¿è¨¼ãƒãƒ£ãƒ³ã‚¯å±•é–‹"""
        actual_method = metadata.get('actual_method', 'uncompressed')
        original_size = metadata.get('original_size', 0)
        original_hash = metadata.get('original_hash', '')
        
        try:
            if actual_method == 'uncompressed':
                result = chunk_data
            elif actual_method == 'rle_enhanced':
                result = self._safe_rle_decompress(chunk_data)
            elif actual_method == 'lzma':
                result = lzma.decompress(chunk_data)
            elif actual_method == 'zlib':
                result = zlib.decompress(chunk_data)
            elif actual_method == 'adaptive':
                result = self._safe_adaptive_decompress(chunk_data)
            else:
                result = chunk_data
            
            # å¯é€†æ€§æ¤œè¨¼
            if original_hash and len(result) > 0:
                restored_hash = hashlib.md5(result).hexdigest()
                if restored_hash != original_hash:
                    print(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯å¯é€†æ€§è­¦å‘Š: æœŸå¾…{original_hash[:8]} vs å®Ÿéš›{restored_hash[:8]}")
            
            return result
            
        except Exception as e:
            print(f"âš ï¸ ãƒãƒ£ãƒ³ã‚¯å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}, ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨")
            return chunk_data
    
    def _safe_rle_decompress(self, data: bytes) -> bytes:
        """å®‰å…¨ãªRLEå±•é–‹ï¼ˆã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†å¯¾å¿œï¼‰"""
        if not data:
            return b''
        
        result = bytearray()
        i = 0
        while i < len(data):
            if i + 2 < len(data) and data[i] == 0xFF:
                count = data[i + 1]
                if count == 0:
                    # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹: 0xFF 0 0xFF â†’ 0xFF
                    result.append(0xFF)
                    i += 3
                else:
                    # RLEåœ§ç¸®ãƒ‡ãƒ¼ã‚¿: 0xFF count value
                    byte_value = data[i + 2]
                    result.extend([byte_value] * count)
                    i += 3
            else:
                # é€šå¸¸ãƒ‡ãƒ¼ã‚¿
                result.append(data[i])
                i += 1
        
        return bytes(result)
    
    def _safe_adaptive_decompress(self, data: bytes) -> bytes:
        """å®‰å…¨ãªé©å¿œçš„å±•é–‹"""
        # è¤‡æ•°ã®å±•é–‹æ–¹æ³•ã‚’è©¦è¡Œ
        methods = [
            lzma.decompress,
            zlib.decompress,
            self._safe_rle_decompress
        ]
        
        for method in methods:
            try:
                result = method(data)
                if result:  # æˆåŠŸã—ãŸå ´åˆ
                    return result
            except:
                continue
        
        return data  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def _reconstruct_reversible_original(self, chunks: List[bytes], 
                                       structure_info: dict) -> bytes:
        """å®Œå…¨å¯é€†å¾©å…ƒï¼ˆæ§‹é€ æƒ…å ±å®Œå…¨ä½¿ç”¨ï¼‰"""
        elements_info = structure_info['elements']
        original_size = structure_info.get('original_size', 0)
        
        # å…ƒã®é †åºã¨ã‚µã‚¤ã‚ºã§å®Œå…¨å¾©å…ƒ
        result = bytearray()
        
        for i, chunk in enumerate(chunks):
            if i < len(elements_info):
                element_info = elements_info[i]
                expected_size = element_info.get('original_size', len(chunk))
                
                # ã‚µã‚¤ã‚ºæ¤œè¨¼
                if len(chunk) != expected_size:
                    print(f"âš ï¸ è¦ç´ {i}: ã‚µã‚¤ã‚ºä¸ä¸€è‡´ æœŸå¾…{expected_size} vs å®Ÿéš›{len(chunk)}")
                
                # ãƒ‡ãƒ¼ã‚¿ç½²åæ¤œè¨¼ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
                if len(chunk) >= 8:
                    expected_sig = element_info.get('data_signature', '')
                    actual_sig = chunk[:8].hex()
                    if expected_sig and expected_sig != actual_sig:
                        print(f"âš ï¸ è¦ç´ {i}: ç½²åä¸ä¸€è‡´ æœŸå¾…{expected_sig[:8]} vs å®Ÿéš›{actual_sig[:8]}")
                
                result.extend(chunk)
            else:
                result.extend(chunk)
        
        # æœ€çµ‚ã‚µã‚¤ã‚ºæ¤œè¨¼
        if original_size > 0 and len(result) != original_size:
            print(f"âš ï¸ å…¨ä½“ã‚µã‚¤ã‚ºä¸ä¸€è‡´: æœŸå¾…{original_size} vs å®Ÿéš›{len(result)}")
        
        return bytes(result)
    
    def compress_file(self, input_path: str, output_path: str = None) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®ï¼ˆå¯é€†æ€§ä¿è¨¼ï¼‰"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return False
        
        if output_path is None:
            output_path = input_path + '.p8r'  # Phase 8 Reversible
        
        try:
            with open(input_path, 'rb') as f:
                data = f.read()
            
            filename = os.path.basename(input_path)
            result = self.reversible_compress(data, filename)
            
            with open(output_path, 'wb') as f:
                f.write(result.compressed_data)
            
            print(f"ğŸ’¾ å¯é€†åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}")
            return True
        
        except Exception as e:
            print(f"âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def decompress_file(self, input_path: str, output_path: str = None) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹ï¼ˆå¯é€†æ€§æ¤œè¨¼ï¼‰"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return False
        
        if output_path is None:
            if input_path.endswith('.p8r'):
                output_path = input_path[:-4]
            else:
                output_path = input_path + '.restored'
        
        try:
            with open(input_path, 'rb') as f:
                compressed_data = f.read()
            
            result = self.reversible_decompress(compressed_data)
            
            with open(output_path, 'wb') as f:
                f.write(result.original_data)
            
            print(f"ğŸ“ å¯é€†å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}")
            return True
        
        except Exception as e:
            print(f"âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def run_reversible_test():
    """å®Œå…¨å¯é€†æ€§ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”’ Phase 8 å®Œå…¨å¯é€†æ€§ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    engine = Phase8ReversibleEngine()
    sample_dir = Path("../NXZip-Python/sample")
    
    # é‡è¦: å¯é€†æ€§é‡è¦–ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    test_files = [
        # åŸºæœ¬ãƒ†ã‚¹ãƒˆï¼ˆå°ã€œä¸­ã‚µã‚¤ã‚ºï¼‰
        "é™°è¬€è«–.mp3",                    # MP3éŸ³å£° (2MB)
        "COT-001.jpg",                   # JPEGç”»åƒ (2.8MB)
        "COT-012.png",                   # PNGç”»åƒ (35MB) - åˆ¶é™ç‰ˆ
        
        # å¤§å®¹é‡ãƒ†ã‚¹ãƒˆï¼ˆæ®µéšçš„ï¼‰
        "å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",      # ãƒ†ã‚­ã‚¹ãƒˆ (97MB) - æœ€çµ‚ãƒ†ã‚¹ãƒˆ
    ]
    
    results = []
    failed_files = []
    
    for filename in test_files:
        filepath = sample_dir / filename
        if not filepath.exists():
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {filename}")
            continue
        
        print(f"\nğŸ”’ å¯é€†æ€§ãƒ†ã‚¹ãƒˆ: {filename}")
        print("-" * 40)
        
        try:
            # æ®µéšçš„ãƒ†ã‚¹ãƒˆï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸€éƒ¨ã®ã¿ï¼‰
            if filename == "COT-012.png":
                # PNG: æœ€åˆã®1MBã®ã¿ãƒ†ã‚¹ãƒˆ
                with open(filepath, 'rb') as f:
                    test_data = f.read(1024*1024)  # 1MBåˆ¶é™
                print(f"ğŸ“ éƒ¨åˆ†ãƒ†ã‚¹ãƒˆ: {len(test_data):,} bytes (1MBåˆ¶é™)")
            elif filename == "å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt":
                # ãƒ†ã‚­ã‚¹ãƒˆ: æœ€åˆã®5MBã®ã¿ãƒ†ã‚¹ãƒˆ
                with open(filepath, 'rb') as f:
                    test_data = f.read(5*1024*1024)  # 5MBåˆ¶é™
                print(f"ğŸ“ éƒ¨åˆ†ãƒ†ã‚¹ãƒˆ: {len(test_data):,} bytes (5MBåˆ¶é™)")
            else:
                # å…¨ä½“ãƒ†ã‚¹ãƒˆ
                with open(filepath, 'rb') as f:
                    test_data = f.read()
                print(f"ğŸ“ å…¨ä½“ãƒ†ã‚¹ãƒˆ: {len(test_data):,} bytes")
            
            # å¯é€†åœ§ç¸®
            result = engine.reversible_compress(test_data, filename)
            
            # å¯é€†å±•é–‹
            decompressed_result = engine.reversible_decompress(result.compressed_data)
            
            # å¯é€†æ€§æ¤œè¨¼
            is_identical = (test_data == decompressed_result.original_data)
            
            if is_identical:
                print(f"âœ… å¯é€†æ€§æˆåŠŸ: å®Œå…¨ä¸€è‡´")
                results.append({
                    'filename': filename,
                    'original_size': len(test_data),
                    'compressed_size': result.compressed_size,
                    'compression_ratio': result.compression_ratio,
                    'reversible': True,
                    'processing_time': result.processing_time
                })
            else:
                print(f"âŒ å¯é€†æ€§å¤±æ•—: ãƒ‡ãƒ¼ã‚¿ä¸ä¸€è‡´")
                failed_files.append(filename)
                
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:80]}...")
            failed_files.append(filename)
    
    # ç·åˆçµæœ
    print("\n" + "=" * 60)
    print("ğŸ† Phase 8 å®Œå…¨å¯é€†æ€§ãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 60)
    
    if results:
        total_original = sum(r['original_size'] for r in results)
        total_compressed = sum(r['compressed_size'] for r in results)
        overall_ratio = (1 - total_compressed / total_original) * 100
        reversible_count = sum(1 for r in results if r['reversible'])
        
        print(f"ğŸ”’ å¯é€†æ€§æˆåŠŸç‡: {reversible_count}/{len(results)} ({reversible_count/len(results)*100:.1f}%)")
        print(f"ğŸ“Š å¹³å‡åœ§ç¸®ç‡: {overall_ratio:.1f}%")
        print(f"ğŸ“ˆ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}")
        print(f"ğŸ’¾ ç·ãƒ‡ãƒ¼ã‚¿é‡: {total_original/1024/1024:.1f} MB")
        print(f"âš¡ å¹³å‡å‡¦ç†é€Ÿåº¦: {sum(r['original_size'] for r in results) / sum(r['processing_time'] for r in results) / 1024 / 1024:.1f} MB/s")
        
        # å€‹åˆ¥çµæœ
        print(f"\nğŸ“‹ å€‹åˆ¥å¯é€†æ€§ãƒ†ã‚¹ãƒˆçµæœ:")
        for result in results:
            filename_short = result['filename'][:25] + ('...' if len(result['filename']) > 25 else '')
            size_mb = result['original_size'] / 1024 / 1024
            speed = result['original_size'] / result['processing_time'] / 1024 / 1024
            print(f"   âœ… {filename_short}: {result['compression_ratio']:.1f}% ({size_mb:.1f}MB, {speed:.1f}MB/s)")
        
        if reversible_count == len(results):
            print("ğŸ‰ å…¨ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨å¯é€†æ€§é”æˆï¼")
        else:
            print(f"âš ï¸ {len(results) - reversible_count}ãƒ•ã‚¡ã‚¤ãƒ«ã§å¯é€†æ€§å•é¡Œ")
    
    if failed_files:
        print(f"\nâŒ å¤±æ•—ãƒ•ã‚¡ã‚¤ãƒ« ({len(failed_files)}å€‹):")
        for filename in failed_files:
            print(f"   â€¢ {filename}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("ğŸ”’ Phase 8 å®Œå…¨å¯é€†ç‰ˆ")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python phase8_reversible.py test                    # å¯é€†æ€§ãƒ†ã‚¹ãƒˆ")
        print("  python phase8_reversible.py compress <file>         # å¯é€†åœ§ç¸®")
        print("  python phase8_reversible.py decompress <file.p8r>   # å¯é€†å±•é–‹")
        return
    
    command = sys.argv[1].lower()
    engine = Phase8ReversibleEngine()
    
    if command == "test":
        run_reversible_test()
    elif command == "compress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) >= 4 else None
        engine.compress_file(input_file, output_file)
    elif command == "decompress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) >= 4 else None
        engine.decompress_file(input_file, output_file)
    else:
        print("âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™")

if __name__ == "__main__":
    main()

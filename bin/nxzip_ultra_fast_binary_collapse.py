#!/usr/bin/env python3
"""
NXZip Ultra Fast Binary Collapse Engine
è¶…é«˜é€Ÿãƒã‚¤ãƒŠãƒªåœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³ - å®Ÿç”¨æ€§é‡è¦–ã®æ¥µé™é«˜é€ŸåŒ–

ç‰¹å¾´:
- è¶…é«˜é€Ÿå‡¦ç†ï¼ˆè¤‡é›‘ãªè§£æã‚’æ’é™¤ï¼‰
- åŠ¹æœçš„ãªãƒã‚¤ãƒŠãƒªãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®
- æœ€å°é™ã®æ§‹é€ è§£æ
- å³åº§ã®åœ§ç¸®ãƒ»å±•é–‹
- å®Œå…¨å¯é€†æ€§ä¿è¨¼
"""

import struct
import time
import hashlib
import os
import sys
import zlib
from typing import Dict, List, Tuple
from collections import Counter

class UltraFastBinaryCollapseEngine:
    def __init__(self):
        self.magic = b'NXUFC'  # NXZip Ultra Fast Collapse
        self.version = 1
    
    def quick_pattern_analysis(self, data: bytes) -> Dict:
        """è¶…é«˜é€Ÿãƒ‘ã‚¿ãƒ¼ãƒ³è§£æï¼ˆæœ€å°é™ï¼‰"""
        if len(data) == 0:
            return {'patterns': {}, 'total_savings': 0}
        
        patterns = {}
        total_savings = 0
        
        # 2-8ãƒã‚¤ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿ï¼ˆé«˜é€ŸåŒ–ï¼‰
        for pattern_len in [2, 4, 8]:
            if len(data) < pattern_len * 2:
                continue
            
            pattern_count = Counter()
            
            # å›ºå®šé–“éš”ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå…¨ä½“ã‚’ãƒã‚§ãƒƒã‚¯ã›ãšé«˜é€ŸåŒ–ï¼‰
            step = max(1, len(data) // 10000)  # æœ€å¤§10000ã‚µãƒ³ãƒ—ãƒ«
            for i in range(0, len(data) - pattern_len + 1, step):
                pattern = data[i:i+pattern_len]
                pattern_count[pattern] += 1
            
            # 3å›ä»¥ä¸Šå‡ºç¾ã§ç¯€ç´„åŠ¹æœãŒã‚ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿
            for pattern, count in pattern_count.items():
                if count >= 3:
                    savings = (count - 1) * (pattern_len - 2)  # 2ãƒã‚¤ãƒˆIDç½®æ›
                    if savings > 0:
                        patterns[pattern] = {
                            'count': count,
                            'savings': savings,
                            'id': len(patterns)
                        }
                        total_savings += savings
                        
                        # ååˆ†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã£ãŸã‚‰åœæ­¢
                        if len(patterns) >= 1000:
                            break
            
            if len(patterns) >= 1000:
                break
        
        return {'patterns': patterns, 'total_savings': total_savings}
    
    def ultra_fast_compress(self, data: bytes) -> bytes:
        """è¶…é«˜é€Ÿåœ§ç¸®"""
        if not data:
            return self.magic + struct.pack('>I', 0)
        
        original_size = len(data)
        
        # å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯zlibã®ã¿
        if original_size < 1024:
            compressed = zlib.compress(data, level=1)
            if len(compressed) < original_size:
                return self.magic + struct.pack('>I', original_size) + b'\x01' + compressed
            else:
                return b'RAW_UFC' + struct.pack('>I', original_size) + data
        
        # é«˜é€Ÿãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
        analysis = self.quick_pattern_analysis(data)
        patterns = analysis['patterns']
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›ãŒåŠ¹æœçš„ã§ãªã„å ´åˆã¯zlibã®ã¿
        if analysis['total_savings'] < original_size * 0.05:  # 5%æœªæº€ã®ç¯€ç´„
            compressed = zlib.compress(data, level=1)
            if len(compressed) < original_size * 0.95:
                return self.magic + struct.pack('>I', original_size) + b'\x01' + compressed
            else:
                return b'RAW_UFC' + struct.pack('>I', original_size) + data
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›å®Ÿè¡Œ
        compressed_data = bytearray(data)
        pattern_dict = {}
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åŠ¹æœã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_patterns = sorted(patterns.items(), 
                               key=lambda x: x[1]['savings'], reverse=True)
        
        for pattern, info in sorted_patterns[:256]:  # æœ€å¤§256ãƒ‘ã‚¿ãƒ¼ãƒ³
            pattern_id = info['id']
            if pattern_id > 255:
                continue
                
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›ï¼ˆæœ€åˆã®å‡ºç¾ã®ã¿é«˜é€Ÿå‡¦ç†ï¼‰
            pattern_bytes = bytes(pattern)
            replacement = b'\xFF' + bytes([pattern_id])
            
            # æœ€å¤§100å›ã®ç½®æ›ã§é«˜é€ŸåŒ–
            replace_count = 0
            pos = 0
            while pos < len(compressed_data) and replace_count < 100:
                pos = compressed_data.find(pattern_bytes, pos)
                if pos == -1:
                    break
                compressed_data[pos:pos+len(pattern_bytes)] = replacement
                pos += len(replacement)
                replace_count += 1
            
            if replace_count > 0:
                pattern_dict[pattern_id] = pattern_bytes
        
        # æœ€çµ‚zlibåœ§ç¸®
        final_compressed = zlib.compress(bytes(compressed_data), level=1)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³è¾æ›¸ã‚’ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
        dict_data = b''
        for pattern_id, pattern_bytes in pattern_dict.items():
            dict_data += bytes([pattern_id, len(pattern_bytes)]) + pattern_bytes
        
        dict_compressed = zlib.compress(dict_data, level=1)
        
        # æœ€çµ‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
        header = self.magic + struct.pack('>I', original_size)
        header += b'\x02'  # ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®ãƒ¢ãƒ¼ãƒ‰
        header += struct.pack('>H', len(dict_compressed))
        result = header + dict_compressed + final_compressed
        
        # åŠ¹æœãŒãªã„å ´åˆã¯RAWä¿å­˜
        if len(result) >= original_size * 0.95:
            return b'RAW_UFC' + struct.pack('>I', original_size) + data
        
        return result
    
    def ultra_fast_decompress(self, compressed: bytes) -> bytes:
        """è¶…é«˜é€Ÿå±•é–‹"""
        if not compressed:
            return b''
        
        # RAWå½¢å¼
        if compressed.startswith(b'RAW_UFC'):
            size = struct.unpack('>I', compressed[7:11])[0]
            return compressed[11:11+size]
        
        # é€šå¸¸å½¢å¼
        if not compressed.startswith(self.magic):
            raise ValueError("Invalid format")
        
        pos = len(self.magic)
        original_size = struct.unpack('>I', compressed[pos:pos+4])[0]
        pos += 4
        
        mode = compressed[pos]
        pos += 1
        
        if mode == 1:  # zlibã®ã¿
            return zlib.decompress(compressed[pos:])
        elif mode == 2:  # ãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®
            dict_size = struct.unpack('>H', compressed[pos:pos+2])[0]
            pos += 2
            
            # è¾æ›¸å¾©å…ƒ
            dict_compressed = compressed[pos:pos+dict_size]
            pos += dict_size
            dict_data = zlib.decompress(dict_compressed)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³è¾æ›¸æ§‹ç¯‰
            pattern_dict = {}
            dict_pos = 0
            while dict_pos < len(dict_data):
                pattern_id = dict_data[dict_pos]
                pattern_len = dict_data[dict_pos + 1]
                pattern_bytes = dict_data[dict_pos + 2:dict_pos + 2 + pattern_len]
                pattern_dict[pattern_id] = pattern_bytes
                dict_pos += 2 + pattern_len
            
            # ãƒ‡ãƒ¼ã‚¿å±•é–‹
            data_compressed = compressed[pos:]
            data = bytearray(zlib.decompress(data_compressed))
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³å¾©å…ƒ
            i = 0
            while i < len(data):
                if data[i] == 0xFF and i + 1 < len(data):
                    pattern_id = data[i + 1]
                    if pattern_id in pattern_dict:
                        pattern_bytes = pattern_dict[pattern_id]
                        data[i:i+2] = pattern_bytes
                        i += len(pattern_bytes)
                    else:
                        i += 2
                else:
                    i += 1
            
            return bytes(data)
        
        raise ValueError(f"Unknown mode: {mode}")
    
    def compress_file(self, input_path: str):
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return None
        
        print(f"ğŸš€ Ultra Fast Binary Collapse: {os.path.basename(input_path)}")
        start_time = time.time()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with open(input_path, 'rb') as f:
            data = f.read()
        
        original_size = len(data)
        original_md5 = hashlib.md5(data).hexdigest()
        
        print(f"ğŸ“ å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {original_size:,} bytes")
        
        # åœ§ç¸®
        compressed = self.ultra_fast_compress(data)
        compressed_size = len(compressed)
        
        # çµæœè¨ˆç®—
        compression_ratio = ((original_size - compressed_size) / original_size) * 100 if original_size > 0 else 0
        processing_time = time.time() - start_time
        throughput = original_size / (1024 * 1024) / processing_time if processing_time > 0 else 0
        
        print(f"ğŸ”¹ åœ§ç¸®å®Œäº†: {compression_ratio:.1f}%")
        print(f"âš¡ å‡¦ç†é€Ÿåº¦: {throughput:.1f} MB/s ({processing_time:.3f}s)")
        
        # ä¿å­˜
        output_path = input_path + '.nxufc'
        with open(output_path, 'wb') as f:
            f.write(compressed)
        
        # å¯é€†æ€§ãƒ†ã‚¹ãƒˆ
        try:
            restored = self.ultra_fast_decompress(compressed)
            restored_md5 = hashlib.md5(restored).hexdigest()
            
            if restored_md5 == original_md5:
                print(f"âœ… å®Œå…¨å¯é€†æ€§ç¢ºèª: MD5ä¸€è‡´")
                print(f"ğŸ¯ SUCCESS: Ultra Fastå®Œäº† - {os.path.basename(output_path)}")
                return True
            else:
                print(f"âŒ MD5ä¸ä¸€è‡´")
                return False
        except Exception as e:
            print(f"âŒ å¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            return False

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ä½¿ç”¨æ³•: python nxzip_ultra_fast_binary_collapse.py <ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        print("\nğŸš€ NXZip Ultra Fast Binary Collapse Engine")
        print("ğŸ“‹ ç‰¹å¾´:")
        print("  âš¡ è¶…é«˜é€Ÿå‡¦ç†ï¼ˆè¤‡é›‘ãªè§£ææ’é™¤ï¼‰")
        print("  ğŸ¯ åŠ¹æœçš„ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¿ãƒ¼ãƒ³åœ§ç¸®")
        print("  ğŸ“Š æœ€å°é™æ§‹é€ è§£æ")
        print("  ğŸ”„ å®Œå…¨å¯é€†æ€§ä¿è¨¼")
        sys.exit(1)
    
    input_file = sys.argv[1]
    engine = UltraFastBinaryCollapseEngine()
    engine.compress_file(input_file)

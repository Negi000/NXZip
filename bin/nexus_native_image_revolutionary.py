#!/usr/bin/env python3
"""
NEXUS Native Image Revolutionary Compressor (NIRC)
å®Œå…¨ç‹¬è‡ªç”»åƒåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  - æ—¢å­˜æŠ€è¡“ã‹ã‚‰ã®å®Œå…¨è„±å´

é©æ–°çš„ç‰¹å¾´:
1. Quantum-Inspired Pixel Redistribution (QIPR): é‡å­åŠ›å­¦çš„ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®
2. Chromatic Frequency Transformation (CFT): è‰²å½©å‘¨æ³¢æ•°å¤‰æ›
3. Spatial Pattern Extinction (SPE): ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»æ³•
4. Neural-Mimetic Prediction Engine (NMPE): ç¥çµŒæ¨¡å€£äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³
5. Fractal-Based Delta Encoding (FBDE): ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–

å®Œå…¨ç‹¬è‡ªå®Ÿè£… - zlib/LZMAç­‰ä¸€åˆ‡ä¸ä½¿ç”¨
"""

import os
import sys
import time
import math
import struct
import hashlib
import random
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional, Union
from collections import defaultdict, Counter
from concurrent.futures import ThreadPoolExecutor

@dataclass
class ImageMetadata:
    """ç”»åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿"""
    width: int
    height: int
    channels: int
    format_type: str
    compression_hint: str
    pixel_density: float
    color_entropy: float
    spatial_complexity: float

@dataclass
class QuantumPixelCluster:
    """é‡å­ãƒ”ã‚¯ã‚»ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿"""
    centroid: Tuple[int, int, int]  # RGBä¸­å¿ƒå€¤
    pixels: List[Tuple[int, int]]   # ãƒ”ã‚¯ã‚»ãƒ«åº§æ¨™ãƒªã‚¹ãƒˆ
    frequency: int                  # å‡ºç¾é »åº¦
    spatial_distribution: float    # ç©ºé–“åˆ†å¸ƒå€¤
    energy_level: float            # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«

@dataclass
class ChromaticFrequency:
    """è‰²å½©å‘¨æ³¢æ•°"""
    frequency: float
    amplitude: float
    phase: float
    harmonic_order: int

class NativeImageRevolutionary:
    """å®Œå…¨ç‹¬è‡ªç”»åƒåœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.version = "1.0-Revolutionary"
        self.magic_header = b'NIRC2025'  # Native Image Revolutionary Compressor
        
        # é‡å­åŠ›å­¦çš„å®šæ•°
        self.quantum_threshold = 0.618  # é»„é‡‘æ¯”ãƒ™ãƒ¼ã‚¹ã®é‡å­é–¾å€¤
        self.planck_constant = 6.626e-34  # ãƒ—ãƒ©ãƒ³ã‚¯å®šæ•°ï¼ˆæ­£è¦åŒ–ç”¨ï¼‰
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å®šæ•°
        self.mandelbrot_iterations = 100
        self.julia_constant = complex(-0.7269, 0.1889)
        
        # ç¥çµŒç¶²æ¨¡å€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.synaptic_weight_decay = 0.95
        self.activation_threshold = 0.75
        
        # ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»è¨­å®š
        self.extinction_radius = 5
        self.pattern_similarity_threshold = 0.88
        
        print(f"ğŸ§¬ NEXUS Native Image Revolutionary v{self.version}")
        print("ğŸ’« é‡å­åŠ›å­¦çš„ãƒ”ã‚¯ã‚»ãƒ«å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def detect_image_format_native(self, data: bytes) -> ImageMetadata:
        """å®Œå…¨ç‹¬è‡ªç”»åƒè§£æ"""
        if len(data) < 100:
            return ImageMetadata(0, 0, 0, "UNKNOWN", "minimal", 0.0, 0.0, 0.0)
        
        print("ğŸ”¬ é‡å­ç”»åƒè§£æé–‹å§‹...")
        
        # PNGæ¤œå‡ºã¨è§£æ
        if data.startswith(b'\x89PNG\r\n\x1a\n'):
            return self._analyze_png_native(data)
        
        # JPEGæ¤œå‡ºã¨è§£æ
        elif data.startswith(b'\xff\xd8\xff'):
            return self._analyze_jpeg_native(data)
        
        # BMPæ¤œå‡º
        elif data.startswith(b'BM'):
            return self._analyze_bmp_native(data)
        
        # RAW/æœªçŸ¥å½¢å¼ - å®Œå…¨ç‹¬è‡ªè§£æ
        else:
            return self._analyze_raw_image_native(data)
    
    def _analyze_png_native(self, data: bytes) -> ImageMetadata:
        """PNGç‹¬è‡ªè§£æ"""
        try:
            # IHDR ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢
            ihdr_pos = data.find(b'IHDR')
            if ihdr_pos == -1:
                return ImageMetadata(0, 0, 0, "PNG", "corrupted", 0.0, 0.0, 0.0)
            
            ihdr_start = ihdr_pos + 4
            width = struct.unpack('>I', data[ihdr_start:ihdr_start+4])[0]
            height = struct.unpack('>I', data[ihdr_start+4:ihdr_start+8])[0]
            bit_depth = data[ihdr_start+8]
            color_type = data[ihdr_start+9]
            
            # ãƒãƒ£ãƒ³ãƒãƒ«æ•°è¨ˆç®—
            channels = self._calculate_png_channels(color_type)
            
            # ãƒ”ã‚¯ã‚»ãƒ«å¯†åº¦è¨ˆç®—
            pixel_density = (width * height) / len(data)
            
            # è‰²å½©ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¨å®š
            color_entropy = self._estimate_color_entropy_png(data, width, height, channels)
            
            # ç©ºé–“è¤‡é›‘åº¦
            spatial_complexity = self._calculate_spatial_complexity(width, height, pixel_density)
            
            compression_hint = self._generate_png_compression_hint(
                width, height, channels, color_entropy, spatial_complexity
            )
            
            return ImageMetadata(
                width, height, channels, "PNG", compression_hint,
                pixel_density, color_entropy, spatial_complexity
            )
            
        except Exception:
            return ImageMetadata(0, 0, 0, "PNG", "fallback", 0.0, 0.0, 0.0)
    
    def _analyze_jpeg_native(self, data: bytes) -> ImageMetadata:
        """JPEGç‹¬è‡ªè§£æ"""
        try:
            # SOF (Start of Frame) ãƒãƒ¼ã‚«ãƒ¼æ¤œç´¢
            sof_markers = [b'\xff\xc0', b'\xff\xc1', b'\xff\xc2']
            sof_pos = -1
            
            for marker in sof_markers:
                pos = data.find(marker)
                if pos != -1:
                    sof_pos = pos
                    break
            
            if sof_pos == -1:
                return ImageMetadata(0, 0, 0, "JPEG", "corrupted", 0.0, 0.0, 0.0)
            
            # SOFãƒ‡ãƒ¼ã‚¿è§£æ
            sof_start = sof_pos + 5  # ãƒãƒ¼ã‚«ãƒ¼ + é•·ã•ã‚’ã‚¹ã‚­ãƒƒãƒ—
            precision = data[sof_start]
            height = struct.unpack('>H', data[sof_start+1:sof_start+3])[0]
            width = struct.unpack('>H', data[sof_start+3:sof_start+5])[0]
            channels = data[sof_start+5]
            
            # JPEGç‰¹æœ‰ã®è§£æ
            pixel_density = (width * height) / len(data)
            color_entropy = self._estimate_jpeg_entropy(data)
            spatial_complexity = self._analyze_jpeg_dct_complexity(data)
            
            compression_hint = self._generate_jpeg_compression_hint(
                width, height, channels, precision, color_entropy
            )
            
            return ImageMetadata(
                width, height, channels, "JPEG", compression_hint,
                pixel_density, color_entropy, spatial_complexity
            )
            
        except Exception:
            return ImageMetadata(0, 0, 0, "JPEG", "fallback", 0.0, 0.0, 0.0)
    
    def _analyze_bmp_native(self, data: bytes) -> ImageMetadata:
        """BMPç‹¬è‡ªè§£æ"""
        try:
            if len(data) < 54:  # BMPãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º
                return ImageMetadata(0, 0, 0, "BMP", "corrupted", 0.0, 0.0, 0.0)
            
            # BMP ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            width = struct.unpack('<I', data[18:22])[0]
            height = struct.unpack('<I', data[22:26])[0]
            bit_count = struct.unpack('<H', data[28:30])[0]
            
            channels = bit_count // 8
            if channels == 0:
                channels = 1
            
            pixel_density = (width * height) / len(data)
            color_entropy = self._estimate_bmp_entropy(data, width, height, bit_count)
            spatial_complexity = self._calculate_spatial_complexity(width, height, pixel_density)
            
            compression_hint = "bmp_native"
            
            return ImageMetadata(
                width, height, channels, "BMP", compression_hint,
                pixel_density, color_entropy, spatial_complexity
            )
            
        except Exception:
            return ImageMetadata(0, 0, 0, "BMP", "fallback", 0.0, 0.0, 0.0)
    
    def _analyze_raw_image_native(self, data: bytes) -> ImageMetadata:
        """RAWç”»åƒç‹¬è‡ªè§£æ"""
        # é‡å­åŠ›å­¦çš„è§£æã«ã‚ˆã‚‹ç”»åƒç‰¹æ€§æ¨å®š
        data_size = len(data)
        
        # é»„é‡‘æ¯”ã«ã‚ˆã‚‹æ¬¡å…ƒæ¨å®š
        golden_ratio = 1.618033988749895
        estimated_pixels = int(data_size / 3)  # RGBä»®å®š
        
        # æœ€é©ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”æ¢ç´¢
        best_width, best_height = self._find_optimal_dimensions(estimated_pixels, golden_ratio)
        
        # é‡å­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
        color_entropy = self._quantum_entropy_analysis(data)
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¤‡é›‘åº¦
        spatial_complexity = self._fractal_complexity_analysis(data, best_width, best_height)
        
        pixel_density = estimated_pixels / data_size
        
        return ImageMetadata(
            best_width, best_height, 3, "RAW", "quantum_native",
            pixel_density, color_entropy, spatial_complexity
        )
    
    def compress_image_revolutionary(self, data: bytes, metadata: ImageMetadata) -> bytes:
        """é©å‘½çš„ç”»åƒåœ§ç¸®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        print(f"ğŸš€ é©å‘½çš„åœ§ç¸®é–‹å§‹: {metadata.format_type} ({metadata.width}x{metadata.height})")
        
        start_time = time.time()
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: é‡å­ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®
        quantum_data, quantum_map = self._quantum_pixel_redistribution(data, metadata)
        print(f"âœ¨ é‡å­ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®å®Œäº† ({len(quantum_data)} bytes)")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: è‰²å½©å‘¨æ³¢æ•°å¤‰æ›
        frequency_data, frequency_table = self._chromatic_frequency_transformation(quantum_data, metadata)
        print(f"ğŸŒˆ è‰²å½©å‘¨æ³¢æ•°å¤‰æ›å®Œäº† ({len(frequency_data)} bytes)")
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»
        extinct_data, extinction_map = self._spatial_pattern_extinction(frequency_data, metadata)
        print(f"ğŸŒŒ ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»å®Œäº† ({len(extinct_data)} bytes)")
        
        # ã‚¹ãƒ†ãƒƒãƒ—4: ç¥çµŒæ¨¡å€£äºˆæ¸¬ç¬¦å·åŒ–
        neural_data, neural_model = self._neural_mimetic_prediction_encoding(extinct_data, metadata)
        print(f"ğŸ§  ç¥çµŒæ¨¡å€£äºˆæ¸¬ç¬¦å·åŒ–å®Œäº† ({len(neural_data)} bytes)")
        
        # ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–
        final_data, fractal_coeffs = self._fractal_delta_encoding(neural_data, metadata)
        print(f"ğŸ”® ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–å®Œäº† ({len(final_data)} bytes)")
        
        # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
        compressed_package = self._package_compressed_data(
            final_data, metadata, quantum_map, frequency_table,
            extinction_map, neural_model, fractal_coeffs
        )
        
        compression_time = time.time() - start_time
        compression_ratio = (1 - len(compressed_package) / len(data)) * 100
        
        print(f"ğŸ¯ åœ§ç¸®å®Œäº†: {len(data)} â†’ {len(compressed_package)} bytes")
        print(f"ğŸ“Š åœ§ç¸®ç‡: {compression_ratio:.2f}% (æ™‚é–“: {compression_time:.3f}s)")
        
        return compressed_package
    
    def _quantum_pixel_redistribution(self, data: bytes, metadata: ImageMetadata) -> Tuple[bytes, Dict]:
        """é‡å­åŠ›å­¦çš„ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®"""
        print("âš›ï¸  é‡å­ãƒ”ã‚¯ã‚»ãƒ«è§£æä¸­...")
        
        if metadata.channels == 0:
            return data, {}
        
        # ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        pixels = []
        bytes_per_pixel = metadata.channels
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹ä½ç½®ã‚’æ¨å®š
        data_start = self._estimate_pixel_data_start(data, metadata)
        pixel_data = data[data_start:]
        
        # ãƒ”ã‚¯ã‚»ãƒ«é…åˆ—æ§‹ç¯‰
        for i in range(0, len(pixel_data) - bytes_per_pixel + 1, bytes_per_pixel):
            pixel = pixel_data[i:i+bytes_per_pixel]
            if len(pixel) == bytes_per_pixel:
                if bytes_per_pixel == 3:  # RGB
                    pixels.append((pixel[0], pixel[1], pixel[2]))
                elif bytes_per_pixel == 4:  # RGBA
                    pixels.append((pixel[0], pixel[1], pixel[2], pixel[3]))
                else:  # Grayscale
                    pixels.append((pixel[0], pixel[0], pixel[0]))
        
        if not pixels:
            return data, {}
        
        # é‡å­ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        quantum_clusters = self._quantum_clustering(pixels)
        
        # é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼é †åºã§ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®
        redistributed_pixels = self._quantum_energy_redistribution(pixels, quantum_clusters)
        
        # ãƒã‚¤ãƒˆåˆ—å†æ§‹ç¯‰
        redistributed_data = bytearray(data[:data_start])
        for pixel in redistributed_pixels:
            if metadata.channels == 3:
                redistributed_data.extend([pixel[0], pixel[1], pixel[2]])
            elif metadata.channels == 4:
                redistributed_data.extend([pixel[0], pixel[1], pixel[2], pixel[3]])
            else:
                redistributed_data.append(pixel[0])
        
        # æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        remaining_start = data_start + len(redistributed_pixels) * bytes_per_pixel
        if remaining_start < len(data):
            redistributed_data.extend(data[remaining_start:])
        
        quantum_map = {
            'clusters': len(quantum_clusters),
            'redistribution_energy': sum(cluster.energy_level for cluster in quantum_clusters),
            'quantum_coherence': self._calculate_quantum_coherence(quantum_clusters)
        }
        
        return bytes(redistributed_data), quantum_map
    
    def _quantum_clustering(self, pixels: List[Tuple]) -> List[QuantumPixelCluster]:
        """é‡å­ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"""
        if not pixels:
            return []
        
        # åˆæœŸã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã‚’é‡å­æ•°ã«åŸºã¥ã„ã¦è¨­å®š
        num_clusters = min(16, max(2, int(math.sqrt(len(pixels)) / 4)))
        clusters = []
        
        # é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«ã§ã‚¯ãƒ©ã‚¹ã‚¿åˆæœŸåŒ–
        for i in range(num_clusters):
            # é»„é‡‘æ¯”ãƒ™ãƒ¼ã‚¹ã®é‡å­ä½ç½®
            quantum_phase = (i * self.quantum_threshold * 2 * math.pi) % (2 * math.pi)
            
            # RGBä¸­å¿ƒå€¤ã‚’é‡å­ä½ç›¸ã‹ã‚‰è¨ˆç®—
            r = int(128 + 127 * math.sin(quantum_phase))
            g = int(128 + 127 * math.sin(quantum_phase + 2*math.pi/3))
            b = int(128 + 127 * math.sin(quantum_phase + 4*math.pi/3))
            
            centroid = (r, g, b)
            energy_level = self._calculate_quantum_energy(centroid)
            
            clusters.append(QuantumPixelCluster(
                centroid=centroid,
                pixels=[],
                frequency=0,
                spatial_distribution=0.0,
                energy_level=energy_level
            ))
        
        # é‡å­è¦ªå’Œæ€§ã«ã‚ˆã‚‹åˆ†é¡
        for i, pixel in enumerate(pixels):
            best_cluster = 0
            min_quantum_distance = float('inf')
            
            for j, cluster in enumerate(clusters):
                quantum_distance = self._quantum_distance(pixel[:3], cluster.centroid)
                if quantum_distance < min_quantum_distance:
                    min_quantum_distance = quantum_distance
                    best_cluster = j
            
            clusters[best_cluster].pixels.append((i % 1000, i // 1000))  # ä»®æƒ³åº§æ¨™
            clusters[best_cluster].frequency += 1
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ä¸­å¿ƒã®å†è¨ˆç®—ï¼ˆé‡å­é‡å¿ƒï¼‰
        for cluster in clusters:
            if cluster.frequency > 0:
                # é‡å­é‡å¿ƒè¨ˆç®—
                total_weight = 0
                weighted_r, weighted_g, weighted_b = 0, 0, 0
                
                for pixel_pos in cluster.pixels:
                    pixel_idx = pixel_pos[1] * 1000 + pixel_pos[0]
                    if pixel_idx < len(pixels):
                        pixel = pixels[pixel_idx]
                        quantum_weight = self._calculate_quantum_weight(pixel[:3])
                        
                        weighted_r += pixel[0] * quantum_weight
                        weighted_g += pixel[1] * quantum_weight
                        weighted_b += pixel[2] * quantum_weight
                        total_weight += quantum_weight
                
                if total_weight > 0:
                    cluster.centroid = (
                        int(weighted_r / total_weight),
                        int(weighted_g / total_weight),
                        int(weighted_b / total_weight)
                    )
                    cluster.energy_level = self._calculate_quantum_energy(cluster.centroid)
        
        return [c for c in clusters if c.frequency > 0]
    
    def _quantum_energy_redistribution(self, pixels: List[Tuple], clusters: List[QuantumPixelCluster]) -> List[Tuple]:
        """é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼é †åºã«ã‚ˆã‚‹å†é…ç½®"""
        if not clusters:
            return pixels
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«é †ã«ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ã‚½ãƒ¼ãƒˆ
        sorted_clusters = sorted(clusters, key=lambda c: c.energy_level)
        
        redistributed = []
        
        # ä½ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‹ã‚‰é«˜ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®é †ã§é…ç½®
        for cluster in sorted_clusters:
            cluster_pixels = []
            
            for pixel_pos in cluster.pixels:
                pixel_idx = pixel_pos[1] * 1000 + pixel_pos[0]
                if pixel_idx < len(pixels):
                    cluster_pixels.append(pixels[pixel_idx])
            
            # ã‚¯ãƒ©ã‚¹ã‚¿å†…ã§ã‚‚é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼é †ã‚½ãƒ¼ãƒˆ
            cluster_pixels.sort(key=lambda p: self._calculate_quantum_energy(p[:3]))
            redistributed.extend(cluster_pixels)
        
        # æ®‹ã‚Šã®ãƒ”ã‚¯ã‚»ãƒ«ã‚’è¿½åŠ 
        redistributed_indices = set()
        for cluster in clusters:
            for pixel_pos in cluster.pixels:
                pixel_idx = pixel_pos[1] * 1000 + pixel_pos[0]
                if pixel_idx < len(pixels):
                    redistributed_indices.add(pixel_idx)
        
        for i, pixel in enumerate(pixels):
            if i not in redistributed_indices:
                redistributed.append(pixel)
        
        return redistributed
    
    def _chromatic_frequency_transformation(self, data: bytes, metadata: ImageMetadata) -> Tuple[bytes, Dict]:
        """è‰²å½©å‘¨æ³¢æ•°å¤‰æ›"""
        print("ğŸŒˆ è‰²å½©å‘¨æ³¢æ•°è§£æä¸­...")
        
        # RGBå€¤ã®å‘¨æ³¢æ•°è§£æ
        rgb_frequencies = self._analyze_rgb_frequencies(data, metadata)
        
        # è‰²ç›¸ãƒ»å½©åº¦ãƒ»æ˜åº¦ã®å‘¨æ³¢æ•°å¤‰æ›
        hsv_frequencies = self._rgb_to_hsv_frequencies(rgb_frequencies)
        
        # å‘¨æ³¢æ•°åœ§ç¸®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰
        frequency_table = self._build_frequency_compression_table(hsv_frequencies)
        
        # å‘¨æ³¢æ•°ç¬¦å·åŒ–
        encoded_data = self._encode_with_frequencies(data, frequency_table, metadata)
        
        return encoded_data, frequency_table
    
    def _spatial_pattern_extinction(self, data: bytes, metadata: ImageMetadata) -> Tuple[bytes, Dict]:
        """ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»æ³•"""
        print("ğŸŒŒ ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³è§£æä¸­...")
        
        # åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        patterns = self._detect_spatial_patterns(data, metadata)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»ãƒãƒƒãƒ—ç”Ÿæˆ
        extinction_map = self._generate_extinction_map(patterns)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³é™¤å»ã¨åœ§ç¸®å‚ç…§ã¸ã®ç½®æ›
        extinct_data = self._apply_pattern_extinction(data, extinction_map, metadata)
        
        return extinct_data, extinction_map
    
    def _neural_mimetic_prediction_encoding(self, data: bytes, metadata: ImageMetadata) -> Tuple[bytes, Dict]:
        """ç¥çµŒæ¨¡å€£äºˆæ¸¬ç¬¦å·åŒ–"""
        print("ğŸ§  ç¥çµŒç¶²äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
        
        # ç°¡æ˜“ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«äºˆæ¸¬å™¨æ§‹ç¯‰
        predictor = self._build_neural_predictor(data, metadata)
        
        # äºˆæ¸¬èª¤å·®ç¬¦å·åŒ–
        predicted_data, error_data = self._neural_prediction_encode(data, predictor)
        
        # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«åœ§ç¸®
        compressed_model = self._compress_neural_model(predictor)
        
        neural_model = {
            'model': compressed_model,
            'prediction_accuracy': self._calculate_prediction_accuracy(predicted_data, data),
            'error_distribution': self._analyze_error_distribution(error_data)
        }
        
        return error_data, neural_model
    
    def _fractal_delta_encoding(self, data: bytes, metadata: ImageMetadata) -> Tuple[bytes, Dict]:
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–"""
        print("ğŸ”® ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å¤‰æ›ä¸­...")
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ä¿‚æ•°è¨ˆç®—
        fractal_coeffs = self._calculate_fractal_coefficients(data, metadata)
        
        # å·®åˆ†ç¬¦å·åŒ–
        delta_encoded = self._apply_fractal_delta_encoding(data, fractal_coeffs)
        
        return delta_encoded, fractal_coeffs
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    
    def _calculate_png_channels(self, color_type: int) -> int:
        """PNGãƒãƒ£ãƒ³ãƒãƒ«æ•°è¨ˆç®—"""
        channel_map = {0: 1, 2: 3, 3: 1, 4: 2, 6: 4}
        return channel_map.get(color_type, 3)
    
    def _estimate_pixel_data_start(self, data: bytes, metadata: ImageMetadata) -> int:
        """ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿é–‹å§‹ä½ç½®æ¨å®š"""
        if metadata.format_type == "PNG":
            # IDAT ãƒãƒ£ãƒ³ã‚¯æ¢ç´¢
            idat_pos = data.find(b'IDAT')
            return idat_pos + 8 if idat_pos != -1 else len(data) // 4
        elif metadata.format_type == "JPEG":
            # SOS ãƒãƒ¼ã‚«ãƒ¼æ¢ç´¢
            sos_pos = data.find(b'\xff\xda')
            return sos_pos + 12 if sos_pos != -1 else len(data) // 4
        elif metadata.format_type == "BMP":
            return 54  # æ¨™æº–BMPãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º
        else:
            return 0
    
    def _quantum_distance(self, pixel1: Tuple[int, int, int], pixel2: Tuple[int, int, int]) -> float:
        """é‡å­è·é›¢è¨ˆç®—"""
        r_diff = (pixel1[0] - pixel2[0]) ** 2
        g_diff = (pixel1[1] - pixel2[1]) ** 2
        b_diff = (pixel1[2] - pixel2[2]) ** 2
        
        euclidean = math.sqrt(r_diff + g_diff + b_diff)
        
        # é‡å­è£œæ­£ä¿‚æ•°
        quantum_factor = abs(math.sin(euclidean * self.quantum_threshold))
        
        return euclidean * (1 + quantum_factor)
    
    def _calculate_quantum_energy(self, pixel: Tuple[int, int, int]) -> float:
        """é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼è¨ˆç®—"""
        r, g, b = pixel
        
        # RGBå€¤ã®é‡å­ã‚¨ãƒãƒ«ã‚®ãƒ¼
        luminance = 0.299 * r + 0.587 * g + 0.114 * b
        
        # é‡å­åŠ±èµ·çŠ¶æ…‹
        quantum_state = math.sin(luminance * math.pi / 255.0)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ¬ãƒ™ãƒ«ï¼ˆãƒ—ãƒ©ãƒ³ã‚¯å®šæ•°æ­£è¦åŒ–ï¼‰
        energy = luminance * abs(quantum_state) * 1e34 / 6.626
        
        return energy
    
    def _calculate_quantum_weight(self, pixel: Tuple[int, int, int]) -> float:
        """é‡å­é‡ã¿è¨ˆç®—"""
        energy = self._calculate_quantum_energy(pixel)
        return 1.0 / (1.0 + math.exp(-energy / 1000.0))  # ã‚·ã‚°ãƒ¢ã‚¤ãƒ‰é–¢æ•°
    
    def _calculate_quantum_coherence(self, clusters: List[QuantumPixelCluster]) -> float:
        """é‡å­ã‚³ãƒ’ãƒ¼ãƒ¬ãƒ³ã‚¹è¨ˆç®—"""
        if not clusters:
            return 0.0
        
        total_coherence = 0.0
        total_pairs = 0
        
        for i in range(len(clusters)):
            for j in range(i + 1, len(clusters)):
                cluster1, cluster2 = clusters[i], clusters[j]
                
                # ã‚¨ãƒãƒ«ã‚®ãƒ¼å·®ã«ã‚ˆã‚‹ç›¸äº’ä½œç”¨
                energy_diff = abs(cluster1.energy_level - cluster2.energy_level)
                coherence = math.exp(-energy_diff / 10000.0)
                
                total_coherence += coherence
                total_pairs += 1
        
        return total_coherence / max(total_pairs, 1)
    
    # ç°¡ç•¥åŒ–ã•ã‚ŒãŸæ®‹ã‚Šã®ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…
    
    def _estimate_color_entropy_png(self, data: bytes, width: int, height: int, channels: int) -> float:
        """PNGè‰²å½©ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¨å®š"""
        return min(8.0, math.log2(len(set(data))) if len(set(data)) > 1 else 0.0)
    
    def _calculate_spatial_complexity(self, width: int, height: int, density: float) -> float:
        """ç©ºé–“è¤‡é›‘åº¦è¨ˆç®—"""
        aspect_ratio = width / max(height, 1)
        return min(1.0, density * abs(math.log(aspect_ratio + 1)))
    
    def _generate_png_compression_hint(self, width: int, height: int, channels: int, entropy: float, complexity: float) -> str:
        """PNGåœ§ç¸®ãƒ’ãƒ³ãƒˆç”Ÿæˆ"""
        if entropy < 2.0:
            return "quantum_low_entropy"
        elif complexity > 0.7:
            return "fractal_high_complexity"
        else:
            return "neural_adaptive"
    
    def _estimate_jpeg_entropy(self, data: bytes) -> float:
        """JPEG ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¨å®š"""
        return min(8.0, math.log2(len(set(data))) * 0.8 if len(set(data)) > 1 else 0.0)
    
    def _analyze_jpeg_dct_complexity(self, data: bytes) -> float:
        """JPEG DCTè¤‡é›‘åº¦è§£æ"""
        # DCT ãƒãƒ¼ã‚«ãƒ¼è¿‘ä¼¼è§£æ
        dct_indicators = data.count(b'\xff\xc4') + data.count(b'\xff\xdb')
        return min(1.0, dct_indicators / 10.0)
    
    def _generate_jpeg_compression_hint(self, width: int, height: int, channels: int, precision: int, entropy: float) -> str:
        """JPEGåœ§ç¸®ãƒ’ãƒ³ãƒˆç”Ÿæˆ"""
        if precision > 8:
            return "high_precision_neural"
        elif entropy > 6.0:
            return "high_entropy_fractal"
        else:
            return "standard_quantum"
    
    def _estimate_bmp_entropy(self, data: bytes, width: int, height: int, bit_count: int) -> float:
        """BMP ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æ¨å®š"""
        pixel_data_size = width * height * (bit_count // 8)
        return min(8.0, math.log2(pixel_data_size) / 3.0 if pixel_data_size > 0 else 0.0)
    
    def _find_optimal_dimensions(self, pixels: int, golden_ratio: float) -> Tuple[int, int]:
        """æœ€é©æ¬¡å…ƒæ¢ç´¢"""
        sqrt_pixels = int(math.sqrt(pixels))
        width = int(sqrt_pixels * golden_ratio)
        height = int(pixels / max(width, 1))
        return max(1, width), max(1, height)
    
    def _quantum_entropy_analysis(self, data: bytes) -> float:
        """é‡å­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è§£æ"""
        if not data:
            return 0.0
        
        byte_counts = Counter(data)
        total = len(data)
        
        entropy = 0.0
        for count in byte_counts.values():
            p = count / total
            if p > 0:
                entropy -= p * math.log2(p)
        
        # é‡å­è£œæ­£
        quantum_correction = abs(math.sin(entropy * self.quantum_threshold))
        return min(8.0, entropy * (1 + quantum_correction * 0.1))
    
    def _fractal_complexity_analysis(self, data: bytes, width: int, height: int) -> float:
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«è¤‡é›‘åº¦è§£æ"""
        if not data or width == 0 or height == 0:
            return 0.0
        
        # ç°¡æ˜“ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ¨å®š
        complexity = 0.0
        sample_size = min(1000, len(data))
        
        for i in range(0, sample_size - 1):
            diff = abs(data[i] - data[i + 1])
            complexity += diff / 255.0
        
        # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¬¡å…ƒæ­£è¦åŒ–
        fractal_dimension = complexity / max(sample_size - 1, 1)
        return min(1.0, fractal_dimension)
    
    # ç°¡ç•¥åŒ–ã•ã‚ŒãŸæ®‹ã‚Šã®å‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰ç¾¤
    
    def _analyze_rgb_frequencies(self, data: bytes, metadata: ImageMetadata) -> Dict:
        """RGBå‘¨æ³¢æ•°è§£æ"""
        return {'r_freq': [], 'g_freq': [], 'b_freq': []}
    
    def _rgb_to_hsv_frequencies(self, rgb_freq: Dict) -> Dict:
        """RGBâ†’HSVå‘¨æ³¢æ•°å¤‰æ›"""
        return {'h_freq': [], 's_freq': [], 'v_freq': []}
    
    def _build_frequency_compression_table(self, hsv_freq: Dict) -> Dict:
        """å‘¨æ³¢æ•°åœ§ç¸®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰"""
        return {'table': {}, 'compression_ratio': 0.5}
    
    def _encode_with_frequencies(self, data: bytes, freq_table: Dict, metadata: ImageMetadata) -> bytes:
        """å‘¨æ³¢æ•°ç¬¦å·åŒ–"""
        # ç°¡ç•¥åŒ–ï¼šåŸºæœ¬çš„ãªç½®æ›
        encoded = bytearray()
        for byte in data:
            encoded.append(byte ^ 0x55)  # ç°¡æ˜“XORå¤‰æ›
        return bytes(encoded)
    
    def _detect_spatial_patterns(self, data: bytes, metadata: ImageMetadata) -> List[Dict]:
        """ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º"""
        patterns = []
        pattern_length = 8
        
        for i in range(0, len(data) - pattern_length, pattern_length):
            pattern = data[i:i + pattern_length]
            count = data.count(pattern)
            if count > 2:
                patterns.append({
                    'pattern': pattern,
                    'frequency': count,
                    'positions': [j for j in range(len(data) - pattern_length + 1) 
                                 if data[j:j + pattern_length] == pattern]
                })
        
        return patterns[:10]  # ä¸Šä½10ãƒ‘ã‚¿ãƒ¼ãƒ³
    
    def _generate_extinction_map(self, patterns: List[Dict]) -> Dict:
        """æ¶ˆå»ãƒãƒƒãƒ—ç”Ÿæˆ"""
        return {
            'patterns': patterns,
            'extinction_count': len(patterns)
        }
    
    def _apply_pattern_extinction(self, data: bytes, extinction_map: Dict, metadata: ImageMetadata) -> bytes:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»é©ç”¨"""
        result = bytearray(data)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç½®æ›ï¼ˆç°¡ç•¥åŒ–ï¼‰
        for i, pattern_info in enumerate(extinction_map.get('patterns', [])):
            pattern = pattern_info['pattern']
            replacement = bytes([i + 1] * len(pattern))  # ç°¡æ˜“ç½®æ›
            
            # æœ€åˆã®å‡ºç¾ã®ã¿ç½®æ›
            pos = result.find(pattern)
            if pos != -1:
                result[pos:pos + len(pattern)] = replacement
        
        return bytes(result)
    
    def _build_neural_predictor(self, data: bytes, metadata: ImageMetadata) -> Dict:
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«äºˆæ¸¬å™¨æ§‹ç¯‰"""
        return {
            'weights': [random.random() for _ in range(16)],
            'bias': [random.random() for _ in range(4)],
            'activation': 'sigmoid'
        }
    
    def _neural_prediction_encode(self, data: bytes, predictor: Dict) -> Tuple[bytes, bytes]:
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«äºˆæ¸¬ç¬¦å·åŒ–"""
        predicted = bytearray()
        errors = bytearray()
        
        weights = predictor['weights']
        
        for i, byte in enumerate(data):
            # ç°¡æ˜“äºˆæ¸¬
            weight_idx = i % len(weights)
            predicted_val = int(byte * weights[weight_idx]) % 256
            error = (byte - predicted_val) % 256
            
            predicted.append(predicted_val)
            errors.append(error)
        
        return bytes(predicted), bytes(errors)
    
    def _compress_neural_model(self, predictor: Dict) -> bytes:
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒ¢ãƒ‡ãƒ«åœ§ç¸®"""
        model_data = bytearray()
        
        # é‡ã¿ã®é‡å­åŒ–
        for weight in predictor['weights']:
            quantized = int(weight * 255)
            model_data.append(quantized)
        
        for bias in predictor['bias']:
            quantized = int(bias * 255)
            model_data.append(quantized)
        
        return bytes(model_data)
    
    def _calculate_prediction_accuracy(self, predicted: bytes, original: bytes) -> float:
        """äºˆæ¸¬ç²¾åº¦è¨ˆç®—"""
        if len(predicted) != len(original):
            return 0.0
        
        correct = sum(1 for p, o in zip(predicted, original) if abs(p - o) < 16)
        return correct / len(original)
    
    def _analyze_error_distribution(self, errors: bytes) -> Dict:
        """èª¤å·®åˆ†å¸ƒè§£æ"""
        error_counts = Counter(errors)
        return {
            'mean_error': sum(errors) / len(errors) if errors else 0,
            'max_error': max(errors) if errors else 0,
            'unique_errors': len(error_counts)
        }
    
    def _calculate_fractal_coefficients(self, data: bytes, metadata: ImageMetadata) -> Dict:
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ä¿‚æ•°è¨ˆç®—"""
        coefficients = []
        
        # ç°¡æ˜“ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å¤‰æ›
        for i in range(0, len(data), 4):
            chunk = data[i:i+4]
            if len(chunk) == 4:
                coeff = (chunk[0] + chunk[1] * 256 + chunk[2] * 65536 + chunk[3] * 16777216) % 65536
                coefficients.append(coeff)
        
        return {
            'coefficients': coefficients[:256],  # æœ€å¤§256ä¿‚æ•°
            'scaling_factor': 0.618,  # é»„é‡‘æ¯”ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            'iteration_limit': self.mandelbrot_iterations
        }
    
    def _apply_fractal_delta_encoding(self, data: bytes, fractal_coeffs: Dict) -> bytes:
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–é©ç”¨"""
        coeffs = fractal_coeffs.get('coefficients', [])
        if not coeffs:
            return data
        
        result = bytearray()
        prev_byte = 0
        
        for i, byte in enumerate(data):
            coeff_idx = i % len(coeffs)
            fractal_prediction = coeffs[coeff_idx] % 256
            
            # å·®åˆ†è¨ˆç®—
            delta = (byte - prev_byte - fractal_prediction) % 256
            result.append(delta)
            
            prev_byte = byte
        
        return bytes(result)
    
    def _package_compressed_data(self, final_data: bytes, metadata: ImageMetadata,
                                quantum_map: Dict, frequency_table: Dict,
                                extinction_map: Dict, neural_model: Dict,
                                fractal_coeffs: Dict) -> bytes:
        """åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°"""
        package = bytearray()
        
        # ãƒã‚¸ãƒƒã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼
        package.extend(self.magic_header)
        
        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        package.append(1)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata_bytes = self._serialize_metadata(metadata)
        package.extend(struct.pack('<H', len(metadata_bytes)))
        package.extend(metadata_bytes)
        
        # å„ãƒãƒƒãƒ—ã®ã‚µã‚¤ã‚ºã¨å†…å®¹
        maps = [quantum_map, frequency_table, extinction_map, neural_model, fractal_coeffs]
        for map_data in maps:
            serialized = self._serialize_dict(map_data)
            package.extend(struct.pack('<H', len(serialized)))
            package.extend(serialized)
        
        # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿
        package.extend(struct.pack('<I', len(final_data)))
        package.extend(final_data)
        
        return bytes(package)
    
    def _serialize_metadata(self, metadata: ImageMetadata) -> bytes:
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        data = struct.pack('<IIIB', metadata.width, metadata.height, 
                          metadata.channels, len(metadata.format_type))
        data += metadata.format_type.encode('utf-8')
        data += struct.pack('<fff', metadata.pixel_density, 
                           metadata.color_entropy, metadata.spatial_complexity)
        return data
    
    def _serialize_dict(self, data: Dict) -> bytes:
        """è¾æ›¸ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        import json
        json_str = json.dumps(data, default=str)
        return json_str.encode('utf-8')[:1024]  # æœ€å¤§1KBåˆ¶é™
    
    def compress_file(self, file_path: str, output_path: str = None) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®ãƒ¡ã‚¤ãƒ³"""
        try:
            if not os.path.exists(file_path):
                return {'success': False, 'error': f'ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}'}
            
            print(f"ğŸ“¸ Native Image Revolutionary åœ§ç¸®é–‹å§‹: {file_path}")
            
            with open(file_path, 'rb') as f:
                data = f.read()
            
            if len(data) == 0:
                return {'success': False, 'error': 'ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™'}
            
            # ç”»åƒè§£æ
            metadata = self.detect_image_format_native(data)
            print(f"ğŸ“Š ç”»åƒè§£æ: {metadata.format_type} {metadata.width}x{metadata.height}")
            
            # é©å‘½çš„åœ§ç¸®å®Ÿè¡Œ
            compressed = self.compress_image_revolutionary(data, metadata)
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
            if output_path is None:
                base_name = os.path.splitext(file_path)[0]
                output_path = f"{base_name}.nirc"
            
            with open(output_path, 'wb') as f:
                f.write(compressed)
            
            compression_ratio = (1 - len(compressed) / len(data)) * 100
            
            return {
                'success': True,
                'input_file': file_path,
                'output_file': output_path,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': compression_ratio,
                'algorithm': 'Native Image Revolutionary',
                'metadata': metadata
            }
            
        except Exception as e:
            return {'success': False, 'error': f'åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {str(e)}'}

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    if len(sys.argv) < 2:
        print("ğŸ§¬ NEXUS Native Image Revolutionary Compressor")
        print("å®Œå…¨ç‹¬è‡ªç”»åƒåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  - æ—¢å­˜æŠ€è¡“å®Œå…¨è„±å´ç‰ˆ")
        print()
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python nexus_native_image_revolutionary.py <ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«>")
        print("  python nexus_native_image_revolutionary.py test")
        print()
        print("é©æ–°çš„ç‰¹å¾´:")
        print("  âš›ï¸  é‡å­åŠ›å­¦çš„ãƒ”ã‚¯ã‚»ãƒ«å†é…ç½®")
        print("  ğŸŒˆ è‰²å½©å‘¨æ³¢æ•°å¤‰æ›")
        print("  ğŸŒŒ ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³æ¶ˆå»æ³•")
        print("  ğŸ§  ç¥çµŒæ¨¡å€£äºˆæ¸¬ç¬¦å·åŒ–")
        print("  ğŸ”® ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«å·®åˆ†ç¬¦å·åŒ–")
        return
    
    if sys.argv[1].lower() == "test":
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        print("ğŸ§ª Native Image Revolutionary ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        compressor = NativeImageRevolutionary()
        
        # ãƒ†ã‚¹ãƒˆç”»åƒãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        test_data = bytearray()
        test_data.extend(b'\x89PNG\r\n\x1a\n')  # PNGç½²å
        test_data.extend(b'\x00\x00\x00\rIHDR')  # IHDR ãƒãƒ£ãƒ³ã‚¯
        test_data.extend(struct.pack('>II', 100, 100))  # 100x100
        test_data.extend(b'\x08\x02\x00\x00\x00')  # 8bit RGB
        test_data.extend(b'\x00' * 1000)  # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        
        metadata = compressor.detect_image_format_native(bytes(test_data))
        print(f"ãƒ†ã‚¹ãƒˆç”»åƒ: {metadata.format_type} {metadata.width}x{metadata.height}")
        
        compressed = compressor.compress_image_revolutionary(bytes(test_data), metadata)
        compression_ratio = (1 - len(compressed) / len(test_data)) * 100
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆå®Œäº†: {len(test_data)} â†’ {len(compressed)} bytes")
        print(f"ğŸ“Š åœ§ç¸®ç‡: {compression_ratio:.2f}%")
        
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®
        file_path = sys.argv[1]
        compressor = NativeImageRevolutionary()
        
        result = compressor.compress_file(file_path)
        
        if result['success']:
            print(f"âœ… åœ§ç¸®æˆåŠŸ!")
            print(f"ğŸ“ å‡ºåŠ›: {result['output_file']}")
            print(f"ğŸ“Š åœ§ç¸®ç‡: {result['compression_ratio']:.2f}%")
            print(f"ğŸ“ ã‚µã‚¤ã‚º: {result['original_size']} â†’ {result['compressed_size']} bytes")
        else:
            print(f"âŒ åœ§ç¸®å¤±æ•—: {result['error']}")

if __name__ == "__main__":
    main()

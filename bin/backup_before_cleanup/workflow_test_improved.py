#!/usr/bin/env python3
"""
NXZip å®Ÿç”¨åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆæ”¹è‰¯ç‰ˆ
SPEæš—å·åŒ– â†’ NXZåœ§ç¸® â†’ å±•é–‹ â†’ SPEå¾©å·åŒ–ã®å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

æ”¹è‰¯ç‚¹:
1. ã‚ˆã‚Šå¤šæ§˜ãªãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ
2. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«(MP4)ã®æ˜ç¢ºãªãƒ†ã‚¹ãƒˆå¯¾è±¡åŒ–  
3. æ—¢å­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã®æ”¹è‰¯ã«ã‚ˆã‚‹åœ§ç¸®ç‡å‘ä¸Š
4. ç†è«–å€¤ã«è¿‘ã¥ã‘ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æœ€é©åŒ–
"""

import os
import sys
import hashlib
import time
from pathlib import Path
import tempfile
import shutil
import lzma
import zlib
import bz2

class ImprovedNXZipEngine:
    """æ”¹è‰¯ç‰ˆNXZipã‚¨ãƒ³ã‚¸ãƒ³ - æ—¢å­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ”¹è‰¯"""
    
    def __init__(self):
        self.version = "2.1"
        self.magic_header = b"NXZI21\x00\x00"  # Improvedç‰ˆãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
    
    def detect_file_type(self, data):
        """ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¤å®š"""
        if data.startswith(b'\xFF\xD8\xFF'):
            return 'jpeg'
        elif data.startswith(b'\x89PNG'):
            return 'png'
        elif data.startswith(b'RIFF') and b'WAVE' in data[:20]:
            return 'wav'
        elif data.startswith((b'\x00\x00\x00\x14ftypmp4', b'\x00\x00\x00\x18ftypmp4', b'\x00\x00\x00\x1Cftypmp4')):
            return 'mp4'
        elif data.startswith(b'ID3') or data.startswith(b'\xFF\xFB'):
            return 'mp3'
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åˆ¤å®šã®æ”¹è‰¯
            try:
                text_data = data.decode('utf-8', errors='ignore')
                if len(text_data.strip()) > 0 and text_data.isprintable():
                    return 'text'
            except:
                pass
            return 'binary'
    
    def analyze_text_patterns(self, data):
        """ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ - æ—¢å­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ”¹è‰¯"""
        try:
            text = data.decode('utf-8', errors='ignore')
            
            # æ”¹è‰¯ã•ã‚ŒãŸè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
            lines = text.split('\n')
            line_patterns = {}
            repetitive_lines = 0
            
            for line in lines:
                stripped_line = line.strip()
                if stripped_line:
                    if stripped_line in line_patterns:
                        line_patterns[stripped_line] += 1
                        repetitive_lines += 1
                    else:
                        line_patterns[stripped_line] = 1
            
            # æ–‡å­—é »åº¦åˆ†æ
            char_freq = {}
            for char in text:
                char_freq[char] = char_freq.get(char, 0) + 1
            
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
            import math
            entropy = 0
            for freq in char_freq.values():
                p = freq / len(text)
                if p > 0:
                    entropy -= p * math.log2(p)
            
            return {
                'repetitive_ratio': repetitive_lines / len(lines) if lines else 0,
                'unique_lines': len(line_patterns),
                'entropy': entropy,
                'avg_line_length': sum(len(line) for line in lines) / len(lines) if lines else 0,
                'char_diversity': len(char_freq) / 256  # ASCIIç¯„å›²ã§ã®æ–‡å­—å¤šæ§˜æ€§
            }
            
        except Exception:
            return {'entropy': 8.0, 'repetitive_ratio': 0, 'unique_lines': 0}
    
    def adaptive_compress(self, data, file_type):
        """é©å¿œçš„åœ§ç¸® - æ—¢å­˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‹ã‚‰æ”¹è‰¯"""
        best_compressed = data
        best_method = "none"
        
        if file_type == 'text':
            # ãƒ†ã‚­ã‚¹ãƒˆç‰¹åŒ–æ”¹è‰¯
            patterns = self.analyze_text_patterns(data)
            
            # è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®çµ„ã¿åˆã‚ã›ãƒ†ã‚¹ãƒˆ
            methods = [
                ('lzma_extreme', lambda d: lzma.compress(d, format=lzma.FORMAT_XZ, preset=9)),
                ('bz2_high', lambda d: bz2.compress(d, compresslevel=9)),
                ('zlib_max', lambda d: zlib.compress(d, level=9)),
            ]
            
            # é«˜ç¹°ã‚Šè¿”ã—ç‡ãƒ†ã‚­ã‚¹ãƒˆã®ç‰¹åˆ¥å‡¦ç†
            if patterns['repetitive_ratio'] > 0.3:
                methods.insert(0, ('lzma_ultra', lambda d: lzma.compress(d, format=lzma.FORMAT_ALONE, preset=9)))
            
        elif file_type == 'wav':
            # WAVéŸ³å£°ç‰¹åŒ–æ”¹è‰¯
            methods = [
                ('lzma_audio', lambda d: lzma.compress(d, format=lzma.FORMAT_XZ, preset=9)),
                ('custom_rle_lzma', lambda d: self._rle_lzma_compress(d)),
                ('zlib_audio', lambda d: zlib.compress(d, level=9)),
            ]
            
        elif file_type == 'mp4':
            # MP4å‹•ç”»ç‰¹åŒ–æ”¹è‰¯ - æ—¢å­˜ã‚’æ”¹è‰¯
            methods = [
                ('lzma_video', lambda d: lzma.compress(d, format=lzma.FORMAT_XZ, preset=6)),
                ('bz2_video', lambda d: bz2.compress(d, compresslevel=6)),
                ('multi_stage', lambda d: self._multi_stage_compress(d)),
            ]
            
        elif file_type == 'mp3':
            # MP3éŸ³å£°ç‰¹åŒ–æ”¹è‰¯
            methods = [
                ('bz2_audio', lambda d: bz2.compress(d, compresslevel=9)),
                ('lzma_audio', lambda d: lzma.compress(d, format=lzma.FORMAT_XZ, preset=8)),
            ]
            
        else:
            # ãã®ä»–ãƒ•ã‚¡ã‚¤ãƒ«
            methods = [
                ('lzma_general', lambda d: lzma.compress(d, format=lzma.FORMAT_XZ, preset=6)),
                ('zlib_general', lambda d: zlib.compress(d, level=6)),
            ]
        
        # æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        for method_name, compress_func in methods:
            try:
                compressed = compress_func(data)
                if len(compressed) < len(best_compressed):
                    best_compressed = compressed
                    best_method = method_name
            except Exception:
                continue
        
        return best_compressed, best_method
    
    def _rle_lzma_compress(self, data):
        """RLE+LZMAæ”¹è‰¯åœ§ç¸®"""
        # å˜ç´”RLEå‰å‡¦ç†
        rle_data = bytearray()
        i = 0
        while i < len(data):
            current_byte = data[i]
            count = 1
            while i + count < len(data) and data[i + count] == current_byte and count < 255:
                count += 1
            
            if count >= 4:  # 4å›ä»¥ä¸Šã®ç¹°ã‚Šè¿”ã—ã§RLEé©ç”¨
                rle_data.extend([0xFF, current_byte, count])
                i += count
            else:
                rle_data.append(current_byte)
                i += 1
        
        # LZMAåœ§ç¸®
        return lzma.compress(bytes(rle_data), format=lzma.FORMAT_XZ, preset=9)
    
    def _multi_stage_compress(self, data):
        """å¤šæ®µéšåœ§ç¸® - æ—¢å­˜ã‹ã‚‰æ”¹è‰¯"""
        # æ®µéš1: è»½ã„å‰å‡¦ç†
        stage1 = zlib.compress(data, level=3)
        
        # æ®µéš2: é«˜åœ§ç¸®
        if len(stage1) < len(data) * 0.8:
            stage2 = lzma.compress(stage1, format=lzma.FORMAT_XZ, preset=6)
            return stage2 if len(stage2) < len(stage1) else stage1
        else:
            return lzma.compress(data, format=lzma.FORMAT_XZ, preset=6)

class ImprovedWorkflowTester:
    """æ”¹è‰¯ç‰ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ã‚¿ãƒ¼"""
    
    def __init__(self):
        self.test_results = []
        self.temp_dir = None
        self.engine = ImprovedNXZipEngine()
        
    def setup(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.temp_dir = tempfile.mkdtemp(prefix="nxzip_improved_")
        print(f"ğŸ”§ æ”¹è‰¯ç‰ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆç’°å¢ƒ: {self.temp_dir}")
    
    def calculate_hash(self, filepath):
        """SHA256ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        sha256_hash = hashlib.sha256()
        with open(filepath, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)
        return sha256_hash.hexdigest()
    
    def spe_encrypt(self, input_file, output_file, password="NXZip2025"):
        """SPEæš—å·åŒ– - æ”¹è‰¯ç‰ˆ"""
        with open(input_file, 'rb') as f:
            data = f.read()
        
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã‚­ãƒ¼ç”Ÿæˆ
        key = hashlib.sha256(password.encode()).digest()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        file_ext = Path(input_file).suffix.encode()
        file_size = len(data).to_bytes(8, 'little')
        
        # æ”¹è‰¯ã•ã‚ŒãŸæ§‹é€ ä¿æŒåœ§ç¸®
        file_type = self.engine.detect_file_type(data)
        compressed_data, method = self.engine.adaptive_compress(data, file_type)
        
        # SPEãƒ˜ãƒƒãƒ€ãƒ¼ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ + æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿
        spe_header = b"SPE2.1\x00\x00"  # æ”¹è‰¯ç‰ˆãƒãƒ¼ã‚¸ãƒ§ãƒ³
        method_bytes = method.encode()[:16].ljust(16, b'\x00')
        metadata = file_size + len(file_ext).to_bytes(2, 'little') + file_ext + method_bytes
        
        # XORæš—å·åŒ–
        encrypted_data = bytes(a ^ key[i % len(key)] for i, a in enumerate(compressed_data))
        
        with open(output_file, 'wb') as f:
            f.write(spe_header + metadata + encrypted_data)
        
        return len(compressed_data), method
    
    def spe_decrypt(self, input_file, output_file, password="NXZip2025"):
        """SPEå¾©å·åŒ– - æ”¹è‰¯ç‰ˆ"""
        with open(input_file, 'rb') as f:
            data = f.read()
        
        if not data.startswith(b"SPE2.1\x00\x00"):
            raise ValueError("ç„¡åŠ¹ãªSPEæ”¹è‰¯ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«")
        
        pos = 8
        file_size = int.from_bytes(data[pos:pos+8], 'little')
        pos += 8
        ext_len = int.from_bytes(data[pos:pos+2], 'little')
        pos += 2
        file_ext = data[pos:pos+ext_len]
        pos += ext_len
        method = data[pos:pos+16].rstrip(b'\x00').decode()
        pos += 16
        encrypted_data = data[pos:]
        
        key = hashlib.sha256(password.encode()).digest()
        compressed_data = bytes(a ^ key[i % len(key)] for i, a in enumerate(encrypted_data))
        
        # æ”¹è‰¯ç‰ˆå¾©å·åŒ–
        decrypted_data = self._decompress_by_method(compressed_data, method)
        
        if len(decrypted_data) != file_size:
            raise ValueError(f"ã‚µã‚¤ã‚ºä¸ä¸€è‡´: {file_size} vs {len(decrypted_data)}")
        
        with open(output_file, 'wb') as f:
            f.write(decrypted_data)
    
    def _decompress_by_method(self, compressed_data, method):
        """æ–¹å¼åˆ¥å¾©å·åŒ–"""
        try:
            if 'lzma' in method:
                if 'ultra' in method:
                    return lzma.decompress(compressed_data, format=lzma.FORMAT_ALONE)
                else:
                    return lzma.decompress(compressed_data, format=lzma.FORMAT_XZ)
            elif 'bz2' in method:
                return bz2.decompress(compressed_data)
            elif 'zlib' in method:
                return zlib.decompress(compressed_data)
            elif 'rle_lzma' in method:
                return self._rle_lzma_decompress(compressed_data)
            elif 'multi_stage' in method:
                return self._multi_stage_decompress(compressed_data)
            else:
                return lzma.decompress(compressed_data, format=lzma.FORMAT_XZ)
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            for decomp_func in [
                lambda d: lzma.decompress(d, format=lzma.FORMAT_XZ),
                lambda d: bz2.decompress(d),
                lambda d: zlib.decompress(d)
            ]:
                try:
                    return decomp_func(compressed_data)
                except:
                    continue
            raise e
    
    def _rle_lzma_decompress(self, compressed_data):
        """RLE+LZMAå¾©å·åŒ–"""
        lzma_data = lzma.decompress(compressed_data, format=lzma.FORMAT_XZ)
        
        # RLEå¾©å·åŒ–
        result = bytearray()
        i = 0
        while i < len(lzma_data):
            if i + 2 < len(lzma_data) and lzma_data[i] == 0xFF:
                byte_val = lzma_data[i + 1]
                count = lzma_data[i + 2]
                result.extend([byte_val] * count)
                i += 3
            else:
                result.append(lzma_data[i])
                i += 1
        
        return bytes(result)
    
    def _multi_stage_decompress(self, compressed_data):
        """å¤šæ®µéšå¾©å·åŒ–"""
        try:
            # LZMAå¾©å·åŒ–è©¦è¡Œ
            stage1 = lzma.decompress(compressed_data, format=lzma.FORMAT_XZ)
            # zlibå¾©å·åŒ–è©¦è¡Œ
            return zlib.decompress(stage1)
        except:
            # ç›´æ¥LZMAå¾©å·åŒ–
            return lzma.decompress(compressed_data, format=lzma.FORMAT_XZ)
    
    def compress_to_nxz(self, input_file, output_file):
        """NXZåœ§ç¸® - æ”¹è‰¯ç‰ˆ"""
        with open(input_file, 'rb') as f:
            data = f.read()
        
        # æ”¹è‰¯ç‰ˆNXZãƒ˜ãƒƒãƒ€ãƒ¼ + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ + LZMAåœ§ç¸®
        nxz_header = self.engine.magic_header
        original_size = len(data).to_bytes(8, 'little')
        timestamp = int(time.time()).to_bytes(8, 'little')
        checksum = hashlib.sha256(data).digest()[:16]
        
        # æ”¹è‰¯ã•ã‚ŒãŸåœ§ç¸®
        file_type = self.engine.detect_file_type(data)
        compressed_data, method = self.engine.adaptive_compress(data, file_type)
        method_bytes = method.encode()[:16].ljust(16, b'\x00')
        
        with open(output_file, 'wb') as f:
            f.write(nxz_header + original_size + timestamp + checksum + method_bytes + compressed_data)
    
    def extract_from_nxz(self, input_file, output_file):
        """NXZå±•é–‹ - æ”¹è‰¯ç‰ˆ"""
        with open(input_file, 'rb') as f:
            data = f.read()
        
        if not data.startswith(self.engine.magic_header):
            raise ValueError("ç„¡åŠ¹ãªNXZæ”¹è‰¯ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«")
        
        pos = 8
        original_size = int.from_bytes(data[pos:pos+8], 'little')
        pos += 8
        timestamp = int.from_bytes(data[pos:pos+8], 'little')
        pos += 8
        expected_checksum = data[pos:pos+16]
        pos += 16
        method = data[pos:pos+16].rstrip(b'\x00').decode()
        pos += 16
        compressed_data = data[pos:]
        
        decompressed_data = self._decompress_by_method(compressed_data, method)
        
        if len(decompressed_data) != original_size:
            raise ValueError(f"ã‚µã‚¤ã‚ºä¸ä¸€è‡´: {original_size} vs {len(decompressed_data)}")
        
        actual_checksum = hashlib.sha256(decompressed_data).digest()[:16]
        if actual_checksum != expected_checksum:
            raise ValueError("ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä¸ä¸€è‡´")
        
        with open(output_file, 'wb') as f:
            f.write(decompressed_data)
    
    def test_workflow(self, test_file):
        """æ”¹è‰¯ç‰ˆå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        print(f"\n{'='*70}")
        print(f"ğŸš€ æ”¹è‰¯ç‰ˆå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ: {os.path.basename(test_file)}")
        print(f"{'='*70}")
        
        original_size = os.path.getsize(test_file)
        original_hash = self.calculate_hash(test_file)
        
        with open(test_file, 'rb') as f:
            data = f.read()
        file_type = self.engine.detect_file_type(data)
        
        print(f"ğŸ“ å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {original_size:,} bytes")
        print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥: {file_type}")
        print(f"ğŸ” å…ƒHash: {original_hash[:32]}...")
        
        try:
            base_name = os.path.basename(test_file)
            
            # Phase 1: æ”¹è‰¯ç‰ˆSPEæš—å·åŒ–
            print(f"\nğŸ” Phase 1: æ”¹è‰¯ç‰ˆSPEæš—å·åŒ–")
            encrypted_file = os.path.join(self.temp_dir, f"{base_name}.spe")
            start_time = time.time()
            spe_compressed_size, spe_method = self.spe_encrypt(test_file, encrypted_file)
            spe_time = time.time() - start_time
            spe_size = os.path.getsize(encrypted_file)
            spe_ratio = ((original_size - spe_compressed_size) / original_size) * 100
            print(f"   âœ… æš—å·åŒ–å®Œäº†: {spe_size:,} bytes, å†…éƒ¨åœ§ç¸®ç‡: {spe_ratio:.1f}% ({spe_method}) ({spe_time:.2f}ç§’)")
            
            # Phase 2: æ”¹è‰¯ç‰ˆNXZåœ§ç¸®
            print(f"\nğŸ“¦ Phase 2: æ”¹è‰¯ç‰ˆNXZåœ§ç¸®")
            nxz_file = os.path.join(self.temp_dir, f"{base_name}.nxz")
            start_time = time.time()
            self.compress_to_nxz(encrypted_file, nxz_file)
            compress_time = time.time() - start_time
            nxz_size = os.path.getsize(nxz_file)
            compression_ratio = ((original_size - nxz_size) / original_size) * 100
            print(f"   âœ… åœ§ç¸®å®Œäº†: {nxz_size:,} bytes, ç·åˆåœ§ç¸®ç‡: {compression_ratio:.1f}% ({compress_time:.2f}ç§’)")
            
            # Phase 3: æ”¹è‰¯ç‰ˆNXZå±•é–‹
            print(f"\nğŸ“‚ Phase 3: æ”¹è‰¯ç‰ˆNXZå±•é–‹")
            extracted_spe = os.path.join(self.temp_dir, f"{base_name}_extracted.spe")
            start_time = time.time()
            self.extract_from_nxz(nxz_file, extracted_spe)
            extract_time = time.time() - start_time
            print(f"   âœ… å±•é–‹å®Œäº†: ({extract_time:.2f}ç§’)")
            
            # Phase 4: æ”¹è‰¯ç‰ˆSPEå¾©å·åŒ–
            print(f"\nğŸ”“ Phase 4: æ”¹è‰¯ç‰ˆSPEå¾©å·åŒ–")
            restored_file = os.path.join(self.temp_dir, f"{base_name}_restored")
            start_time = time.time()
            self.spe_decrypt(extracted_spe, restored_file)
            decrypt_time = time.time() - start_time
            print(f"   âœ… å¾©å·åŒ–å®Œäº†: ({decrypt_time:.2f}ç§’)")
            
            # Phase 5: å®Œå…¨æ€§æ¤œè¨¼
            print(f"\nâœ… Phase 5: å®Œå…¨æ€§æ¤œè¨¼")
            restored_hash = self.calculate_hash(restored_file)
            restored_size = os.path.getsize(restored_file)
            
            size_match = (original_size == restored_size)
            hash_match = (original_hash == restored_hash)
            is_reversible = size_match and hash_match
            
            print(f"   ã‚µã‚¤ã‚ºä¸€è‡´: {'âœ…' if size_match else 'âŒ'} ({original_size:,} vs {restored_size:,})")
            print(f"   Hashä¸€è‡´: {'âœ…' if hash_match else 'âŒ'}")
            print(f"   å¾©å…ƒHash: {restored_hash[:32]}...")
            
            total_time = spe_time + compress_time + extract_time + decrypt_time
            
            result = {
                "file": os.path.basename(test_file),
                "file_type": file_type,
                "original_size": original_size,
                "nxz_size": nxz_size,
                "compression_ratio": compression_ratio,
                "spe_method": spe_method,
                "total_time": total_time,
                "reversible": is_reversible,
                "size_match": size_match,
                "hash_match": hash_match,
                "status": "âœ…" if is_reversible else "âŒ"
            }
            
            if is_reversible:
                print(f"\nğŸ‰ çµæœ: å®Œå…¨å¯é€†æ€§ç¢ºèªï¼(åœ§ç¸®ç‡: {compression_ratio:.1f}%)")
                if compression_ratio > 80:
                    print(f"ğŸ”¥ å„ªç§€ãªåœ§ç¸®ç‡é”æˆï¼")
                elif compression_ratio > 50:
                    print(f"âœ¨ è‰¯å¥½ãªåœ§ç¸®ç‡é”æˆï¼")
            else:
                print(f"\nâŒ çµæœ: å¯é€†æ€§å•é¡Œç™ºç”Ÿ")
            
            return result
            
        except Exception as e:
            print(f"\nâŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "file": os.path.basename(test_file),
                "status": "âŒ",
                "error": str(e),
                "reversible": False
            }
    
    def run_tests(self):
        """æ”¹è‰¯ç‰ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒ†ã‚¹ãƒˆ"""
        print("ğŸš€ NXZipæ”¹è‰¯ç‰ˆå®Ÿç”¨åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("æ—¢å­˜ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®æ”¹è‰¯ç‰ˆ - ç†è«–å€¤ã¸ã®æ¥è¿‘ã‚’ç›®æŒ‡ã™")
        print("SPEæ”¹è‰¯ç‰ˆæš—å·åŒ– â†’ NXZæ”¹è‰¯ç‰ˆåœ§ç¸® â†’ NXZå±•é–‹ â†’ SPEå¾©å·åŒ–")
        print("=" * 80)
        
        # ã‚ˆã‚Šå¤šæ§˜ãªãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« - å‹•ç”»ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’é‡è¦–
        test_files = [
            # å¤šæ§˜ãªãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\test-data\sample_text.txt",
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\test-data\large_test.txt", 
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\test-data\repetitive_test.txt",
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",
            
            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ« (æ˜ç¢ºã«ãƒ†ã‚¹ãƒˆå¯¾è±¡)
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4",
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\é™°è¬€è«–.mp3",
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\generated-music-1752042054079.wav",
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\COT-001.jpg",
            r"c:\Users\241822\Desktop\æ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€ãƒ¼ (2)\NXZip\NXZip-Python\sample\COT-012.png"
        ]
        
        existing_files = [f for f in test_files if os.path.exists(f)]
        print(f"ğŸ“ ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(existing_files)}")
        
        for test_file in existing_files:
            result = self.test_workflow(test_file)
            self.test_results.append(result)
        
        self.print_summary()
    
    def print_summary(self):
        """æ”¹è‰¯ç‰ˆçµæœã‚µãƒãƒªãƒ¼"""
        print("\n" + "=" * 80)
        print("ğŸ† NXZipæ”¹è‰¯ç‰ˆå®Ÿç”¨åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 80)
        
        successful = sum(1 for r in self.test_results if r.get('reversible', False))
        total = len(self.test_results)
        success_rate = (successful / total * 100) if total > 0 else 0
        
        print(f"ğŸ¯ å®Œå…¨å¯é€†æ€§æˆåŠŸç‡: {successful}/{total} ({success_rate:.1f}%)")
        print()
        
        print("ğŸ“‹ SPEæ”¹è‰¯ç‰ˆ+NXZæ”¹è‰¯ç‰ˆå®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœ:")
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ ãƒ•ã‚¡ã‚¤ãƒ«            â”‚ å…ƒã‚µã‚¤ã‚º â”‚ NXZã‚µã‚¤ã‚ºâ”‚åœ§ç¸®ç‡â”‚å‡¦ç†æ™‚é–“â”‚ åœ§ç¸®æ‰‹æ³• â”‚å¯é€†æ€§â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤")
        
        for result in self.test_results:
            if 'error' in result:
                name = result['file'][:19]
                print(f"â”‚ {name:<19} â”‚   ERROR  â”‚   ERROR  â”‚ ERR  â”‚  ERR   â”‚   ERROR  â”‚  âŒ  â”‚")
            else:
                name = result['file'][:19]
                orig = f"{result['original_size']:,}"[:8]
                nxz = f"{result['nxz_size']:,}"[:8]
                ratio = f"{result['compression_ratio']:.1f}%"[:5]
                time_s = f"{result['total_time']:.1f}s"[:6]
                method = result.get('spe_method', 'unknown')[:8]
                status = result['status']
                
                print(f"â”‚ {name:<19} â”‚{orig:>8} â”‚{nxz:>8} â”‚{ratio:>5} â”‚{time_s:>6} â”‚{method:>8} â”‚  {status}  â”‚")
        
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜")
        
        if self.test_results:
            valid_results = [r for r in self.test_results if 'error' not in r]
            if valid_results:
                avg_compression = sum(r['compression_ratio'] for r in valid_results) / len(valid_results)
                avg_time = sum(r['total_time'] for r in valid_results) / len(valid_results)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¥çµ±è¨ˆ
                type_stats = {}
                for result in valid_results:
                    file_type = result.get('file_type', 'unknown')
                    if file_type not in type_stats:
                        type_stats[file_type] = []
                    type_stats[file_type].append(result['compression_ratio'])
                
                print(f"\nğŸ“Š æ”¹è‰¯ç‰ˆçµ±è¨ˆæƒ…å ±:")
                print(f"   å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1f}%")
                print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.1f}ç§’")
                
                print(f"\nğŸ“ˆ ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ¥åœ§ç¸®ç‡:")
                for file_type, ratios in type_stats.items():
                    avg_ratio = sum(ratios) / len(ratios)
                    max_ratio = max(ratios)
                    print(f"   {file_type:>8}: å¹³å‡ {avg_ratio:.1f}%, æœ€å¤§ {max_ratio:.1f}%")
        
        # ç†è«–å€¤ã¨ã®æ¯”è¼ƒ
        print(f"\nğŸ¯ ç†è«–å€¤æ¯”è¼ƒ:")
        theoretical_targets = {
            'text': 95.0,
            'mp3': 85.0,
            'mp4': 75.0,
            'wav': 90.0,
            'jpeg': 85.0,
            'png': 80.0
        }
        
        for result in self.test_results:
            if 'error' not in result:
                file_type = result.get('file_type', 'unknown')
                achieved = result['compression_ratio']
                target = theoretical_targets.get(file_type, 50.0)
                progress = (achieved / target) * 100 if target > 0 else 0
                status_icon = "âœ…" if progress >= 80 else "âš ï¸" if progress >= 50 else "âŒ"
                print(f"   {result['file'][:20]:>20}: {achieved:>5.1f}% / {target:>5.1f}% ({progress:>5.1f}%) {status_icon}")
        
        failed_files = [r for r in self.test_results if not r.get('reversible', False)]
        if failed_files:
            print(f"\nâš ï¸ å¯é€†æ€§ã«å•é¡ŒãŒã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:")
            for result in failed_files:
                if 'error' in result:
                    print(f"   âŒ {result['file']}: {result['error']}")
                else:
                    issues = []
                    if not result.get('size_match', True):
                        issues.append("ã‚µã‚¤ã‚ºä¸ä¸€è‡´")
                    if not result.get('hash_match', True):
                        issues.append("Hashä¸ä¸€è‡´")
                    print(f"   âŒ {result['file']}: {', '.join(issues)}")
        
        print()
        print("ğŸ¯ æ”¹è‰¯ç‰ˆå®Ÿç”¨åŒ–è©•ä¾¡:")
        if success_rate >= 95:
            print("âœ… å•†ç”¨ãƒ¬ãƒ™ãƒ«: æ”¹è‰¯ã«ã‚ˆã‚Šå®Ÿç”¨åŒ–é”æˆ")
        elif success_rate >= 80:
            print("âš ï¸ æº–å®Ÿç”¨ãƒ¬ãƒ™ãƒ«: æ”¹è‰¯ã«ã‚ˆã‚Šå¤§å¹…å‘ä¸Šã€å¾®èª¿æ•´ã§å®Œæˆ")
        else:
            print("âŒ æ”¹è‰¯ç¶™ç¶š: æ›´ãªã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ”¹è‰¯ãŒå¿…è¦")
        
        # æ”¹è‰¯åŠ¹æœã¾ã¨ã‚
        if valid_results:
            high_compression = [r for r in valid_results if r['compression_ratio'] > 70]
            if high_compression:
                print(f"\nğŸ”¥ æ”¹è‰¯ã«ã‚ˆã‚‹é«˜åœ§ç¸®ç‡é”æˆ:")
                for result in high_compression:
                    print(f"   ğŸ–ï¸ {result['file']}: {result['compression_ratio']:.1f}% ({result['file_type']})")
    
    def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
            print(f"\nğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {self.temp_dir}")

def main():
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        tester = ImprovedWorkflowTester()
        try:
            tester.setup()
            tester.run_tests()
        finally:
            tester.cleanup()
    else:
        print("ä½¿ç”¨æ–¹æ³•: python workflow_test_improved.py test")
        print("æ”¹è‰¯ç‚¹:")
        print("  1. ã‚ˆã‚Šå¤šæ§˜ãªãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆ")
        print("  2. MP4å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®æ˜ç¢ºãªãƒ†ã‚¹ãƒˆå¯¾è±¡åŒ–")
        print("  3. æ—¢å­˜ã‚¨ãƒ³ã‚¸ãƒ³ãƒ™ãƒ¼ã‚¹ã®é©å¿œçš„åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ”¹è‰¯")
        print("  4. ç†è«–å€¤æ¥è¿‘ã®ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥ç‰¹åŒ–æœ€é©åŒ–")

if __name__ == "__main__":
    main()

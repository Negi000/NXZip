#!/usr/bin/env python3
"""
NEXUS vs 7Z vs Zstandard ç«¶äº‰æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
åœ§ç¸®ç‡ã€åœ§ç¸®é€Ÿåº¦ã€å±•é–‹é€Ÿåº¦ã€å¯é€†æ€§ã®ç·åˆè©•ä¾¡
"""

import os
import sys
import time
import subprocess
import tempfile
import numpy as np
import hashlib
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import json


# TMCã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'nxzip', 'engine'))

try:
    from nexus_tmc_engine import NEXUSTMCEngine
    NEXUS_AVAILABLE = True
except ImportError:
    print("âš ï¸ NEXUS TMCã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    NEXUS_AVAILABLE = False


class CompressionCompetitor:
    """åœ§ç¸®ç«¶åˆè€…ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, name: str, compress_cmd: str, decompress_cmd: str, 
                 file_extension: str, available: bool = True):
        self.name = name
        self.compress_cmd = compress_cmd
        self.decompress_cmd = decompress_cmd
        self.file_extension = file_extension
        self.available = available
        self.temp_dir = tempfile.mkdtemp()
    
    def compress(self, data: bytes, level: int = 6) -> Tuple[bytes, Dict]:
        """ãƒ‡ãƒ¼ã‚¿åœ§ç¸®"""
        if not self.available:
            return data, {'error': 'compressor_not_available'}
        
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            input_file = os.path.join(self.temp_dir, 'input.bin')
            output_file = os.path.join(self.temp_dir, f'output.{self.file_extension}')
            
            # ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
            with open(input_file, 'wb') as f:
                f.write(data)
            
            # åœ§ç¸®å®Ÿè¡Œ
            start_time = time.perf_counter()
            
            if self.name == '7z':
                # 7zipåœ§ç¸®
                cmd = f'7z a -t7z -mx={level} -y "{output_file}" "{input_file}"'
            elif self.name == 'zstd':
                # Zstandardåœ§ç¸®
                cmd = f'zstd -{level} "{input_file}" -o "{output_file}"'
            else:
                return data, {'error': 'unknown_compressor'}
            
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            compress_time = time.perf_counter() - start_time
            
            if result.returncode != 0:
                return data, {'error': 'compression_failed', 'stderr': result.stderr}
            
            # åœ§ç¸®çµæœèª­ã¿è¾¼ã¿
            if os.path.exists(output_file):
                with open(output_file, 'rb') as f:
                    compressed_data = f.read()
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(input_file)
                os.remove(output_file)
                
                compression_ratio = (1 - len(compressed_data) / len(data)) * 100 if len(data) > 0 else 0
                throughput = (len(data) / 1024 / 1024) / compress_time if compress_time > 0 else 0
                
                return compressed_data, {
                    'success': True,
                    'compression_ratio': compression_ratio,
                    'compression_time': compress_time,
                    'throughput_mb_s': throughput,
                    'original_size': len(data),
                    'compressed_size': len(compressed_data),
                    'compressor': self.name,
                    'level': level
                }
            else:
                return data, {'error': 'output_file_not_found'}
                
        except Exception as e:
            return data, {'error': str(e)}
    
    def decompress(self, compressed_data: bytes, original_size: int) -> Tuple[bytes, Dict]:
        """ãƒ‡ãƒ¼ã‚¿å±•é–‹"""
        if not self.available:
            return compressed_data, {'error': 'compressor_not_available'}
        
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            input_file = os.path.join(self.temp_dir, f'compressed.{self.file_extension}')
            output_file = os.path.join(self.temp_dir, 'decompressed.bin')
            
            # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿
            with open(input_file, 'wb') as f:
                f.write(compressed_data)
            
            # å±•é–‹å®Ÿè¡Œ
            start_time = time.perf_counter()
            
            if self.name == '7z':
                # 7zipå±•é–‹
                cmd = f'7z e -y "{input_file}" -o"{self.temp_dir}"'
            elif self.name == 'zstd':
                # Zstandardå±•é–‹
                cmd = f'zstd -d "{input_file}" -o "{output_file}"'
            else:
                return compressed_data, {'error': 'unknown_compressor'}
            
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            decompress_time = time.perf_counter() - start_time
            
            if result.returncode != 0:
                return compressed_data, {'error': 'decompression_failed', 'stderr': result.stderr}
            
            # å±•é–‹çµæœèª­ã¿è¾¼ã¿
            if self.name == '7z':
                # 7zipã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã§å±•é–‹ã•ã‚Œã‚‹
                decompressed_file = os.path.join(self.temp_dir, 'input.bin')
            else:
                decompressed_file = output_file
            
            if os.path.exists(decompressed_file):
                with open(decompressed_file, 'rb') as f:
                    decompressed_data = f.read()
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                os.remove(input_file)
                if os.path.exists(decompressed_file):
                    os.remove(decompressed_file)
                
                throughput = (len(decompressed_data) / 1024 / 1024) / decompress_time if decompress_time > 0 else 0
                
                return decompressed_data, {
                    'success': True,
                    'decompression_time': decompress_time,
                    'throughput_mb_s': throughput,
                    'decompressed_size': len(decompressed_data),
                    'compressor': self.name
                }
            else:
                return compressed_data, {'error': 'decompressed_file_not_found'}
                
        except Exception as e:
            return compressed_data, {'error': str(e)}


class NEXUSCompetitor:
    """NEXUS TMCã‚¨ãƒ³ã‚¸ãƒ³ç«¶åˆè€…"""
    
    def __init__(self):
        self.name = 'NEXUS-TMC'
        self.available = NEXUS_AVAILABLE
        if self.available:
            self.engine = NEXUSTMCEngine(max_workers=4)
    
    def compress(self, data: bytes, level: int = 6) -> Tuple[bytes, Dict]:
        """NEXUSåœ§ç¸®"""
        if not self.available:
            return data, {'error': 'nexus_not_available'}
        
        try:
            start_time = time.perf_counter()
            compressed_data, info = self.engine.compress_tmc(data)
            compress_time = time.perf_counter() - start_time
            
            # çµæœæƒ…å ±ã‚’æ¨™æº–åŒ–
            result_info = {
                'success': True,
                'compression_ratio': info.get('compression_ratio', 0),
                'compression_time': compress_time,
                'throughput_mb_s': (len(data) / 1024 / 1024) / compress_time if compress_time > 0 else 0,
                'original_size': len(data),
                'compressed_size': len(compressed_data),
                'compressor': self.name,
                'level': level,
                'data_type': info.get('data_type', 'unknown'),
                'transform_method': info.get('transform_info', {}).get('transform_method', 'unknown')
            }
            
            return compressed_data, result_info
            
        except Exception as e:
            return data, {'error': str(e)}
    
    def decompress(self, compressed_data: bytes, original_size: int) -> Tuple[bytes, Dict]:
        """NEXUSå±•é–‹ï¼ˆç¾åœ¨ã¯åœ§ç¸®ã®ã¿å®Ÿè£…ã®ãŸã‚ã€ãƒ€ãƒŸãƒ¼å®Ÿè£…ï¼‰"""
        # æ³¨æ„: TMCã‚¨ãƒ³ã‚¸ãƒ³ã¯ã¾ã å±•é–‹æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€
        # ãƒ†ã‚¹ãƒˆç”¨ã«ã‚ªãƒªã‚¸ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        try:
            start_time = time.perf_counter()
            
            # å®Ÿéš›ã®å±•é–‹å‡¦ç†ã‚’ã“ã“ã«å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
            # ç¾åœ¨ã¯ãƒ†ã‚¹ãƒˆç”¨ã«ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            decompressed_data = np.random.randint(0, 256, original_size, dtype=np.uint8).tobytes()
            
            decompress_time = time.perf_counter() - start_time
            
            return decompressed_data, {
                'success': True,
                'decompression_time': decompress_time,
                'throughput_mb_s': (len(decompressed_data) / 1024 / 1024) / decompress_time if decompress_time > 0 else 0,
                'decompressed_size': len(decompressed_data),
                'compressor': self.name,
                'note': 'decompression_not_implemented_yet'
            }
            
        except Exception as e:
            return compressed_data, {'error': str(e)}


def check_compressor_availability() -> Dict[str, bool]:
    """åœ§ç¸®ãƒ„ãƒ¼ãƒ«ã®åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯"""
    availability = {}
    
    # 7zipãƒã‚§ãƒƒã‚¯
    try:
        result = subprocess.run('7z', shell=True, capture_output=True, text=True)
        availability['7z'] = True
    except:
        availability['7z'] = False
    
    # Zstandardãƒã‚§ãƒƒã‚¯
    try:
        result = subprocess.run('zstd --version', shell=True, capture_output=True, text=True)
        availability['zstd'] = True
    except:
        availability['zstd'] = False
    
    availability['nexus'] = NEXUS_AVAILABLE
    
    return availability


def create_benchmark_datasets() -> Dict[str, bytes]:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ"""
    datasets = {}
    
    print("ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...")
    
    # 1. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆé«˜åœ§ç¸®ç‡æœŸå¾…ï¼‰
    print("   ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    text_content = """
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor 
    incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis 
    nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
    
    ã“ã‚Œã¯æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚åœ§ç¸®ç‡ãƒ†ã‚¹ãƒˆã®ãŸã‚ã«ç¹°ã‚Šè¿”ã—æ–‡ç« ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
    ãƒ‡ãƒ¼ã‚¿åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ€§èƒ½æ¯”è¼ƒã‚’è¡Œã†ãŸã‚ã®é‡è¦ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚
    
    NEXUS TMC Engine represents a revolutionary approach to data compression,
    utilizing Transform-Model-Code methodology for superior compression ratios.
    The system intelligently analyzes data structure and applies appropriate
    transformation strategies for optimal compression efficiency.
    """ * 200  # 200å›ç¹°ã‚Šè¿”ã—
    
    datasets['text_data'] = text_content.encode('utf-8')
    
    # 2. æ§‹é€ åŒ–æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼ˆNEXUSæœ‰åˆ©ãƒ‡ãƒ¼ã‚¿ï¼‰
    print("   ğŸ”¢ æ§‹é€ åŒ–æ•°å€¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    structured_data = bytearray()
    for i in range(5000):
        # 4ãƒã‚¤ãƒˆæ•´æ•°ã®æ§‹é€ 
        value = i % 1000
        structured_data.extend(struct.pack('<I', value))
        structured_data.extend(struct.pack('<H', (value * 2) % 65536))
        structured_data.extend(struct.pack('<H', (value * 3) % 65536))
    
    datasets['structured_numeric'] = bytes(structured_data)
    
    # 3. ç”»åƒé¢¨ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸­ç¨‹åº¦åœ§ç¸®æœŸå¾…ï¼‰
    print("   ğŸ–¼ï¸ ç”»åƒé¢¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    image_width, image_height = 256, 256
    image_data = bytearray()
    for y in range(image_height):
        for x in range(image_width):
            # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³
            r = (x * 255) // image_width
            g = (y * 255) // image_height
            b = ((x + y) * 255) // (image_width + image_height)
            
            # ãƒã‚¤ã‚ºè¿½åŠ 
            r = max(0, min(255, r + np.random.randint(-20, 20)))
            g = max(0, min(255, g + np.random.randint(-20, 20)))
            b = max(0, min(255, b + np.random.randint(-20, 20)))
            
            image_data.extend([r, g, b])
    
    datasets['image_data'] = bytes(image_data)
    
    # 4. ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆä½åœ§ç¸®ç‡æœŸå¾…ï¼‰
    print("   ğŸ² ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    random_data = np.random.randint(0, 256, 50000, dtype=np.uint8)
    datasets['random_data'] = random_data.tobytes()
    
    # 5. æ··åˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿç”¨çš„ãƒ†ã‚¹ãƒˆï¼‰
    print("   ğŸ“¦ æ··åˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ...")
    mixed_data = bytearray()
    # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
    header = "FILE_HEADER_MIXED_DATA_BENCHMARK_TEST\n" * 50
    mixed_data.extend(header.encode('utf-8'))
    
    # æ•°å€¤éƒ¨åˆ†
    for i in range(1000):
        mixed_data.extend(struct.pack('<f', i * 3.14159))
        mixed_data.extend(struct.pack('<I', i * i))
    
    # ãƒ©ãƒ³ãƒ€ãƒ éƒ¨åˆ†
    random_part = np.random.randint(0, 256, 10000, dtype=np.uint8)
    mixed_data.extend(random_part.tobytes())
    
    datasets['mixed_data'] = bytes(mixed_data)
    
    return datasets


def run_comprehensive_benchmark(datasets: Dict[str, bytes]) -> Dict[str, Dict]:
    """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("\nğŸš€ NEXUS vs 7Z vs Zstandard ç«¶äº‰æ¯”è¼ƒãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 80)
    
    # åœ§ç¸®ãƒ„ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
    availability = check_compressor_availability()
    print(f"\nğŸ”§ åœ§ç¸®ãƒ„ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½æ€§:")
    for tool, available in availability.items():
        status = "âœ… åˆ©ç”¨å¯èƒ½" if available else "âŒ åˆ©ç”¨ä¸å¯"
        print(f"   {tool}: {status}")
    
    # ç«¶åˆè€…åˆæœŸåŒ–
    competitors = {}
    
    if availability['7z']:
        competitors['7z'] = CompressionCompetitor(
            '7z', '7z a', '7z e', '7z', True
        )
    
    if availability['zstd']:
        competitors['zstd'] = CompressionCompetitor(
            'zstd', 'zstd', 'zstd -d', 'zst', True
        )
    
    if availability['nexus']:
        competitors['nexus'] = NEXUSCompetitor()
    
    if not competitors:
        print("âŒ åˆ©ç”¨å¯èƒ½ãªåœ§ç¸®ãƒ„ãƒ¼ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        return {}
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜ç”¨
    results = {}
    
    # åœ§ç¸®ãƒ¬ãƒ™ãƒ«è¨­å®š
    compression_levels = {
        '7z': [1, 5, 9],      # é«˜é€Ÿã€æ¨™æº–ã€æœ€é«˜
        'zstd': [1, 6, 19],   # é«˜é€Ÿã€æ¨™æº–ã€æœ€é«˜
        'nexus': [6]          # NEXUSæ¨™æº–ãƒ¬ãƒ™ãƒ«
    }
    
    for dataset_name, data in datasets.items():
        print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_name}")
        print(f"   ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(data):,} bytes ({len(data)/1024:.1f} KB)")
        
        dataset_results = {}
        
        for comp_name, competitor in competitors.items():
            print(f"\n   ğŸ”„ {competitor.name} ãƒ†ã‚¹ãƒˆä¸­...")
            
            comp_results = {}
            
            levels = compression_levels.get(comp_name, [6])
            
            for level in levels:
                print(f"      ãƒ¬ãƒ™ãƒ« {level}:", end=" ")
                
                # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
                compressed_data, compress_info = competitor.compress(data, level)
                
                if compress_info.get('success', False):
                    compression_ratio = compress_info['compression_ratio']
                    compress_time = compress_info['compression_time']
                    compress_throughput = compress_info['throughput_mb_s']
                    
                    print(f"åœ§ç¸®ç‡{compression_ratio:.1f}% ", end="")
                    print(f"({compress_throughput:.1f}MB/s) ", end="")
                    
                    # å±•é–‹ãƒ†ã‚¹ãƒˆ
                    if comp_name != 'nexus':  # NEXUSã¯å±•é–‹æœªå®Ÿè£…
                        decompressed_data, decompress_info = competitor.decompress(
                            compressed_data, len(data)
                        )
                        
                        if decompress_info.get('success', False):
                            decompress_time = decompress_info['decompression_time']
                            decompress_throughput = decompress_info['throughput_mb_s']
                            
                            # å¯é€†æ€§ãƒã‚§ãƒƒã‚¯
                            original_hash = hashlib.sha256(data).hexdigest()
                            decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
                            is_reversible = (original_hash == decompressed_hash)
                            
                            print(f"å±•é–‹({decompress_throughput:.1f}MB/s) ", end="")
                            print(f"å¯é€†æ€§{'âœ…' if is_reversible else 'âŒ'}")
                            
                            comp_results[f'level_{level}'] = {
                                'compression_ratio': compression_ratio,
                                'compression_time': compress_time,
                                'compression_throughput': compress_throughput,
                                'decompression_time': decompress_time,
                                'decompression_throughput': decompress_throughput,
                                'compressed_size': len(compressed_data),
                                'is_reversible': is_reversible,
                                'level': level
                            }
                        else:
                            print(f"å±•é–‹å¤±æ•—: {decompress_info.get('error', 'unknown')}")
                            comp_results[f'level_{level}'] = {
                                'compression_ratio': compression_ratio,
                                'compression_time': compress_time,
                                'compression_throughput': compress_throughput,
                                'error': 'decompression_failed'
                            }
                    else:
                        # NEXUSã®å ´åˆã¯åœ§ç¸®ã®ã¿
                        print("(å±•é–‹æ©Ÿèƒ½é–‹ç™ºä¸­)")
                        comp_results[f'level_{level}'] = {
                            'compression_ratio': compression_ratio,
                            'compression_time': compress_time,
                            'compression_throughput': compress_throughput,
                            'compressed_size': len(compressed_data),
                            'note': 'decompression_not_implemented',
                            'level': level,
                            'data_type': compress_info.get('data_type', 'unknown'),
                            'transform_method': compress_info.get('transform_method', 'unknown')
                        }
                else:
                    print(f"åœ§ç¸®å¤±æ•—: {compress_info.get('error', 'unknown')}")
                    comp_results[f'level_{level}'] = {
                        'error': compress_info.get('error', 'compression_failed')
                    }
            
            dataset_results[comp_name] = comp_results
        
        results[dataset_name] = dataset_results
    
    return results


def analyze_benchmark_results(results: Dict[str, Dict]) -> None:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœåˆ†æ"""
    print("\n" + "=" * 80)
    print("ğŸ“Š ç«¶äº‰æ¯”è¼ƒåˆ†æçµæœ")
    print("=" * 80)
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåˆ¥åˆ†æ
    for dataset_name, dataset_results in results.items():
        print(f"\nğŸ“‹ {dataset_name} åˆ†æ:")
        print("-" * 50)
        
        # æœ€é«˜åœ§ç¸®ç‡ã€æœ€é«˜é€Ÿåº¦ã®è¨˜éŒ²
        best_compression = {'ratio': 0, 'compressor': None, 'level': None}
        best_compress_speed = {'speed': 0, 'compressor': None, 'level': None}
        best_decompress_speed = {'speed': 0, 'compressor': None, 'level': None}
        
        for comp_name, comp_results in dataset_results.items():
            for level_key, level_result in comp_results.items():
                if 'error' not in level_result:
                    ratio = level_result.get('compression_ratio', 0)
                    comp_speed = level_result.get('compression_throughput', 0)
                    decomp_speed = level_result.get('decompression_throughput', 0)
                    level = level_result.get('level', 'unknown')
                    
                    # æœ€é«˜åœ§ç¸®ç‡æ›´æ–°
                    if ratio > best_compression['ratio']:
                        best_compression.update({
                            'ratio': ratio,
                            'compressor': comp_name,
                            'level': level
                        })
                    
                    # æœ€é«˜åœ§ç¸®é€Ÿåº¦æ›´æ–°
                    if comp_speed > best_compress_speed['speed']:
                        best_compress_speed.update({
                            'speed': comp_speed,
                            'compressor': comp_name,
                            'level': level
                        })
                    
                    # æœ€é«˜å±•é–‹é€Ÿåº¦æ›´æ–°
                    if decomp_speed > best_decompress_speed['speed']:
                        best_decompress_speed.update({
                            'speed': decomp_speed,
                            'compressor': comp_name,
                            'level': level
                        })
        
        # çµæœè¡¨ç¤º
        print(f"   ğŸ† æœ€é«˜åœ§ç¸®ç‡: {best_compression['compressor']} (ãƒ¬ãƒ™ãƒ«{best_compression['level']}) - {best_compression['ratio']:.2f}%")
        print(f"   âš¡ æœ€é«˜åœ§ç¸®é€Ÿåº¦: {best_compress_speed['compressor']} (ãƒ¬ãƒ™ãƒ«{best_compress_speed['level']}) - {best_compress_speed['speed']:.2f}MB/s")
        if best_decompress_speed['speed'] > 0:
            print(f"   ğŸš€ æœ€é«˜å±•é–‹é€Ÿåº¦: {best_decompress_speed['compressor']} (ãƒ¬ãƒ™ãƒ«{best_decompress_speed['level']}) - {best_decompress_speed['speed']:.2f}MB/s")
    
    # ç·åˆåˆ†æ
    print(f"\nğŸ¯ ç·åˆç«¶äº‰åŠ›åˆ†æ:")
    print("-" * 50)
    
    compressor_scores = {'7z': 0, 'zstd': 0, 'nexus': 0}
    
    for dataset_name, dataset_results in results.items():
        dataset_winners = {'compression': None, 'speed': None}
        
        best_ratio = 0
        best_speed = 0
        
        for comp_name, comp_results in dataset_results.items():
            for level_key, level_result in comp_results.items():
                if 'error' not in level_result:
                    ratio = level_result.get('compression_ratio', 0)
                    speed = level_result.get('compression_throughput', 0)
                    
                    if ratio > best_ratio:
                        best_ratio = ratio
                        dataset_winners['compression'] = comp_name
                    
                    if speed > best_speed:
                        best_speed = speed
                        dataset_winners['speed'] = comp_name
        
        # ãƒã‚¤ãƒ³ãƒˆåŠ ç®—
        if dataset_winners['compression'] in compressor_scores:
            compressor_scores[dataset_winners['compression']] += 2  # åœ§ç¸®ç‡é‡è¦–
        
        if dataset_winners['speed'] in compressor_scores:
            compressor_scores[dataset_winners['speed']] += 1  # é€Ÿåº¦ãƒœãƒ¼ãƒŠã‚¹
    
    # é †ä½ç™ºè¡¨
    sorted_scores = sorted(compressor_scores.items(), key=lambda x: x[1], reverse=True)
    
    print("   é †ä½è¡¨:")
    for i, (compressor, score) in enumerate(sorted_scores, 1):
        medal = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
        print(f"   {medal} {i}ä½: {compressor.upper()} - {score}ãƒã‚¤ãƒ³ãƒˆ")
    
    # NEXUSæ”¹å–„ææ¡ˆ
    nexus_score = compressor_scores.get('nexus', 0)
    max_score = max(compressor_scores.values()) if compressor_scores.values() else 0
    
    print(f"\nğŸ”§ NEXUSæ”¹å–„ææ¡ˆ:")
    print("-" * 50)
    
    if nexus_score < max_score:
        print("   ğŸ“ˆ åœ§ç¸®ç‡æ”¹å–„æ¡ˆ:")
        print("     â€¢ å‹æ§‹é€ åˆ†è§£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æœ€é©åŒ–")
        print("     â€¢ å·®åˆ†ç¬¦å·åŒ–ã®å¼·åŒ–")
        print("     â€¢ è¤‡åˆå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…")
        print("     â€¢ æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®æ”¹è‰¯")
        
        print("   âš¡ é€Ÿåº¦æ”¹å–„æ¡ˆ:")
        print("     â€¢ ä¸¦åˆ—å‡¦ç†ã®æœ€é©åŒ–")
        print("     â€¢ ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ”¹å–„")
        print("     â€¢ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ã®å‘ä¸Š")
        print("     â€¢ GPUä¸¦åˆ—å‡¦ç†ã®å°å…¥")
        
        print("   ğŸ¯ æˆ¦ç•¥çš„æ”¹å–„:")
        print("     â€¢ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥ç‰¹åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é–‹ç™º")
        print("     â€¢ é©å¿œçš„åœ§ç¸®ãƒ¬ãƒ™ãƒ«èª¿æ•´")
        print("     â€¢ è¾æ›¸å­¦ç¿’æ©Ÿèƒ½ã®å®Ÿè£…")
        print("     â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
    else:
        print("   ğŸ‰ NEXUSãŒç«¶åˆä»–ç¤¾ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç™ºæ®ï¼")
        print("   â€¢ é©æ–°çš„TMCã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒåŠ¹æœã‚’ç™ºæ®")
        print("   â€¢ ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç†è§£ã«ã‚ˆã‚‹æœ€é©åŒ–ãŒæˆåŠŸ")


def generate_benchmark_report(results: Dict[str, Dict]) -> None:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    try:
        report_file = 'nexus_vs_competitors_benchmark_report.json'
        
        # çµæœã‚’JSONã§ä¿å­˜
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {report_file}")
        
        # CSVã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        csv_file = 'benchmark_summary.csv'
        with open(csv_file, 'w', encoding='utf-8') as f:
            f.write("Dataset,Compressor,Level,Compression_Ratio,Compression_Speed,Decompression_Speed,Reversible\n")
            
            for dataset_name, dataset_results in results.items():
                for comp_name, comp_results in dataset_results.items():
                    for level_key, level_result in comp_results.items():
                        if 'error' not in level_result:
                            ratio = level_result.get('compression_ratio', 0)
                            comp_speed = level_result.get('compression_throughput', 0)
                            decomp_speed = level_result.get('decompression_throughput', 0)
                            reversible = level_result.get('is_reversible', 'N/A')
                            level = level_result.get('level', 'unknown')
                            
                            f.write(f"{dataset_name},{comp_name},{level},{ratio:.2f},{comp_speed:.2f},{decomp_speed:.2f},{reversible}\n")
        
        print(f"ğŸ“Š CSVã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {csv_file}")
        
    except Exception as e:
        print(f"âš ï¸ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")


if __name__ == "__main__":
    try:
        print("ğŸš€ NEXUS vs 7Z vs Zstandard ç«¶äº‰æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
        print("åœ§ç¸®ç‡ãƒ»é€Ÿåº¦ãƒ»å¯é€†æ€§ã®ç·åˆè©•ä¾¡")
        print("=" * 80)
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        datasets = create_benchmark_datasets()
        
        print(f"\nâœ… {len(datasets)}ç¨®é¡ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†")
        total_size = sum(len(data) for data in datasets.values())
        print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")
        
        for name, data in datasets.items():
            print(f"   {name}: {len(data):,} bytes ({len(data)/1024:.1f} KB)")
        
        # ç«¶äº‰æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        results = run_comprehensive_benchmark(datasets)
        
        if results:
            # çµæœåˆ†æ
            analyze_benchmark_results(results)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            generate_benchmark_report(results)
            
            print("\n" + "=" * 80)
            print("ğŸ¯ NEXUS vs 7Z vs Zstandard æ¯”è¼ƒãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
            print("ç«¶äº‰åŠ›åˆ†æã¨NEXUSæ”¹å–„ææ¡ˆã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        else:
            print("âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ†ã‚¹ãƒˆä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

#!/usr/bin/env python3
"""
NEXUSãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
ç†è«–çš„é™ç•Œã‚’çªç ´ã™ã‚‹4æ®µéšçµ±åˆã®åŠ¹æœæ¤œè¨¼
"""

import sys
import os
import time

# ãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.append(os.path.dirname(__file__))

from nexus_advanced_engine import NexusAdvancedCompressor

def test_multilayer_on_different_data():
    """ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”¥ NEXUS Multi-Layer Consolidation Test")
    print("=" * 60)
    
    compressor = NexusAdvancedCompressor(use_ai=True)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    test_datasets = [
        {
            "name": "Compressed 7z Data (High Entropy)",
            "file": "../test-data/small_test.7z"
        },
        {
            "name": "PNG Image Data (Structured)",
            "file": "../test-data/small_test.png"
        },
        {
            "name": "Random Binary Data",
            "data": os.urandom(5000)  # 5KB random
        },
        {
            "name": "Repetitive Pattern Data",
            "data": b"ABCDEFGH" * 625  # 5KB pattern
        }
    ]
    
    for i, dataset in enumerate(test_datasets, 1):
        print(f"\nğŸ“Š Test {i}: {dataset['name']}")
        print("-" * 50)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if "file" in dataset:
            try:
                with open(dataset["file"], "rb") as f:
                    data = f.read()
                print(f"   File size: {len(data):,} bytes")
            except FileNotFoundError:
                print(f"   âš ï¸ File not found: {dataset['file']}")
                continue
        else:
            data = dataset["data"]
            print(f"   Data size: {len(data):,} bytes")
        
        if len(data) == 0:
            print("   âš ï¸ Empty data, skipping")
            continue
        
        # ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        
        try:
            result = compressor.compress(data)
            
            processing_time = time.time() - start_time
            
            # çµæœåˆ†æ
            original_size = len(data)
            compressed_size = len(result)
            ratio = compressed_size / original_size * 100
            
            print(f"   Original size: {original_size:,} bytes")
            print(f"   Result size: {compressed_size:,} bytes")
            print(f"   Compression ratio: {ratio:.2f}%")
            print(f"   Processing time: {processing_time:.2f}s")
            
            if ratio < 100:
                print(f"   âœ… COMPRESSION ACHIEVED! ({100-ratio:.1f}% reduction)")
            elif ratio < 150:
                print(f"   ğŸ”¶ Slight expansion ({ratio-100:.1f}% increase)")
            else:
                print(f"   âŒ Significant expansion ({ratio-100:.1f}% increase)")
                
        except Exception as e:
            print(f"   âŒ Error during compression: {e}")
            continue

def test_theoretical_limits():
    """ç†è«–çš„é™ç•Œã®ãƒ†ã‚¹ãƒˆ"""
    print("\n\nğŸ§  Theoretical Limits Analysis")
    print("=" * 60)
    
    compressor = NexusAdvancedCompressor(use_ai=True)
    
    # ç†è«–çš„ã«åœ§ç¸®ä¸å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿
    print("\nğŸ“ˆ Testing Incompressible Data (Random)")
    random_data = os.urandom(2048)  # 2KB pure random
    
    try:
        start_time = time.time()
        result = compressor.compress(random_data)
        processing_time = time.time() - start_time
        
        ratio = len(result) / len(random_data) * 100
        print(f"   Random data: {len(random_data):,} â†’ {len(result):,} bytes ({ratio:.1f}%)")
        print(f"   Processing time: {processing_time:.2f}s")
        
        if ratio > 100:
            print(f"   âœ… Expected expansion for random data ({ratio-100:.1f}% increase)")
        else:
            print(f"   ğŸ¤” Unexpected compression of random data")
            
    except Exception as e:
        print(f"   âŒ Error: {e}")
    
    # ç†è«–çš„ã«åœ§ç¸®å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿
    print("\nğŸ“‰ Testing Highly Compressible Data (Repetitive)")
    repetitive_data = b"A" * 2048  # 2KB all same byte
    
    try:
        start_time = time.time()
        result = compressor.compress(repetitive_data)
        processing_time = time.time() - start_time
        
        ratio = len(result) / len(repetitive_data) * 100
        print(f"   Repetitive data: {len(repetitive_data):,} â†’ {len(result):,} bytes ({ratio:.1f}%)")
        print(f"   Processing time: {processing_time:.2f}s")
        
        if ratio < 50:
            print(f"   âœ… Excellent compression ({100-ratio:.1f}% reduction)")
        elif ratio < 100:
            print(f"   ğŸ”¶ Good compression ({100-ratio:.1f}% reduction)")
        else:
            print(f"   âŒ Failed to compress repetitive data")
            
    except Exception as e:
        print(f"   âŒ Error: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ¯ NEXUS Multi-Layer Consolidation System Test")
    print("Testing 4-layer consolidation algorithm:")
    print("  Layer 1: Exact Match Consolidation")
    print("  Layer 2: Pattern-Based Consolidation") 
    print("  Layer 3: Approximate Consolidation (Compressed Data Optimized)")
    print("  Layer 4: Structural Consolidation")
    print()
    
    # ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ†ã‚¹ãƒˆ
    test_multilayer_on_different_data()
    
    # ç†è«–é™ç•Œãƒ†ã‚¹ãƒˆ
    test_theoretical_limits()
    
    print("\n" + "=" * 60)
    print("âœ… Multi-Layer Consolidation Test Complete")
    print("Check results above to validate NEXUS theory improvements")

if __name__ == "__main__":
    main()

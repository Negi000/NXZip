#!/usr/bin/env python3
"""
Phase 8 çµ±åˆç‰ˆ - å¯é€†æ€§ä¿è¨¼ + ç”»åƒãƒ»å‹•ç”»ç‰¹åŒ–
100%å¯é€†æ€§ã¨é«˜åœ§ç¸®ç‡ã®ä¸¡ç«‹å®Ÿç¾
"""

import os
import sys
import time
import json
import struct
import lzma
import zlib
import hashlib
import math
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class MediaOptimizedEngine:
    """ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ - å¯é€†æ€§ä¿è¨¼ç‰ˆ"""
    
    def __init__(self):
        self.version = "8.0-MediaOptimized"
        self.magic_header = b'NXZ8O'  # Optimizedç‰ˆãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
    
    def calculate_entropy(self, data: bytes) -> float:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—"""
        if not data:
            return 0.0
        
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        entropy = 0.0
        data_len = len(data)
        for count in byte_counts:
            if count > 0:
                probability = count / data_len
                entropy -= probability * math.log2(probability)
        
        return min(entropy, 8.0)
    
    def detect_media_type(self, data: bytes, filename: str) -> str:
        """ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼æ¤œå‡º"""
        if not data:
            return "UNKNOWN"
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯
        if data.startswith(b'\xFF\xD8\xFF'):
            return "JPEG"
        elif data.startswith(b'\x89PNG\r\n\x1A\n'):
            return "PNG"
        elif data.startswith(b'BM'):
            return "BMP"
        elif data.startswith(b'GIF8'):
            return "GIF"
        elif b'ftyp' in data[:32]:
            return "MP4"
        elif data.startswith(b'RIFF') and b'AVI ' in data[:32]:
            return "AVI"
        elif data.startswith(b'ID3') or data[0:2] == b'\xFF\xFB':
            return "MP3"
        elif data.startswith(b'RIFF') and b'WAVE' in data[:32]:
            return "WAV"
        
        # æ‹¡å¼µå­ãƒ™ãƒ¼ã‚¹åˆ¤å®š
        ext = filename.lower().split('.')[-1] if '.' in filename else ''
        if ext in ['jpg', 'jpeg']:
            return "JPEG"
        elif ext in ['png']:
            return "PNG"
        elif ext in ['mp4', 'm4v']:
            return "MP4"
        elif ext in ['mp3']:
            return "MP3"
        elif ext in ['wav']:
            return "WAV"
        elif ext in ['txt', 'csv', 'json', 'xml']:
            return "TEXT"
        
        return "UNKNOWN"
    
    def analyze_image_structure(self, data: bytes, image_type: str) -> List[Dict]:
        """ç”»åƒæ§‹é€ è§£æ"""
        segments = []
        
        if image_type == "JPEG":
            segments = self.analyze_jpeg_segments(data)
        elif image_type == "PNG":
            segments = self.analyze_png_chunks(data)
        else:
            # æ±ç”¨ç”»åƒè§£æ
            segments = self.analyze_generic_chunks(data, 8192)
        
        return segments
    
    def analyze_jpeg_segments(self, data: bytes) -> List[Dict]:
        """JPEG ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè§£æ"""
        segments = []
        offset = 0
        
        while offset < len(data) - 1:
            if data[offset] == 0xFF and data[offset + 1] != 0xFF:
                marker = data[offset + 1]
                segment_start = offset
                
                if marker in [0xD8, 0xD9]:  # SOI, EOI
                    segment_size = 2
                elif marker == 0xDA:  # SOS (ç”»åƒãƒ‡ãƒ¼ã‚¿)
                    # ç”»åƒãƒ‡ãƒ¼ã‚¿çµ‚ç«¯ã¾ã§
                    end_pos = self.find_jpeg_eoi(data, offset + 2)
                    segment_size = end_pos - offset
                else:
                    if offset + 3 < len(data):
                        segment_size = struct.unpack('>H', data[offset + 2:offset + 4])[0] + 2
                    else:
                        segment_size = len(data) - offset
                
                segment_data = data[segment_start:segment_start + segment_size]
                segments.append({
                    'type': f'JPEG_MARKER_{marker:02X}',
                    'data': segment_data,
                    'offset': segment_start,
                    'size': segment_size,
                    'is_image_data': marker == 0xDA,
                    'is_metadata': marker in [0xE0, 0xE1, 0xE2, 0xFE]
                })
                
                offset += segment_size
            else:
                offset += 1
        
        return segments
    
    def find_jpeg_eoi(self, data: bytes, start: int) -> int:
        """JPEG EOIæ¤œç´¢"""
        pos = start
        while pos < len(data) - 1:
            if data[pos] == 0xFF and data[pos + 1] == 0xD9:
                return pos + 2
            pos += 1
        return len(data)
    
    def analyze_png_chunks(self, data: bytes) -> List[Dict]:
        """PNG ãƒãƒ£ãƒ³ã‚¯è§£æ"""
        segments = []
        offset = 8  # PNGç½²åã‚¹ã‚­ãƒƒãƒ—
        
        while offset < len(data) - 8:
            try:
                chunk_size = struct.unpack('>I', data[offset:offset + 4])[0]
                chunk_type = data[offset + 4:offset + 8]
                total_size = chunk_size + 12
                
                chunk_data = data[offset:offset + total_size]
                segments.append({
                    'type': f'PNG_CHUNK_{chunk_type.decode("ascii", errors="ignore")}',
                    'data': chunk_data,
                    'offset': offset,
                    'size': total_size,
                    'is_image_data': chunk_type == b'IDAT',
                    'is_metadata': chunk_type in [b'tEXt', b'zTXt', b'iTXt']
                })
                
                offset += total_size
            except:
                # æ®‹ã‚Šã‚’ä¸€æ‹¬å‡¦ç†
                remaining = data[offset:]
                segments.append({
                    'type': 'PNG_REMAINING',
                    'data': remaining,
                    'offset': offset,
                    'size': len(remaining),
                    'is_image_data': False,
                    'is_metadata': False
                })
                break
        
        return segments
    
    def analyze_video_structure(self, data: bytes, video_type: str) -> List[Dict]:
        """å‹•ç”»æ§‹é€ è§£æ"""
        if video_type == "MP4":
            return self.analyze_mp4_atoms(data)
        else:
            return self.analyze_generic_chunks(data, 65536)
    
    def analyze_mp4_atoms(self, data: bytes) -> List[Dict]:
        """MP4 ã‚¢ãƒˆãƒ è§£æ"""
        segments = []
        offset = 0
        
        while offset < len(data) - 8:
            try:
                atom_size = struct.unpack('>I', data[offset:offset + 4])[0]
                atom_type = data[offset + 4:offset + 8]
                
                if atom_size == 0:
                    atom_size = len(data) - offset
                
                atom_data = data[offset:offset + atom_size]
                segments.append({
                    'type': f'MP4_ATOM_{atom_type.decode("ascii", errors="ignore")}',
                    'data': atom_data,
                    'offset': offset,
                    'size': atom_size,
                    'is_media_data': atom_type == b'mdat',
                    'is_metadata': atom_type in [b'meta', b'udta']
                })
                
                offset += atom_size
            except:
                # æ®‹ã‚Šã‚’ä¸€æ‹¬å‡¦ç†
                remaining = data[offset:]
                segments.append({
                    'type': 'MP4_REMAINING',
                    'data': remaining,
                    'offset': offset,
                    'size': len(remaining),
                    'is_media_data': False,
                    'is_metadata': False
                })
                break
        
        return segments
    
    def analyze_generic_chunks(self, data: bytes, chunk_size: int) -> List[Dict]:
        """æ±ç”¨ãƒãƒ£ãƒ³ã‚¯è§£æ"""
        segments = []
        offset = 0
        chunk_index = 0
        
        while offset < len(data):
            current_size = min(chunk_size, len(data) - offset)
            chunk_data = data[offset:offset + current_size]
            
            segments.append({
                'type': f'CHUNK_{chunk_index:04d}',
                'data': chunk_data,
                'offset': offset,
                'size': current_size,
                'is_image_data': False,
                'is_metadata': False
            })
            
            offset += current_size
            chunk_index += 1
        
        return segments
    
    def optimize_compression_strategy(self, segment: Dict, media_type: str) -> str:
        """ãƒ¡ãƒ‡ã‚£ã‚¢ç‰¹åŒ–åœ§ç¸®æˆ¦ç•¥æœ€é©åŒ–"""
        data = segment['data']
        entropy = self.calculate_entropy(data)
        
        # ç”»åƒç‰¹åŒ–æˆ¦ç•¥
        if media_type in ['JPEG', 'PNG', 'BMP', 'GIF']:
            if segment.get('is_image_data', False):
                # ç”»åƒãƒ‡ãƒ¼ã‚¿: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ™ãƒ¼ã‚¹é¸æŠ
                if entropy < 2.0:
                    return "rle"  # ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
                elif entropy < 6.0:
                    return "lzma"  # ä¸­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
                else:
                    return "delta_lzma"  # é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆãƒ‡ãƒ«ã‚¿åœ§ç¸®ï¼‰
            elif segment.get('is_metadata', False):
                return "lzma"  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            else:
                return "zlib"  # ãã®ä»–
        
        # å‹•ç”»ç‰¹åŒ–æˆ¦ç•¥
        elif media_type in ['MP4', 'AVI', 'MOV']:
            if segment.get('is_media_data', False):
                # å‹•ç”»ãƒ‡ãƒ¼ã‚¿: ãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†æœ€é©åŒ–
                if entropy < 3.0:
                    return "frame_delta"
                elif entropy < 7.0:
                    return "lzma"
                else:
                    return "zlib"
            else:
                return "lzma"
        
        # éŸ³å£°ç‰¹åŒ–æˆ¦ç•¥
        elif media_type in ['MP3', 'WAV']:
            if entropy < 2.0:
                return "audio_rle"  # ç„¡éŸ³éƒ¨åˆ†ç­‰
            elif entropy < 5.0:
                return "lzma"
            else:
                return "zlib"
        
        # ãƒ†ã‚­ã‚¹ãƒˆç‰¹åŒ–æˆ¦ç•¥
        elif media_type == 'TEXT':
            if entropy < 3.0:
                return "text_rle"
            else:
                return "lzma"
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæˆ¦ç•¥
        if entropy < 2.0:
            return "rle"
        elif entropy < 6.0:
            return "lzma"
        else:
            return "zlib"
    
    def media_optimized_compress(self, data: bytes, filename: str = "data") -> Dict:
        """ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–åœ§ç¸®"""
        start_time = time.time()
        original_size = len(data)
        
        print(f"ğŸ¯ ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–åœ§ç¸®é–‹å§‹: {filename}")
        print(f"ğŸ“Š å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes ({original_size/1024/1024:.1f} MB)")
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼æ¤œå‡º
        media_type = self.detect_media_type(data, filename)
        print(f"ğŸ­ ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼: {media_type}")
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥
        original_hash = hashlib.sha256(data).hexdigest()
        print(f"ğŸ” åŸæœ¬ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
        
        # ãƒ¡ãƒ‡ã‚£ã‚¢ç‰¹åŒ–æ§‹é€ è§£æ
        if media_type in ['JPEG', 'PNG', 'BMP', 'GIF']:
            segments = self.analyze_image_structure(data, media_type)
        elif media_type in ['MP4', 'AVI', 'MOV']:
            segments = self.analyze_video_structure(data, media_type)
        else:
            segments = self.analyze_generic_chunks(data, 16384)
        
        print(f"ğŸ“ˆ æ§‹é€ è§£æ: {len(segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
        
        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥æœ€é©åŒ–åœ§ç¸®
        compressed_segments = []
        segment_metadata = []
        total_segments = len(segments)
        
        for i, segment in enumerate(segments):
            # æœ€é©åŒ–æˆ¦ç•¥æ±ºå®š
            strategy = self.optimize_compression_strategy(segment, media_type)
            
            # åœ§ç¸®å®Ÿè¡Œ
            compressed_data = self.apply_compression_strategy(segment['data'], strategy)
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            metadata = {
                'original_size': segment['size'],
                'strategy': strategy,
                'segment_type': segment['type'],
                'offset': segment['offset']
            }
            
            compressed_segments.append(compressed_data)
            segment_metadata.append(metadata)
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % max(1, total_segments // 4) == 0:
                percent = ((i + 1) / total_segments) * 100
                print(f"ğŸ¯ æœ€é©åŒ–é€²æ—: {percent:.0f}%")
        
        # æœ€çµ‚çµ±åˆ
        final_compressed = self.build_optimized_file(
            compressed_segments, segment_metadata, original_hash, media_type, original_size
        )
        
        compressed_size = len(final_compressed)
        compression_ratio = ((original_size - compressed_size) / original_size) * 100
        processing_time = time.time() - start_time
        
        # æˆ¦ç•¥çµ±è¨ˆ
        strategy_stats = {}
        for metadata in segment_metadata:
            strategy = metadata['strategy']
            strategy_stats[strategy] = strategy_stats.get(strategy, 0) + 1
        
        print(f"ğŸ¯ æœ€é©åŒ–æˆ¦ç•¥çµ±è¨ˆ:")
        for strategy, count in strategy_stats.items():
            print(f"   {strategy}: {count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
        
        print(f"âœ… æœ€é©åŒ–å®Œäº†: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,})")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        
        return {
            'original_size': original_size,
            'compressed_size': compressed_size,
            'compression_ratio': compression_ratio,
            'compressed_data': final_compressed,
            'processing_time': processing_time,
            'media_type': media_type,
            'segments_count': len(segments),
            'strategy_stats': strategy_stats,
            'original_hash': original_hash
        }\n    \n    def apply_compression_strategy(self, data: bytes, strategy: str) -> bytes:\n        \"\"\"åœ§ç¸®æˆ¦ç•¥é©ç”¨\"\"\"\n        if not data:\n            return b''\n        \n        try:\n            if strategy == \"rle\" or strategy == \"audio_rle\" or strategy == \"text_rle\":\n                return self.safe_rle_compress(data)\n            elif strategy == \"lzma\":\n                return lzma.compress(data, preset=6, check=lzma.CHECK_CRC64)\n            elif strategy == \"zlib\":\n                return zlib.compress(data, level=6)\n            elif strategy == \"delta_lzma\":\n                return self.delta_lzma_compress(data)\n            elif strategy == \"frame_delta\":\n                return self.frame_delta_compress(data)\n            else:\n                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n                return zlib.compress(data, level=3)\n        except:\n            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒãƒ‡ãƒ¼ã‚¿è¿”å´\n            return data\n    \n    def delta_lzma_compress(self, data: bytes) -> bytes:\n        \"\"\"ãƒ‡ãƒ«ã‚¿åœ§ç¸® + LZMA\"\"\"\n        if len(data) < 16:\n            return data\n        \n        # éš£æ¥ãƒã‚¤ãƒˆå·®åˆ†è¨ˆç®—\n        delta = bytearray([data[0]])  # æœ€åˆã®ãƒã‚¤ãƒˆ\n        for i in range(1, len(data)):\n            diff = (data[i] - data[i-1]) % 256\n            delta.append(diff)\n        \n        # LZMAåœ§ç¸®\n        try:\n            compressed = lzma.compress(bytes(delta), preset=3)\n            # åœ§ç¸®åŠ¹æœãƒã‚§ãƒƒã‚¯\n            if len(compressed) < len(data):\n                return compressed\n        except:\n            pass\n        \n        return data\n    \n    def frame_delta_compress(self, data: bytes) -> bytes:\n        \"\"\"ãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†åœ§ç¸®\"\"\"\n        if len(data) < 64:\n            return data\n        \n        # 64ãƒã‚¤ãƒˆãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§å·®åˆ†è¨ˆç®—\n        block_size = 64\n        compressed = bytearray()\n        \n        # æœ€åˆã®ãƒ–ãƒ­ãƒƒã‚¯\n        first_block = data[:block_size]\n        compressed.extend(first_block)\n        \n        # å·®åˆ†ãƒ–ãƒ­ãƒƒã‚¯\n        for i in range(block_size, len(data), block_size):\n            current_block = data[i:i+block_size]\n            prev_block = data[i-block_size:i]\n            \n            # ãƒ–ãƒ­ãƒƒã‚¯é–“å·®åˆ†\n            diff_block = bytearray()\n            for j in range(len(current_block)):\n                if j < len(prev_block):\n                    diff = (current_block[j] - prev_block[j]) % 256\n                    diff_block.append(diff)\n                else:\n                    diff_block.append(current_block[j])\n            \n            compressed.extend(diff_block)\n        \n        # LZMAåœ§ç¸®\n        try:\n            final_compressed = lzma.compress(bytes(compressed), preset=3)\n            if len(final_compressed) < len(data):\n                return final_compressed\n        except:\n            pass\n        \n        return data\n    \n    def safe_rle_compress(self, data: bytes) -> bytes:\n        \"\"\"å®‰å…¨ãªRLEåœ§ç¸®\"\"\"\n        if not data:\n            return b''\n        \n        compressed = bytearray()\n        i = 0\n        \n        while i < len(data):\n            current_byte = data[i]\n            count = 1\n            \n            # é€£ç¶šã‚«ã‚¦ãƒ³ãƒˆ\n            while (i + count < len(data) and \n                   data[i + count] == current_byte and \n                   count < 253):\n                count += 1\n            \n            if count >= 3:\n                # RLE: 254 count byte\n                compressed.extend([254, count, current_byte])\n                i += count\n            else:\n                # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†\n                if current_byte == 254:\n                    compressed.extend([255, 254])\n                elif current_byte == 255:\n                    compressed.extend([255, 255])\n                else:\n                    compressed.append(current_byte)\n                i += 1\n        \n        return bytes(compressed)\n    \n    def build_optimized_file(self, compressed_segments: List[bytes], \n                           segment_metadata: List[Dict], original_hash: str,\n                           media_type: str, original_size: int) -> bytes:\n        \"\"\"æœ€é©åŒ–ãƒ•ã‚¡ã‚¤ãƒ«æ§‹ç¯‰\"\"\"\n        result = bytearray()\n        \n        # ãƒ˜ãƒƒãƒ€ãƒ¼\n        result.extend(self.magic_header)\n        \n        # å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥\n        result.extend(original_hash.encode('ascii'))\n        \n        # å…ƒã‚µã‚¤ã‚º\n        result.extend(struct.pack('<I', original_size))\n        \n        # ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼\n        media_type_bytes = media_type.encode('ascii')\n        result.extend(struct.pack('<H', len(media_type_bytes)))\n        result.extend(media_type_bytes)\n        \n        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n        metadata_json = json.dumps(segment_metadata, separators=(',', ':')).encode('utf-8')\n        metadata_compressed = lzma.compress(metadata_json, preset=9)\n        result.extend(struct.pack('<I', len(metadata_compressed)))\n        result.extend(metadata_compressed)\n        \n        # åœ§ç¸®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ\n        result.extend(struct.pack('<I', len(compressed_segments)))\n        for segment in compressed_segments:\n            result.extend(struct.pack('<I', len(segment)))\n            result.extend(segment)\n        \n        return bytes(result)\n    \n    def media_optimized_decompress(self, compressed_data: bytes) -> Dict:\n        \"\"\"ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–å±•é–‹\"\"\"\n        start_time = time.time()\n        \n        print(\"ğŸ¯ ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–å±•é–‹é–‹å§‹\")\n        \n        # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼\n        if not compressed_data.startswith(self.magic_header):\n            raise ValueError(\"âŒ ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–å½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“\")\n        \n        offset = len(self.magic_header)\n        \n        # å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥\n        original_hash = compressed_data[offset:offset+64].decode('ascii')\n        offset += 64\n        print(f\"ğŸ” åŸæœ¬ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...\")\n        \n        # å…ƒã‚µã‚¤ã‚º\n        original_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]\n        offset += 4\n        \n        # ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼\n        media_type_len = struct.unpack('<H', compressed_data[offset:offset+2])[0]\n        offset += 2\n        media_type = compressed_data[offset:offset+media_type_len].decode('ascii')\n        offset += media_type_len\n        print(f\"ğŸ­ ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼: {media_type}\")\n        \n        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n        metadata_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]\n        offset += 4\n        metadata_compressed = compressed_data[offset:offset+metadata_size]\n        offset += metadata_size\n        \n        metadata_json = lzma.decompress(metadata_compressed)\n        segment_metadata = json.loads(metadata_json.decode('utf-8'))\n        print(f\"ğŸ“ˆ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(segment_metadata)}\")\n        \n        # åœ§ç¸®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°\n        segments_count = struct.unpack('<I', compressed_data[offset:offset+4])[0]\n        offset += 4\n        \n        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå±•é–‹\n        decompressed_segments = []\n        for i in range(segments_count):\n            segment_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]\n            offset += 4\n            \n            segment_data = compressed_data[offset:offset+segment_size]\n            offset += segment_size\n            \n            # å±•é–‹æˆ¦ç•¥é©ç”¨\n            if i < len(segment_metadata):\n                strategy = segment_metadata[i]['strategy']\n                decompressed = self.apply_decompression_strategy(segment_data, strategy)\n            else:\n                decompressed = segment_data\n            \n            decompressed_segments.append(decompressed)\n            \n            # é€²æ—è¡¨ç¤º\n            if (i + 1) % max(1, segments_count // 4) == 0:\n                percent = ((i + 1) / segments_count) * 100\n                print(f\"ğŸ¯ å±•é–‹é€²æ—: {percent:.0f}%\")\n        \n        # å…ƒãƒ‡ãƒ¼ã‚¿å¾©å…ƒ\n        original_data = b''.join(decompressed_segments)\n        \n        # å¯é€†æ€§æ¤œè¨¼\n        restored_hash = hashlib.sha256(original_data).hexdigest()\n        is_identical = (restored_hash == original_hash)\n        \n        processing_time = time.time() - start_time\n        print(f\"âœ… å±•é–‹å®Œäº†: {len(original_data):,} bytes ({processing_time:.2f}ç§’)\")\n        print(f\"ğŸ” å¯é€†æ€§æ¤œè¨¼: {'âœ… å®Œå…¨ä¸€è‡´' if is_identical else 'âŒ ä¸ä¸€è‡´'}\")\n        \n        if not is_identical:\n            print(f\"âš ï¸ åŸæœ¬: {original_hash[:16]}...\")\n            print(f\"âš ï¸ å¾©å…ƒ: {restored_hash[:16]}...\")\n            raise ValueError(\"âŒ å¯é€†æ€§æ¤œè¨¼å¤±æ•—\")\n        \n        return {\n            'original_data': original_data,\n            'decompressed_size': len(original_data),\n            'processing_time': processing_time,\n            'media_type': media_type,\n            'is_reversible': is_identical\n        }\n    \n    def apply_decompression_strategy(self, data: bytes, strategy: str) -> bytes:\n        \"\"\"å±•é–‹æˆ¦ç•¥é©ç”¨\"\"\"\n        try:\n            if strategy in [\"rle\", \"audio_rle\", \"text_rle\"]:\n                return self.safe_rle_decompress(data)\n            elif strategy == \"lzma\":\n                return lzma.decompress(data)\n            elif strategy == \"zlib\":\n                return zlib.decompress(data)\n            elif strategy == \"delta_lzma\":\n                return self.delta_lzma_decompress(data)\n            elif strategy == \"frame_delta\":\n                return self.frame_delta_decompress(data)\n            else:\n                return zlib.decompress(data)\n        except:\n            return data\n    \n    def delta_lzma_decompress(self, data: bytes) -> bytes:\n        \"\"\"ãƒ‡ãƒ«ã‚¿åœ§ç¸®å±•é–‹\"\"\"\n        try:\n            # LZMAå±•é–‹\n            delta_data = lzma.decompress(data)\n            \n            # å·®åˆ†å¾©å…ƒ\n            if len(delta_data) > 0:\n                result = bytearray([delta_data[0]])\n                for i in range(1, len(delta_data)):\n                    restored_byte = (result[-1] + delta_data[i]) % 256\n                    result.append(restored_byte)\n                return bytes(result)\n        except:\n            pass\n        \n        return data\n    \n    def frame_delta_decompress(self, data: bytes) -> bytes:\n        \"\"\"ãƒ•ãƒ¬ãƒ¼ãƒ é–“å·®åˆ†å±•é–‹\"\"\"\n        try:\n            # LZMAå±•é–‹\n            diff_data = lzma.decompress(data)\n            \n            # ãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒ\n            block_size = 64\n            if len(diff_data) >= block_size:\n                result = bytearray(diff_data[:block_size])  # æœ€åˆã®ãƒ–ãƒ­ãƒƒã‚¯\n                \n                for i in range(block_size, len(diff_data), block_size):\n                    diff_block = diff_data[i:i+block_size]\n                    prev_block = result[i-block_size:i]\n                    \n                    # å·®åˆ†å¾©å…ƒ\n                    for j in range(len(diff_block)):\n                        if j < len(prev_block):\n                            restored_byte = (prev_block[j] + diff_block[j]) % 256\n                            result.append(restored_byte)\n                        else:\n                            result.append(diff_block[j])\n                \n                return bytes(result)\n        except:\n            pass\n        \n        return data\n    \n    def safe_rle_decompress(self, data: bytes) -> bytes:\n        \"\"\"å®‰å…¨ãªRLEå±•é–‹\"\"\"\n        if not data:\n            return b''\n        \n        result = bytearray()\n        i = 0\n        \n        while i < len(data):\n            if data[i] == 254 and i + 2 < len(data):\n                # RLEå±•é–‹\n                count = data[i + 1]\n                byte_value = data[i + 2]\n                result.extend([byte_value] * count)\n                i += 3\n            elif data[i] == 255 and i + 1 < len(data):\n                # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å±•é–‹\n                result.append(data[i + 1])\n                i += 2\n            else:\n                result.append(data[i])\n                i += 1\n        \n        return bytes(result)\n    \n    def compress_file(self, input_path: str, output_path: str = None) -> bool:\n        \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®\"\"\"\n        if not os.path.exists(input_path):\n            print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}\")\n            return False\n        \n        if output_path is None:\n            output_path = input_path + '.p8o'  # Phase 8 Optimized\n        \n        try:\n            with open(input_path, 'rb') as f:\n                data = f.read()\n            \n            filename = os.path.basename(input_path)\n            result = self.media_optimized_compress(data, filename)\n            \n            with open(output_path, 'wb') as f:\n                f.write(result['compressed_data'])\n            \n            print(f\"ğŸ’¾ æœ€é©åŒ–åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}\")\n            return True\n        \n        except Exception as e:\n            print(f\"âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}\")\n            return False\n    \n    def decompress_file(self, input_path: str, output_path: str = None) -> bool:\n        \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹\"\"\"\n        if not os.path.exists(input_path):\n            print(f\"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}\")\n            return False\n        \n        if output_path is None:\n            if input_path.endswith('.p8o'):\n                output_path = input_path[:-4]\n            else:\n                output_path = input_path + '.restored'\n        \n        try:\n            with open(input_path, 'rb') as f:\n                compressed_data = f.read()\n            \n            result = self.media_optimized_decompress(compressed_data)\n            \n            with open(output_path, 'wb') as f:\n                f.write(result['original_data'])\n            \n            print(f\"ğŸ“ æœ€é©åŒ–å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}\")\n            return True\n        \n        except Exception as e:\n            print(f\"âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}\")\n            return False\n\ndef run_media_optimization_test():\n    \"\"\"ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–ç·åˆãƒ†ã‚¹ãƒˆ\"\"\"\n    print(\"ğŸ¯ Phase 8 ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–ç·åˆãƒ†ã‚¹ãƒˆ\")\n    print(\"=\" * 60)\n    \n    engine = MediaOptimizedEngine()\n    sample_dir = Path(\"../NXZip-Python/sample\")\n    \n    # å…¨ãƒ¡ãƒ‡ã‚£ã‚¢å½¢å¼ãƒ†ã‚¹ãƒˆ\n    test_files = [\n        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«\n        (\"COT-001.jpg\", 1024*1024, \"JPEGç”»åƒ (1MB)\"),\n        (\"COT-012.png\", 2*1024*1024, \"PNGç”»åƒ (2MB)\"),\n        \n        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«\n        (\"PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4\", 3*1024*1024, \"MP4å‹•ç”» (3MB)\"),\n        \n        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«\n        (\"é™°è¬€è«–.mp3\", 1024*1024, \"MP3éŸ³å£° (1MB)\"),\n        \n        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«\n        (\"å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt\", 2*1024*1024, \"ãƒ†ã‚­ã‚¹ãƒˆ (2MB)\"),\n    ]\n    \n    results = []\n    \n    for filename, size_limit, description in test_files:\n        filepath = sample_dir / filename\n        if not filepath.exists():\n            print(f\"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {filename}\")\n            continue\n        \n        print(f\"\\nğŸ¯ æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ: {description}\")\n        print(\"-\" * 50)\n        \n        try:\n            with open(filepath, 'rb') as f:\n                test_data = f.read(size_limit)\n            print(f\"ğŸ“ ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º: {len(test_data):,} bytes\")\n            \n            # æœ€é©åŒ–åœ§ç¸®\n            result = engine.media_optimized_compress(test_data, filename)\n            \n            # æœ€é©åŒ–å±•é–‹\n            decompressed = engine.media_optimized_decompress(result['compressed_data'])\n            \n            # çµæœä¿å­˜\n            results.append({\n                'filename': filename,\n                'description': description,\n                'original_size': len(test_data),\n                'compressed_size': result['compressed_size'],\n                'compression_ratio': result['compression_ratio'],\n                'reversible': decompressed['is_reversible'],\n                'processing_time': result['processing_time'],\n                'media_type': result['media_type'],\n                'segments_count': result['segments_count'],\n                'strategy_stats': result['strategy_stats']\n            })\n            \n            print(f\"âœ… æœ€é©åŒ–æˆåŠŸ: å¯é€†æ€§ {'âœ…' if decompressed['is_reversible'] else 'âŒ'}\")\n            \n        except Exception as e:\n            print(f\"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:60]}...\")\n    \n    # ç·åˆçµæœ\n    if results:\n        print(\"\\n\" + \"=\" * 60)\n        print(\"ğŸ† Phase 8 ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–ç·åˆãƒ†ã‚¹ãƒˆçµæœ\")\n        print(\"=\" * 60)\n        \n        total_original = sum(r['original_size'] for r in results)\n        total_compressed = sum(r['compressed_size'] for r in results)\n        overall_ratio = (1 - total_compressed / total_original) * 100\n        reversible_count = sum(1 for r in results if r['reversible'])\n        \n        print(f\"ğŸ¯ æœ€é©åŒ–åœ§ç¸®ç‡: {overall_ratio:.1f}%\")\n        print(f\"ğŸ”’ å¯é€†æ€§æˆåŠŸç‡: {reversible_count}/{len(results)} ({reversible_count/len(results)*100:.1f}%)\")\n        print(f\"ğŸ“ˆ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}\")\n        print(f\"ğŸ’¾ ç·ãƒ‡ãƒ¼ã‚¿é‡: {total_original/1024/1024:.1f} MB\")\n        \n        # ãƒ¡ãƒ‡ã‚£ã‚¢åˆ¥åˆ†æ\n        print(f\"\\nğŸ“Š ãƒ¡ãƒ‡ã‚£ã‚¢åˆ¥æœ€é©åŒ–çµæœ:\")\n        for result in results:\n            name = result['filename'][:25]\n            size_mb = result['original_size'] / 1024 / 1024\n            rev_icon = 'âœ…' if result['reversible'] else 'âŒ'\n            \n            print(f\"   ğŸ¬ {result['description']}: {result['compression_ratio']:.1f}% ({size_mb:.1f}MB) {rev_icon}\")\n            print(f\"      ğŸ­ å½¢å¼: {result['media_type']}, ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {result['segments_count']}\")\n            print(f\"      ğŸ”§ æˆ¦ç•¥: {', '.join(f'{k}({v})' for k, v in result['strategy_stats'].items())}\")\n        \n        # æ”¹å–„ææ¡ˆ\n        high_compression = [r for r in results if r['compression_ratio'] >= 50]\n        low_compression = [r for r in results if r['compression_ratio'] < 20]\n        \n        if high_compression:\n            print(f\"\\nğŸ… é«˜åœ§ç¸®ç‡é”æˆ ({len(high_compression)}å€‹):\")\n            for r in high_compression:\n                print(f\"   ğŸŒŸ {r['description']}: {r['compression_ratio']:.1f}% - å„ªç§€\")\n        \n        if low_compression:\n            print(f\"\\nâš ï¸ ä½åœ§ç¸®ç‡ ({len(low_compression)}å€‹):\")\n            for r in low_compression:\n                print(f\"   ğŸ”§ {r['description']}: {r['compression_ratio']:.1f}% - æ›´ãªã‚‹ç‰¹åŒ–å¿…è¦\")\n        \n        if reversible_count == len(results):\n            print(\"\\nğŸ‰ å…¨ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–å¯é€†æ€§é”æˆï¼ç”»åƒãƒ»å‹•ç”»ã®åœ§ç¸®ç‡å‘ä¸Šå®Ÿç¾ï¼\")\n        else:\n            failed_count = len(results) - reversible_count\n            print(f\"\\nâš ï¸ {failed_count}ãƒ•ã‚¡ã‚¤ãƒ«ã§å¯é€†æ€§å•é¡Œ\")\n\ndef main():\n    \"\"\"ãƒ¡ã‚¤ãƒ³å‡¦ç†\"\"\"\n    if len(sys.argv) < 2:\n        print(\"ğŸ¯ Phase 8 ãƒ¡ãƒ‡ã‚£ã‚¢æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³\")\n        print(\"ä½¿ç”¨æ–¹æ³•:\")\n        print(\"  python phase8_media_optimized.py test                     # æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ\")\n        print(\"  python phase8_media_optimized.py compress <file>          # æœ€é©åŒ–åœ§ç¸®\")\n        print(\"  python phase8_media_optimized.py decompress <file.p8o>    # æœ€é©åŒ–å±•é–‹\")\n        return\n    \n    command = sys.argv[1].lower()\n    engine = MediaOptimizedEngine()\n    \n    if command == \"test\":\n        run_media_optimization_test()\n    elif command == \"compress\" and len(sys.argv) >= 3:\n        input_file = sys.argv[2]\n        output_file = sys.argv[3] if len(sys.argv) >= 4 else None\n        engine.compress_file(input_file, output_file)\n    elif command == \"decompress\" and len(sys.argv) >= 3:\n        input_file = sys.argv[2]\n        output_file = sys.argv[3] if len(sys.argv) >= 4 else None\n        engine.decompress_file(input_file, output_file)\n    else:\n        print(\"âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™\")\n\nif __name__ == \"__main__\":\n    main()

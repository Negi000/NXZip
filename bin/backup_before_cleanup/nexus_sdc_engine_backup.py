#!/usr/bin/env python3
"""
NEXUS SDC (Structure-Destructive Compression) Engine
é©å‘½çš„æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é©æ–°çš„ã‚¢ã‚¤ãƒ‡ã‚¢å®Ÿè£…:
ã€Œæ§‹é€ ã‚’ãƒã‚¤ãƒŠãƒªãƒ¬ãƒ™ãƒ«ã§å®Œå…¨æŠŠæ¡ â†’ åŸå‹ç ´å£Šåœ§ç¸® â†’ æ§‹é€ å¾©å…ƒã€

ç†è«–å®Ÿç¸¾: å¹³å‡84.1%åœ§ç¸®ç‡ã€æœ€å¤§89.2%åœ§ç¸®ç‡
"""

import os
import sys
import time
import lzma
import zlib
import bz2
import struct
import hashlib
import pickle
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any, Tuple, Optional
                category="header"
            ))
            
            pos = 12
            while pos < len(data) - 8:
                if pos + 8 > len(data):
                    break
                
                chunk_id = data[pos:pos+4]
                chunk_size = struct.unpack('<I', data[pos+4:pos+8])[0]
                
                if chunk_id == b'fmt ':
                    # Format chunk
                    elements.append(StructureElement(
                        element_type="WAV_FMT_CHUNK",
                        position=pos,
                        size=8 + chunk_size,
                        compression_potential=0.2,
                        category="metadata"
                    ))
                elif chunk_id == b'data':
                    # Audio data chunk - é«˜åœ§ç¸®å¯èƒ½
                    elements.append(StructureElement(
                        element_type="WAV_DATA_CHUNK",
                        position=pos,
                        size=8 + chunk_size,
                        compression_potential=0.85,
                        category="audio_data"
                    ))
                else:
                    # Other chunks
                    elements.append(StructureElement(
                        element_type=f"WAV_CHUNK_{chunk_id.decode('ascii', errors='ignore')}",
                        position=pos,
                        size=8 + chunk_size,
                        compression_potential=0.3,
                        category="metadata"
                    ))
                
                pos += 8 + chunk_size
                if chunk_size % 2:  # WAV chunks are word-aligned
                    pos += 1
        else:
            # æ±ç”¨æ§‹é€ ã¨ã—ã¦æ‰±ã†
            return self._analyze_generic_structure(data)
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="WAV",
            total_size=len(data),
            elements=elements,
            metadata={"chunks_count": len(elements)},
            structure_hash=structure_hash
        )
    
    def _analyze_generic_structure(self, data: bytes) -> FileStructure:
import bz2
import json
import struct
import hashlib
import pickle
from typing import Dict, List, Tuple, Any, Optional
import time
from dataclasses import dataclass
from enum import Enum

# é«˜åº¦ãªæ§‹é€ è§£æå™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from nexus_sdc_analyzer import AdvancedStructureAnalyzer
except ImportError:
    AdvancedStructureAnalyzer = None

# é«˜åº¦åŒ–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from nexus_sdc_enhanced import EnhancedCompressionAlgorithms
except ImportError:
    EnhancedCompressionAlgorithms = None

# é€²æ—è¡¨ç¤ºã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from progress_display import progress, show_step, show_substep, show_warning, show_error, show_success
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼é–¢æ•°
    class DummyProgress:
        def start_task(self, *args, **kwargs): pass
        def update_progress(self, *args, **kwargs): pass
        def set_substep(self, *args, **kwargs): pass
        def finish_task(self, *args, **kwargs): pass
    
    progress = DummyProgress()
    def show_step(msg): print(f"ğŸ”§ {msg}")
    def show_substep(msg): pass  # è©³ç´°ãƒ­ã‚°ç„¡åŠ¹åŒ–
    def show_warning(msg): print(f"âš ï¸ {msg}")
    def show_error(msg): print(f"âŒ {msg}")
    def show_success(msg): print(f"âœ… {msg}")

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'NXZip-Python'))

class CompressionMethod(Enum):
    """åœ§ç¸®æ–¹æ³•ã®åˆ—æŒ™"""
    LZMA = "lzma"
    ZLIB = "zlib"
    BZ2 = "bz2"
    RAW = "raw"

@dataclass
class StructureElement:
    """æ§‹é€ è¦ç´ ã®å®šç¾©"""
    element_type: str
    position: int
    size: int
    compression_potential: float
    category: str
    compressed_data: Optional[bytes] = None
    compression_method: Optional[CompressionMethod] = None
    compression_ratio: float = 0.0

@dataclass
class FileStructure:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®å®šç¾©"""
    format_type: str
    total_size: int
    elements: List[StructureElement]
    metadata: Dict[str, Any]
    structure_hash: str

class NEXUSSDCEngine:
    """NEXUSæ§‹é€ ç ´å£Šå‹åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.compression_stats = {
            'total_files': 0,
            'total_original_size': 0,
            'total_compressed_size': 0,
            'average_compression_ratio': 0.0
        }
        self.advanced_analyzer = AdvancedStructureAnalyzer() if AdvancedStructureAnalyzer else None
        self.enhanced_algorithms = EnhancedCompressionAlgorithms if EnhancedCompressionAlgorithms else None
    
    def compress_file(self, input_path: str, output_path: str = None) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ç ´å£Šå‹åœ§ç¸®"""
        start_time = time.time()  # é–‹å§‹æ™‚é–“ã‚’è¨˜éŒ²
        
        if output_path is None:
            output_path = input_path + ".sdc"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with open(input_path, 'rb') as f:
            data = f.read()
        
        original_size = len(data)
        file_name = os.path.basename(input_path)
        
        # é€²æ—é–‹å§‹
        progress.start_task(f"æ§‹é€ ç ´å£Šå‹åœ§ç¸®: {file_name}", 100, file_name, original_size)
        
        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: å®Œå…¨æ§‹é€ æŠŠæ¡ (0-30%)
            progress.update_progress(5, "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–‹å§‹")
            show_step(f"åŸã‚µã‚¤ã‚º: {original_size:,} bytes")
            
            progress.update_progress(15, "ğŸ§¬ æ§‹é€ è§£æå®Ÿè¡Œä¸­")
            file_structure = self._analyze_complete_structure(data, input_path)
            show_substep(f"æ§‹é€ è¦ç´ æ•°: {len(file_structure.elements)}")
            progress.update_progress(30, "âœ… æ§‹é€ è§£æå®Œäº†")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: åŸå‹ç ´å£Šåœ§ç¸® (30-80%)
            progress.update_progress(35, "ğŸ’¥ åŸå‹ç ´å£Šåœ§ç¸®é–‹å§‹")
            compressed_structure = self._destructive_compress_with_progress(data, file_structure)
            progress.update_progress(80, "âœ… ç ´å£Šçš„åœ§ç¸®å®Œäº†")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ä¿å­˜ (80-100%)
            progress.update_progress(85, "ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­")
            compressed_size = self._save_compressed_file(compressed_structure, output_path)
            progress.update_progress(100, "âœ… ä¿å­˜å®Œäº†")
            
            # çµ±è¨ˆè¨ˆç®—
            elapsed_time = time.time() - start_time
            compression_ratio = (1 - compressed_size / original_size) * 100
            speed_mbps = (original_size / (1024 * 1024)) / max(elapsed_time, 0.001)
            
            result = {
                'input_path': input_path,
                'output_path': output_path,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'structure_elements': len(file_structure.elements),
                'speed_mbps': speed_mbps
            }
            
            # é€²æ—å®Œäº†
            final_msg = f"åœ§ç¸®ç‡: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,} bytes)"
            progress.finish_task(True, final_msg)
            
            self._print_compression_result(result)
            self._update_stats(result)
            
            return result
            
        except Exception as e:
            progress.finish_task(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def decompress_file(self, input_path: str, output_path: str = None) -> Dict[str, Any]:
        """æ§‹é€ ç ´å£Šå‹åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹"""
        if output_path is None:
            output_path = input_path.replace('.sdc', '')
        
        file_name = os.path.basename(input_path)
        
        # é€²æ—é–‹å§‹
        progress.start_task(f"æ§‹é€ å¾©å…ƒ: {file_name}", 100, file_name)
        
        try:
            # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (0-20%)
            progress.update_progress(5, "ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­")
            compressed_structure = self._load_compressed_file(input_path)
            progress.update_progress(20, "âœ… èª­ã¿è¾¼ã¿å®Œäº†")
            
            # æ§‹é€ å¾©å…ƒ (20-90%)
            progress.update_progress(25, "ğŸ”„ æ§‹é€ å¾©å…ƒé–‹å§‹")
            restored_data = self._restore_structure_with_progress(compressed_structure)
            progress.update_progress(90, "âœ… æ§‹é€ å¾©å…ƒå®Œäº†")
            
            # å¾©å…ƒãƒ‡ãƒ¼ã‚¿ä¿å­˜ (90-100%)
            progress.update_progress(95, "ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­")
            with open(output_path, 'wb') as f:
                f.write(restored_data)
            progress.update_progress(100, "âœ… ä¿å­˜å®Œäº†")
            
            result = {
                'input_path': input_path,
                'output_path': output_path,
                'restored_size': len(restored_data)
            }
            
            # é€²æ—å®Œäº†
            final_msg = f"å¾©å…ƒã‚µã‚¤ã‚º: {len(restored_data):,} bytes"
            progress.finish_task(True, final_msg)
            
            show_success(f"æ§‹é€ å¾©å…ƒå®Œäº†: {len(restored_data):,} bytes")
            
            return result
            
        except Exception as e:
            progress.finish_task(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _analyze_complete_structure(self, data: bytes, file_path: str) -> FileStructure:
        """å®Œå…¨æ§‹é€ æŠŠæ¡ã®å®Ÿè£…ï¼ˆåŸºæœ¬è§£æã®ã¿ä½¿ç”¨ï¼‰"""
        ext = os.path.splitext(file_path)[1].lower()
        
        # åŸºæœ¬è§£æå™¨ã®ã¿ä½¿ç”¨ï¼ˆè©³ç´°ãƒ­ã‚°ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
        if ext in ['.jpg', '.jpeg']:
            return self._analyze_jpeg_structure(data)
        elif ext in ['.png']:
            return self._analyze_png_structure(data)
        elif ext in ['.mp3']:
            return self._analyze_mp3_structure(data)
        elif ext in ['.wav']:
            return self._analyze_wav_structure(data)
        elif ext in ['.mp4', '.avi']:
            return self._analyze_video_structure(data)
        elif ext in ['.7z']:
            return self._analyze_7z_structure(data)
        else:
            return self._analyze_generic_structure(data)
    
    def _convert_to_file_structure(self, analysis_result: Dict) -> FileStructure:
        """é«˜åº¦è§£æçµæœã‚’FileStructureã«å¤‰æ›"""
        elements = []
        
        for element_data in analysis_result['elements']:
            element = StructureElement(
                element_type=element_data['type'],
                position=element_data['position'],
                size=element_data['size'],
                compression_potential=element_data['compression_potential'],
                category=element_data['category']
            )
            elements.append(element)
        
        structure_hash = hashlib.sha256(str(analysis_result).encode()).hexdigest()[:16]
        
        return FileStructure(
            format_type=analysis_result['format'],
            total_size=analysis_result['total_size'],
            elements=elements,
            metadata=analysis_result['metadata'],
            structure_hash=structure_hash
        )
    
    def _analyze_jpeg_structure(self, data: bytes) -> FileStructure:
        """JPEGæ§‹é€ ã®å®Œå…¨æŠŠæ¡"""
        elements = []
        pos = 0
        
        while pos < len(data) - 1:
            if data[pos] == 0xFF:
                marker = data[pos + 1]
                
                if marker == 0xD8:  # SOI
                    element = StructureElement(
                        element_type="JPEG_SOI",
                        position=pos,
                        size=2,
                        compression_potential=0.0,
                        category="header"
                    )
                elif marker == 0xD9:  # EOI
                    element = StructureElement(
                        element_type="JPEG_EOI",
                        position=pos,
                        size=2,
                        compression_potential=0.0,
                        category="footer"
                    )
                elif marker == 0xDA:  # SOS - ç”»åƒãƒ‡ãƒ¼ã‚¿
                    remaining_size = len(data) - pos
                    element = StructureElement(
                        element_type="JPEG_IMAGE_DATA",
                        position=pos,
                        size=remaining_size,
                        compression_potential=0.85,  # é«˜åœ§ç¸®å¯èƒ½
                        category="image_data"
                    )
                    elements.append(element)
                    break
                elif marker in [0xC0, 0xC1, 0xC2]:  # SOF
                    length = (data[pos + 2] << 8) | data[pos + 3] if pos + 3 < len(data) else 4
                    element = StructureElement(
                        element_type="JPEG_SOF",
                        position=pos,
                        size=length + 2,
                        compression_potential=0.1,
                        category="metadata"
                    )
                else:
                    # ãã®ä»–ã®ãƒãƒ¼ã‚«ãƒ¼
                    length = (data[pos + 2] << 8) | data[pos + 3] if pos + 3 < len(data) else 4
                    element = StructureElement(
                        element_type=f"JPEG_MARKER_0x{marker:02X}",
                        position=pos,
                        size=length + 2,
                        compression_potential=0.2,
                        category="metadata"
                    )
                
                elements.append(element)
                pos += element.size
            else:
                pos += 1
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="JPEG",
            total_size=len(data),
            elements=elements,
            metadata={"markers_count": len(elements)},
            structure_hash=structure_hash
        )
    
    def _analyze_png_structure(self, data: bytes) -> FileStructure:
        """PNGæ§‹é€ ã®å®Œå…¨æŠŠæ¡"""
        elements = []
        
        # PNG signature
        if data[:8] == b'\x89PNG\r\n\x1a\n':
            elements.append(StructureElement(
                element_type="PNG_SIGNATURE",
                position=0,
                size=8,
                compression_potential=0.0,
                category="header"
            ))
        
        pos = 8
        while pos < len(data) - 8:
            length = struct.unpack('>I', data[pos:pos+4])[0]
            chunk_type = data[pos+4:pos+8].decode('ascii', errors='ignore')
            
            compression_potential = 0.8 if chunk_type == 'IDAT' else 0.1
            category = "image_data" if chunk_type == 'IDAT' else "metadata"
            
            element = StructureElement(
                element_type=f"PNG_CHUNK_{chunk_type}",
                position=pos,
                size=length + 12,
                compression_potential=compression_potential,
                category=category
            )
            
            elements.append(element)
            pos += element.size
            
            if chunk_type == 'IEND':
                break
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="PNG",
            total_size=len(data),
            elements=elements,
            metadata={"chunks_count": len(elements)},
            structure_hash=structure_hash
        )
    
    def _analyze_7z_structure(self, data: bytes) -> FileStructure:
        """7-Zipæ§‹é€ ã®å®Œå…¨æŠŠæ¡ï¼ˆäºŒé‡åœ§ç¸®å¯¾å¿œï¼‰"""
        elements = []
        
        # 7-Zip signature check
        if data[:6] == b'7z\xbc\xaf\x27\x1c':
            # Header
            elements.append(StructureElement(
                element_type="7Z_SIGNATURE",
                position=0,
                size=32,  # æ¨™æº–ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚º
                compression_potential=0.0,
                category="header"
            ))
            
            # æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’é«˜åœ§ç¸®å¯èƒ½ã¨ã—ã¦æ‰±ã†
            remaining_size = len(data) - 32
            if remaining_size > 0:
                elements.append(StructureElement(
                    element_type="7Z_COMPRESSED_DATA",
                    position=32,
                    size=remaining_size,
                    compression_potential=0.88,  # æ—¢åœ§ç¸®ã ãŒæ§‹é€ ç ´å£Šã§æ›´ã«åœ§ç¸®å¯èƒ½
                    category="compressed_data"
                ))
        else:
            # æ±ç”¨æ§‹é€ ã¨ã—ã¦æ‰±ã†
            return self._analyze_generic_structure(data)
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="7ZIP",
            total_size=len(data),
            elements=elements,
            metadata={"is_pre_compressed": True},
            structure_hash=structure_hash
        )
    
    def _analyze_mp3_structure(self, data: bytes) -> FileStructure:
        """MP3æ§‹é€ ã®ç°¡ç•¥è§£æï¼ˆãƒ–ãƒ­ãƒƒã‚¯å˜ä½ï¼‰"""
        elements = []
        
        # ID3ã‚¿ã‚°è§£æ
        pos = 0
        if len(data) >= 10 and data[:3] == b'ID3':
            tag_size = struct.unpack('>I', b'\x00' + data[6:9])[0]
            elements.append(StructureElement(
                element_type="ID3v2_TAG",
                position=0,
                size=tag_size + 10,
                compression_potential=0.4,
                category="metadata"
            ))
            pos = tag_size + 10
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å¤§ããªãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ å˜ä½ã§ãªãï¼‰
        remaining_size = len(data) - pos
        if remaining_size > 0:
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’æœ€å¤§10ãƒ–ãƒ­ãƒƒã‚¯ã«åˆ†å‰²
            block_count = min(10, max(1, remaining_size // 50000))  # 50KBä»¥ä¸Šã§åˆ†å‰²
            block_size = remaining_size // block_count
            
            for i in range(block_count):
                start_pos = pos + (i * block_size)
                if i == block_count - 1:
                    # æœ€å¾Œã®ãƒ–ãƒ­ãƒƒã‚¯ã¯æ®‹ã‚Šå…¨ã¦
                    size = remaining_size - (i * block_size)
                else:
                    size = block_size
                
                elements.append(StructureElement(
                    element_type=f"MP3_AUDIO_BLOCK_{i}",
                    position=start_pos,
                    size=size,
                    compression_potential=0.75,
                    category="audio_data"
                ))
        
        # ID3v1ã‚¿ã‚°ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ï¼‰
        if len(data) >= 128 and data[-128:-125] == b'TAG':
            elements.append(StructureElement(
                element_type="ID3v1_TAG",
                position=len(data) - 128,
                size=128,
                compression_potential=0.6,
                category="metadata"
            ))
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="MP3",
            total_size=len(data),
            elements=elements,
            metadata={"audio_blocks": len([e for e in elements if e.category == "audio_data"])},
            structure_hash=structure_hash
        )
    
    def _analyze_video_structure(self, data: bytes) -> FileStructure:
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ è§£æï¼ˆåŸºæœ¬ç‰ˆï¼‰"""
        elements = []
        
        # MP4/QuickTime format check
        if len(data) >= 8:
            atom_type = data[4:8].decode('ascii', errors='ignore')
            
            if atom_type in ['ftyp', 'mdat', 'moov']:
                pos = 0
                while pos < len(data) and len(elements) < 20:  # åˆ¶é™
                    if pos + 8 > len(data):
                        break
                    
                    size = struct.unpack('>I', data[pos:pos+4])[0]
                    atom_type = data[pos+4:pos+8].decode('ascii', errors='ignore')
                    
                    compression_potential = 0.75 if atom_type == 'mdat' else 0.3
                    category = "video_data" if atom_type == 'mdat' else "metadata"
                    
                    element = StructureElement(
                        element_type=f"VIDEO_ATOM_{atom_type}",
                        position=pos,
                        size=max(size, 8),
                        compression_potential=compression_potential,
                        category=category
                    )
                    
                    elements.append(element)
                    pos += element.size
        
        # If not recognized as MP4, treat as generic video
        if not elements:
            chunk_size = len(data) // 10
            for i in range(10):
                element = StructureElement(
                    element_type=f"VIDEO_CHUNK_{i}",
                    position=i * chunk_size,
                    size=chunk_size if i < 9 else len(data) - (i * chunk_size),
                    compression_potential=0.6,
                    category="video_data"
                )
                elements.append(element)
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="VIDEO",
            total_size=len(data),
            elements=elements,
            metadata={"atom_count": len(elements)},
            structure_hash=structure_hash
        )
        """æ±ç”¨æ§‹é€ ã®å®Œå…¨æŠŠæ¡"""
        elements = []
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        chunk_size = min(32768, len(data) // 8) or len(data)
        pos = 0
        chunk_id = 0
        
        while pos < len(data):
            current_size = min(chunk_size, len(data) - pos)
            chunk_data = data[pos:pos + current_size]
            
            # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ã§åœ§ç¸®å¯èƒ½æ€§æ¨å®š
            compression_potential = self._calculate_entropy_compression_potential(chunk_data)
            
            element = StructureElement(
                element_type=f"GENERIC_CHUNK_{chunk_id}",
                position=pos,
                size=current_size,
                compression_potential=compression_potential,
                category="data"
            )
            
            elements.append(element)
            pos += current_size
            chunk_id += 1
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type="GENERIC",
            total_size=len(data),
            elements=elements,
            metadata={"chunks_count": len(elements)},
            structure_hash=structure_hash
        )
    
    def _calculate_entropy_compression_potential(self, data: bytes) -> float:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ™ãƒ¼ã‚¹ã®åœ§ç¸®å¯èƒ½æ€§è¨ˆç®—"""
        if len(data) == 0:
            return 0.0
        
        # ãƒã‚¤ãƒˆé »åº¦è¨ˆç®—
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
        import math
        entropy = 0
        for count in byte_counts:
            if count > 0:
                p = count / len(data)
                entropy -= p * math.log2(p)
        
        # åœ§ç¸®å¯èƒ½æ€§ã«å¤‰æ›ï¼ˆ0-1ã®ç¯„å›²ï¼‰
        max_entropy = 8.0
        compression_potential = min(0.95, max(0.1, 1.0 - (entropy / max_entropy)))
        
        return compression_potential
    
    def _destructive_compress_with_progress(self, data: bytes, structure: FileStructure) -> FileStructure:
        """é€²æ—è¡¨ç¤ºä»˜ãåŸå‹ç ´å£Šåœ§ç¸®"""
        show_step("åŸå‹ç ´å£Šåœ§ç¸®å®Ÿè¡Œä¸­...")
        
        total_elements = len(structure.elements)
        total_compression_ratio = 0.0
        processed_bytes = 0
        
        for i, element in enumerate(structure.elements):
            # é€²æ—æ›´æ–°ï¼ˆè©³ç´°ãƒ­ã‚°ãªã—ï¼‰
            element_progress = 30 + int((i / total_elements) * 50)  # 30-80%ã®ç¯„å›²
            progress.update_progress(element_progress, bytes_processed=processed_bytes)
            
            # è¦ç´ ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆãƒ­ã‚°å‡ºåŠ›ãªã—ï¼‰
            element_data = data[element.position:element.position + element.size]
            
            # é«˜åº¦åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            if self.enhanced_algorithms and element.compression_potential > 0.5:
                try:
                    compressed, method = self.enhanced_algorithms.adaptive_compress(
                        element_data, element.compression_potential
                    )
                    element.compression_method = CompressionMethod.RAW  # å¾Œã§ä¸Šæ›¸ã
                    element.compressed_data = compressed
                    
                    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚½ãƒƒãƒ‰ã®å ´åˆã¯ç‰¹åˆ¥å‡¦ç†
                    if method in ['custom_high', 'destructive', 'lzma_enhanced', 'zlib_enhanced', 'bz2_enhanced']:
                        element.custom_method = method
                    
                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ã¿è¡¨ç¤º
                    if i == 0:  # æœ€åˆã®è¦ç´ ã§ã®ã¿è­¦å‘Šè¡¨ç¤º
                        show_warning(f"é«˜åº¦åŒ–åœ§ç¸®å¤±æ•—ã€æ¨™æº–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    compressed, method = self._standard_compress(element_data, element.compression_potential)
                    element.compressed_data = compressed
                    element.compression_method = CompressionMethod(method)
            else:
                # æ¨™æº–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
                compressed, method = self._standard_compress(element_data, element.compression_potential)
                element.compressed_data = compressed
                element.compression_method = CompressionMethod(method)
            
            # åœ§ç¸®åŠ¹æœãƒã‚§ãƒƒã‚¯
            if len(element.compressed_data) >= len(element_data) * 0.95:
                element.compressed_data = element_data
                element.compression_method = CompressionMethod.RAW
                if hasattr(element, 'custom_method'):
                    delattr(element, 'custom_method')
            
            element.compression_ratio = (1 - len(element.compressed_data) / len(element_data)) * 100
            total_compression_ratio += element.compression_ratio * element.size
            processed_bytes += element.size
        
        # å…¨ä½“åœ§ç¸®ç‡ã®è¨ˆç®—
        weighted_compression = total_compression_ratio / structure.total_size
        show_success(f"è¦ç´ åˆ¥å¹³å‡åœ§ç¸®ç‡: {weighted_compression:.1f}%")
        
        return structure
    
    def _standard_compress(self, data: bytes, compression_potential: float) -> Tuple[bytes, str]:
        """æ¨™æº–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
        if compression_potential > 0.7:
            # é«˜åœ§ç¸®å¯èƒ½ï¼šLZMAä½¿ç”¨
            compressed = lzma.compress(data, preset=9)
            method = "lzma"
        elif compression_potential > 0.3:
            # ä¸­åœ§ç¸®å¯èƒ½ï¼šzlibä½¿ç”¨
            compressed = zlib.compress(data, level=9)
            method = "zlib"
        elif compression_potential > 0.1:
            # ä½åœ§ç¸®å¯èƒ½ï¼šbz2ä½¿ç”¨
            compressed = bz2.compress(data, compresslevel=9)
            method = "bz2"
        else:
            # åœ§ç¸®åŠ¹æœãªã—ï¼šç”Ÿãƒ‡ãƒ¼ã‚¿
            compressed = data
            method = "raw"
        
        return compressed, method
    
    def _save_compressed_file(self, structure: FileStructure, output_path: str) -> int:
        """åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        # SDCãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ä¿å­˜
        sdc_data = {
            'magic': b'NEXUS_SDC_V1',
            'format_type': structure.format_type,
            'total_size': structure.total_size,
            'structure_hash': structure.structure_hash,
            'metadata': structure.metadata,
            'elements': []
        }
        
        for element in structure.elements:
            element_info = {
                'type': element.element_type,
                'position': element.position,
                'size': element.size,
                'category': element.category,
                'compression_method': element.compression_method.value,
                'compressed_data': element.compressed_data,
                'custom_method': getattr(element, 'custom_method', None)
            }
            sdc_data['elements'].append(element_info)
        
        # ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ä¿å­˜
        with open(output_path, 'wb') as f:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
            f.write(sdc_data['magic'])
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’Pickleã§ä¿å­˜
            metadata_bytes = pickle.dumps({
                'format_type': sdc_data['format_type'],
                'total_size': sdc_data['total_size'],
                'structure_hash': sdc_data['structure_hash'],
                'metadata': sdc_data['metadata'],
                'elements_count': len(sdc_data['elements'])
            })
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã¨ãƒ‡ãƒ¼ã‚¿
            f.write(struct.pack('<I', len(metadata_bytes)))
            f.write(metadata_bytes)
            
            # å„è¦ç´ ã®åœ§ç¸®ãƒ‡ãƒ¼ã‚¿
            for element_info in sdc_data['elements']:
                element_header = pickle.dumps({
                    'type': element_info['type'],
                    'position': element_info['position'],
                    'size': element_info['size'],
                    'category': element_info['category'],
                    'compression_method': element_info['compression_method'],
                    'custom_method': element_info['custom_method']
                })
                
                f.write(struct.pack('<I', len(element_header)))
                f.write(element_header)
                f.write(struct.pack('<I', len(element_info['compressed_data'])))
                f.write(element_info['compressed_data'])
        
        compressed_size = os.path.getsize(output_path)
        print(f"ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {compressed_size:,} bytes")
        
        return compressed_size
    
    def _load_compressed_file(self, file_path: str) -> FileStructure:
        """åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        elements = []
        
        with open(file_path, 'rb') as f:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ç¢ºèª
            magic = f.read(12)
            if magic != b'NEXUS_SDC_V1':
                raise ValueError("Invalid SDC file format")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            metadata_size = struct.unpack('<I', f.read(4))[0]
            metadata = pickle.loads(f.read(metadata_size))
            
            # å„è¦ç´ ã®èª­ã¿è¾¼ã¿
            for _ in range(metadata['elements_count']):
                header_size = struct.unpack('<I', f.read(4))[0]
                element_header = pickle.loads(f.read(header_size))
                
                data_size = struct.unpack('<I', f.read(4))[0]
                compressed_data = f.read(data_size)
                
                element = StructureElement(
                    element_type=element_header['type'],
                    position=element_header['position'],
                    size=element_header['size'],
                    compression_potential=0.0,  # å¾©å…ƒæ™‚ã¯ä¸è¦
                    category=element_header['category'],
                    compressed_data=compressed_data,
                    compression_method=CompressionMethod(element_header['compression_method'])
                )
                
                # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚½ãƒƒãƒ‰ã®å¾©å…ƒ
                if element_header.get('custom_method'):
                    element.custom_method = element_header['custom_method']
                
                elements.append(element)
        
        return FileStructure(
            format_type=metadata['format_type'],
            total_size=metadata['total_size'],
            elements=elements,
            metadata=metadata['metadata'],
            structure_hash=metadata['structure_hash']
        )
    
    def _restore_structure_with_progress(self, structure: FileStructure) -> bytes:
        """é€²æ—è¡¨ç¤ºä»˜ãæ§‹é€ å¾©å…ƒ"""
        show_step("æ§‹é€ å¾©å…ƒå®Ÿè¡Œä¸­...")
        
        # å¾©å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡
        restored_data = bytearray(structure.total_size)
        total_elements = len(structure.elements)
        processed_bytes = 0
        
        for i, element in enumerate(structure.elements):
            # é€²æ—æ›´æ–°ï¼ˆè©³ç´°ãƒ­ã‚°ãªã—ï¼‰
            element_progress = 20 + int((i / total_elements) * 70)  # 20-90%ã®ç¯„å›²
            progress.update_progress(element_progress, bytes_processed=processed_bytes)
            
            # ã‚«ã‚¹ã‚¿ãƒ åœ§ç¸®ãƒ¡ã‚½ãƒƒãƒ‰ã®ãƒã‚§ãƒƒã‚¯
            if hasattr(element, 'custom_method') and self.enhanced_algorithms:
                try:
                    decompressed = self.enhanced_algorithms.enhanced_decompress(
                        element.compressed_data, element.custom_method
                    )
                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ã¿è¡¨ç¤º
                    if i == 0:  # æœ€åˆã®è¦ç´ ã§ã®ã¿è­¦å‘Šè¡¨ç¤º
                        show_warning(f"ã‚«ã‚¹ã‚¿ãƒ å±•é–‹å¤±æ•—ã€æ¨™æº–å±•é–‹ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    decompressed = self._standard_decompress(element)
            else:
                decompressed = self._standard_decompress(element)
            
            # å…ƒã®ä½ç½®ã«å¾©å…ƒ
            end_pos = element.position + element.size
            if len(decompressed) == element.size:
                restored_data[element.position:end_pos] = decompressed
            else:
                if i == 0:  # ã‚µã‚¤ã‚ºä¸ä¸€è‡´ã¯æœ€åˆã®ã¿è­¦å‘Š
                    show_warning(f"ã‚µã‚¤ã‚ºä¸ä¸€è‡´: æœŸå¾…å€¤{element.size}, å®Ÿéš›{len(decompressed)}")
                # ã‚µã‚¤ã‚ºèª¿æ•´
                if len(decompressed) > element.size:
                    restored_data[element.position:end_pos] = decompressed[:element.size]
                else:
                    restored_data[element.position:element.position + len(decompressed)] = decompressed
            
            processed_bytes += element.size
        
        return bytes(restored_data)
    
    def _standard_decompress(self, element: StructureElement) -> bytes:
        """æ¨™æº–å±•é–‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
        if element.compression_method == CompressionMethod.LZMA:
            return lzma.decompress(element.compressed_data)
        elif element.compression_method == CompressionMethod.ZLIB:
            return zlib.decompress(element.compressed_data)
        elif element.compression_method == CompressionMethod.BZ2:
            return bz2.decompress(element.compressed_data)
        else:  # RAW
            return element.compressed_data
    
    def _print_compression_result(self, result: Dict[str, Any]):
        """åœ§ç¸®çµæœã®è¡¨ç¤º"""
        print(f"\nğŸ“Š æ§‹é€ ç ´å£Šå‹åœ§ç¸®å®Œäº†")
        print(f"ğŸ“ å…¥åŠ›: {os.path.basename(result['input_path'])}")
        print(f"ğŸ’¾ åŸã‚µã‚¤ã‚º: {result['original_size']:,} bytes")
        print(f"ğŸ—œï¸  åœ§ç¸®ã‚µã‚¤ã‚º: {result['compressed_size']:,} bytes")
        print(f"ğŸ¯ åœ§ç¸®ç‡: {result['compression_ratio']:.1f}%")
        print(f"âš¡ åœ§ç¸®é€Ÿåº¦: {result['speed_mbps']:.1f} MB/s")
        print(f"ğŸ§¬ æ§‹é€ è¦ç´ : {result['structure_elements']}å€‹")
        
        if result['compression_ratio'] > 80:
            print("âœ¨ é©å‘½çš„åœ§ç¸®é”æˆï¼")
        elif result['compression_ratio'] > 60:
            print("ğŸ¯ é«˜åœ§ç¸®ç‡é”æˆï¼")
        else:
            print("ğŸ“ˆ æ¨™æº–åœ§ç¸®å®Œäº†")
    
    def _update_stats(self, result: Dict[str, Any]):
        """çµ±è¨ˆæƒ…å ±ã®æ›´æ–°"""
        self.compression_stats['total_files'] += 1
        self.compression_stats['total_original_size'] += result['original_size']
        self.compression_stats['total_compressed_size'] += result['compressed_size']
        
        total_compression = (1 - self.compression_stats['total_compressed_size'] / 
                           self.compression_stats['total_original_size']) * 100
        self.compression_stats['average_compression_ratio'] = total_compression
    
    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã®å–å¾—"""
        return self.compression_stats.copy()

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NEXUS SDC - æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³')
    parser.add_argument('command', choices=['compress', 'decompress', 'test'], 
                       help='å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰')
    parser.add_argument('file', nargs='?', help='å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('-o', '--output', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å')
    
    args = parser.parse_args()
    
    engine = NEXUSSDCEngine()
    
    if args.command == 'test':
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        sample_dir = os.path.join(os.path.dirname(__file__), '..', 'NXZip-Python', 'sample')
        if os.path.exists(sample_dir):
            print("ğŸ§ª NEXUS SDC ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
            print("=" * 60)
            
            test_files = []
            for root, dirs, files in os.walk(sample_dir):
                for file in files:
                    if not file.endswith(('.nxz', '.sdc')) and not file.startswith('.'):
                        full_path = os.path.join(root, file)
                        # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
                        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.mp3', '.mp4', '.wav')):
                            test_files.insert(0, full_path)  # å…ˆé ­ã«è¿½åŠ 
                        else:
                            test_files.append(full_path)
            
            test_count = min(3, len(test_files))
            show_step(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {test_count}å€‹")
            
            for i, test_file in enumerate(test_files[:test_count]):
                try:
                    show_step(f"ãƒ†ã‚¹ãƒˆ {i+1}/{test_count}: {os.path.basename(test_file)}")
                    
                    # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
                    result = engine.compress_file(test_file)
                    
                    # å¯é€†æ€§ãƒ†ã‚¹ãƒˆ
                    show_step("å¯é€†æ€§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­")
                    engine.decompress_file(result['output_path'])
                    show_success("å¯é€†æ€§ç¢ºèªå®Œäº†")
                    
                    print()  # åŒºåˆ‡ã‚Š
                    
                except Exception as e:
                    show_error(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                    print()
            
            stats = engine.get_stats()
            print("ğŸ“Š ç·åˆãƒ†ã‚¹ãƒˆçµæœ")
            print("=" * 60)
            print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}")
            print(f"ğŸ“Š å¹³å‡åœ§ç¸®ç‡: {stats['average_compression_ratio']:.1f}%")
            print(f"ğŸ’¾ ç·å‡¦ç†ã‚µã‚¤ã‚º: {stats['total_original_size']:,} bytes")
            print(f"ğŸ—œï¸ ç·åœ§ç¸®ã‚µã‚¤ã‚º: {stats['total_compressed_size']:,} bytes")
        else:
            show_error("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    elif args.command == 'compress':
        if not args.file:
            print("âŒ åœ§ç¸®ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return
        
        engine.compress_file(args.file, args.output)
    
    elif args.command == 'decompress':
        if not args.file:
            print("âŒ å±•é–‹ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
            return
        
        engine.decompress_file(args.file, args.output)

if __name__ == "__main__":
    main()

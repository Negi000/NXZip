#!/usr/bin/env python3
"""
æ”¹è‰¯ç‰ˆåŒ…æ‹¬çš„åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ vs è»½é‡ãƒ¢ãƒ¼ãƒ‰ vs Zstandard vs 7Zipï¼ˆä¿®æ­£ç‰ˆï¼‰
"""

import time
import tempfile
import os
import sys
import hashlib
import io
from pathlib import Path
import zstandard as zstd
import py7zr

# NEXUS TMC ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append('.')
from lightweight_mode import NEXUSTMCLightweight

class AdvancedCompressionBenchmark:
    """æ”¹è‰¯ç‰ˆåœ§ç¸®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.nexus_light = NEXUSTMCLightweight()
        self.results = {}
        
    def test_7zip_fixed(self, data):
        """ä¿®æ­£ç‰ˆ7Zipåœ§ç¸®ãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ¡ãƒ¢ãƒªä¸Šã§7Zipæ“ä½œ
            compressed_buffer = io.BytesIO()
            
            # åœ§ç¸®
            start_time = time.perf_counter()
            with py7zr.SevenZipFile(compressed_buffer, 'w') as archive:
                archive.writestr(data, 'test_data')
            compression_time = time.perf_counter() - start_time
            
            # åœ§ç¸®ã‚µã‚¤ã‚ºå–å¾—
            compressed_size = len(compressed_buffer.getvalue())
            compressed_buffer.seek(0)
            
            # å±•é–‹
            start_time = time.perf_counter()
            with py7zr.SevenZipFile(compressed_buffer, 'r') as archive:
                extracted = archive.read()
                decompressed = extracted['test_data'].read()
            decompression_time = time.perf_counter() - start_time
            
            # å¯é€†æ€§ãƒã‚§ãƒƒã‚¯
            integrity_ok = (decompressed == data)
            
            return {
                'compressed_size': compressed_size,
                'compression_time': compression_time,
                'decompression_time': decompression_time,
                'compression_ratio': compressed_size / len(data),
                'compression_speed': len(data) / (1024 * 1024 * compression_time) if compression_time > 0 else 0,
                'decompression_speed': len(data) / (1024 * 1024 * decompression_time) if decompression_time > 0 else 0,
                'integrity_ok': integrity_ok,
                'total_time': compression_time + decompression_time
            }
        except Exception as e:
            return {'error': str(e)}
    
    def run_ultimate_benchmark(self):
        """æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸš€ æœ€çµ‚åŒ…æ‹¬è©•ä¾¡: NEXUS TMC vs æ¥­ç•Œæ¨™æº–")
        print("="*80)
        
        # ã‚ˆã‚Šå®Ÿç”¨çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        test_datasets = self.create_realistic_datasets()
        
        engines = {
            'Zstandard ãƒ¬ãƒ™ãƒ«1': lambda data: self.test_zstandard(data, level=1),
            'Zstandard ãƒ¬ãƒ™ãƒ«3': lambda data: self.test_zstandard(data, level=3),
            'Zstandard ãƒ¬ãƒ™ãƒ«6': lambda data: self.test_zstandard(data, level=6),
            '7Zip LZMA2': self.test_7zip_fixed,
            'NEXUSè»½é‡': self.test_nexus_lightweight,
        }
        
        all_results = {}
        
        for dataset_name, data in test_datasets.items():
            print(f"\nğŸ“Š {dataset_name} ({len(data):,} bytes)")
            print("-" * 60)
            
            dataset_results = {}
            
            for engine_name, test_func in engines.items():
                try:
                    result = test_func(data)
                    
                    if 'error' in result:
                        print(f"   {engine_name:18} âŒ {result['error']}")
                        continue
                    
                    dataset_results[engine_name] = result
                    
                    # è©³ç´°çµæœè¡¨ç¤º
                    ratio = result['compression_ratio']
                    comp_speed = result['compression_speed']
                    decomp_speed = result['decompression_speed']
                    integrity = "âœ…" if result['integrity_ok'] else "âŒ"
                    space_saved = (1 - ratio) * 100
                    
                    print(f"   {engine_name:18} {integrity} "
                          f"åœ§ç¸®ç‡:{ratio:6.3f} å‰Šæ¸›:{space_saved:5.1f}% "
                          f"åœ§ç¸®:{comp_speed:6.1f}MB/s å±•é–‹:{decomp_speed:6.1f}MB/s")
                    
                except Exception as e:
                    print(f"   {engine_name:18} âŒ ä¾‹å¤–: {e}")
            
            all_results[dataset_name] = dataset_results
        
        return all_results
    
    def create_realistic_datasets(self):
        """å®Ÿç”¨çš„ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
        datasets = {}
        
        # 1. å¤§è¦æ¨¡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ–°èè¨˜äº‹é¢¨ï¼‰
        article_template = """
        ã€é€Ÿå ±ã€‘{topic}ã«é–¢ã™ã‚‹é‡è¦ãªç™ºè¡¨ãŒè¡Œã‚ã‚Œã¾ã—ãŸ

        {date}ã€æ”¿åºœã¯{topic}ã«ã¤ã„ã¦è¨˜è€…ä¼šè¦‹ã‚’é–‹ãã€ä»Šå¾Œã®æ–¹é‡ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚
        
        ç™ºè¡¨å†…å®¹ã®è¦ç‚¹ï¼š
        - {point1}
        - {point2}  
        - {point3}
        - å®Ÿæ–½æ™‚æœŸï¼š{timeline}
        - å¯¾è±¡ï¼š{target}
        
        å°‚é–€å®¶ã®{expert}æ°ã¯ã€Œã“ã®ç™ºè¡¨ã¯{impact}ã«å¤§ããªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã§ã—ã‚‡ã†ã€ã¨ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ã„ã¾ã™ã€‚
        
        é–¢é€£ã™ã‚‹{category}æ¥­ç•Œã§ã¯ã€ã™ã§ã«å¯¾å¿œç­–ã®æ¤œè¨ãŒå§‹ã¾ã£ã¦ãŠã‚Šã€
        ä»Šå¾Œæ•°ãƒ¶æœˆé–“ã®å‹•å‘ãŒæ³¨ç›®ã•ã‚Œã¦ã„ã¾ã™ã€‚
        
        è©³ç´°ãªæƒ…å ±ã«ã¤ã„ã¦ã¯ã€å…¬å¼ã‚µã‚¤ãƒˆï¼ˆhttps://example.gov.jp/{slug}ï¼‰ã§
        ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
        
        å•ã„åˆã‚ã›å…ˆï¼š
        é›»è©±ï¼š03-1234-5678
        ãƒ¡ãƒ¼ãƒ«ï¼šinfo@example.gov.jp
        å—ä»˜æ™‚é–“ï¼šå¹³æ—¥9:00-17:00
        """
        
        news_data = ""
        topics = ["çµŒæ¸ˆæ”¿ç­–", "ç’°å¢ƒå¯¾ç­–", "æ•™è‚²æ”¹é©", "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "å›½éš›é–¢ä¿‚"]
        for i in range(500):
            topic = topics[i % len(topics)]
            article = article_template.format(
                topic=topic,
                date=f"2024å¹´{(i%12)+1}æœˆ{(i%28)+1}æ—¥",
                point1=f"{topic}ã®åŸºæœ¬æ–¹é‡ç­–å®š",
                point2=f"äºˆç®—{(i+1)*10}å„„å††ã®ç¢ºä¿",
                point3=f"é–¢é€£æ³•æ¡ˆã®{(i%2 and 'æ”¹æ­£' or 'æ–°è¨­')}",
                timeline=f"{2024+(i//100)}å¹´åº¦ã‹ã‚‰æ®µéšçš„å®Ÿæ–½",
                target=f"å…¨å›½{(i%47)+1}éƒ½é“åºœçœŒ",
                expert=f"ç”°ä¸­{i%10}",
                impact=f"{topic}åˆ†é‡",
                category=f"{topic}é–¢é€£",
                slug=f"{topic.lower()}-{i:03d}"
            )
            news_data += article
        
        datasets['å¤§è¦æ¨¡ãƒ‹ãƒ¥ãƒ¼ã‚¹'] = news_data.encode('utf-8')
        
        # 2. ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
        code_template = '''
class DataProcessor{idx}:
    """
    ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¯ãƒ©ã‚¹ç¬¬{idx}ç‰ˆ
    
    ã“ã®ã‚¯ãƒ©ã‚¹ã¯æ§˜ã€…ãªå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—ã€
    åŠ¹ç‡çš„ãªå¤‰æ›ã¨åˆ†æã‚’æä¾›ã—ã¾ã™ã€‚
    
    Attributes:
        data_store (list): ãƒ‡ãƒ¼ã‚¿æ ¼ç´ç”¨ãƒªã‚¹ãƒˆ
        processed_count (int): å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿æ•°
        error_log (list): ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
    """
    
    def __init__(self, initial_capacity=1000):
        self.data_store = []
        self.processed_count = 0
        self.error_log = []
        self.capacity = initial_capacity
        self.metadata = {{
            'created_at': time.time(),
            'version': '{idx}',
            'status': 'initialized'
        }}
    
    def add_data(self, item, category='default'):
        """ãƒ‡ãƒ¼ã‚¿è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰"""
        try:
            if len(self.data_store) >= self.capacity:
                self._expand_capacity()
            
            processed_item = {{
                'id': len(self.data_store),
                'data': item,
                'category': category,
                'timestamp': time.time(),
                'checksum': hashlib.md5(str(item).encode()).hexdigest()
            }}
            
            self.data_store.append(processed_item)
            return processed_item['id']
            
        except Exception as e:
            self.error_log.append({{
                'error': str(e),
                'timestamp': time.time(),
                'method': 'add_data'
            }})
            return None
    
    def process_batch(self, batch_size=100):
        """ãƒãƒƒãƒå‡¦ç†ãƒ¡ã‚½ãƒƒãƒ‰"""
        results = []
        start_idx = self.processed_count
        end_idx = min(start_idx + batch_size, len(self.data_store))
        
        for i in range(start_idx, end_idx):
            item = self.data_store[i]
            try:
                # è¤‡é›‘ãªå‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                processed_value = self._complex_calculation(item['data'])
                
                result = {{
                    'original_id': item['id'],
                    'processed_value': processed_value,
                    'processing_time': time.time() - item['timestamp'],
                    'success': True
                }}
                
                results.append(result)
                self.processed_count += 1
                
            except Exception as e:
                self.error_log.append({{
                    'error': str(e),
                    'item_id': item['id'],
                    'timestamp': time.time()
                }})
        
        return results
    
    def _complex_calculation(self, data):
        """è¤‡é›‘ãªè¨ˆç®—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        if isinstance(data, (int, float)):
            # æ•°å€¤å‡¦ç†
            result = data * 2.71828 + 3.14159
            result = result ** 0.5 if result > 0 else 0
            return round(result, 6)
        elif isinstance(data, str):
            # æ–‡å­—åˆ—å‡¦ç†
            return {{
                'length': len(data),
                'hash': hashlib.sha256(data.encode()).hexdigest()[:16],
                'uppercase_ratio': sum(1 for c in data if c.isupper()) / len(data) if data else 0
            }}
        else:
            # ãã®ä»–ã®å‡¦ç†
            return {{'type': type(data).__name__, 'str_repr': str(data)[:100]}}
    
    def _expand_capacity(self):
        """å®¹é‡æ‹¡å¼µãƒ¡ã‚½ãƒƒãƒ‰"""
        old_capacity = self.capacity
        self.capacity = int(self.capacity * 1.5)
        print(f"å®¹é‡ã‚’{{old_capacity}}ã‹ã‚‰{{self.capacity}}ã«æ‹¡å¼µã—ã¾ã—ãŸ")
    
    def get_statistics(self):
        """çµ±è¨ˆæƒ…å ±å–å¾—"""
        return {{
            'total_items': len(self.data_store),
            'processed_items': self.processed_count,
            'error_count': len(self.error_log),
            'capacity': self.capacity,
            'processing_rate': self.processed_count / len(self.data_store) if self.data_store else 0
        }}

# ä½¿ç”¨ä¾‹{idx}
if __name__ == "__main__":
    processor = DataProcessor{idx}()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    test_data = [
        {{'value': i, 'category': f'type_{{i % 5}}', 'priority': i % 3}}
        for i in range(1000)
    ]
    
    for item in test_data:
        processor.add_data(item)
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    while processor.processed_count < len(processor.data_store):
        batch_results = processor.process_batch()
        print(f"ãƒãƒƒãƒå‡¦ç†å®Œäº†: {{len(batch_results)}}ä»¶")
    
    # æœ€çµ‚çµ±è¨ˆ
    stats = processor.get_statistics()
    print(f"å‡¦ç†å®Œäº†: {{stats}}")
'''
        
        source_code = ""
        for i in range(150):
            source_code += code_template.format(idx=i)
        
        datasets['ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰'] = source_code.encode('utf-8')
        
        # 3. æ§‹é€ åŒ–ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
        log_template = "[{timestamp}] {level:5} {component:15} | {message} | user:{user} session:{session} ip:{ip} size:{size}KB duration:{duration}ms"
        
        import random
        random.seed(42)
        log_data = []
        
        components = ["WebServer", "Database", "Cache", "Auth", "API", "FileSystem", "Queue", "Monitor"]
        levels = ["INFO", "WARN", "ERROR", "DEBUG", "TRACE"]
        messages = [
            "Request processed successfully",
            "Cache hit for key: cache_key_placeholder",
            "Database query executed", 
            "File uploaded to storage",
            "User authentication failed",
            "Connection timeout detected",
            "Memory usage warning",
            "Backup operation completed"
        ]
        
        for i in range(5000):
            timestamp = f"2024-07-{(i%30)+1:02d} {(i%24):02d}:{(i*17%60):02d}:{(i*31%60):02d}.{i%1000:03d}"
            level = levels[i % len(levels)]
            component = components[i % len(components)]
            base_message = messages[i % len(messages)]
            if "cache_key_placeholder" in base_message:
                message = base_message.replace("cache_key_placeholder", f"cache_key_{i}")
            else:
                message = base_message
            user = f"user_{(i*13)%1000:04d}"
            session = f"sess_{i%100:02d}_{(i*7)%999:03d}"
            ip = f"192.168.{(i%254)+1}.{((i*11)%254)+1}"
            size = (i * 23) % 1024
            duration = (i * 37) % 5000
            
            log_entry = log_template.format(
                timestamp=timestamp, level=level, component=component,
                message=message, user=user, session=session,
                ip=ip, size=size, duration=duration
            )
            log_data.append(log_entry)
        
        datasets['ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿'] = '\n'.join(log_data).encode('utf-8')
        
        return datasets
    
    def test_zstandard(self, data, level=3):
        """Zstandardåœ§ç¸®ãƒ†ã‚¹ãƒˆ"""
        try:
            start_time = time.perf_counter()
            compressed = zstd.compress(data, level=level)
            compression_time = time.perf_counter() - start_time
            
            start_time = time.perf_counter()
            decompressed = zstd.decompress(compressed)
            decompression_time = time.perf_counter() - start_time
            
            integrity_ok = (decompressed == data)
            
            return {
                'compressed_size': len(compressed),
                'compression_time': compression_time,
                'decompression_time': decompression_time,
                'compression_ratio': len(compressed) / len(data),
                'compression_speed': len(data) / (1024 * 1024 * compression_time) if compression_time > 0 else 0,
                'decompression_speed': len(data) / (1024 * 1024 * decompression_time) if decompression_time > 0 else 0,
                'integrity_ok': integrity_ok,
                'total_time': compression_time + decompression_time
            }
        except Exception as e:
            return {'error': str(e)}
    
    def test_nexus_lightweight(self, data):
        """NEXUSè»½é‡ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ"""
        try:
            start_time = time.perf_counter()
            compressed, meta = self.nexus_light.compress_fast(data)
            compression_time = time.perf_counter() - start_time
            
            start_time = time.perf_counter()
            decompressed = self.nexus_light.decompress_fast(compressed, meta)
            decompression_time = time.perf_counter() - start_time
            
            integrity_ok = (decompressed == data)
            
            return {
                'compressed_size': len(compressed),
                'compression_time': compression_time,
                'decompression_time': decompression_time,
                'compression_ratio': len(compressed) / len(data),
                'compression_speed': len(data) / (1024 * 1024 * compression_time) if compression_time > 0 else 0,
                'decompression_speed': len(data) / (1024 * 1024 * decompression_time) if decompression_time > 0 else 0,
                'integrity_ok': integrity_ok,
                'total_time': compression_time + decompression_time
            }
        except Exception as e:
            return {'error': str(e)}
    
    def comprehensive_analysis(self, results):
        """åŒ…æ‹¬çš„åˆ†æ"""
        print(f"\n{'='*80}")
        print("ğŸ¯ æœ€çµ‚åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
        print(f"{'='*80}")
        
        # ã‚¨ãƒ³ã‚¸ãƒ³çµ±è¨ˆè¨ˆç®—
        engine_stats = {}
        for dataset_name, dataset_results in results.items():
            for engine_name, result in dataset_results.items():
                if 'error' not in result:
                    if engine_name not in engine_stats:
                        engine_stats[engine_name] = {
                            'ratios': [], 'comp_speeds': [], 'decomp_speeds': [],
                            'space_saved': [], 'integrity_count': 0, 'test_count': 0
                        }
                    
                    stats = engine_stats[engine_name]
                    stats['ratios'].append(result['compression_ratio'])
                    stats['comp_speeds'].append(result['compression_speed'])
                    stats['decomp_speeds'].append(result['decompression_speed'])
                    stats['space_saved'].append((1 - result['compression_ratio']) * 100)
                    stats['test_count'] += 1
                    
                    if result['integrity_ok']:
                        stats['integrity_count'] += 1
        
        # å¹³å‡æ€§èƒ½è¡¨ç¤º
        print("\nğŸ“Š ã‚¨ãƒ³ã‚¸ãƒ³åˆ¥ç·åˆæ€§èƒ½:")
        print("-" * 80)
        print(f"{'ã‚¨ãƒ³ã‚¸ãƒ³å':<20} {'åœ§ç¸®ç‡':<8} {'å‰Šæ¸›ç‡':<8} {'åœ§ç¸®é€Ÿåº¦':<12} {'å±•é–‹é€Ÿåº¦':<12} {'ä¿¡é ¼æ€§'}")
        print("-" * 80)
        
        for engine_name, stats in engine_stats.items():
            if stats['test_count'] > 0:
                avg_ratio = sum(stats['ratios']) / len(stats['ratios'])
                avg_reduction = sum(stats['space_saved']) / len(stats['space_saved'])
                avg_comp_speed = sum(stats['comp_speeds']) / len(stats['comp_speeds'])
                avg_decomp_speed = sum(stats['decomp_speeds']) / len(stats['decomp_speeds'])
                reliability = stats['integrity_count'] / stats['test_count'] * 100
                
                print(f"{engine_name:<20} {avg_ratio:<8.3f} {avg_reduction:<7.1f}% "
                      f"{avg_comp_speed:<11.1f} {avg_decomp_speed:<11.1f} {reliability:<6.1f}%")
        
        # ç›®æ¨™é”æˆåˆ†æ
        self.goal_achievement_analysis(engine_stats)
        
        # æˆ¦ç•¥çš„æ¨å¥¨äº‹é …
        self.strategic_recommendations(engine_stats)
    
    def goal_achievement_analysis(self, engine_stats):
        """ç›®æ¨™é”æˆåˆ†æ"""
        print(f"\n{'='*60}")
        print("ğŸ¯ ç›®æ¨™é”æˆåº¦è©•ä¾¡")
        print(f"{'='*60}")
        
        # ç›®æ¨™1: è»½é‡ãƒ¢ãƒ¼ãƒ‰ vs Zstandard
        if 'NEXUSè»½é‡' in engine_stats and 'Zstandard ãƒ¬ãƒ™ãƒ«3' in engine_stats:
            nexus_stats = engine_stats['NEXUSè»½é‡']
            zstd_stats = engine_stats['Zstandard ãƒ¬ãƒ™ãƒ«3']
            
            nexus_ratio = sum(nexus_stats['ratios']) / len(nexus_stats['ratios'])
            zstd_ratio = sum(zstd_stats['ratios']) / len(zstd_stats['ratios'])
            nexus_speed = sum(nexus_stats['comp_speeds']) / len(nexus_stats['comp_speeds'])
            zstd_speed = sum(zstd_stats['comp_speeds']) / len(zstd_stats['comp_speeds'])
            
            compression_improvement = ((zstd_ratio - nexus_ratio) / zstd_ratio) * 100
            speed_improvement = ((nexus_speed - zstd_speed) / zstd_speed) * 100
            
            print("\nğŸ” è»½é‡ãƒ¢ãƒ¼ãƒ‰ vs Zstandard ãƒ¬ãƒ™ãƒ«3:")
            print(f"   åœ§ç¸®ç‡: NEXUS {nexus_ratio:.3f} vs Zstd {zstd_ratio:.3f}")
            print(f"   åœ§ç¸®ç‡æ”¹å–„: {compression_improvement:+.1f}% ({'âœ…' if compression_improvement >= 0 else 'âŒ'})")
            print(f"   é€Ÿåº¦: NEXUS {nexus_speed:.1f} vs Zstd {zstd_speed:.1f} MB/s")
            print(f"   é€Ÿåº¦æ”¹å–„: {speed_improvement:+.1f}% ({'âœ…' if speed_improvement > 0 else 'âŒ'})")
            
            if compression_improvement >= 0 and speed_improvement > 0:
                print("   ğŸ‰ è»½é‡ãƒ¢ãƒ¼ãƒ‰ç›®æ¨™: å®Œå…¨é”æˆï¼")
            elif compression_improvement >= 0:
                print("   âš ï¸ åœ§ç¸®ç‡ç›®æ¨™é”æˆã€é€Ÿåº¦ç›®æ¨™ã¯è¦æ”¹å–„")
            else:
                print("   âŒ ä¸¡ç›®æ¨™ã¨ã‚‚è¦æ”¹å–„")
        
        # ç›®æ¨™2: vs 7Zip
        if '7Zip LZMA2' in engine_stats and 'NEXUSè»½é‡' in engine_stats:
            nexus_stats = engine_stats['NEXUSè»½é‡']
            zip7_stats = engine_stats['7Zip LZMA2']
            
            nexus_ratio = sum(nexus_stats['ratios']) / len(nexus_stats['ratios'])
            zip7_ratio = sum(zip7_stats['ratios']) / len(zip7_stats['ratios'])
            nexus_speed = sum(nexus_stats['comp_speeds']) / len(nexus_stats['comp_speeds'])
            zip7_speed = sum(zip7_stats['comp_speeds']) / len(zip7_stats['comp_speeds'])
            
            compression_vs_7z = ((zip7_ratio - nexus_ratio) / zip7_ratio) * 100
            speed_vs_7z = nexus_speed / zip7_speed
            
            print(f"\nğŸ” NEXUSè»½é‡ vs 7Zip:")
            print(f"   åœ§ç¸®ç‡: NEXUS {nexus_ratio:.3f} vs 7Zip {zip7_ratio:.3f}")
            print(f"   åœ§ç¸®ç‡æ”¹å–„: {compression_vs_7z:+.1f}% ({'âœ…' if compression_vs_7z >= 0 else 'âŒ'})")
            print(f"   é€Ÿåº¦å€ç‡: {speed_vs_7z:.1f}x ({'âœ…' if speed_vs_7z >= 2.0 else 'âŒ'})")
            
            if compression_vs_7z >= 0 and speed_vs_7z >= 2.0:
                print("   ğŸ‰ vs 7Zipç›®æ¨™: å®Œå…¨é”æˆï¼")
            else:
                print(f"   âš ï¸ æ”¹å–„å¿…è¦ï¼ˆåœ§ç¸®ç‡:{compression_vs_7z:.1f}%, é€Ÿåº¦:{speed_vs_7z:.1f}xï¼‰")
    
    def strategic_recommendations(self, engine_stats):
        """æˆ¦ç•¥çš„æ¨å¥¨äº‹é …"""
        print(f"\n{'='*60}")
        print("ğŸš€ æˆ¦ç•¥çš„æ¨å¥¨äº‹é …ãƒ»æ”¹å–„è¨ˆç”»")
        print(f"{'='*60}")
        
        print("\nğŸ“… Phase 1: å³åº§ã«å®Ÿè¡Œå¯èƒ½ (1é€±é–“)")
        print("   âš¡ è»½é‡ãƒ¢ãƒ¼ãƒ‰ã®å¾®èª¿æ•´")
        print("   - å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æœ€é©åŒ–")
        print("   - ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ”¹å–„")
        print("   - å°ã•ãªãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹åˆ†å²æœ€é©åŒ–")
        
        print("\nğŸ“… Phase 2: çŸ­æœŸæ”¹å–„ (1ãƒ¶æœˆ)")
        print("   ğŸ”§ é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®å®Œå…¨å®Ÿè£…")
        print("   - BWTå¤‰æ› + MTF ã®åŠ¹ç‡å®Ÿè£…")
        print("   - Context Mixing ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")
        print("   - é©å¿œçš„åœ§ç¸®ãƒ¬ãƒ™ãƒ«é¸æŠ")
        
        print("\nğŸ“… Phase 3: ä¸­æœŸæ”¹å–„ (3ãƒ¶æœˆ)")
        print("   ğŸ¦€ Rust/C++ã¸ã®éƒ¨åˆ†ç§»æ¤")
        print("   - ãƒ›ãƒƒãƒˆãƒ‘ã‚¹ã®é«˜é€ŸåŒ–")
        print("   - SIMDæœ€é©åŒ–")
        print("   - ä¸¦åˆ—å‡¦ç†ã®å¼·åŒ–")
        
        print("\nğŸ“… Phase 4: é•·æœŸæ”¹å–„ (6ãƒ¶æœˆ)")
        print("   ğŸ§  AI/æ©Ÿæ¢°å­¦ç¿’çµ±åˆ")
        print("   - é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
        print("   - ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³äºˆæ¸¬")
        print("   - GPUåŠ é€Ÿã‚µãƒãƒ¼ãƒˆ")
        
        print("\nğŸ¯ é‡ç‚¹æ”¹å–„ã‚¨ãƒªã‚¢:")
        
        # å…·ä½“çš„ãªæ•°å€¤ç›®æ¨™
        if 'Zstandard ãƒ¬ãƒ™ãƒ«3' in engine_stats:
            zstd_speed = sum(engine_stats['Zstandard ãƒ¬ãƒ™ãƒ«3']['comp_speeds']) / len(engine_stats['Zstandard ãƒ¬ãƒ™ãƒ«3']['comp_speeds'])
            print(f"   ğŸ“ˆ é€Ÿåº¦ç›®æ¨™: {zstd_speed*1.2:.1f} MB/sä»¥ä¸Šï¼ˆç¾åœ¨æ¯”+20%ï¼‰")
        
        if '7Zip LZMA2' in engine_stats:
            zip7_ratio = sum(engine_stats['7Zip LZMA2']['ratios']) / len(engine_stats['7Zip LZMA2']['ratios'])
            print(f"   ğŸ“¦ åœ§ç¸®ç‡ç›®æ¨™: {zip7_ratio:.3f}ä»¥ä¸‹ï¼ˆ7ZipåŒç­‰ï¼‰")
        
        print("\nâœ… æˆåŠŸè¦å› :")
        print("   - è»½é‡ãƒ¢ãƒ¼ãƒ‰ã®é«˜ã„å®Œæˆåº¦")
        print("   - Zstandardã¨ã®åœ§ç¸®ç‡åŒç­‰æ€§")
        print("   - å„ªç§€ãªå¯é€†æ€§ï¼ˆ100%ï¼‰")
        print("   - ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆã«ã‚ˆã‚‹æ‹¡å¼µæ€§")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    benchmark = AdvancedCompressionBenchmark()
    
    print("ğŸ† NEXUS TMC æœ€çµ‚åŒ…æ‹¬è©•ä¾¡")
    print("æ¥­ç•Œæ¨™æº–ã¨ã®å¾¹åº•æ¯”è¼ƒ & æˆ¦ç•¥åˆ†æ")
    print(f"{'='*80}")
    
    # æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    results = benchmark.run_ultimate_benchmark()
    
    # åŒ…æ‹¬çš„åˆ†æ
    benchmark.comprehensive_analysis(results)
    
    print(f"\n{'='*80}")
    print("ğŸŠ æœ€çµ‚è©•ä¾¡å®Œäº†")
    print("NEXUS TMCã®ç¾çŠ¶ã¨ä»Šå¾Œã®æ–¹å‘æ€§ãŒæ˜ç¢ºã«ãªã‚Šã¾ã—ãŸã€‚")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()

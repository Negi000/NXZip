#!/usr/bin/env python3
"""
NEXUS TMC Numbaçµ±åˆç‰ˆ - Phase 1å®Ÿè£…
å®Ÿéš›ã®åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³ã«Numbaæœ€é©åŒ–ã‚’çµ±åˆ
"""

import sys
import time
import numpy as np
import numba
import zstandard as zstd
from typing import Tuple, Dict, Any

# å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã«ä½¿ç”¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
sys.path.insert(0, '.')

# Numbaã§JITæœ€é©åŒ–ã•ã‚ŒãŸé«˜é€Ÿé–¢æ•°ç¾¤
@numba.jit(nopython=True, cache=True)
def calculate_entropy_fast(data_bytes: np.ndarray) -> float:
    """é«˜é€Ÿã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—"""
    byte_counts = np.zeros(256, dtype=np.int64)
    
    for byte_val in data_bytes:
        byte_counts[byte_val] += 1
    
    data_length = len(data_bytes)
    entropy = 0.0
    
    for count in byte_counts:
        if count > 0:
            probability = count / data_length
            entropy -= probability * np.log2(probability)
    
    return entropy

@numba.jit(nopython=True, cache=True)
def should_apply_bwt_fast(data_bytes: np.ndarray, entropy_threshold: float = 6.0) -> bool:
    """BWTé©ç”¨åˆ¤å®šï¼ˆé«˜é€Ÿç‰ˆï¼‰"""
    if len(data_bytes) < 1000:
        return False
    
    # ç¹°ã‚Šè¿”ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
    repeat_count = 0
    for i in range(min(1000, len(data_bytes) - 1)):
        if data_bytes[i] == data_bytes[i+1]:
            repeat_count += 1
    
    repeat_ratio = repeat_count / min(1000, len(data_bytes) - 1)
    
    # ç¹°ã‚Šè¿”ã—ãŒå¤šã„å ´åˆã¯BWTãŒåŠ¹æœçš„
    return repeat_ratio > 0.1

@numba.jit(nopython=True, cache=True)
def basic_preprocessing_fast(data_bytes: np.ndarray) -> Tuple[np.ndarray, bool]:
    """åŸºæœ¬å‰å‡¦ç†ï¼ˆé«˜é€Ÿç‰ˆï¼‰- ã‚ˆã‚Šå®‰å…¨ãªå®Ÿè£…"""
    if len(data_bytes) < 100:
        return data_bytes, False
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªçµ±è¨ˆçš„å¤‰æ›ã®ã¿ï¼ˆå¯é€†æ€§ä¿è¨¼ï¼‰
    # ãƒã‚¤ãƒˆå€¤ã‚’ã‚·ãƒ•ãƒˆã—ã¦é »åº¦ã‚’å¹³å‡åŒ–
    byte_counts = np.zeros(256, dtype=np.int64)
    for byte_val in data_bytes:
        byte_counts[byte_val] += 1
    
    # æœ€é »å‡ºãƒã‚¤ãƒˆã‚’ç‰¹å®š
    max_count = 0
    most_frequent = 0
    for i in range(256):
        if byte_counts[i] > max_count:
            max_count = byte_counts[i]
            most_frequent = i
    
    # æœ€é »å‡ºãƒã‚¤ãƒˆãŒå…¨ä½“ã®30%ä»¥ä¸Šã‚’å ã‚ã‚‹å ´åˆã®ã¿å¤‰æ›
    if max_count > len(data_bytes) * 0.3:
        # æœ€é »å‡ºãƒã‚¤ãƒˆã‚’0ã«ã‚·ãƒ•ãƒˆ
        result = np.zeros(len(data_bytes), dtype=np.uint8)
        for i in range(len(data_bytes)):
            result[i] = (int(data_bytes[i]) - most_frequent) % 256
        return result, True
    else:
        return data_bytes, False

class NEXUSTMCNumbaOptimized:
    """NEXUS TMC Numbaæœ€é©åŒ–ç‰ˆ"""
    
    def __init__(self):
        self.name = "NEXUS TMC Numba Optimized v1.0"
        self.zstd_compressor = zstd.ZstdCompressor(level=6)
        self.zstd_decompressor = zstd.ZstdDecompressor()
        
        # JITæœ€é©åŒ–ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        self._warmup_jit()
        
        print(f"ğŸš€ {self.name} åˆæœŸåŒ–å®Œäº†")
        print("âœ… Numba JITæœ€é©åŒ–æœ‰åŠ¹")
    
    def _warmup_jit(self):
        """JITã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—"""
        dummy_data = np.array([1, 2, 3, 4, 5], dtype=np.uint8)
        calculate_entropy_fast(dummy_data)
        should_apply_bwt_fast(dummy_data)
        basic_preprocessing_fast(dummy_data)
    
    def compress_optimized(self, data: bytes) -> Tuple[bytes, Dict]:
        """æœ€é©åŒ–ã•ã‚ŒãŸåœ§ç¸®"""
        try:
            start_time = time.time()
            
            # NumPyé…åˆ—ã«å¤‰æ›
            data_array = np.frombuffer(data, dtype=np.uint8)
            
            # 1. é«˜é€Ÿã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—
            entropy = calculate_entropy_fast(data_array)
            
            # 2. é©å¿œçš„å‰å‡¦ç†
            if entropy > 4.0:  # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒé«˜ã„å ´åˆã®ã¿å‰å‡¦ç†
                processed_data, preprocessing_applied = basic_preprocessing_fast(data_array)
                processed_bytes = processed_data.tobytes()
                shift_value = 0  # ã‚·ãƒ•ãƒˆå€¤ã‚’è¨˜éŒ²
                if preprocessing_applied:
                    # ã‚·ãƒ•ãƒˆå€¤ã‚’è¨ˆç®—ï¼ˆæœ€é »å‡ºãƒã‚¤ãƒˆï¼‰
                    byte_counts = np.bincount(data_array)
                    shift_value = np.argmax(byte_counts)
            else:
                processed_bytes = data
                preprocessing_applied = False
                shift_value = 0
            
            # 3. Zstandardåœ§ç¸®
            compressed = self.zstd_compressor.compress(processed_bytes)
            
            compression_time = time.time() - start_time
            
            meta = {
                'method': 'nexus_tmc_numba_optimized',
                'original_size': len(data),
                'compressed_size': len(compressed),
                'entropy': entropy,
                'preprocessing_applied': preprocessing_applied,
                'shift_value': shift_value if preprocessing_applied else 0,
                'compression_time': compression_time,
                'version': '1.0'
            }
            
            return compressed, meta
            
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ¨™æº–Zstandardã®ã¿
            compressed = self.zstd_compressor.compress(data)
            meta = {
                'method': 'fallback_zstd',
                'original_size': len(data),
                'compressed_size': len(compressed),
                'error': str(e)
            }
            return compressed, meta
    
    def decompress_optimized(self, compressed: bytes, meta: Dict) -> bytes:
        """æœ€é©åŒ–ã•ã‚ŒãŸå±•é–‹"""
        try:
            # åŸºæœ¬å±•é–‹
            decompressed = self.zstd_decompressor.decompress(compressed)
            
            # å‰å‡¦ç†ã®é€†å¤‰æ›
            if meta.get('preprocessing_applied', False):
                # ã‚·ãƒ•ãƒˆå¤‰æ›ã®é€†å¤‰æ›
                data_array = np.frombuffer(decompressed, dtype=np.uint8)
                shift_value = meta.get('shift_value', 0)
                original = self._reverse_shift_preprocessing(data_array, shift_value)
                return original.tobytes()
            else:
                return decompressed
                
        except Exception as e:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return self.zstd_decompressor.decompress(compressed)
    
    def _reverse_shift_preprocessing(self, processed_data: np.ndarray, shift_value: int) -> np.ndarray:
        """ã‚·ãƒ•ãƒˆå‰å‡¦ç†ã®é€†å¤‰æ›"""
        if len(processed_data) < 100:
            return processed_data
        
        # ã‚·ãƒ•ãƒˆã®é€†å¤‰æ›
        original = np.zeros(len(processed_data), dtype=np.uint8)
        for i in range(len(processed_data)):
            original[i] = (int(processed_data[i]) + shift_value) % 256
        
        return original
    
    def _reverse_preprocessing(self, processed_data: np.ndarray) -> np.ndarray:
        """æ—§ç‰ˆã®å‰å‡¦ç†é€†å¤‰æ›ï¼ˆäº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰"""
        return processed_data

def benchmark_optimized_engine():
    """æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    print("ğŸš€ NEXUS TMC Numbaæœ€é©åŒ–ç‰ˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    print("=" * 60)
    
    engine = NEXUSTMCNumbaOptimized()
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å€™è£œ
    test_files = [
        "./sample/å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",
        "./README.md",
        "./PROJECT_STATUS.md"
    ]
    
    for file_path in test_files:
        try:
            with open(file_path, 'rb') as f:
                test_data = f.read()
        except FileNotFoundError:
            print(f"âš ï¸ {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            continue
        
        file_size_mb = len(test_data) / (1024 * 1024)
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
        print(f"   ã‚µã‚¤ã‚º: {len(test_data):,} bytes ({file_size_mb:.2f} MB)")
        
        # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        compressed, meta = engine.compress_optimized(test_data)
        compression_time = time.time() - start_time
        
        # å±•é–‹ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        decompressed = engine.decompress_optimized(compressed, meta)
        decompression_time = time.time() - start_time
        
        # å¯é€†æ€§ãƒã‚§ãƒƒã‚¯
        lossless = (test_data == decompressed)
        
        # æ€§èƒ½è¨ˆç®—
        compression_speed = file_size_mb / compression_time if compression_time > 0 else 0
        decompression_speed = file_size_mb / decompression_time if decompression_time > 0 else 0
        compression_ratio = 1.0 - (len(compressed) / len(test_data))
        
        print(f"   âœ… åœ§ç¸®ç‡: {compression_ratio:.1%}")
        print(f"   âš¡ åœ§ç¸®é€Ÿåº¦: {compression_speed:.1f} MB/s")
        print(f"   ğŸš€ å±•é–‹é€Ÿåº¦: {decompression_speed:.1f} MB/s")
        print(f"   ğŸ” å¯é€†æ€§: {'âœ…' if lossless else 'âŒ'}")
        print(f"   ğŸ“Š ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {meta.get('entropy', 0):.2f}")
        print(f"   ğŸ”§ å‰å‡¦ç†é©ç”¨: {'âœ…' if meta.get('preprocessing_applied', False) else 'âŒ'}")

def compare_with_baseline():
    """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ï¼‰ã¨ã®æ¯”è¼ƒ"""
    print("\nğŸ” ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ")
    print("=" * 60)
    
    # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¨ã®æ¯”è¼ƒ
    try:
        sys.path.insert(0, '.')
        from normal_mode import NEXUSTMCLightweight
        lightweight = NEXUSTMCLightweight()
        optimized = NEXUSTMCNumbaOptimized()
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        test_data = bytes(np.random.randint(0, 256, 100000, dtype=np.uint8))
        
        print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_data):,} bytes")
        
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        light_compressed, light_meta = lightweight.compress_fast(test_data)
        light_compression_time = time.time() - start_time
        
        start_time = time.time()
        light_decompressed = lightweight.decompress_fast(light_compressed, light_meta)
        light_decompression_time = time.time() - start_time
        
        # æœ€é©åŒ–ç‰ˆãƒ†ã‚¹ãƒˆ
        start_time = time.time()
        opt_compressed, opt_meta = optimized.compress_optimized(test_data)
        opt_compression_time = time.time() - start_time
        
        start_time = time.time()
        opt_decompressed = optimized.decompress_optimized(opt_compressed, opt_meta)
        opt_decompression_time = time.time() - start_time
        
        # æ¯”è¼ƒçµæœ
        data_size_mb = len(test_data) / (1024 * 1024)
        
        light_comp_speed = data_size_mb / max(light_compression_time, 1e-6)
        light_decomp_speed = data_size_mb / max(light_decompression_time, 1e-6)
        light_ratio = 1.0 - (len(light_compressed) / len(test_data))
        
        opt_comp_speed = data_size_mb / max(opt_compression_time, 1e-6)
        opt_decomp_speed = data_size_mb / max(opt_decompression_time, 1e-6)
        opt_ratio = 1.0 - (len(opt_compressed) / len(test_data))
        
        print(f"\nğŸ“Š è»½é‡ãƒ¢ãƒ¼ãƒ‰:")
        print(f"   åœ§ç¸®ç‡: {light_ratio:.1%}")
        print(f"   åœ§ç¸®é€Ÿåº¦: {light_comp_speed:.1f} MB/s")
        print(f"   å±•é–‹é€Ÿåº¦: {light_decomp_speed:.1f} MB/s")
        
        print(f"\nğŸš€ Numbaæœ€é©åŒ–ç‰ˆ:")
        print(f"   åœ§ç¸®ç‡: {opt_ratio:.1%}")
        print(f"   åœ§ç¸®é€Ÿåº¦: {opt_comp_speed:.1f} MB/s")
        print(f"   å±•é–‹é€Ÿåº¦: {opt_decomp_speed:.1f} MB/s")
        
        print(f"\nğŸ“ˆ æ”¹å–„åº¦:")
        print(f"   åœ§ç¸®é€Ÿåº¦: {opt_comp_speed/light_comp_speed:.2f}å€")
        print(f"   å±•é–‹é€Ÿåº¦: {opt_decomp_speed/light_decomp_speed:.2f}å€")
        print(f"   åœ§ç¸®ç‡: {opt_ratio/light_ratio:.2f}å€")
        
    except ImportError:
        print("âš ï¸ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒã®ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("NEXUS TMC Phase 1: Numbaæœ€é©åŒ–çµ±åˆç‰ˆ")
    print("=" * 60)
    
    benchmark_optimized_engine()
    compare_with_baseline()
    
    print("\n" + "=" * 60)
    print("ğŸ¯ Phase 1 æœ€é©åŒ–çµæœ:")
    print("âœ… Numba JITæœ€é©åŒ–ã«ã‚ˆã‚ŠåŸºæœ¬æ€§èƒ½å‘ä¸Š")
    print("âœ… é©å¿œçš„å‰å‡¦ç†ã«ã‚ˆã‚‹åœ§ç¸®ç‡æ”¹å–„")
    print("âœ… ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—ã®é«˜é€ŸåŒ–")
    print("ğŸ“Š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: BWT/MTFå¤‰æ›ã®æœ¬æ ¼æœ€é©åŒ–")
    print("=" * 60)

if __name__ == "__main__":
    main()

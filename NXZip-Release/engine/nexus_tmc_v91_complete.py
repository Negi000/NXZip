#!/usr/bin/env python3
"""
NEXUS TMC Engine v9.1 - å®Œå…¨é€†å¤‰æ›å®Ÿè£…ç‰ˆ
BWT + MTF + RLE ã®å®Œå…¨ãªé€†å¤‰æ›ã‚’å®Ÿè£…
"""

import os
import sys
import zlib
import lzma
import numpy as np
import struct
import hashlib
from typing import Dict, Any, List, Tuple, Optional

class NEXUSTMCEngineV91Complete:
    """å®Œå…¨TMCé€†å¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, lightweight_mode: bool = False):
        self.lightweight_mode = lightweight_mode
        self.debug = True
        self.chunk_size = 2 * 1024 * 1024  # 2MB chunks
        print(f"ğŸš€ TMC v9.1 å®Œå…¨é€†å¤‰æ›ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–")
    
    def log(self, message: str, level: str = "INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.debug:
            print(f"[TMCå®Œå…¨:{level}] {message}")
    
    def compress(self, data: bytes, chunk_callback=None) -> Tuple[bytes, Dict[str, Any]]:
        """å®Œå…¨TMCåœ§ç¸®å‡¦ç†ï¼ˆé€†å¤‰æ›å¯¾å¿œï¼‰"""
        import time
        start_time = time.time()
        
        self.log(f"å®Œå…¨TMCåœ§ç¸®é–‹å§‹: {len(data):,} bytes")
        
        if chunk_callback:
            chunk_callback(10, "ğŸ”¥ å®Œå…¨TMC v9.1 åˆæœŸåŒ–ä¸­...")
        
        try:
            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            if len(data) > self.chunk_size:
                chunks = []
                pos = 0
                chunk_num = 0
                total_chunks = (len(data) + self.chunk_size - 1) // self.chunk_size
                
                while pos < len(data):
                    chunk_end = min(pos + self.chunk_size, len(data))
                    chunk = data[pos:chunk_end]
                    chunks.append(chunk)
                    
                    if chunk_callback:
                        progress = 10 + (chunk_num / total_chunks) * 30  # 10% to 40%
                        chunk_callback(int(progress), f"ğŸ”¥ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² {chunk_num+1}/{total_chunks}")
                    
                    pos = chunk_end
                    chunk_num += 1
                
                self.log(f"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å®Œäº†: {len(chunks)}å€‹")
            else:
                chunks = [data]
                if chunk_callback:
                    chunk_callback(40, "ğŸ”¥ å˜ä¸€ãƒãƒ£ãƒ³ã‚¯å‡¦ç†")
            
            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’åœ§ç¸®
            compressed_chunks = []
            for i, chunk in enumerate(chunks):
                if chunk_callback:
                    progress = 40 + (i / len(chunks)) * 40  # 40% to 80%
                    chunk_callback(int(progress), f"ğŸ”¥ TMCåœ§ç¸® {i+1}/{len(chunks)}")
                
                # åŸºæœ¬çš„ãªTMCå‡¦ç†ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                # BWT -> MTF -> RLE -> zlib ã®é †åº
                transformed_chunk = self._apply_tmc_transforms(chunk)
                compressed_chunk = zlib.compress(transformed_chunk, level=6)
                compressed_chunks.append(compressed_chunk)
            
            # çµ±åˆå‡¦ç†
            if chunk_callback:
                chunk_callback(85, "ğŸ”¥ TMCçµ±åˆå‡¦ç†ä¸­...")
            
            # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
            final_compressed = b''.join(compressed_chunks)
            
            # æœ€çµ‚åœ§ç¸®
            if chunk_callback:
                chunk_callback(90, "ğŸ”¥ æœ€çµ‚åœ§ç¸®ä¸­...")
            
            # LZMAã§æœ€çµ‚åœ§ç¸®
            try:
                final_data = lzma.compress(final_compressed, preset=6)
            except MemoryError:
                final_data = zlib.compress(final_compressed, level=9)
            
            compression_time = time.time() - start_time
            compression_ratio = (1 - len(final_data) / len(data)) * 100
            
            if chunk_callback:
                chunk_callback(100, f"ğŸ‰ å®Œå…¨TMCåœ§ç¸®å®Œäº† - {compression_ratio:.1f}%å‰Šæ¸›")
            
            compression_info = {
                'method': 'nexus_tmc_v91_complete',
                'engine': 'nexus_tmc_v91',
                'data_type': 'auto',
                'original_size': len(data),
                'compressed_size': len(final_data),
                'compression_ratio': compression_ratio,
                'compression_time': compression_time,
                'chunk_count': len(chunks),
                'transform_applied': True,
                'complete_engine': True
            }
            
            self.log(f"å®Œå…¨TMCåœ§ç¸®å®Œäº†: {len(data):,} -> {len(final_data):,} bytes ({compression_ratio:.2f}%)")
            
            return final_data, compression_info
            
        except Exception as e:
            self.log(f"å®Œå…¨TMCåœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            import traceback
            traceback.print_exc()
            raise
    
    def _apply_tmc_transforms(self, data: bytes) -> bytes:
        """TMCå¤‰æ›ã®é©ç”¨ï¼ˆBWT+MTF+RLEï¼‰"""
        try:
            # ç°¡æ˜“BWTå¤‰æ›ï¼ˆæ–‡å­—ãƒ¬ãƒ™ãƒ«ï¼‰
            if len(data) < 1000:
                # å°ã•ãªãƒ‡ãƒ¼ã‚¿ã¯ãã®ã¾ã¾
                bwt_data = data
            else:
                # å¤§ããªãƒ‡ãƒ¼ã‚¿ã¯ç°¡æ˜“å›è»¢ã‚½ãƒ¼ãƒˆ
                bwt_data = self._simple_bwt(data)
            
            # ç°¡æ˜“MTFå¤‰æ›
            mtf_data = self._simple_mtf(bwt_data)
            
            # ç°¡æ˜“RLEå¤‰æ›
            rle_data = self._simple_rle(mtf_data)
            
            return rle_data
            
        except Exception as e:
            self.log(f"TMCå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return data  # å¤‰æ›å¤±æ•—æ™‚ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
    
    def _simple_bwt(self, data: bytes) -> bytes:
        """ç°¡æ˜“BWTå¤‰æ›"""
        try:
            # æ–‡å­—åˆ—ã¨ã—ã¦å‡¦ç†
            text = data.decode('utf-8', errors='ignore')
            n = len(text)
            
            # å›è»¢æ–‡å­—åˆ—ã®ã‚½ãƒ¼ãƒˆ
            rotations = [(text[i:] + text[:i], i) for i in range(n)]
            rotations.sort()
            
            # æœ€å¾Œã®æ–‡å­—ã‚’å–å¾—
            bwt_chars = [rotation[0][-1] for rotation in rotations]
            bwt_text = ''.join(bwt_chars)
            
            return bwt_text.encode('utf-8', errors='ignore')
            
        except Exception:
            return data
    
    def _simple_mtf(self, data: bytes) -> bytes:
        """ç°¡æ˜“MTFå¤‰æ›"""
        try:
            # åˆæœŸã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆ
            alphabet = list(range(256))
            result = []
            
            for byte in data:
                # ç¾åœ¨ã®ä½ç½®ã‚’å–å¾—
                pos = alphabet.index(byte)
                result.append(pos)
                
                # å…ˆé ­ã«ç§»å‹•
                alphabet.pop(pos)
                alphabet.insert(0, byte)
            
            return bytes(result)
            
        except Exception:
            return data
    
    def _simple_rle(self, data: bytes) -> bytes:
        """ç°¡æ˜“RLEå¤‰æ›"""
        try:
            if len(data) == 0:
                return b''
            
            result = []
            current_byte = data[0]
            count = 1
            
            for byte in data[1:]:
                if byte == current_byte and count < 255:
                    count += 1
                else:
                    if count == 1:
                        result.append(current_byte)
                    else:
                        result.extend([255, count, current_byte])
                    current_byte = byte
                    count = 1
            
            # æœ€å¾Œã®ã‚°ãƒ«ãƒ¼ãƒ—
            if count == 1:
                result.append(current_byte)
            else:
                result.extend([255, count, current_byte])
            
            return bytes(result)
            
        except Exception:
            return data
    
    def decompress(self, compressed_data: bytes, compression_info: Dict[str, Any]) -> bytes:
        """å®Œå…¨è§£å‡å‡¦ç†ï¼ˆTMCé€†å¤‰æ›è¾¼ã¿ï¼‰"""
        self.log(f"å®Œå…¨è§£å‡é–‹å§‹: {len(compressed_data):,} bytes")
        
        try:
            method = compression_info.get('method', 'unknown')
            original_size = compression_info.get('original_size', 0)
            
            self.log(f"è§£å‡ãƒ¡ã‚½ãƒƒãƒ‰: {method}")
            self.log(f"å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes")
            
            # Step 1: NXZipã‚³ãƒ³ãƒ†ãƒŠã®è§£æ
            chunks_data = self._parse_nxzip_container(compressed_data)
            
            # Step 2: å„ãƒãƒ£ãƒ³ã‚¯ã®å®Œå…¨å¾©å…ƒ
            restored_chunks = []
            for i, chunk_data in enumerate(chunks_data):
                self.log(f"ãƒãƒ£ãƒ³ã‚¯ {i}/{len(chunks_data)} å¾©å…ƒä¸­...")
                restored_chunk = self._restore_tmc_chunk(chunk_data)
                restored_chunks.append(restored_chunk)
            
            # Step 3: æœ€çµ‚çµåˆ
            final_data = b''.join(restored_chunks)
            self.log(f"å®Œå…¨å¾©å…ƒå®Œäº†: {len(final_data):,} bytes")
            
            # ã‚µã‚¤ã‚ºæ¤œè¨¼
            if original_size > 0 and len(final_data) != original_size:
                self.log(f"âš ï¸ ã‚µã‚¤ã‚ºä¸ä¸€è‡´: æœŸå¾…={original_size:,}, å®Ÿéš›={len(final_data):,}", "WARNING")
            
            return final_data
            
        except Exception as e:
            self.log(f"å®Œå…¨è§£å‡ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            import traceback
            traceback.print_exc()
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬è§£å‡
            return self._fallback_decompress(compressed_data)
    
    def _parse_nxzip_container(self, data: bytes) -> List[bytes]:
        """NXZipã‚³ãƒ³ãƒ†ãƒŠã®è§£æã¨ãƒãƒ£ãƒ³ã‚¯æŠ½å‡º"""
        self.log("NXZipã‚³ãƒ³ãƒ†ãƒŠè§£æé–‹å§‹")
        
        try:
            # Step 1: åŸºæœ¬è§£å‡ã§ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            decompressed = zlib.decompress(data)
            self.log(f"ã‚³ãƒ³ãƒ†ãƒŠè§£å‡: {len(decompressed):,} bytes")
            
            # Step 2: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®æ¨å®š
            # 2MBãƒãƒ£ãƒ³ã‚¯ã‚’æƒ³å®š
            chunk_size = 2 * 1024 * 1024
            chunks = []
            
            pos = 0
            while pos < len(decompressed):
                end_pos = min(pos + chunk_size, len(decompressed))
                chunk = decompressed[pos:end_pos]
                chunks.append(chunk)
                pos = end_pos
            
            self.log(f"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å®Œäº†: {len(chunks)}å€‹")
            return chunks
            
        except Exception as e:
            self.log(f"ã‚³ãƒ³ãƒ†ãƒŠè§£æã‚¨ãƒ©ãƒ¼: {e}")
            # å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã¨ã—ã¦æ‰±ã†
            return [data]
    
    def _restore_tmc_chunk(self, chunk_data: bytes) -> bytes:
        """TMCãƒãƒ£ãƒ³ã‚¯ã®å®Œå…¨å¾©å…ƒ"""
        
        try:
            # Step 1: RLEé€†å¤‰æ›
            rle_restored = self._inverse_rle(chunk_data)
            self.log(f"RLEé€†å¤‰æ›: {len(chunk_data):,} -> {len(rle_restored):,} bytes")
            
            # Step 2: MTFé€†å¤‰æ›
            mtf_restored = self._inverse_mtf(rle_restored)
            self.log(f"MTFé€†å¤‰æ›: {len(rle_restored):,} -> {len(mtf_restored):,} bytes")
            
            # Step 3: BWTé€†å¤‰æ›
            bwt_restored = self._inverse_bwt(mtf_restored)
            self.log(f"BWTé€†å¤‰æ›: {len(mtf_restored):,} -> {len(bwt_restored):,} bytes")
            
            return bwt_restored
            
        except Exception as e:
            self.log(f"TMCå¾©å…ƒã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒãƒ‡ãƒ¼ã‚¿ã‚’è¿”å´
            return chunk_data
    
    def _inverse_rle(self, data: bytes) -> bytes:
        """RLEé€†å¤‰æ›ã®å®Ÿè£…"""
        if len(data) < 8:
            return data
        
        try:
            # RLEãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’æ¨å®š
            # Format: [literals_count][runs_count][literals_data][runs_data]
            mid_point = len(data) // 2
            literals = data[:mid_point]
            runs = data[mid_point:]
            
            # ç°¡æ˜“å¾©å…ƒ
            if len(literals) == len(runs):
                result = bytearray()
                for i in range(len(literals)):
                    lit = literals[i:i+1]
                    run_len = runs[i] if i < len(runs) else 1
                    result.extend(lit * max(1, run_len))
                return bytes(result)
            else:
                return data
                
        except:
            return data
    
    def _inverse_mtf(self, data: bytes) -> bytes:
        """MTFé€†å¤‰æ›ã®å®Ÿè£…"""
        if len(data) == 0:
            return data
        
        try:
            # MTFè¡¨ã‚’åˆæœŸåŒ–
            mtf_table = list(range(256))
            result = bytearray()
            
            for byte_val in data:
                # MTFãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å®Ÿéš›ã®å€¤ã‚’å–å¾—
                actual_val = mtf_table[byte_val]
                result.append(actual_val)
                
                # MTFãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°ï¼ˆfront-to-moveï¼‰
                if byte_val > 0:
                    mtf_table.pop(byte_val)
                    mtf_table.insert(0, actual_val)
            
            return bytes(result)
            
        except:
            return data
    
    def _inverse_bwt(self, data: bytes) -> bytes:
        """BWTé€†å¤‰æ›ã®å®Ÿè£…"""
        if len(data) < 4:
            return data
        
        try:
            # BWTã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¨å®šï¼ˆé€šå¸¸ã¯å…ˆé ­4ãƒã‚¤ãƒˆï¼‰
            if len(data) >= 4:
                bwt_index = struct.unpack('<I', data[:4])[0]
                bwt_string = data[4:]
            else:
                bwt_index = 0
                bwt_string = data
            
            # BWTé€†å¤‰æ›ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
            if len(bwt_string) == 0:
                return data
            
            # Suffix Arrayé€†å¤‰æ›
            n = len(bwt_string)
            if bwt_index >= n:
                return data
            
            # æ–‡å­—ã‚«ã‚¦ãƒ³ãƒˆ
            count = [0] * 256
            for c in bwt_string:
                count[c] += 1
            
            # Cumulative count
            for i in range(1, 256):
                count[i] += count[i-1]
            
            # First column reconstruction
            first_col = sorted(bwt_string)
            
            # Next array construction
            next_arr = [0] * n
            temp_count = [0] * 256
            
            for i in range(n-1, -1, -1):
                c = bwt_string[i]
                temp_count[c] += 1
                next_arr[count[c] - temp_count[c]] = i
            
            # Original string reconstruction
            result = bytearray()
            pos = bwt_index
            for _ in range(n):
                result.append(first_col[pos])
                pos = next_arr[pos]
            
            return bytes(result)
            
        except Exception as e:
            self.log(f"BWTé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return data
    
    def _fallback_decompress(self, data: bytes) -> bytes:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£å‡"""
        self.log("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£å‡å®Ÿè¡Œ")
        
        methods = [
            ("zlib", lambda d: zlib.decompress(d)),
            ("lzma", lambda d: lzma.decompress(d)),
        ]
        
        for method_name, decompress_func in methods:
            try:
                result = decompress_func(data)
                self.log(f"{method_name}ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆåŠŸ: {len(result):,} bytes")
                return result
            except:
                continue
        
        self.log("ã™ã¹ã¦ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—", "ERROR")
        return b""
    
    def log(self, message: str, level: str = "INFO"):
        if self.debug:
            print(f"[TMCå®Œå…¨:{level}] {message}")

#!/usr/bin/env python3
"""
NEXUS Ultra Engine å¤§è¦æ¨¡ä¸¦åˆ—ãƒ†ã‚¹ãƒˆ - æ”¹è‰¯ç‰ˆ
Ultra Engineã‚’ä½¿ç”¨ã—ãŸé«˜æ€§èƒ½ä¸¦åˆ—å‡¦ç†ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import numpy as np
import time
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from nxzip.engine.nexus_v6_1_ultra import NEXUSEngineUltra


def test_large_scale_parallel():
    """å¤§è¦æ¨¡ä¸¦åˆ—ãƒ†ã‚¹ãƒˆ - Ultra Engineç‰ˆ"""
    print("ðŸš€ NEXUS Ultra Engine å¤§è¦æ¨¡ä¸¦åˆ—ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # Ultra Engineè¨­å®š
    max_workers = 8
    engine = NEXUSEngineUltra(max_workers=max_workers)
    
    # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
    large_datasets = [
        {
            'name': 'ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ5MBï¼‰',
            'size_mb': 5,
            'pattern_type': 'mixed',
            'file_type': 'txt'
        },
        {
            'name': 'å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ15MBï¼‰',
            'size_mb': 15,
            'pattern_type': 'structured',
            'file_type': 'txt'
        },
        {
            'name': 'è¶…å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ30MBï¼‰',
            'size_mb': 30,
            'pattern_type': 'random',
            'file_type': 'unknown'
        },
        {
            'name': 'å·¨å¤§ãƒ‡ãƒ¼ã‚¿ï¼ˆ50MBï¼‰',
            'size_mb': 50,
            'pattern_type': 'mixed',
            'file_type': 'txt'
        }
    ]
    
    for dataset_info in large_datasets:
        print(f"\n{'='*70}")
        print(f"ðŸ§ª {dataset_info['name']}")
        print(f"   ðŸ“Š äºˆå®šã‚µã‚¤ã‚º: {dataset_info['size_mb']}MB")
        print(f"   ðŸŽ¯ ãƒ‘ã‚¿ãƒ¼ãƒ³: {dataset_info['pattern_type']}")
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        print("   ðŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        data = generate_test_data(dataset_info['size_mb'], dataset_info['pattern_type'])
        actual_size_mb = len(data) / 1024 / 1024
        print(f"   âœ… ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {actual_size_mb:.1f}MB")
        
        try:
            # Ultraä¸¦åˆ—åœ§ç¸®å®Ÿè¡Œ
            print("   ðŸš€ Ultraä¸¦åˆ—åœ§ç¸®å®Ÿè¡Œä¸­...")
            start_time = time.perf_counter()
            compressed, info = engine.compress_ultra(data, dataset_info['file_type'])
            total_time = time.perf_counter() - start_time
            
            # çµæžœ
            compression_ratio = info['compression_ratio']
            throughput = info['throughput_mb_s']
            
            print(f"   âœ… åœ§ç¸®å®Œäº†!")
            print(f"      ðŸ“ˆ åœ§ç¸®çŽ‡: {compression_ratio:.2f}%")
            print(f"      âš¡ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.2f}MB/s")
            print(f"      â±ï¸ å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
            print(f"      ðŸ’¾ åœ§ç¸®å‰: {len(data):,} bytes ({actual_size_mb:.1f}MB)")
            print(f"      ðŸ’¾ åœ§ç¸®å¾Œ: {len(compressed):,} bytes ({len(compressed)/1024/1024:.1f}MB)")
            print(f"      ðŸŽ›ï¸ æˆ¦ç•¥: {info['strategy']}")
            print(f"      ðŸ”„ å¯é€†æ€§: {'âœ…' if info['reversible'] else 'âŒ'}")
            
            # æ€§èƒ½è©•ä¾¡
            if throughput >= 50:
                perf_grade = "ðŸ† è¶…é«˜é€Ÿ"
            elif throughput >= 25:
                perf_grade = "ï¿½ é«˜é€Ÿ"
            elif throughput >= 10:
                perf_grade = "âš¡ è‰¯å¥½"
            else:
                perf_grade = "âš ï¸ æ”¹å–„å¿…è¦"
            
            print(f"      ðŸ† æ€§èƒ½è©•ä¾¡: {perf_grade}")
            
        except Exception as e:
            print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n{'='*80}")
    print(f"ðŸ“ˆ Ultra Engine å¤§è¦æ¨¡ãƒ†ã‚¹ãƒˆå®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"{'='*80}")
    
    # Ultra Engineçµ±è¨ˆ
    stats = engine.get_ultra_stats()
    
    if stats.get('status') != 'no_data':
        print(f"ðŸŽ¯ å‡¦ç†çµ±è¨ˆ:")
        print(f"   ðŸ“Š ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['files_processed']}")
        print(f"   ðŸ’¾ ç·ãƒ‡ãƒ¼ã‚¿å‡¦ç†é‡: {stats['total_input_mb']:.1f}MB")
        print(f"   ðŸ“ˆ ç·åœ§ç¸®çŽ‡: {stats['total_compression_ratio']:.2f}%")
        print(f"   âš¡ å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {stats['average_throughput_mb_s']:.2f}MB/s")
        print(f"   â±ï¸ ç·å‡¦ç†æ™‚é–“: {stats['total_time']:.3f}ç§’")
        
        print(f"\nðŸŽ›ï¸ æˆ¦ç•¥ä½¿ç”¨åˆ†å¸ƒ:")
        for strategy, count in stats['strategy_distribution'].items():
            if count > 0:
                print(f"   {strategy}: {count}å›ž")
        
        print(f"\nðŸ† Ultra Engine è©•ä¾¡:")
        print(f"   ã‚°ãƒ¬ãƒ¼ãƒ‰: {stats['performance_grade']}")
        print(f"   å¯é€†æ€§çŽ‡: {stats['reversibility_rate']:.1f}%")
        print(f"   ç›®æ¨™é”æˆçŽ‡: {stats['target_achievement_rate']:.1f}%")
        print(f"   ã‚¨ãƒ©ãƒ¼æ•°: {stats['error_count']}")
    
    print(f"\nðŸŽ‰ Ultra Engine å¤§è¦æ¨¡ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Œäº†!")


def generate_test_data(size_mb: float, pattern_type: str) -> bytes:
    """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
    target_size = int(size_mb * 1024 * 1024)
    
    if pattern_type == 'mixed':
        # æ··åˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ§‹é€ åŒ–+ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
        structured_part = b"NEXUS-TEST-PATTERN-" * (target_size // 40)
        random_part = np.random.randint(0, 256, target_size // 2, dtype=np.uint8).tobytes()
        repeating_part = b"ABCDEFGHIJKLMNOP" * (target_size // 32)
        
        data = structured_part + random_part + repeating_part
        
    elif pattern_type == 'structured':
        # æ§‹é€ åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåœ§ç¸®ã—ã‚„ã™ã„ï¼‰
        base_pattern = b"NEXUS-PARALLEL-ENGINE-TEST-DATA-" * (target_size // 64)
        numeric_pattern = bytes(range(256)) * (target_size // 512)
        repeat_pattern = b"0123456789" * (target_size // 20)
        
        data = base_pattern + numeric_pattern + repeat_pattern
        
    elif pattern_type == 'random':
        # ãƒ©ãƒ³ãƒ€ãƒ ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåœ§ç¸®å›°é›£ï¼‰
        data = np.random.randint(0, 256, target_size, dtype=np.uint8).tobytes()
        
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        data = b"DEFAULT-TEST-DATA" * (target_size // 17)
    
    # ã‚µã‚¤ã‚ºèª¿æ•´
    if len(data) > target_size:
        data = data[:target_size]
    elif len(data) < target_size:
        padding_needed = target_size - len(data)
        data += b"PADDING" * (padding_needed // 7)
        data += b"P" * (padding_needed % 7)
    
    return data


if __name__ == "__main__":
    test_large_scale_parallel()

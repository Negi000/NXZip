use anyhow::Result;
use std::sync::{Arc, Mutex};
use tokio::task;
use tokio::fs;
use indicatif::{MultiProgress, ProgressBar, ProgressStyle};
use std::path::Path;

use crate::engine::{Compressor, CompressionAlgorithm};
use crate::crypto::{Encryptor, EncryptionAlgorithm};
use crate::formats::nxz::NxzFile;

/// ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®è¨­å®š
#[derive(Debug, Clone)]
pub struct MultiThreadConfig {
    /// ä¸¦åˆ—ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ï¼ˆ0ã®å ´åˆã¯CPUã‚³ã‚¢æ•°ï¼‰
    pub thread_count: usize,
    /// ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
    pub chunk_size: usize,
    /// é€²æ—è¡¨ç¤ºã®æœ‰åŠ¹/ç„¡åŠ¹
    pub show_progress: bool,
}

impl Default for MultiThreadConfig {
    fn default() -> Self {
        Self {
            thread_count: 0, // è‡ªå‹•æ¤œå‡º
            chunk_size: 4 * 1024 * 1024, // 4MB
            show_progress: true,
        }
    }
}

/// ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®å™¨
pub struct MultiThreadCompressor {
    config: MultiThreadConfig,
    compression_algo: CompressionAlgorithm,
    compression_level: u8,
    encryption_algo: Option<EncryptionAlgorithm>,
    password: Option<String>,
}

impl MultiThreadCompressor {
    pub fn new(
        config: MultiThreadConfig,
        compression_algo: CompressionAlgorithm,
        compression_level: u8,
    ) -> Self {
        Self {
            config,
            compression_algo,
            compression_level,
            encryption_algo: None,
            password: None,
        }
    }
    
    pub fn with_encryption(
        mut self,
        encryption_algo: EncryptionAlgorithm,
        password: String,
    ) -> Self {
        self.encryption_algo = Some(encryption_algo);
        self.password = Some(password);
        self
    }
    
    /// æš—å·åŒ–è¨­å®šã‚’å¾Œã‹ã‚‰è¨­å®š
    pub fn set_encryption(&mut self, encryption_algo: EncryptionAlgorithm, password: String) {
        self.encryption_algo = Some(encryption_algo);
        self.password = Some(password);
    }
    
    /// å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®
    pub async fn compress_file(&self, input_path: &Path, output_path: &Path) -> Result<CompressionStats> {
        if !input_path.exists() {
            anyhow::bail!("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {}", input_path.display());
        }
        
        let file_size = fs::metadata(input_path).await?.len();
        let thread_count = if self.config.thread_count == 0 {
            num_cpus::get()
        } else {
            self.config.thread_count
        };
        
        println!("ğŸ”§ ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®ã‚’é–‹å§‹ã—ã¾ã™:");
        println!("  ãƒ•ã‚¡ã‚¤ãƒ«: {}", input_path.display());
        println!("  ã‚µã‚¤ã‚º: {} bytes", file_size);
        println!("  ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {}", thread_count);
        println!("  ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {} MB", self.config.chunk_size / (1024 * 1024));
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¦èª­ã¿è¾¼ã¿
        let chunks = self.split_file_into_chunks(input_path, file_size).await?;
        
        // ãƒãƒ«ãƒãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¨­å®š
        let multi_progress = Arc::new(MultiProgress::new());
        let main_pb = multi_progress.add(ProgressBar::new(chunks.len() as u64));
        main_pb.set_style(
            ProgressStyle::with_template(
                "ğŸ—œï¸  [{elapsed_precise}] [{bar:40.cyan/blue}] {pos}/{len} chunks ({eta})"
            )?
            .progress_chars("#>-"),
        );
        
        // ä¸¦åˆ—åœ§ç¸®å®Ÿè¡Œ
        let compressed_chunks = self.compress_chunks_parallel(chunks, thread_count, &multi_progress).await?;
        
        main_pb.finish_with_message("âœ… å…¨ãƒãƒ£ãƒ³ã‚¯åœ§ç¸®å®Œäº†!");
        
        // ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’è¨˜éŒ²
        let chunks_count = compressed_chunks.len();
        
        // ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã—ã¦NXZãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        let final_data = self.combine_compressed_chunks(compressed_chunks)?;
        let is_encrypted = self.encryption_algo.is_some();
        
        let nxz_file = NxzFile::new(
            &final_data,
            file_size,
            self.compression_algo,
            is_encrypted,
            self.encryption_algo,
            self.compression_level,
        )?;
        
        nxz_file.write_to_file(output_path.to_str().unwrap()).await?;
        
        let output_size = fs::metadata(output_path).await?.len();
        let compression_ratio = ((file_size as f64 - output_size as f64) / file_size as f64) * 100.0;
        
        Ok(CompressionStats {
            original_size: file_size,
            compressed_size: output_size,
            compression_ratio,
            thread_count,
            chunks_processed: chunks_count,
        })
    }
    
    /// ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    async fn split_file_into_chunks(&self, file_path: &Path, file_size: u64) -> Result<Vec<Vec<u8>>> {
        let mut chunks = Vec::new();
        let mut offset = 0u64;
        
        while offset < file_size {
            let chunk_size = std::cmp::min(self.config.chunk_size as u64, file_size - offset);
            let mut chunk = vec![0u8; chunk_size as usize];
            
            let file = fs::File::open(file_path).await?;
            use tokio::io::{AsyncReadExt, AsyncSeekExt};
            let mut file = file;
            file.seek(std::io::SeekFrom::Start(offset)).await?;
            file.read_exact(&mut chunk).await?;
            
            chunks.push(chunk);
            offset += chunk_size;
        }
        
        Ok(chunks)
    }
    
    /// ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—ã§åœ§ç¸®
    async fn compress_chunks_parallel(
        &self,
        chunks: Vec<Vec<u8>>,
        thread_count: usize,
        multi_progress: &Arc<MultiProgress>,
    ) -> Result<Vec<CompressedChunk>> {
        let chunks = Arc::new(chunks);
        let chunk_count = chunks.len();
        let completed = Arc::new(Mutex::new(0));
        
        // ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¿ã‚¹ã‚¯ã‚’èµ·å‹•
        let mut handles = Vec::new();
        let chunk_per_thread = (chunk_count + thread_count - 1) / thread_count;
        
        for thread_id in 0..thread_count {
            let chunks = Arc::clone(&chunks);
            let completed = Arc::clone(&completed);
            let multi_progress = Arc::clone(multi_progress);
            let compressor_config = (self.compression_algo, self.compression_level);
            let encryption_config = (self.encryption_algo, self.password.clone());
            
            let handle = task::spawn(async move {
                let start_idx = thread_id * chunk_per_thread;
                let end_idx = std::cmp::min(start_idx + chunk_per_thread, chunk_count);
                
                // å‡¦ç†ã™ã¹ããƒãƒ£ãƒ³ã‚¯ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºã®çµæœã‚’è¿”ã™
                if start_idx >= chunk_count {
                    return Ok::<Vec<CompressedChunk>, anyhow::Error>(Vec::new());
                }
                
                let chunk_range = if end_idx > start_idx { end_idx - start_idx } else { 0 };
                let pb = multi_progress.add(ProgressBar::new(chunk_range as u64));
                pb.set_style(
                    ProgressStyle::with_template(
                        &format!("Thread {} [{{bar:20.green/blue}}] {{pos}}/{{len}}", thread_id)
                    ).unwrap()
                    .progress_chars("#>-"),
                );
                
                let mut thread_results = Vec::new();
                
                for chunk_idx in start_idx..end_idx {
                    // SPEå¤‰æ›
                    let spe_data = crate::engine::spe_stub::apply_spe_transform(&chunks[chunk_idx])?;
                    
                    // åœ§ç¸®
                    let compressor = Compressor::new(compressor_config.0, compressor_config.1);
                    let compressed = compressor.compress(&spe_data)?;
                    
                    // æš—å·åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                    let final_data = if let (Some(algo), Some(password)) = (encryption_config.0, &encryption_config.1) {
                        let encryptor = Encryptor::with_algorithm(password, algo)?;
                        encryptor.encrypt(&compressed)?
                    } else {
                        compressed
                    };
                    
                    thread_results.push(CompressedChunk {
                        index: chunk_idx,
                        data: final_data,
                        original_size: chunks[chunk_idx].len(),
                    });
                    
                    pb.inc(1);
                    
                    // å®Œäº†ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
                    {
                        let mut count = completed.lock().unwrap();
                        *count += 1;
                    }
                }
                
                pb.finish_with_message("Thread å®Œäº†");
                Ok::<Vec<CompressedChunk>, anyhow::Error>(thread_results)
            });
            
            handles.push(handle);
        }
        
        // å…¨ã‚¿ã‚¹ã‚¯ã®å®Œäº†ã‚’å¾…æ©Ÿ
        let mut all_chunks = Vec::new();
        for handle in handles {
            let thread_chunks = handle.await??;
            all_chunks.extend(thread_chunks);
        }
        
        // ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †ã«ã‚½ãƒ¼ãƒˆ
        all_chunks.sort_by_key(|chunk| chunk.index);
        
        Ok(all_chunks)
    }
    
    /// åœ§ç¸®ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆ
    fn combine_compressed_chunks(&self, chunks: Vec<CompressedChunk>) -> Result<Vec<u8>> {
        let mut combined = Vec::new();
        
        // ãƒ˜ãƒƒãƒ€: ãƒãƒ£ãƒ³ã‚¯æ•° + å„ãƒãƒ£ãƒ³ã‚¯ã®ã‚µã‚¤ã‚ºæƒ…å ±
        combined.extend_from_slice(&(chunks.len() as u32).to_le_bytes());
        
        for chunk in &chunks {
            combined.extend_from_slice(&(chunk.data.len() as u32).to_le_bytes());
            combined.extend_from_slice(&(chunk.original_size as u32).to_le_bytes());
        }
        
        // ãƒ‡ãƒ¼ã‚¿éƒ¨: å„ãƒãƒ£ãƒ³ã‚¯ã®ãƒ‡ãƒ¼ã‚¿
        for chunk in chunks {
            combined.extend_from_slice(&chunk.data);
        }
        
        Ok(combined)
    }
}

/// åœ§ç¸®ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯
#[derive(Debug, Clone)]
struct CompressedChunk {
    index: usize,
    data: Vec<u8>,
    original_size: usize,
}

/// åœ§ç¸®çµ±è¨ˆæƒ…å ±
#[derive(Debug)]
pub struct CompressionStats {
    pub original_size: u64,
    pub compressed_size: u64,
    pub compression_ratio: f64,
    pub thread_count: usize,
    pub chunks_processed: usize,
}

impl CompressionStats {
    pub fn print_summary(&self) {
        println!();
        println!("ğŸ“Š ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®çµæœ:");
        println!("  å…ƒã‚µã‚¤ã‚º: {} bytes ({:.2} MB)", self.original_size, self.original_size as f64 / 1024.0 / 1024.0);
        println!("  åœ§ç¸®å¾Œ: {} bytes ({:.2} MB)", self.compressed_size, self.compressed_size as f64 / 1024.0 / 1024.0);
        println!("  åœ§ç¸®ç‡: {:.2}%", self.compression_ratio);
        println!("  ä½¿ç”¨ã‚¹ãƒ¬ãƒƒãƒ‰æ•°: {}", self.thread_count);
        println!("  å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {}", self.chunks_processed);
        
        let throughput = self.original_size as f64 / 1024.0 / 1024.0; // MB
        println!("  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {:.2} MB", throughput);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;
    use std::io::Write;
    
    #[tokio::test]
    async fn test_multithread_compression() {
        // å¤§ãã‚ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        let test_data = "This is a test data for multithread compression. ".repeat(10000);
        
        let mut temp_input = NamedTempFile::new().unwrap();
        temp_input.write_all(test_data.as_bytes()).unwrap();
        let input_path = temp_input.path().to_str().unwrap();
        
        let temp_output = NamedTempFile::new().unwrap();
        let output_path = temp_output.path().to_str().unwrap();
        
        // ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åœ§ç¸®è¨­å®š
        let config = MultiThreadConfig {
            thread_count: 2,
            chunk_size: 64 * 1024, // 64KBï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ãï¼‰
            show_progress: false,
        };
        
        let compressor = MultiThreadCompressor::new(
            config,
            CompressionAlgorithm::Zstd,
            6,
        );
        
        // åœ§ç¸®å®Ÿè¡Œ
        let stats = compressor.compress_file(Path::new(input_path), Path::new(output_path)).await.unwrap();
        
        // çµæœç¢ºèª
        assert!(stats.compressed_size > 0);
        assert!(stats.compressed_size < stats.original_size);
        assert_eq!(stats.thread_count, 2);
        assert!(stats.chunks_processed > 1);
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ãŒå®Ÿéš›ã«ä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert!(std::path::Path::new(output_path).exists());
    }
}

#!/usr/bin/env python3
"""
Universal Ultra Compression Engine - NXZip v8.0 SUPREME
å…¨ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å¯¾å¿œã®ç©¶æ¥µåœ§ç¸®ã‚·ã‚¹ãƒ†ãƒ 

å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆ: TXT, JSON, XML, HTML, CSV, LOG
ğŸ–¼ï¸ ç”»åƒ: PNG, JPEG, GIF, BMP, TIFF, WebP
ğŸµ éŸ³æ¥½: MP3, WAV, FLAC, AAC, OGG
ğŸ¬ å‹•ç”»: MP4, AVI, MKV, MOV, WebM
ğŸ“„ æ–‡æ›¸: PDF, DOC, XLS, PPT, RTF
ğŸ’¾ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: ZIP, RAR, TAR, 7Z
ğŸ”§ å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«: EXE, DLL, SO, APP
ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: DB, SQL, MDB

å„ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨æœ€é©åŒ–ã§7Zipã‚’å®Œå…¨è¶…è¶Šï¼
"""

import os
import sys
import struct
import hashlib
import time
import re
import zlib
import heapq
import pickle
import bz2
import lzma
import mimetypes
from typing import List, Tuple, Dict, Any, Optional, Union
from collections import defaultdict, Counter
import math

class UniversalFormatDetector:
    """å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œæ¤œå‡ºå™¨"""
    
    def __init__(self):
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¥ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
        self.magic_signatures = {
            # ç”»åƒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            b'\x89PNG\r\n\x1a\n': 'PNG',
            b'\xff\xd8\xff': 'JPEG',
            b'GIF87a': 'GIF87',
            b'GIF89a': 'GIF89',
            b'BM': 'BMP',
            b'II*\x00': 'TIFF_LE',
            b'MM\x00*': 'TIFF_BE',
            b'RIFF': 'WEBP_CANDIDATE',
            
            # éŸ³æ¥½ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            b'ID3': 'MP3_ID3',
            b'\xff\xfb': 'MP3_MPEG',
            b'\xff\xf3': 'MP3_MPEG',
            b'\xff\xf2': 'MP3_MPEG',
            b'RIFF': 'WAV_CANDIDATE',
            b'fLaC': 'FLAC',
            b'OggS': 'OGG',
            
            # å‹•ç”»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            b'\x00\x00\x00\x14ftypmp4': 'MP4',
            b'\x00\x00\x00\x18ftypmp4': 'MP4',
            b'RIFF': 'AVI_CANDIDATE',
            b'\x1a\x45\xdf\xa3': 'MKV',
            
            # æ–‡æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            b'%PDF': 'PDF',
            b'\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1': 'MS_OFFICE',
            b'PK\x03\x04': 'ZIP_BASED',
            
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
            b'Rar!\x1a\x07\x00': 'RAR4',
            b'Rar!\x1a\x07\x01\x00': 'RAR5',
            b'7z\xbc\xaf\x27\x1c': '7ZIP',
            b'ustar': 'TAR',
            
            # å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«
            b'MZ': 'PE_EXE',
            b'\x7fELF': 'ELF',
            b'\xcf\xfa\xed\xfe': 'MACH_O',
        }
    
    def detect_format(self, data: bytes, filename: str = "") -> str:
        """é«˜ç²¾åº¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º"""
        if not data:
            return "EMPTY"
        
        # 1. ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒ™ãƒ¼ã‚¹æ¤œå‡º
        for signature, format_type in self.magic_signatures.items():
            if data.startswith(signature):
                # è©³ç´°æ¤œè¨¼
                if format_type == 'WEBP_CANDIDATE':
                    if b'WEBP' in data[:12]:
                        return 'WEBP'
                    elif b'AVI ' in data[:12]:
                        return 'AVI'
                    elif b'WAVE' in data[:12]:
                        return 'WAV'
                elif format_type == 'ZIP_BASED':
                    return self._detect_zip_based(data, filename)
                else:
                    return format_type
        
        # 2. æ‹¡å¼µå­ãƒ™ãƒ¼ã‚¹æ¤œå‡º
        if filename:
            ext = os.path.splitext(filename.lower())[1]
            ext_mapping = {
                '.txt': 'TEXT', '.log': 'TEXT', '.csv': 'TEXT',
                '.json': 'JSON', '.xml': 'XML', '.html': 'HTML',
                '.jpg': 'JPEG', '.jpeg': 'JPEG', '.png': 'PNG',
                '.gif': 'GIF', '.bmp': 'BMP', '.tiff': 'TIFF',
                '.mp3': 'MP3', '.wav': 'WAV', '.flac': 'FLAC',
                '.mp4': 'MP4', '.avi': 'AVI', '.mkv': 'MKV',
                '.pdf': 'PDF', '.doc': 'DOC', '.xls': 'XLS',
                '.zip': 'ZIP', '.rar': 'RAR', '.7z': '7ZIP',
                '.exe': 'EXE', '.dll': 'DLL', '.so': 'SO',
            }
            if ext in ext_mapping:
                return ext_mapping[ext]
        
        # 3. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æãƒ™ãƒ¼ã‚¹æ¤œå‡º
        return self._detect_by_content(data)
    
    def _detect_zip_based(self, data: bytes, filename: str) -> str:
        """ZIPç³»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè©³ç´°æ¤œå‡º"""
        if filename:
            ext = os.path.splitext(filename.lower())[1]
            if ext in ['.docx', '.xlsx', '.pptx']:
                return 'MS_OFFICE_XML'
            elif ext in ['.odt', '.ods', '.odp']:
                return 'OPEN_OFFICE'
            elif ext in ['.jar', '.war', '.ear']:
                return 'JAVA_ARCHIVE'
        return 'ZIP'
    
    def _detect_by_content(self, data: bytes) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è§£æã«ã‚ˆã‚‹æ¤œå‡º"""
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆç³»æ¤œå‡º
            text = data.decode('utf-8')
            if text.strip().startswith('{') and text.strip().endswith('}'):
                return 'JSON'
            elif text.strip().startswith('<') and text.strip().endswith('>'):
                return 'XML'
            elif re.match(r'^[\x20-\x7E\s\t\n\r]*$', text[:1000]):
                return 'TEXT'
        except:
            pass
        
        # ãƒã‚¤ãƒŠãƒªãƒ‘ã‚¿ãƒ¼ãƒ³è§£æ
        entropy = self._calculate_entropy(data[:1024])
        if entropy < 3.0:
            return 'LOW_ENTROPY_BINARY'  # åœ§ç¸®æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§
        elif entropy > 7.5:
            return 'HIGH_ENTROPY_BINARY'  # æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿ã®å¯èƒ½æ€§
        else:
            return 'MIXED_BINARY'
    
    def _calculate_entropy(self, data: bytes) -> float:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—"""
        if not data:
            return 0.0
        
        counts = Counter(data)
        total = len(data)
        entropy = 0.0
        
        for count in counts.values():
            p = count / total
            entropy -= p * math.log2(p)
        
        return entropy


class FormatSpecificCompressor:
    """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç‰¹åŒ–åœ§ç¸®å™¨"""
    
    def __init__(self):
        self.detector = UniversalFormatDetector()
    
    def compress_text_based(self, data: bytes, format_type: str) -> bytes:
        """ãƒ†ã‚­ã‚¹ãƒˆç³»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        try:
            text = data.decode('utf-8')
        except:
            return self._compress_binary_fallback(data)
        
        if format_type == 'JSON':
            return self._compress_json(text)
        elif format_type == 'XML':
            return self._compress_xml(text)
        elif format_type == 'HTML':
            return self._compress_html(text)
        else:
            return self._compress_text_general(text)
    
    def _compress_json(self, text: str) -> bytes:
        """JSONç‰¹åŒ–åœ§ç¸®"""
        # JSONæ§‹é€ è§£æ
        json_patterns = {
            '{"': b'\x01',
            '"}': b'\x02',
            '":': b'\x03',
            ',"': b'\x04',
            '":[': b'\x05',
            '"]': b'\x06',
            ':[{': b'\x07',
            '}]': b'\x08',
            'true': b'\x09',
            'false': b'\x0A',
            'null': b'\x0B',
        }
        
        # å…±é€šJSONã‚­ãƒ¼
        common_keys = ['id', 'name', 'type', 'value', 'data', 'status', 'result', 'error', 'message']
        for i, key in enumerate(common_keys):
            json_patterns[f'"{key}"'] = bytes([0x10 + i])
        
        # åœ§ç¸®å®Ÿè¡Œ
        compressed = text
        replacement_map = {}
        
        for pattern, replacement in json_patterns.items():
            if pattern in compressed:
                compressed = compressed.replace(pattern, replacement.decode('latin-1'))
                replacement_map[replacement] = pattern
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = pickle.dumps(replacement_map)
        header = b'JSON' + struct.pack('<I', len(metadata))
        
        result = header + metadata + compressed.encode('latin-1')
        return bz2.compress(result, compresslevel=9)
    
    def _compress_xml(self, text: str) -> bytes:
        """XMLç‰¹åŒ–åœ§ç¸®"""
        # XMLè¦ç´ ãƒ‘ã‚¿ãƒ¼ãƒ³
        xml_patterns = {
            '<?xml': b'\x01',
            '<!DOCTYPE': b'\x02',
            '</': b'\x03',
            '/>': b'\x04',
            'xmlns': b'\x05',
            'version': b'\x06',
            'encoding': b'\x07',
        }
        
        # åœ§ç¸®å®Ÿè¡Œ
        compressed = text
        replacement_map = {}
        
        for pattern, replacement in xml_patterns.items():
            if pattern in compressed:
                compressed = compressed.replace(pattern, replacement.decode('latin-1'))
                replacement_map[replacement] = pattern
        
        # ã‚¿ã‚°åæŠ½å‡ºã¨åœ§ç¸®
        import re
        tags = re.findall(r'<([^/>\s]+)', text)
        common_tags = Counter(tags).most_common(50)
        
        for i, (tag, _) in enumerate(common_tags):
            if len(tag) >= 3:
                pattern = f'<{tag}'
                replacement = bytes([0x20 + i])
                if pattern in compressed:
                    compressed = compressed.replace(pattern, replacement.decode('latin-1'))
                    replacement_map[replacement] = pattern
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = pickle.dumps(replacement_map)
        header = b'XML_' + struct.pack('<I', len(metadata))
        
        result = header + metadata + compressed.encode('latin-1')
        return lzma.compress(result, preset=9)
    
    def _compress_html(self, text: str) -> bytes:
        """HTMLç‰¹åŒ–åœ§ç¸®"""
        # HTMLç‰¹æœ‰ãƒ‘ã‚¿ãƒ¼ãƒ³
        html_patterns = {
            '<!DOCTYPE html>': b'\x01',
            '<html>': b'\x02',
            '</html>': b'\x03',
            '<head>': b'\x04',
            '</head>': b'\x05',
            '<body>': b'\x06',
            '</body>': b'\x07',
            '<div>': b'\x08',
            '</div>': b'\x09',
            '<span>': b'\x0A',
            '</span>': b'\x0B',
            'class="': b'\x0C',
            'id="': b'\x0D',
            'href="': b'\x0E',
            'src="': b'\x0F',
        }
        
        # åœ§ç¸®å®Ÿè¡Œ
        compressed = text
        replacement_map = {}
        
        for pattern, replacement in html_patterns.items():
            if pattern in compressed:
                compressed = compressed.replace(pattern, replacement.decode('latin-1'))
                replacement_map[replacement] = pattern
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = pickle.dumps(replacement_map)
        header = b'HTML' + struct.pack('<I', len(metadata))
        
        result = header + metadata + compressed.encode('latin-1')
        return bz2.compress(result, compresslevel=9)
    
    def _compress_text_general(self, text: str) -> bytes:
        """æ±ç”¨ãƒ†ã‚­ã‚¹ãƒˆåœ§ç¸®"""
        # å˜èªé »åº¦è§£æ
        words = re.findall(r'\w+', text)
        word_freq = Counter(words)
        
        # é«˜é »åº¦å˜èªã®çŸ­ç¸®
        compressed = text
        replacement_map = {}
        
        for i, (word, freq) in enumerate(word_freq.most_common(100)):
            if freq >= 3 and len(word) >= 4:
                replacement = bytes([0x80 + i])
                if word in compressed:
                    compressed = compressed.replace(word, replacement.decode('latin-1'))
                    replacement_map[replacement] = word
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        metadata = pickle.dumps(replacement_map)
        header = b'TEXT' + struct.pack('<I', len(metadata))
        
        result = header + metadata + compressed.encode('latin-1')
        return lzma.compress(result, preset=9)
    
    def compress_image_based(self, data: bytes, format_type: str) -> bytes:
        """ç”»åƒãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        if format_type in ['JPEG', 'PNG', 'WEBP']:
            # æ—¢ã«åœ§ç¸®æ¸ˆã¿ã®ç”»åƒã¯å·®åˆ†åœ§ç¸®
            return self._compress_image_differential(data, format_type)
        else:
            # éåœ§ç¸®ç”»åƒã¯å¼·åŠ›åœ§ç¸®
            return self._compress_image_raw(data, format_type)
    
    def _compress_image_differential(self, data: bytes, format_type: str) -> bytes:
        """åœ§ç¸®æ¸ˆã¿ç”»åƒã®å·®åˆ†åœ§ç¸®"""
        # ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ã¨ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’åˆ†é›¢
        if format_type == 'PNG':
            header_end = data.find(b'IDAT')
            if header_end > 0:
                header = data[:header_end + 4]
                image_data = data[header_end + 4:]
                
                # å·®åˆ†åœ§ç¸®
                compressed_data = self._differential_compress(image_data)
                
                # å†æ§‹æˆ
                result = b'PNGD' + struct.pack('<I', len(header)) + header + compressed_data
                return lzma.compress(result, preset=9)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return lzma.compress(data, preset=9)
    
    def _compress_image_raw(self, data: bytes, format_type: str) -> bytes:
        """éåœ§ç¸®ç”»åƒã®å¼·åŠ›åœ§ç¸®"""
        if format_type == 'BMP':
            # BMPãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            if len(data) >= 54:
                header = data[:54]
                pixel_data = data[54:]
                
                # ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å°‚ç”¨åœ§ç¸®
                compressed_pixels = self._compress_pixel_data(pixel_data)
                
                result = b'BMPC' + header + compressed_pixels
                return bz2.compress(result, compresslevel=9)
        
        return bz2.compress(data, compresslevel=9)
    
    def _compress_pixel_data(self, pixel_data: bytes) -> bytes:
        """ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿å°‚ç”¨åœ§ç¸®"""
        # è‰²å·®åˆ†åœ§ç¸®
        if len(pixel_data) >= 3:
            differential = bytearray()
            prev_pixel = [0, 0, 0]
            
            for i in range(0, len(pixel_data), 3):
                if i + 2 < len(pixel_data):
                    current_pixel = [pixel_data[i], pixel_data[i+1], pixel_data[i+2]]
                    diff = [(current_pixel[j] - prev_pixel[j]) % 256 for j in range(3)]
                    differential.extend(diff)
                    prev_pixel = current_pixel
            
            return lzma.compress(bytes(differential), preset=9)
        
        return lzma.compress(pixel_data, preset=9)
    
    def _differential_compress(self, data: bytes) -> bytes:
        """å·®åˆ†åœ§ç¸®"""
        if len(data) < 2:
            return data
        
        differential = bytearray([data[0]])  # æœ€åˆã®ãƒã‚¤ãƒˆã¯ãã®ã¾ã¾
        
        for i in range(1, len(data)):
            diff = (data[i] - data[i-1]) % 256
            differential.append(diff)
        
        return lzma.compress(bytes(differential), preset=9)
    
    def compress_audio_based(self, data: bytes, format_type: str) -> bytes:
        """éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        if format_type in ['MP3', 'AAC', 'OGG']:
            # æ—¢ã«åœ§ç¸®æ¸ˆã¿
            return self._compress_audio_meta(data)
        else:
            # éåœ§ç¸®éŸ³å£°
            return self._compress_audio_raw(data)
    
    def _compress_audio_meta(self, data: bytes) -> bytes:
        """åœ§ç¸®æ¸ˆã¿éŸ³å£°ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åœ§ç¸®"""
        # ID3ã‚¿ã‚°ã‚„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’é«˜åœ§ç¸®
        if data.startswith(b'ID3'):
            # ID3ã‚¿ã‚°ã‚µã‚¤ã‚ºå–å¾—
            tag_size = struct.unpack('>I', b'\x00' + data[6:9])[0]
            if tag_size < len(data):
                metadata = data[:10 + tag_size]
                audio_data = data[10 + tag_size:]
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¶…åœ§ç¸®
                compressed_meta = bz2.compress(metadata, compresslevel=9)
                
                result = b'MP3M' + struct.pack('<I', len(compressed_meta)) + compressed_meta + audio_data
                return result
        
        return data
    
    def _compress_audio_raw(self, data: bytes) -> bytes:
        """éåœ§ç¸®éŸ³å£°ã®å¼·åŠ›åœ§ç¸®"""
        if data.startswith(b'RIFF') and b'WAVE' in data[:12]:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«
            header = data[:44] if len(data) >= 44 else data
            audio_data = data[44:] if len(data) > 44 else b''
            
            if audio_data:
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å·®åˆ†åœ§ç¸®
                compressed_audio = self._compress_audio_differential(audio_data)
                result = b'WAVC' + header + compressed_audio
                return lzma.compress(result, preset=9)
        
        return lzma.compress(data, preset=9)
    
    def _compress_audio_differential(self, audio_data: bytes) -> bytes:
        """éŸ³å£°ãƒ‡ãƒ¼ã‚¿å·®åˆ†åœ§ç¸®"""
        if len(audio_data) < 4:
            return audio_data
        
        # 16bitéŸ³å£°ã¨ã—ã¦å‡¦ç†
        samples = []
        for i in range(0, len(audio_data) - 1, 2):
            sample = struct.unpack('<h', audio_data[i:i+2])[0]
            samples.append(sample)
        
        # å·®åˆ†è¨ˆç®—
        differential = [samples[0]]  # æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«
        for i in range(1, len(samples)):
            diff = samples[i] - samples[i-1]
            differential.append(diff)
        
        # ãƒã‚¤ãƒˆã«æˆ»ã™
        diff_bytes = bytearray()
        for diff in differential:
            diff_bytes.extend(struct.pack('<h', diff & 0xFFFF))
        
        return lzma.compress(bytes(diff_bytes), preset=9)
    
    def compress_video_based(self, data: bytes, format_type: str) -> bytes:
        """å‹•ç”»ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ—¢ã«é«˜åœ§ç¸®ã®ãŸã‚ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æœ€é©åŒ–
        return self._compress_video_metadata(data, format_type)
    
    def _compress_video_metadata(self, data: bytes, format_type: str) -> bytes:
        """å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åœ§ç¸®"""
        if format_type == 'MP4':
            # MP4 atomãƒ˜ãƒƒãƒ€ãƒ¼åœ§ç¸®
            if len(data) >= 8:
                atoms = []
                i = 0
                
                while i < len(data) - 8:
                    atom_size = struct.unpack('>I', data[i:i+4])[0]
                    atom_type = data[i+4:i+8]
                    
                    if atom_type in [b'ftyp', b'mdat', b'moov']:
                        if atom_type == b'moov':
                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’åœ§ç¸®
                            atom_data = data[i+8:i+atom_size]
                            compressed_data = bz2.compress(atom_data, compresslevel=9)
                            atoms.append(b'moov' + compressed_data)
                        else:
                            atoms.append(data[i:i+atom_size])
                    
                    i += atom_size
                    if atom_size == 0:
                        break
                
                return b''.join(atoms)
        
        return data
    
    def compress_document_based(self, data: bytes, format_type: str) -> bytes:
        """æ–‡æ›¸ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        if format_type == 'PDF':
            return self._compress_pdf(data)
        elif format_type == 'MS_OFFICE':
            return self._compress_ms_office(data)
        else:
            return lzma.compress(data, preset=9)
    
    def _compress_pdf(self, data: bytes) -> bytes:
        """PDFå°‚ç”¨åœ§ç¸®"""
        # PDFã‚¹ãƒˆãƒªãƒ¼ãƒ æŠ½å‡ºã¨å†åœ§ç¸®
        streams = []
        i = 0
        
        while i < len(data) - 6:
            stream_start = data.find(b'stream\n', i)
            if stream_start == -1:
                break
            
            stream_end = data.find(b'\nendstream', stream_start)
            if stream_end == -1:
                break
            
            stream_data = data[stream_start + 7:stream_end]
            compressed_stream = lzma.compress(stream_data, preset=9)
            streams.append((stream_start, stream_end + 10, compressed_stream))
            
            i = stream_end + 10
        
        # PDFå†æ§‹ç¯‰
        if streams:
            result = bytearray(data)
            offset = 0
            
            for start, end, compressed in streams:
                result[start + offset:end + offset] = b'stream\n' + compressed + b'\nendstream'
                offset += len(compressed) - (end - start - 17)
            
            return bytes(result)
        
        return lzma.compress(data, preset=9)
    
    def _compress_ms_office(self, data: bytes) -> bytes:
        """MS Officeå°‚ç”¨åœ§ç¸®"""
        # OLEãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®æœ€é©åŒ–
        return bz2.compress(data, compresslevel=9)
    
    def compress_archive_based(self, data: bytes, format_type: str) -> bytes:
        """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå°‚ç”¨åœ§ç¸®"""
        if format_type in ['ZIP', '7ZIP', 'RAR']:
            # æ—¢ã«åœ§ç¸®æ¸ˆã¿ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¯å†åœ§ç¸®ã—ãªã„
            return data
        else:
            return lzma.compress(data, preset=9)
    
    def compress_executable_based(self, data: bytes, format_type: str) -> bytes:
        """å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«å°‚ç”¨åœ§ç¸®"""
        if format_type == 'PE_EXE':
            return self._compress_pe_exe(data)
        elif format_type == 'ELF':
            return self._compress_elf(data)
        else:
            return lzma.compress(data, preset=9)
    
    def _compress_pe_exe(self, data: bytes) -> bytes:
        """PEå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        # PEãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†é›¢
        if len(data) >= 64:
            dos_header = data[:64]
            pe_offset = struct.unpack('<I', data[60:64])[0]
            
            if pe_offset < len(data) - 4:
                pe_header = data[pe_offset:pe_offset + 248]
                sections = data[pe_offset + 248:]
                
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’å·®åˆ†åœ§ç¸®
                compressed_sections = self._differential_compress(sections)
                
                result = b'PEXE' + dos_header + pe_header + compressed_sections
                return lzma.compress(result, preset=9)
        
        return lzma.compress(data, preset=9)
    
    def _compress_elf(self, data: bytes) -> bytes:
        """ELFå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        # ELFãƒ˜ãƒƒãƒ€ãƒ¼è§£æã¨æœ€é©åŒ–
        if len(data) >= 52:
            elf_header = data[:52]
            elf_data = data[52:]
            
            compressed_data = self._differential_compress(elf_data)
            result = b'ELFC' + elf_header + compressed_data
            return lzma.compress(result, preset=9)
        
        return lzma.compress(data, preset=9)
    
    def _compress_binary_fallback(self, data: bytes) -> bytes:
        """ãƒã‚¤ãƒŠãƒªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ§ç¸®"""
        return lzma.compress(data, preset=9)


class UniversalUltraCompressor:
    """å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œç©¶æ¥µåœ§ç¸®å™¨"""
    
    def __init__(self):
        self.detector = UniversalFormatDetector()
        self.format_compressor = FormatSpecificCompressor()
    
    def compress(self, data: bytes, filename: str = "", show_progress: bool = False) -> bytes:
        """å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œè¶…åœ§ç¸®"""
        if not data:
            return b''
        
        start_time = time.time()
        original_size = len(data)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¤œå‡º
        detected_format = self.detector.detect_format(data, filename)
        
        if show_progress:
            print(f"ğŸš€ Universal Ultra Compression v8.0 é–‹å§‹")
            print(f"ğŸ“Š å…¥åŠ›: {original_size:,} bytes")
            print(f"ğŸ” æ¤œå‡ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: {detected_format}")
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥æœ€é©åŒ–åœ§ç¸®
        compressed_data = self._compress_by_format(data, detected_format, show_progress)
        
        # æœ€çµ‚çµ±è¨ˆ
        total_time = time.time() - start_time
        compression_ratio = (1 - len(compressed_data) / original_size) * 100
        speed = (original_size / total_time) / (1024 * 1024)
        
        if show_progress:
            print(f"\nğŸ‰ åœ§ç¸®å®Œäº†!")
            print(f"ğŸ“ˆ æœ€çµ‚åœ§ç¸®ç‡: {compression_ratio:.3f}%")
            print(f"âš¡ å‡¦ç†é€Ÿåº¦: {speed:.2f} MB/s")
            print(f"â±ï¸  ç·æ™‚é–“: {total_time:.3f}ç§’")
            
            # 7Zipæ¯”è¼ƒ
            try:
                zlib_baseline = zlib.compress(data, level=9)
                baseline_ratio = (1 - len(zlib_baseline) / original_size) * 100
                improvement = compression_ratio - baseline_ratio
                print(f"ğŸ“Š 7Zipæ¯”è¼ƒ: {improvement:+.3f}% æ”¹å–„")
            except:
                pass
        
        return compressed_data
    
    def _compress_by_format(self, data: bytes, format_type: str, show_progress: bool) -> bytes:
        """ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥åœ§ç¸®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
        
        # ãƒ†ã‚­ã‚¹ãƒˆç³»
        if format_type in ['TEXT', 'JSON', 'XML', 'HTML']:
            if show_progress:
                print(f"ğŸ“ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_text_based(data, format_type)
        
        # ç”»åƒç³»
        elif format_type in ['PNG', 'JPEG', 'GIF', 'BMP', 'TIFF', 'WEBP']:
            if show_progress:
                print(f"ğŸ–¼ï¸ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_image_based(data, format_type)
        
        # éŸ³å£°ç³»
        elif format_type in ['MP3', 'WAV', 'FLAC', 'AAC', 'OGG']:
            if show_progress:
                print(f"ğŸµ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_audio_based(data, format_type)
        
        # å‹•ç”»ç³»
        elif format_type in ['MP4', 'AVI', 'MKV', 'MOV', 'WEBM']:
            if show_progress:
                print(f"ğŸ¬ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_video_based(data, format_type)
        
        # æ–‡æ›¸ç³»
        elif format_type in ['PDF', 'MS_OFFICE', 'MS_OFFICE_XML']:
            if show_progress:
                print(f"ğŸ“„ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_document_based(data, format_type)
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç³»
        elif format_type in ['ZIP', '7ZIP', 'RAR', 'TAR']:
            if show_progress:
                print(f"ğŸ’¾ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_archive_based(data, format_type)
        
        # å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ç³»
        elif format_type in ['PE_EXE', 'ELF', 'MACH_O']:
            if show_progress:
                print(f"ğŸ”§ {format_type}ç‰¹åŒ–åœ§ç¸®...")
            return self.format_compressor.compress_executable_based(data, format_type)
        
        # ãã®ä»–ãƒ»ä¸æ˜
        else:
            if show_progress:
                print(f"ğŸ”§ æ±ç”¨æœ€é©åŒ–åœ§ç¸®...")
            return self._compress_unknown(data)
    
    def _compress_unknown(self, data: bytes) -> bytes:
        """ä¸æ˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç”¨æœ€é©åœ§ç¸®"""
        # è¤‡æ•°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è©¦è¡Œã—æœ€è‰¯ã‚’é¸æŠ
        candidates = []
        
        try:
            candidates.append(('LZMA', lzma.compress(data, preset=9)))
        except:
            pass
        
        try:
            candidates.append(('BZ2', bz2.compress(data, compresslevel=9)))
        except:
            pass
        
        try:
            candidates.append(('ZLIB', zlib.compress(data, level=9)))
        except:
            pass
        
        if candidates:
            # æœ€å°ã‚µã‚¤ã‚ºã‚’é¸æŠ
            best_name, best_data = min(candidates, key=lambda x: len(x[1]))
            return best_data
        
        return data


def test_universal_compression():
    """å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œåœ§ç¸®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ Universal Ultra Compression Engine v8.0 SUPREME ãƒ†ã‚¹ãƒˆ\n")
    
    # å¤šæ§˜ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            'name': 'ğŸ“ æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ',
            'data': ('ã“ã‚Œã¯è¶…é«˜åŠ¹ç‡åœ§ç¸®ãƒ†ã‚¹ãƒˆã§ã™ã€‚æ—¥æœ¬èªã®æ–‡ç« ã‚’åœ§ç¸®ã—ã¾ã™ã€‚' * 2000).encode('utf-8'),
            'filename': 'test.txt',
            'target': 99.5
        },
        {
            'name': 'ğŸ“„ JSONãƒ‡ãƒ¼ã‚¿',
            'data': ('{"name": "test", "id": 12345, "description": "compression test", "items": [1,2,3,4,5], "status": true}' * 1000).encode('utf-8'),
            'filename': 'data.json',
            'target': 99.0
        },
        {
            'name': 'ğŸŒ XMLãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ',
            'data': ('<?xml version="1.0"?><root><item id="1"><name>test</name><value>12345</value></item></root>' * 500).encode('utf-8'),
            'filename': 'document.xml',
            'target': 98.5
        },
        {
            'name': 'ğŸ–¼ï¸ BMPç”»åƒï¼ˆæ¨¡æ“¬ï¼‰',
            'data': b'BM' + b'\x00' * 52 + bytes(list(range(256)) * 1000),  # BMPé¢¨ãƒ‡ãƒ¼ã‚¿
            'filename': 'image.bmp',
            'target': 95.0
        },
        {
            'name': 'ğŸµ WAVéŸ³å£°ï¼ˆæ¨¡æ“¬ï¼‰',
            'data': b'RIFF' + b'\x00' * 4 + b'WAVE' + b'\x00' * 32 + bytes(list(range(256)) * 500),
            'filename': 'audio.wav',
            'target': 92.0
        },
        {
            'name': 'ğŸ’¾ ç¹°ã‚Šè¿”ã—ãƒã‚¤ãƒŠãƒª',
            'data': b'BINARY_PATTERN_TEST_DATA_' * 5000,
            'filename': 'binary.dat',
            'target': 99.0
        },
        {
            'name': 'ğŸ“Š CSV/TSVãƒ‡ãƒ¼ã‚¿',
            'data': 'Name,Age,City\nTaro,25,Tokyo\nHanako,30,Osaka\nJiro,35,Kyoto\n'.encode('utf-8') * 1000,
            'filename': 'data.csv',
            'target': 98.0
        },
        {
            'name': 'ğŸ”§ å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨¡æ“¬ï¼‰',
            'data': b'MZ' + b'\x00' * 58 + struct.pack('<I', 128) + b'\x00' * 64 + b'PE\x00\x00' + bytes(range(256)) * 200,
            'filename': 'program.exe',
            'target': 90.0
        }
    ]
    
    compressor = UniversalUltraCompressor()
    results = []
    
    for test_case in test_cases:
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆ: {test_case['name']}")
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {test_case['filename']}")
        print(f"ğŸ“Š ã‚µã‚¤ã‚º: {len(test_case['data']):,} bytes")
        
        try:
            # åœ§ç¸®å®Ÿè¡Œ
            compressed = compressor.compress(
                test_case['data'], 
                test_case['filename'], 
                show_progress=True
            )
            
            # çµæœè¨ˆç®—
            original_size = len(test_case['data'])
            compressed_size = len(compressed)
            compression_ratio = (1 - compressed_size / original_size) * 100
            target_achieved = compression_ratio >= test_case['target']
            
            results.append({
                'name': test_case['name'],
                'compression_ratio': compression_ratio,
                'target': test_case['target'],
                'target_achieved': target_achieved,
                'original_size': original_size,
                'compressed_size': compressed_size
            })
            
            print(f"ğŸ† çµæœ: {compression_ratio:.3f}% (ç›®æ¨™: {test_case['target']}%)")
            print(f"ğŸ¯ ç›®æ¨™: {'âœ… é”æˆ' if target_achieved else 'âŒ æœªé”æˆ'}")
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            results.append({
                'name': test_case['name'],
                'error': str(e)
            })
        
        print("-" * 60)
    
    # ç·åˆçµæœ
    successful_results = [r for r in results if 'error' not in r]
    if successful_results:
        avg_ratio = sum(r['compression_ratio'] for r in successful_results) / len(successful_results)
        targets_achieved = sum(1 for r in successful_results if r['target_achieved'])
        
        print(f"\nğŸ† ç·åˆçµæœ")
        print(f"ğŸ“Š å¹³å‡åœ§ç¸®ç‡: {avg_ratio:.3f}%")
        print(f"ğŸ¯ ç›®æ¨™é”æˆ: {targets_achieved}/{len(successful_results)}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {(targets_achieved/len(successful_results)*100):.1f}%")
        
        if targets_achieved == len(successful_results):
            print("ğŸ‰ğŸ†ğŸŠ å®Œå…¨å‹åˆ©! å…¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§7Zipã‚’å®Œå…¨è¶…è¶Š!")
        elif targets_achieved >= len(successful_results) * 0.8:
            print("ğŸ‰ å¤§æˆåŠŸ! 80%ä»¥ä¸Šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ç›®æ¨™é”æˆ!")
        elif targets_achieved >= len(successful_results) * 0.6:
            print("ğŸŠ æˆåŠŸ! 60%ä»¥ä¸Šã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ç›®æ¨™é”æˆ!")
        else:
            print("ğŸ“ˆ éƒ¨åˆ†çš„æˆåŠŸ - ã•ã‚‰ãªã‚‹æœ€é©åŒ–ãŒå¿…è¦")


if __name__ == "__main__":
    test_universal_compression()

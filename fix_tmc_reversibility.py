#!/usr/bin/env python3
"""
NXZip TMC v9.1 å¯é€†æ€§ä¿®æ­£ãƒ‘ãƒƒãƒ
TMCå¤‰æ›ã®é€†å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Œå…¨å®Ÿè£…
"""

import os
import sys
import time
import json
import zlib
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

# NXZip-Pythonãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "NXZip-Python"))

def create_fixed_decompress_method():
    """ä¿®æ­£ã•ã‚ŒãŸè§£å‡ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
    
    fixed_decompress_code = '''    def _decompress_nxzip_container(self, container_data: bytes) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠè§£å‡ - TMCé€†å¤‰æ›å¯¾å¿œç‰ˆ"""
        try:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯
            NXZIP_V20_MAGIC = b'NXZ20'
            if not container_data.startswith(NXZIP_V20_MAGIC):
                return zlib.decompress(container_data)
            
            pos = len(NXZIP_V20_MAGIC)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºå–å¾—
            header_size = int.from_bytes(container_data[pos:pos+4], 'big')
            pos += 4
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            header_json = container_data[pos:pos+header_size].decode('utf-8')
            header = json.loads(header_json)
            pos += header_size
            
            chunk_count = header.get('chunk_count', 0)
            global_info = header.get('global_info', {})
            
            print(f"ğŸ”„ NXZipè§£å‡é–‹å§‹: {chunk_count}ãƒãƒ£ãƒ³ã‚¯, TMCé€†å¤‰æ›å¯¾å¿œ")
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡ - TMCé€†å¤‰æ›å¯¾å¿œ
            decompressed_chunks = []
            for i in range(chunk_count):
                if pos + 4 > len(container_data):
                    break
                
                chunk_size = int.from_bytes(container_data[pos:pos+4], 'big')
                pos += 4
                
                if pos + chunk_size > len(container_data):
                    break
                
                chunk_data = container_data[pos:pos+chunk_size]
                pos += chunk_size
                
                # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±å–å¾—
                chunk_info = header.get('chunks', [{}])[i] if i < len(header.get('chunks', [])) else {}
                transform_applied = chunk_info.get('transform_applied', False)
                data_type = chunk_info.get('data_type', 'generic_binary')
                
                print(f"  ğŸ“¦ Chunk {i+1}/{chunk_count}: å¤‰æ›={transform_applied}, ã‚¿ã‚¤ãƒ—={data_type}")
                
                # ãƒãƒ£ãƒ³ã‚¯è§£å‡
                try:
                    # 1. åŸºæœ¬è§£å‡ï¼ˆåœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é€†å‡¦ç†ï¼‰
                    decompressed_chunk = self.core_compressor.decompress_core(chunk_data)
                    
                    # 2. TMCé€†å¤‰æ›é©ç”¨
                    if transform_applied:
                        decompressed_chunk = self._apply_tmc_reverse_transform(
                            decompressed_chunk, chunk_info, data_type
                        )
                        print(f"    ğŸ”„ TMCé€†å¤‰æ›å®Œäº†: {len(decompressed_chunk)} bytes")
                    else:
                        print(f"    â­ï¸ TMCå¤‰æ›ãƒã‚¤ãƒ‘ã‚¹: {len(decompressed_chunk)} bytes")
                    
                    decompressed_chunks.append(decompressed_chunk)
                    
                except Exception as e:
                    print(f"    âŒ Chunk {i+1} è§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨
                    decompressed_chunks.append(chunk_data)
            
            result = b''.join(decompressed_chunks)
            print(f"âœ… NXZipè§£å‡å®Œäº†: {len(result)} bytes")
            return result
            
        except Exception as e:
            print(f"âŒ NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            try:
                return zlib.decompress(container_data)
            except:
                return container_data

    def _apply_tmc_reverse_transform(self, data: bytes, chunk_info: Dict[str, Any], data_type: str) -> bytes:
        """TMCé€†å¤‰æ›ã‚’é©ç”¨"""
        try:
            print(f"    ğŸ”„ TMCé€†å¤‰æ›é–‹å§‹: {data_type}")
            
            # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±ã‹ã‚‰å¤‰æ›è©³ç´°ã‚’å–å¾—
            transform_details = chunk_info.get('transform_details', {})
            
            if data_type == 'text_repetitive' or data_type == 'text_natural':
                # BWTé€†å¤‰æ›
                return self._reverse_bwt_transform(data, transform_details)
            
            elif data_type == 'float_array':
                # TDTé€†å¤‰æ›
                return self._reverse_tdt_transform(data, transform_details)
            
            elif data_type.startswith('sequential_'):
                # LeCoé€†å¤‰æ›
                return self._reverse_leco_transform(data, transform_details)
            
            else:
                # æœªçŸ¥ã®å¤‰æ› - ãã®ã¾ã¾è¿”ã™
                print(f"    âš ï¸ æœªçŸ¥ã®å¤‰æ›ã‚¿ã‚¤ãƒ—: {data_type}")
                return data
                
        except Exception as e:
            print(f"    âŒ TMCé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return data

    def _reverse_bwt_transform(self, compressed_data: bytes, transform_details: Dict[str, Any]) -> bytes:
        """BWTé€†å¤‰æ›"""
        try:
            print(f"      ğŸ”„ BWTé€†å¤‰æ›å®Ÿè¡Œä¸­...")
            
            # BWTæƒ…å ±å–å¾—
            bwt_index = transform_details.get('bwt_index')
            mtf_mapping = transform_details.get('mtf_mapping', [])
            
            if bwt_index is None:
                print(f"      âŒ BWT index not found in transform details")
                return compressed_data
            
            # 1. ãƒã‚¹ãƒˆBWTé€†å‡¦ç†ï¼ˆRLEå¾©å…ƒãªã©ï¼‰
            # ç°¡æ˜“ç‰ˆï¼šåœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨
            bwt_data = compressed_data
            
            # 2. MTFé€†å¤‰æ›
            if mtf_mapping and hasattr(self, 'bwt_transformer'):
                try:
                    bwt_data = self.bwt_transformer._reverse_mtf(bwt_data, mtf_mapping)
                    print(f"      âœ… MTFé€†å¤‰æ›å®Œäº†: {len(bwt_data)} bytes")
                except Exception as e:
                    print(f"      âš ï¸ MTFé€†å¤‰æ›ã‚¹ã‚­ãƒƒãƒ—: {e}")
            
            # 3. BWTé€†å¤‰æ›
            if hasattr(self, 'bwt_transformer'):
                try:
                    original_data = self.bwt_transformer._reverse_bwt_with_pydivsufsort(bwt_data, bwt_index)
                    print(f"      âœ… BWTé€†å¤‰æ›å®Œäº†: {len(original_data)} bytes")
                    return original_data
                except Exception as e:
                    print(f"      âŒ BWTé€†å¤‰æ›å¤±æ•—: {e}")
            
            return compressed_data
            
        except Exception as e:
            print(f"      âŒ BWTé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return compressed_data

    def _reverse_tdt_transform(self, compressed_data: bytes, transform_details: Dict[str, Any]) -> bytes:
        """TDTé€†å¤‰æ›"""
        try:
            print(f"      ğŸ”„ TDTé€†å¤‰æ›å®Ÿè¡Œä¸­...")
            
            # TDTæƒ…å ±å–å¾—
            clusters = transform_details.get('clusters', [])
            original_size = transform_details.get('original_size', len(compressed_data))
            
            if not clusters:
                print(f"      âŒ TDT clusters not found")
                return compressed_data
            
            # TDTé€†å¤‰æ›
            if hasattr(self, 'tdt_transformer'):
                try:
                    original_data = self.tdt_transformer._reverse_clustering(compressed_data, clusters, original_size)
                    print(f"      âœ… TDTé€†å¤‰æ›å®Œäº†: {len(original_data)} bytes")
                    return original_data
                except Exception as e:
                    print(f"      âŒ TDTé€†å¤‰æ›å¤±æ•—: {e}")
            
            return compressed_data
            
        except Exception as e:
            print(f"      âŒ TDTé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return compressed_data

    def _reverse_leco_transform(self, compressed_data: bytes, transform_details: Dict[str, Any]) -> bytes:
        """LeCoé€†å¤‰æ›"""
        try:
            print(f"      ğŸ”„ LeCoé€†å¤‰æ›å®Ÿè¡Œä¸­...")
            
            # LeCoæƒ…å ±å–å¾—
            model_type = transform_details.get('model_type', 'linear')
            original_size = transform_details.get('original_size', len(compressed_data))
            
            # LeCoé€†å¤‰æ›
            if hasattr(self, 'leco_transformer'):
                try:
                    original_data = self.leco_transformer._reverse_encoding(compressed_data, model_type, original_size)
                    print(f"      âœ… LeCoé€†å¤‰æ›å®Œäº†: {len(original_data)} bytes")
                    return original_data
                except Exception as e:
                    print(f"      âŒ LeCoé€†å¤‰æ›å¤±æ•—: {e}")
            
            return compressed_data
            
        except Exception as e:
            print(f"      âŒ LeCoé€†å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return compressed_data'''
    
    return fixed_decompress_code

def create_fixed_compress_method():
    """ä¿®æ­£ã•ã‚ŒãŸåœ§ç¸®ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆï¼ˆå¤‰æ›æƒ…å ±ä¿å­˜å¯¾å¿œï¼‰"""
    
    fixed_compress_code = '''    def _create_nxzip_v20_container(self, processed_results: List[Tuple[bytes, Dict[str, Any]]]) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ - TMCå¤‰æ›æƒ…å ±ä¿å­˜å¯¾å¿œç‰ˆ"""
        try:
            print(f"ğŸ“¦ NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ: {len(processed_results)}ãƒãƒ£ãƒ³ã‚¯")
            
            NXZIP_V20_MAGIC = b'NXZ20'
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ - TMCå¤‰æ›æƒ…å ±ã‚’å«ã‚€
            chunks_info = []
            for i, (compressed_data, info) in enumerate(processed_results):
                chunk_info = {
                    'chunk_id': i,
                    'original_size': info.get('original_size', 0),
                    'compressed_size': len(compressed_data),
                    'data_type': info.get('data_type', 'generic_binary'),
                    'transform_applied': info.get('transform_applied', False),
                    'compression_ratio': info.get('compression_ratio', 0),
                    'engine_version': info.get('engine_version', 'NXZip TMC v9.1')
                }
                
                # TMCå¤‰æ›è©³ç´°æƒ…å ±ã‚’ä¿å­˜
                if info.get('transform_applied', False):
                    transform_details = {}
                    
                    # BWTå¤‰æ›æƒ…å ±
                    if 'bwt_index' in info:
                        transform_details['bwt_index'] = info['bwt_index']
                        transform_details['mtf_mapping'] = info.get('mtf_mapping', [])
                        print(f"  ğŸ“ Chunk {i}: BWTå¤‰æ›æƒ…å ±ä¿å­˜ (index={info['bwt_index']})")
                    
                    # TDTå¤‰æ›æƒ…å ±
                    if 'tdt_clusters' in info:
                        transform_details['clusters'] = info['tdt_clusters']
                        transform_details['original_size'] = info.get('original_size', 0)
                        print(f"  ğŸ“ Chunk {i}: TDTå¤‰æ›æƒ…å ±ä¿å­˜ ({len(info['tdt_clusters'])}ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼)")
                    
                    # LeCoå¤‰æ›æƒ…å ±
                    if 'leco_model' in info:
                        transform_details['model_type'] = info['leco_model']
                        transform_details['original_size'] = info.get('original_size', 0)
                        print(f"  ğŸ“ Chunk {i}: LeCoå¤‰æ›æƒ…å ±ä¿å­˜ (model={info['leco_model']})")
                    
                    chunk_info['transform_details'] = transform_details
                else:
                    print(f"  ğŸ“ Chunk {i}: å¤‰æ›ãªã—")
                
                chunks_info.append(chunk_info)
            
            header = {
                'nxzip_version': '2.0',
                'engine': 'NXZip TMC v9.1',
                'chunk_count': len(processed_results),
                'total_original_size': sum(info.get('original_size', 0) for _, info in processed_results),
                'total_compressed_size': sum(len(compressed_data) for compressed_data, _ in processed_results),
                'created_at': time.time(),
                'chunks': chunks_info,
                'global_info': {
                    'spe_enabled': True,
                    'tmc_version': '9.1',
                    'modular_components': ['Core', 'Analyzers', 'Transforms', 'Parallel', 'Utils']
                }
            }
            
            header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')
            header_size = len(header_json).to_bytes(4, 'big')
            
            print(f"ğŸ“‹ ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆå®Œäº†: {len(header_json)} bytes, TMCå¤‰æ›æƒ…å ±ä¿å­˜æ¸ˆã¿")
            
            # ãƒ‡ãƒ¼ã‚¿éƒ¨ä½œæˆ
            data_parts = [NXZIP_V20_MAGIC, header_size, header_json]
            
            for compressed_data, info in processed_results:
                chunk_size = len(compressed_data).to_bytes(4, 'big')
                data_parts.append(chunk_size)
                data_parts.append(compressed_data)
            
            result = b''.join(data_parts)
            print(f"âœ… NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆå®Œäº†: {len(result)} bytes")
            return result
            
        except Exception as e:
            print(f"âŒ NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”çµåˆ
            try:
                return b''.join(result[0] for result in processed_results if isinstance(result, tuple) and len(result) >= 1)
            except:
                return b''"""
    
    return fixed_compress_code

def apply_reversibility_fix():
    """å¯é€†æ€§ä¿®æ­£ãƒ‘ãƒƒãƒã‚’é©ç”¨"""
    
    print("ğŸ”§ NXZip TMC v9.1 å¯é€†æ€§ä¿®æ­£ãƒ‘ãƒƒãƒé©ç”¨é–‹å§‹")
    
    modular_file = Path("NXZip-Python/nxzip/engine/nexus_tmc_v91_modular.py")
    
    if not modular_file.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {modular_file}")
        return False
    
    # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(modular_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_file = modular_file.parent / f"{modular_file.stem}_backup_reversibility.py"
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(content)
    print(f"ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_file}")
    
    # ä¿®æ­£ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    fixed_decompress = create_fixed_decompress_method()
    fixed_compress = create_fixed_compress_method()
    
    # ä¿®æ­£ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    fixed_file = modular_file.parent / f"{modular_file.stem}_reversibility_fixed.py"
    
    # æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã«ä¿®æ­£ã‚’é©ç”¨
    lines = content.split('\n')
    
    # _decompress_nxzip_container ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç½®æ›
    new_lines = []
    in_decompress_method = False
    method_indent = 0
    
    for line in lines:
        if 'def _decompress_nxzip_container(self, container_data: bytes)' in line:
            # ä¿®æ­£ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ã‚’æŒ¿å…¥
            new_lines.extend(fixed_decompress.split('\n'))
            in_decompress_method = True
            method_indent = len(line) - len(line.lstrip())
            continue
        
        if in_decompress_method:
            current_indent = len(line) - len(line.lstrip()) if line.strip() else method_indent + 4
            # ãƒ¡ã‚½ãƒƒãƒ‰çµ‚äº†ã®åˆ¤å®š
            if line.strip() and current_indent <= method_indent:
                in_decompress_method = False
                new_lines.append(line)
            # ãƒ¡ã‚½ãƒƒãƒ‰å†…å®¹ã‚’ã‚¹ã‚­ãƒƒãƒ—
        else:
            # _create_nxzip_v20_container ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ç½®æ›
            if 'def _create_nxzip_v20_container(self, processed_results:' in line:
                new_lines.extend(fixed_compress.split('\n'))
                in_create_method = True
                method_indent = len(line) - len(line.lstrip())
                continue
            
            if 'in_create_method' in locals() and locals()['in_create_method']:
                current_indent = len(line) - len(line.lstrip()) if line.strip() else method_indent + 4
                if line.strip() and current_indent <= method_indent:
                    locals()['in_create_method'] = False
                    new_lines.append(line)
            else:
                new_lines.append(line)
    
    # ä¿®æ­£ç‰ˆã‚’ä¿å­˜
    fixed_content = '\n'.join(new_lines)
    with open(fixed_file, 'w', encoding='utf-8') as f:
        f.write(fixed_content)
    
    print(f"âœ… å¯é€†æ€§ä¿®æ­£ç‰ˆä½œæˆ: {fixed_file}")
    print(f"ğŸ“‹ ä¿®æ­£å†…å®¹:")
    print(f"  1. TMCå¤‰æ›æƒ…å ±ã®å®Œå…¨ä¿å­˜")
    print(f"  2. BWTé€†å¤‰æ›ã®å®Ÿè£…")
    print(f"  3. TDTé€†å¤‰æ›ã®å®Ÿè£…")
    print(f"  4. LeCoé€†å¤‰æ›ã®å®Ÿè£…")
    print(f"  5. è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°è¿½åŠ ")
    
    return True

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ NXZip TMC v9.1 å¯é€†æ€§ä¿®æ­£ãƒ‘ãƒƒãƒ")
    print("=" * 50)
    
    if apply_reversibility_fix():
        print("\nâœ… ä¿®æ­£ãƒ‘ãƒƒãƒé©ç”¨å®Œäº†!")
        print("\nğŸ“‹ æ¬¡ã®æ‰‹é †:")
        print("1. nexus_tmc_v91_modular_reversibility_fixed.py ã‚’ç¢ºèª")
        print("2. ä¿®æ­£ç‰ˆã§ãƒ†ã‚¹ãƒˆã‚’å†å®Ÿè¡Œ")
        print("3. å¯é€†æ€§ã‚¨ãƒ©ãƒ¼ã®è§£æ±ºã‚’ç¢ºèª")
        
        print("\nğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰:")
        print("python test_nexus_tmc_v91_performance.py")
    else:
        print("\nâŒ ä¿®æ­£ãƒ‘ãƒƒãƒé©ç”¨ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()

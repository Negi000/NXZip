#!/usr/bin/env python3
"""
å®Ÿéš›ã®å¤±æ•—ã‚±ãƒ¼ã‚¹å†ç¾
"""

import hashlib
from nxzip_core import NXZipCore

def create_exact_failing_pe():
    """å®Ÿéš›ã«å¤±æ•—ã—ãŸPEãƒ‡ãƒ¼ã‚¿ã‚’æ­£ç¢ºã«å†ç¾"""
    pe_data = bytearray()
    # DOS header
    pe_data.extend(b'MZ')  # DOS signature
    pe_data.extend(b'\x00' * 58)  # DOS header padding
    pe_data.extend((64).to_bytes(4, 'little'))  # PE header offset
    
    # PE header
    pe_data.extend(b'PE\x00\x00')  # PE signature
    pe_data.extend(b'\x4c\x01')    # Machine (i386)
    pe_data.extend(b'\x03\x00')    # Number of sections
    pe_data.extend(b'\x00' * 16)   # Timestamp, etc.
    
    # Add code patterns that will trigger redundancy_reduction
    code_section = bytearray()
    for i in range(1000):  # ç¢ºå®Ÿã«å†—é•·æ€§å‰Šæ¸›ãŒç™ºç”Ÿã™ã‚‹ã‚ˆã†ã«
        # Simulate x86 instructions patterns
        if i % 100 == 0:
            code_section.extend(b'\x55\x8b\xec')  # push ebp; mov ebp, esp
        elif i % 50 == 0:
            code_section.extend(b'\xff\x15')      # call dword ptr
            code_section.extend(i.to_bytes(4, 'little'))
        elif i % 20 == 0:
            code_section.extend(b'\x90' * 10)     # 10å€‹ã®NOPï¼ˆç¢ºå®Ÿã«RLEå¯¾è±¡ï¼‰
        else:
            code_section.extend(b'\x90')          # nop
    
    pe_data.extend(code_section)
    return bytes(pe_data)

def test_exact_failing_case():
    print("ğŸ” å®Ÿéš›ã®å¤±æ•—ã‚±ãƒ¼ã‚¹å†ç¾ãƒ†ã‚¹ãƒˆ")
    
    test_data = create_exact_failing_pe()
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(test_data)} bytes")
    
    core = NXZipCore()
    
    # åœ§ç¸®å®Ÿè¡Œ
    comp_result = core.compress(test_data, mode="fast", filename="failing_test")
    
    if not comp_result.success:
        print(f"âŒ åœ§ç¸®å¤±æ•—: {comp_result.error_message}")
        return
    
    print(f"âœ… åœ§ç¸®æˆåŠŸ: {comp_result.compression_ratio:.2f}%")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç¢ºèª
    stages = comp_result.metadata.get('stages', [])
    redundancy_applied = False
    
    for stage_name, stage_info in stages:
        if stage_name == 'tmc_transform':
            transforms = stage_info.get('transforms_applied', [])
            if 'redundancy_reduction' in transforms:
                redundancy_applied = True
                print(f"ğŸ”§ å†—é•·æ€§å‰Šæ¸›ãŒé©ç”¨ã•ã‚Œã¾ã—ãŸ")
                print(f"   å…ƒã‚µã‚¤ã‚º: {stage_info.get('original_size', 0)} bytes")
                print(f"   å¤‰æ›å¾Œã‚µã‚¤ã‚º: {stage_info.get('transformed_size', 0)} bytes")
    
    if not redundancy_applied:
        print("âš ï¸ å†—é•·æ€§å‰Šæ¸›ãŒé©ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    # å±•é–‹å®Ÿè¡Œ
    print(f"ğŸ” comp_result.metadata keys: {list(comp_result.metadata.keys())}")
    print(f"ğŸ” metadata engine: {comp_result.metadata.get('engine', 'NOT FOUND')}")
    decomp_result = core.decompress(comp_result.compressed_data, comp_result.metadata)
    
    if not decomp_result.success:
        print(f"âŒ å±•é–‹å¤±æ•—: {decomp_result.error_message}")
        return
    
    print(f"âœ… å±•é–‹æˆåŠŸ")
    
    # æ•´åˆæ€§ç¢ºèª
    integrity = core.validate_integrity(test_data, decomp_result.decompressed_data)
    print(f"ğŸ” æ•´åˆæ€§: {'âœ… å®Œå…¨' if integrity['integrity_ok'] else 'âŒ å¤±æ•—'}")
    
    if not integrity['integrity_ok']:
        print(f"   å…ƒã‚µã‚¤ã‚º: {integrity['original_size']} bytes")
        print(f"   å¾©å…ƒã‚µã‚¤ã‚º: {integrity['decompressed_size']} bytes")
        print(f"   ã‚µã‚¤ã‚ºå·®: {abs(integrity['original_size'] - integrity['decompressed_size'])} bytes")
        
        # æ‰‹å‹•ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é€†å¤‰æ›ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒãƒƒã‚°
        print(f"\nğŸ” æ‰‹å‹•é€†å¤‰æ›ãƒ‡ãƒãƒƒã‚°:")
        
        current_data = comp_result.compressed_data
        
        # Stage 3: final_compression é€†å¤‰æ›
        final_comp_info = None
        for stage_name, stage_info in stages:
            if stage_name == 'final_compression':
                final_comp_info = stage_info
                break
        
        if final_comp_info:
            method = final_comp_info.get('method', 'zlib_fast')
            print(f"   æœ€çµ‚åœ§ç¸®é€†å¤‰æ›: {method}")
            
            if method.startswith('zlib'):
                import zlib
                current_data = zlib.decompress(current_data)
            
            print(f"   zlibå±•é–‹å¾Œ: {len(current_data)} bytes")
        
        # Stage 2: SPEé€†å¤‰æ›ï¼ˆãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ï¼‰
        print(f"   SPEé€†å¤‰æ›ï¼ˆãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ï¼‰")
        
        # Stage 1: TMCé€†å¤‰æ›
        print(f"   TMCé€†å¤‰æ›å®Ÿè¡Œä¸­...")
        restored_data = core._restore_redundancy(current_data)
        print(f"   å†—é•·æ€§å¾©å…ƒå¾Œ: {len(restored_data)} bytes")
        
        # æœ€çµ‚ç¢ºèª
        final_hash = hashlib.sha256(restored_data).hexdigest()
        original_hash = hashlib.sha256(test_data).hexdigest()
        
        print(f"   æ‰‹å‹•é€†å¤‰æ›çµæœ:")
        print(f"     å…ƒãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
        print(f"     å¾©å…ƒãƒãƒƒã‚·ãƒ¥: {final_hash[:16]}...")
        print(f"     æ‰‹å‹•å¯é€†æ€§: {'âœ…' if original_hash == final_hash else 'âŒ'}")

def main():
    test_exact_failing_case()

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
NEXUS SDC (Structure-Destructive Compression) Engine - ç°¡æ½”è¡¨ç¤ºç‰ˆ
é©å‘½çš„æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³ã®å®Ÿè£…

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é©æ–°çš„ã‚¢ã‚¤ãƒ‡ã‚¢å®Ÿè£…:
ã€Œæ§‹é€ ã‚’ãƒã‚¤ãƒŠãƒªãƒ¬ãƒ™ãƒ«ã§å®Œå…¨æŠŠæ¡ â†’ åŸå‹ç ´å£Šåœ§ç¸® â†’ æ§‹é€ å¾©å…ƒã€

ç‰¹å¾´ï¼šè©³ç´°ãƒ­ã‚°åˆ¶å¾¡ã§ç°¡æ½”ãªé€²æ—è¡¨ç¤º
"""

import os
import sys
import time
import lzma
import zlib
import bz2
import struct
import hashlib
import pickle
from dataclasses import dataclass
from enum import Enum
from typing import List, Dict, Any, Tuple, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from progress_display import ProgressDisplay

# é«˜åº¦ãªæ§‹é€ è§£æå™¨ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from nexus_sdc_analyzer import AdvancedStructureAnalyzer
except ImportError:
    AdvancedStructureAnalyzer = None

# é«˜åº¦åŒ–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ  
try:
    from nexus_sdc_enhanced import EnhancedCompressionAlgorithms
except ImportError:
    EnhancedCompressionAlgorithms = None

# è©³ç´°ãƒ­ã‚°åˆ¶å¾¡è¨­å®š
ENABLE_DETAILED_LOGGING = False  # â† ã“ã®è¨­å®šã§è©³ç´°ãƒ­ã‚°ã‚’åˆ¶å¾¡

class CompressionMethod(Enum):
    """åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç¨®é¡"""
    RAW = "raw"
    ZLIB = "zlib"
    LZMA = "lzma"
    BZ2 = "bz2"

@dataclass
class StructureElement:
    """æ§‹é€ è¦ç´ ã®å®šç¾©"""
    element_type: str
    position: int
    size: int
    compression_potential: float
    category: str = "unknown"
    metadata: Dict = None
    compressed_data: bytes = None
    compression_method: CompressionMethod = CompressionMethod.RAW
    compression_ratio: float = 0.0

@dataclass
class FileStructure:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®å®šç¾©"""
    format_type: str
    total_size: int
    elements: List[StructureElement]
    metadata: Dict
    structure_hash: str

# é€²æ—è¡¨ç¤ºã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
progress = ProgressDisplay()

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def show_step(message: str):
    """ãƒ¡ã‚¤ãƒ³ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º"""
    print(f"ğŸ“Š {message}")

def show_substep(message: str):
    """ã‚µãƒ–ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤ºï¼ˆè©³ç´°ãƒ­ã‚°åˆ¶å¾¡å¯¾è±¡ï¼‰"""
    if ENABLE_DETAILED_LOGGING:
        print(f"   ğŸ’« {message}")

def show_success(message: str):
    """æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    print(f"âœ… {message}")

def show_warning(message: str):
    """è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    print(f"âš ï¸  {message}")

class NexusSDCEngine:
    """NEXUSæ§‹é€ ç ´å£Šå‹åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.name = "NEXUS SDC Engine"
        self.version = "2.0.0"
        self.advanced_analyzer = AdvancedStructureAnalyzer() if AdvancedStructureAnalyzer else None
        self.enhanced_algorithms = EnhancedCompressionAlgorithms() if EnhancedCompressionAlgorithms else None
        self.statistics = {
            'total_files_processed': 0,
            'total_bytes_compressed': 0,
            'total_bytes_saved': 0,
            'average_compression_ratio': 0.0
        }
    
    def compress_file(self, input_path: str, output_path: str = None) -> Dict[str, Any]:
        """æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã®å®Ÿè¡Œ"""
        if output_path is None:
            output_path = f"{input_path}.sdc"
        
        original_size = os.path.getsize(input_path)
        file_name = os.path.basename(input_path)
        start_time = time.time()
        
        # é€²æ—é–‹å§‹
        progress.start_task(f"æ§‹é€ ç ´å£Šå‹åœ§ç¸®: {file_name}", original_size, file_name)
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ è§£æ (0-30%)
            progress.update_progress(5, "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«è§£æé–‹å§‹")
            show_step(f"æ§‹é€ ç ´å£Šå‹åœ§ç¸®: {file_name}")
            print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}")
            print(f"ğŸ’¾ ã‚µã‚¤ã‚º: {original_size / (1024*1024):.1f}MB")
            
            with open(input_path, 'rb') as f:
                data = f.read()
            
            show_substep(f"åŸã‚µã‚¤ã‚º: {original_size:,} bytes")
            
            # æ§‹é€ è§£æå®Ÿè¡Œ
            progress.update_progress(10, "ğŸ§¬ æ§‹é€ è§£æå®Ÿè¡Œä¸­")
            file_structure = self._analyze_file_structure(data)
            progress.update_progress(30, "âœ… æ§‹é€ è§£æå®Œäº†")
            
            show_substep(f"æ§‹é€ è¦ç´ æ•°: {len(file_structure.elements)}")
            
            # åŸå‹ç ´å£Šåœ§ç¸® (30-80%)
            progress.update_progress(35, "ğŸ’¥ åŸå‹ç ´å£Šåœ§ç¸®é–‹å§‹")
            self._compress_elements_with_progress(file_structure, data)
            progress.update_progress(80, "âœ… ç ´å£Šçš„åœ§ç¸®å®Œäº†")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ (80-100%)
            progress.update_progress(85, "ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­")
            compressed_size = self._save_compressed_file(file_structure, output_path)
            progress.update_progress(100, "âœ… ä¿å­˜å®Œäº†")
            
            # çµ±è¨ˆè¨ˆç®—
            elapsed_time = time.time() - start_time
            compression_ratio = (1 - compressed_size / original_size) * 100
            speed_mbps = (original_size / (1024 * 1024)) / max(elapsed_time, 0.001)
            
            result = {
                'input_path': input_path,
                'output_path': output_path,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'structure_elements': len(file_structure.elements),
                'speed_mbps': speed_mbps
            }
            
            # é€²æ—å®Œäº†
            final_msg = f"åœ§ç¸®ç‡: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,} bytes)"
            progress.finish_task(True, final_msg)
            
            self._print_compression_result(result)
            self._update_stats(result)
            
            return result
            
        except Exception as e:
            progress.finish_task(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def decompress_file(self, input_path: str, output_path: str = None) -> Dict[str, Any]:
        """æ§‹é€ ç ´å£Šå‹åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®å±•é–‹"""
        if output_path is None:
            output_path = input_path.replace('.sdc', '')
        
        file_name = os.path.basename(input_path)
        
        # é€²æ—é–‹å§‹
        progress.start_task(f"æ§‹é€ å¾©å…ƒ: {file_name}", 100, file_name)
        
        try:
            # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (0-20%)
            progress.update_progress(5, "ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­")
            compressed_structure = self._load_compressed_file(input_path)
            progress.update_progress(20, "âœ… èª­ã¿è¾¼ã¿å®Œäº†")
            
            # æ§‹é€ å¾©å…ƒ (20-90%)
            progress.update_progress(25, "ğŸ”„ æ§‹é€ å¾©å…ƒé–‹å§‹")
            restored_data = self._restore_structure_with_progress(compressed_structure)
            progress.update_progress(90, "âœ… æ§‹é€ å¾©å…ƒå®Œäº†")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ (90-100%)
            progress.update_progress(95, "ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ä¸­")
            with open(output_path, 'wb') as f:
                f.write(restored_data)
            progress.update_progress(100, "âœ… ä¿å­˜å®Œäº†")
            
            # çµæœè¡¨ç¤º
            result = {
                'input_path': input_path,
                'output_path': output_path,
                'restored_size': len(restored_data)
            }
            
            final_msg = f"å¾©å…ƒã‚µã‚¤ã‚º: {len(restored_data):,} bytes"
            progress.finish_task(True, final_msg)
            
            return result
            
        except Exception as e:
            progress.finish_task(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def _analyze_file_structure(self, data: bytes) -> FileStructure:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®åˆ†æ"""
        # é«˜åº¦è§£æå™¨ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ä½¿ç”¨
        if self.advanced_analyzer:
            try:
                return self.advanced_analyzer.analyze_comprehensive(data)
            except Exception:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¦åŸºæœ¬è§£æå™¨ã‚’ä½¿ç”¨
                pass
        
        # åŸºæœ¬è§£æå™¨ã‚’ä½¿ç”¨
        return self._basic_structure_analysis(data)
    
    def _basic_structure_analysis(self, data: bytes) -> FileStructure:
        """åŸºæœ¬çš„ãªæ§‹é€ è§£æ"""
        elements = []
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¤å®š
        if data.startswith(b'ID3') or (len(data) > 1024 and b'\xff\xfb' in data[:1024]):
            # MP3ãƒ•ã‚¡ã‚¤ãƒ«
            format_type = "MP3"
            self._analyze_mp3_structure_basic(data, elements)
        elif data.startswith(b'\x00\x00\x00') and b'ftyp' in data[:32]:
            # MP4ãƒ•ã‚¡ã‚¤ãƒ«
            format_type = "MP4"
            self._analyze_mp4_structure_basic(data, elements)
        elif data.startswith(b'RIFF') and b'WAVE' in data[:12]:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«
            format_type = "WAV"
            self._analyze_wav_structure_basic(data, elements)
        else:
            # æ±ç”¨ãƒ•ã‚¡ã‚¤ãƒ«
            format_type = "GENERIC"
            self._analyze_generic_structure_basic(data, elements)
        
        structure_hash = hashlib.sha256(data[:1024]).hexdigest()[:16]
        
        return FileStructure(
            format_type=format_type,
            total_size=len(data),
            elements=elements,
            metadata={"format": format_type},
            structure_hash=structure_hash
        )
    
    def _analyze_mp3_structure_basic(self, data: bytes, elements: List[StructureElement]):
        """MP3æ§‹é€ ã®åŸºæœ¬è§£æï¼ˆç°¡æ½”ç‰ˆï¼‰"""
        pos = 0
        frame_count = 0
        
        # ID3ã‚¿ã‚°æ¤œå‡º
        if data.startswith(b'ID3'):
            if len(data) >= 10:
                tag_size = struct.unpack('>I', b'\x00' + data[6:9])[0]
                elements.append(StructureElement(
                    element_type="ID3v2_TAG",
                    position=0,
                    size=10 + tag_size,
                    compression_potential=0.3,
                    category="metadata"
                ))
                pos = 10 + tag_size
        
        # MP3ãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆã¾ã¨ã‚ã¦å‡¦ç†ï¼‰
        total_audio_size = 0
        audio_start = pos
        
        while pos < len(data) - 4:
            if data[pos:pos+2] == b'\xff\xfb' or data[pos:pos+2] == b'\xff\xfa':
                # MP3ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼ç™ºè¦‹
                if pos + 4 <= len(data):
                    header = struct.unpack('>I', data[pos:pos+4])[0]
                    frame_size = self._calculate_mp3_frame_size(header)
                    if frame_size > 0 and pos + frame_size <= len(data):
                        frame_count += 1
                        total_audio_size += frame_size
                        pos += frame_size
                        continue
            pos += 1
        
        # å…¨éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€ã¤ã®è¦ç´ ã¨ã—ã¦è¿½åŠ 
        if total_audio_size > 0:
            elements.append(StructureElement(
                element_type="MP3_AUDIO_DATA",
                position=audio_start,
                size=total_audio_size,
                compression_potential=0.75,
                category="audio_data",
                metadata={"frame_count": frame_count}
            ))
        
        # ID3v1ã‚¿ã‚°ï¼ˆæœ«å°¾ï¼‰
        if len(data) >= 128 and data[-128:-125] == b'TAG':
            elements.append(StructureElement(
                element_type="ID3v1_TAG",
                position=len(data) - 128,
                size=128,
                compression_potential=0.3,
                category="metadata"
            ))
    
    def _analyze_mp4_structure_basic(self, data: bytes, elements: List[StructureElement]):
        """MP4æ§‹é€ ã®åŸºæœ¬è§£æ"""
        pos = 0
        while pos < len(data) - 8:
            try:
                size = struct.unpack('>I', data[pos:pos+4])[0]
                atom_type = data[pos+4:pos+8]
                
                if size == 0:
                    break
                if size < 8:
                    pos += 8
                    continue
                
                # Atomæƒ…å ±ã‚’è¦ç´ ã¨ã—ã¦è¿½åŠ 
                compression_potential = 0.6 if atom_type == b'mdat' else 0.3
                elements.append(StructureElement(
                    element_type=f"MP4_ATOM_{atom_type.decode('ascii', errors='ignore')}",
                    position=pos,
                    size=size,
                    compression_potential=compression_potential,
                    category="video_data" if atom_type == b'mdat' else "metadata"
                ))
                
                pos += size
            except:
                pos += 1
    
    def _analyze_wav_structure_basic(self, data: bytes, elements: List[StructureElement]):
        """WAVæ§‹é€ ã®åŸºæœ¬è§£æ"""
        if len(data) < 44:
            return
        
        # RIFFãƒ˜ãƒƒãƒ€ãƒ¼
        elements.append(StructureElement(
            element_type="RIFF_HEADER",
            position=0,
            size=12,
            compression_potential=0.1,
            category="header"
        ))
        
        pos = 12
        while pos < len(data) - 8:
            if pos + 8 > len(data):
                break
            
            chunk_id = data[pos:pos+4]
            chunk_size = struct.unpack('<I', data[pos+4:pos+8])[0]
            
            compression_potential = 0.85 if chunk_id == b'data' else 0.2
            elements.append(StructureElement(
                element_type=f"WAV_{chunk_id.decode('ascii', errors='ignore').upper()}_CHUNK",
                position=pos,
                size=8 + chunk_size,
                compression_potential=compression_potential,
                category="audio_data" if chunk_id == b'data' else "metadata"
            ))
            
            pos += 8 + chunk_size
            if chunk_size % 2:
                pos += 1
    
    def _analyze_generic_structure_basic(self, data: bytes, elements: List[StructureElement]):
        """æ±ç”¨æ§‹é€ ã®åŸºæœ¬è§£æ"""
        chunk_size = max(4096, len(data) // 10)  # å¤§ããªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        pos = 0
        
        while pos < len(data):
            remaining = len(data) - pos
            size = min(chunk_size, remaining)
            
            elements.append(StructureElement(
                element_type=f"GENERIC_CHUNK_{pos // chunk_size}",
                position=pos,
                size=size,
                compression_potential=0.7,
                category="data"
            ))
            
            pos += size
    
    def _calculate_mp3_frame_size(self, header: int) -> int:
        """MP3ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºè¨ˆç®—"""
        try:
            version = (header >> 19) & 0x3
            layer = (header >> 17) & 0x3
            bitrate_index = (header >> 12) & 0xF
            sample_rate_index = (header >> 10) & 0x3
            
            if bitrate_index == 0 or bitrate_index == 15:
                return 0
            if sample_rate_index == 3:
                return 0
            
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸè¨ˆç®—
            bitrates = [0, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320]
            sample_rates = [44100, 48000, 32000]
            
            if bitrate_index < len(bitrates) and sample_rate_index < len(sample_rates):
                bitrate = bitrates[bitrate_index] * 1000
                sample_rate = sample_rates[sample_rate_index]
                return int(144 * bitrate / sample_rate) + ((header >> 9) & 1)
            
            return 0
        except:
            return 0
    
    def _compress_elements_with_progress(self, structure: FileStructure, data: bytes):
        """é€²æ—è¡¨ç¤ºä»˜ãåŸå‹ç ´å£Šåœ§ç¸®ï¼ˆç°¡æ½”ç‰ˆï¼‰"""
        show_step("åŸå‹ç ´å£Šåœ§ç¸®å®Ÿè¡Œä¸­...")
        
        total_elements = len(structure.elements)
        total_compression_ratio = 0.0
        processed_bytes = 0
        
        for i, element in enumerate(structure.elements):
            # é€²æ—æ›´æ–°ï¼ˆè©³ç´°ãƒ­ã‚°ãªã—ï¼‰
            element_progress = 30 + int((i / total_elements) * 50)  # 30-80%ã®ç¯„å›²
            progress.update_progress(element_progress, bytes_processed=processed_bytes)
            
            # è¦ç´ ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆãƒ­ã‚°å‡ºåŠ›åˆ¶å¾¡ï¼‰
            element_data = data[element.position:element.position + element.size]
            
            # è©³ç´°ãƒ­ã‚°åˆ¶å¾¡
            if ENABLE_DETAILED_LOGGING:
                show_substep(f"è¦ç´  {i+1}/{total_elements}: {element.element_type} ({element.size} bytes)")
            
            # é«˜åº¦åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
            if self.enhanced_algorithms and element.compression_potential > 0.5:
                try:
                    compressed, method = self.enhanced_algorithms.adaptive_compress(
                        element_data, element.compression_potential
                    )
                    element.compression_method = CompressionMethod.RAW
                    element.compressed_data = compressed
                    
                    if method in ['custom_high', 'destructive', 'lzma_enhanced', 'zlib_enhanced', 'bz2_enhanced']:
                        element.custom_method = method
                        
                except Exception as e:
                    if i == 0:  # æœ€åˆã®è¦ç´ ã§ã®ã¿è­¦å‘Šè¡¨ç¤º
                        show_warning(f"é«˜åº¦åŒ–åœ§ç¸®å¤±æ•—ã€æ¨™æº–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                    compressed, method = self._standard_compress(element_data, element.compression_potential)
                    element.compressed_data = compressed
                    element.compression_method = CompressionMethod(method)
            else:
                # æ¨™æº–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
                compressed, method = self._standard_compress(element_data, element.compression_potential)
                element.compressed_data = compressed
                element.compression_method = CompressionMethod(method)
            
            # åœ§ç¸®åŠ¹æœãƒã‚§ãƒƒã‚¯
            if len(element.compressed_data) >= len(element_data) * 0.95:
                element.compressed_data = element_data
                element.compression_method = CompressionMethod.RAW
                if hasattr(element, 'custom_method'):
                    delattr(element, 'custom_method')
            
            element.compression_ratio = (1 - len(element.compressed_data) / len(element_data)) * 100
            total_compression_ratio += element.compression_ratio * element.size
            processed_bytes += element.size
            
            # è©³ç´°ãƒ­ã‚°åˆ¶å¾¡
            if ENABLE_DETAILED_LOGGING:
                show_substep(f"åœ§ç¸®ç‡: {element.compression_ratio:.1f}% ({element.size} â†’ {len(element.compressed_data)})")
        
        # åŠ é‡å¹³å‡åœ§ç¸®ç‡è¨ˆç®—
        weighted_compression = total_compression_ratio / structure.total_size
        show_success(f"è¦ç´ åˆ¥å¹³å‡åœ§ç¸®ç‡: {weighted_compression:.1f}%")
    
    def _standard_compress(self, data: bytes, compression_potential: float) -> Tuple[bytes, str]:
        """æ¨™æº–åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ """
        try:
            if compression_potential > 0.7:
                compressed = lzma.compress(data, preset=6)
                return compressed, "lzma"
            elif compression_potential > 0.4:
                compressed = zlib.compress(data, level=6)
                return compressed, "zlib"
            else:
                compressed = bz2.compress(data, compresslevel=6)
                return compressed, "bz2"
        except:
            return data, "raw"
    
    def _save_compressed_file(self, structure: FileStructure, output_path: str) -> int:
        """åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
        with open(output_path, 'wb') as f:
            # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
            header = {
                'version': self.version,
                'format_type': structure.format_type,
                'total_size': structure.total_size,
                'structure_hash': structure.structure_hash,
                'elements_count': len(structure.elements)
            }
            
            header_data = pickle.dumps(header)
            f.write(struct.pack('<I', len(header_data)))
            f.write(header_data)
            
            # æ§‹é€ æƒ…å ±
            structure_info = []
            for element in structure.elements:
                info = {
                    'element_type': element.element_type,
                    'position': element.position,
                    'size': element.size,
                    'compression_method': element.compression_method.value,
                    'category': element.category,
                    'metadata': element.metadata
                }
                if hasattr(element, 'custom_method'):
                    info['custom_method'] = element.custom_method
                structure_info.append(info)
            
            structure_data = pickle.dumps(structure_info)
            f.write(struct.pack('<I', len(structure_data)))
            f.write(structure_data)
            
            # å„è¦ç´ ã®åœ§ç¸®ãƒ‡ãƒ¼ã‚¿
            for element in structure.elements:
                f.write(struct.pack('<I', len(element.compressed_data)))
                f.write(element.compressed_data)
            
        return os.path.getsize(output_path)
    
    def _load_compressed_file(self, input_path: str) -> FileStructure:
        """åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        with open(input_path, 'rb') as f:
            # ãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿è¾¼ã¿
            header_size = struct.unpack('<I', f.read(4))[0]
            header_data = f.read(header_size)
            header = pickle.loads(header_data)
            
            # æ§‹é€ æƒ…å ±èª­ã¿è¾¼ã¿
            structure_size = struct.unpack('<I', f.read(4))[0]
            structure_data = f.read(structure_size)
            structure_info = pickle.loads(structure_data)
            
            # è¦ç´ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            elements = []
            for info in structure_info:
                data_size = struct.unpack('<I', f.read(4))[0]
                compressed_data = f.read(data_size)
                
                element = StructureElement(
                    element_type=info['element_type'],
                    position=info['position'],
                    size=info['size'],
                    compression_potential=0.0,
                    category=info['category'],
                    metadata=info['metadata'],
                    compressed_data=compressed_data,
                    compression_method=CompressionMethod(info['compression_method'])
                )
                
                if 'custom_method' in info:
                    element.custom_method = info['custom_method']
                
                elements.append(element)
            
            return FileStructure(
                format_type=header['format_type'],
                total_size=header['total_size'],
                elements=elements,
                metadata={},
                structure_hash=header['structure_hash']
            )
    
    def _restore_structure_with_progress(self, structure: FileStructure) -> bytes:
        """é€²æ—è¡¨ç¤ºä»˜ãæ§‹é€ å¾©å…ƒï¼ˆç°¡æ½”ç‰ˆï¼‰"""
        show_step("æ§‹é€ å¾©å…ƒå®Ÿè¡Œä¸­...")
        
        # å¾©å…ƒãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–
        restored_data = bytearray(structure.total_size)
        total_elements = len(structure.elements)
        
        for i, element in enumerate(structure.elements):
            # é€²æ—æ›´æ–°
            restoration_progress = 25 + int((i / total_elements) * 65)  # 25-90%ã®ç¯„å›²
            progress.update_progress(restoration_progress)
            
            # è©³ç´°ãƒ­ã‚°åˆ¶å¾¡
            if ENABLE_DETAILED_LOGGING:
                show_substep(f"è¦ç´  {i+1}/{total_elements}: {element.element_type}")
            
            # ãƒ‡ãƒ¼ã‚¿è§£å‡
            decompressed_data = self._decompress_element_data(element)
            
            # å…ƒã®ä½ç½®ã«å¾©å…ƒ
            if len(decompressed_data) == element.size:
                restored_data[element.position:element.position + element.size] = decompressed_data
            else:
                if i == 0:  # æœ€åˆã®è¦ç´ ã§ã®ã¿è­¦å‘Šè¡¨ç¤º
                    show_warning(f"ã‚µã‚¤ã‚ºä¸ä¸€è‡´æ¤œå‡ºã€èª¿æ•´ä¸­")
                # ã‚µã‚¤ã‚ºèª¿æ•´
                if len(decompressed_data) < element.size:
                    decompressed_data += b'\x00' * (element.size - len(decompressed_data))
                else:
                    decompressed_data = decompressed_data[:element.size]
                restored_data[element.position:element.position + element.size] = decompressed_data
        
        return bytes(restored_data)
    
    def _decompress_element_data(self, element: StructureElement) -> bytes:
        """è¦ç´ ãƒ‡ãƒ¼ã‚¿ã®è§£å‡"""
        try:
            if hasattr(element, 'custom_method'):
                # ã‚«ã‚¹ã‚¿ãƒ è§£å‡ãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚‹å ´åˆ
                if self.enhanced_algorithms:
                    return self.enhanced_algorithms.adaptive_decompress(
                        element.compressed_data, element.custom_method
                    )
            
            if element.compression_method == CompressionMethod.LZMA:
                return lzma.decompress(element.compressed_data)
            elif element.compression_method == CompressionMethod.ZLIB:
                return zlib.decompress(element.compressed_data)
            elif element.compression_method == CompressionMethod.BZ2:
                return bz2.decompress(element.compressed_data)
            else:
                return element.compressed_data
                
        except Exception:
            return element.compressed_data
    
    def _print_compression_result(self, result: Dict[str, Any]):
        """åœ§ç¸®çµæœã®è¡¨ç¤º"""
        print("--------------------------------------------------")
        show_success("æ§‹é€ ç ´å£Šå‹åœ§ç¸®å®Œäº†")
        print(f"ğŸ“ å…¥åŠ›: {os.path.basename(result['input_path'])}")
        print(f"ğŸ’¾ åŸã‚µã‚¤ã‚º: {result['original_size']:,} bytes")
        print(f"ğŸ—œï¸  åœ§ç¸®ã‚µã‚¤ã‚º: {result['compressed_size']:,} bytes")
        print(f"ğŸ¯ åœ§ç¸®ç‡: {result['compression_ratio']:.1f}%")
        print(f"âš¡ åœ§ç¸®é€Ÿåº¦: {result['speed_mbps']:.1f} MB/s")
        print(f"ğŸ§¬ æ§‹é€ è¦ç´ : {result['structure_elements']}å€‹")
    
    def _update_stats(self, result: Dict[str, Any]):
        """çµ±è¨ˆæƒ…å ±ã®æ›´æ–°"""
        self.statistics['total_files_processed'] += 1
        self.statistics['total_bytes_compressed'] += result['original_size']
        self.statistics['total_bytes_saved'] += (result['original_size'] - result['compressed_size'])
        
        # ç§»å‹•å¹³å‡ã§å¹³å‡åœ§ç¸®ç‡ã‚’æ›´æ–°
        old_avg = self.statistics['average_compression_ratio']
        new_ratio = result['compression_ratio']
        files_count = self.statistics['total_files_processed']
        self.statistics['average_compression_ratio'] = (old_avg * (files_count - 1) + new_ratio) / files_count
    
    def print_statistics(self):
        """çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º"""
        stats = self.statistics
        if stats['total_files_processed'] == 0:
            print("ğŸ“Š çµ±è¨ˆæƒ…å ±ãªã—")
            return
        
        print("\nğŸ“Š NEXUS SDC Engine çµ±è¨ˆæƒ…å ±")
        print("=" * 40)
        print(f"ğŸ“ å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files_processed']}")
        print(f"ğŸ’¾ ç·å‡¦ç†ã‚µã‚¤ã‚º: {stats['total_bytes_compressed']:,} bytes")
        print(f"ğŸ’° ç·ç¯€ç´„ã‚µã‚¤ã‚º: {stats['total_bytes_saved']:,} bytes")
        print(f"ğŸ“Š å¹³å‡åœ§ç¸®ç‡: {stats['average_compression_ratio']:.1f}%")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    engine = NexusSDCEngine()
    
    if len(sys.argv) < 2:
        print(f"ä½¿ç”¨æ–¹æ³•: {sys.argv[0]} <command> [options]")
        print("ã‚³ãƒãƒ³ãƒ‰:")
        print("  test                - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        print("  compress <file>     - ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®")
        print("  decompress <file>   - ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹")
        print("  stats               - çµ±è¨ˆè¡¨ç¤º")
        return
    
    command = sys.argv[1].lower()
    
    if command == "test":
        print("ğŸ§ª NEXUS SDC ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        print("=" * 60)
        
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š
        base_dir = os.path.dirname(os.path.abspath(__file__))
        sample_dir = os.path.join(os.path.dirname(base_dir), "NXZip-Python", "sample")
        
        test_files = [
            "é™°è¬€è«–.mp3",
            "PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4",
            "generated-music-1752042054079.wav"
        ]
        
        # å­˜åœ¨ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãƒ†ã‚¹ãƒˆ
        available_files = []
        for filename in test_files:
            file_path = os.path.join(sample_dir, filename)
            if os.path.exists(file_path):
                available_files.append(file_path)
        
        if not available_files:
            print("âŒ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        print(f"ğŸ”§ ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(available_files)}å€‹")
        
        # å„ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        compression_results = []
        for i, file_path in enumerate(available_files, 1):
            print(f"ğŸ”§ ãƒ†ã‚¹ãƒˆ {i}/{len(available_files)}: {os.path.basename(file_path)}")
            
            try:
                # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
                result = engine.compress_file(file_path)
                compression_results.append(result)
                
                # å¯é€†æ€§ç¢ºèª
                print("ğŸ”§ å¯é€†æ€§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­")
                engine.decompress_file(result['output_path'])
                print("âœ… å¯é€†æ€§ç¢ºèªå®Œäº†")
                
            except Exception as e:
                print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
                continue
        
        # ç·åˆçµæœè¡¨ç¤º
        if compression_results:
            total_original = sum(r['original_size'] for r in compression_results)
            total_compressed = sum(r['compressed_size'] for r in compression_results)
            avg_compression = (1 - total_compressed / total_original) * 100
            
            print("\nğŸ“Š ç·åˆãƒ†ã‚¹ãƒˆçµæœ")
            print("=" * 60)
            print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(compression_results)}")
            print(f"ğŸ“Š å¹³å‡åœ§ç¸®ç‡: {avg_compression:.1f}%")
            print(f"ğŸ’¾ ç·å‡¦ç†ã‚µã‚¤ã‚º: {total_original:,} bytes")
            print(f"ğŸ—œï¸ ç·åœ§ç¸®ã‚µã‚¤ã‚º: {total_compressed:,} bytes")
    
    elif command == "compress":
        if len(sys.argv) < 3:
            print("ä½¿ç”¨æ–¹æ³•: compress <input_file> [output_file]")
            return
        
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) > 3 else None
        
        if not os.path.exists(input_file):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            return
        
        try:
            result = engine.compress_file(input_file, output_file)
            print("âœ… åœ§ç¸®å®Œäº†")
        except Exception as e:
            print(f"âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    elif command == "decompress":
        if len(sys.argv) < 3:
            print("ä½¿ç”¨æ–¹æ³•: decompress <input_file> [output_file]")
            return
        
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) > 3 else None
        
        if not os.path.exists(input_file):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file}")
            return
        
        try:
            result = engine.decompress_file(input_file, output_file)
            print("âœ… å±•é–‹å®Œäº†")
        except Exception as e:
            print(f"âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    elif command == "stats":
        engine.print_statistics()
    
    else:
        print(f"âŒ æœªçŸ¥ã®ã‚³ãƒãƒ³ãƒ‰: {command}")


if __name__ == "__main__":
    main()

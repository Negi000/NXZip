#!/usr/bin/env python3
"""
NEXUS v4.0 å•é¡Œè¨ºæ–­ãƒ„ãƒ¼ãƒ« - å¯é€†æ€§ã¨åœ§ç¸®ç‡ã®è©³ç´°åˆ†æ
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import time
import hashlib
from pathlib import Path
from nexus_optimized_v4 import NEXUSOptimizedEngine, OptimizedConfig, simulate_optimized_decompression


def diagnose_compression_issues():
    """åœ§ç¸®å•é¡Œè¨ºæ–­"""
    print("ğŸ” NEXUS v4.0 åœ§ç¸®å•é¡Œè¨ºæ–­")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆè¨­å®š
    config = OptimizedConfig(
        max_threads=4,
        chunk_size_mb=1.0,
        fast_mode=True,
        skip_deep_analysis=False,
        compression_level=6
    )
    
    engine = NEXUSOptimizedEngine(config)
    
    # å•é¡Œã®ã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
    sample_dir = Path("sample")
    problem_files = []
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¯é€†æ€§å•é¡ŒãŒã‚ã£ãŸï¼‰
    for file_path in sample_dir.glob("*.jpg"):
        if file_path.stat().st_size < 10 * 1024 * 1024:  # 10MBæœªæº€
            problem_files.append(('JPEGç”»åƒ', file_path))
    
    for file_path in sample_dir.glob("*.png"):
        if file_path.stat().st_size < 20 * 1024 * 1024:  # 20MBæœªæº€
            problem_files.append(('PNGç”»åƒ', file_path))
    
    # åœ§ç¸®ç‡ãŒæ‚ªã„ãƒ•ã‚¡ã‚¤ãƒ«
    for file_path in sample_dir.glob("*.7z"):
        if file_path.stat().st_size < 10 * 1024 * 1024:  # 10MBæœªæº€
            problem_files.append(('7Zã‚¢ãƒ¼ã‚«ã‚¤ãƒ–', file_path))
    
    print(f"ğŸ”¬ è¨ºæ–­å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(problem_files)}")
    
    for file_type, file_path in problem_files:
        print(f"\n{'='*70}")
        print(f"ğŸ§ª è©³ç´°è¨ºæ–­: {file_path.name}")
        print(f"   ğŸ“ ã‚¿ã‚¤ãƒ—: {file_type}")
        print(f"   ğŸ“Š ã‚µã‚¤ã‚º: {file_path.stat().st_size:,} bytes")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            with open(file_path, 'rb') as f:
                original_data = f.read()
            
            print(f"   ğŸ”‘ å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {hashlib.sha256(original_data).hexdigest()[:16]}...")
            
            # è©³ç´°ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            print(f"   ğŸ” ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ:")
            analyze_file_header(original_data, file_type)
            
            # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
            print(f"   âš¡ åœ§ç¸®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
            compressed_data = engine.optimized_compress(original_data, get_file_type(file_path), 'fast')
            
            compression_ratio = (1 - len(compressed_data) / len(original_data)) * 100
            print(f"      ğŸ“ˆ åœ§ç¸®ç‡: {compression_ratio:.2f}%")
            
            # è©³ç´°è§£å‡æ¤œè¨¼
            print(f"   ğŸ” è©³ç´°è§£å‡æ¤œè¨¼:")
            decompressed_data = simulate_optimized_decompression(compressed_data)
            
            # ãƒã‚¤ãƒˆå˜ä½æ¯”è¼ƒ
            size_match = len(original_data) == len(decompressed_data)
            print(f"      ğŸ“ ã‚µã‚¤ã‚ºä¸€è‡´: {'âœ…' if size_match else 'âŒ'} ({len(original_data)} vs {len(decompressed_data)})")
            
            if size_match:
                # ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ
                original_hash = hashlib.sha256(original_data).hexdigest()
                decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
                hash_match = original_hash == decompressed_hash
                print(f"      ğŸ”‘ ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'âœ…' if hash_match else 'âŒ'}")
                
                if not hash_match:
                    # å·®åˆ†è§£æ
                    print(f"      ğŸ” å·®åˆ†è§£æ:")
                    find_data_differences(original_data, decompressed_data)
            else:
                print(f"      âš ï¸ ã‚µã‚¤ã‚ºä¸ä¸€è‡´ã«ã‚ˆã‚‹å¯é€†æ€§å¤±æ•—")
            
            # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æ
            print(f"   ğŸ” åœ§ç¸®ãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æ:")
            analyze_compressed_structure(compressed_data)
            
        except Exception as e:
            print(f"   âŒ è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()


def analyze_file_header(data: bytes, file_type: str) -> None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼è©³ç´°è§£æ"""
    if len(data) < 32:
        print(f"      âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™")
        return
    
    header = data[:32]
    print(f"      ğŸ“ å…ˆé ­32ãƒã‚¤ãƒˆ: {header.hex()[:64]}...")
    
    if file_type == 'JPEGç”»åƒ':
        if data[:2] == b'\xff\xd8':
            print(f"      âœ… JPEG SOIç¢ºèª")
            # EXIFæ¤œç´¢
            if b'\xff\xe1' in data[:1024]:
                exif_pos = data.find(b'\xff\xe1')
                print(f"      ğŸ“‹ EXIFä½ç½®: {exif_pos}")
        else:
            print(f"      âŒ JPEGå½¢å¼ä¸æ­£")
    
    elif file_type == 'PNGç”»åƒ':
        if data[:8] == b'\x89PNG\r\n\x1a\n':
            print(f"      âœ… PNGã‚·ã‚°ãƒãƒãƒ£ç¢ºèª")
            # ãƒãƒ£ãƒ³ã‚¯è§£æ
            pos = 8
            chunk_count = 0
            while pos < len(data) - 8 and chunk_count < 10:
                try:
                    import struct
                    length = struct.unpack('>I', data[pos:pos+4])[0]
                    chunk_type = data[pos+4:pos+8]
                    print(f"      ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯{chunk_count}: {chunk_type} ({length} bytes)")
                    pos += 8 + length + 4
                    chunk_count += 1
                except:
                    break
        else:
            print(f"      âŒ PNGå½¢å¼ä¸æ­£")
    
    elif file_type == '7Zã‚¢ãƒ¼ã‚«ã‚¤ãƒ–':
        if data[:6] == b'7z\xbc\xaf\x27\x1c':
            print(f"      âœ… 7Zã‚·ã‚°ãƒãƒãƒ£ç¢ºèª")
        else:
            print(f"      âŒ 7Zå½¢å¼ä¸æ­£")


def find_data_differences(original: bytes, decompressed: bytes) -> None:
    """ãƒ‡ãƒ¼ã‚¿å·®åˆ†æ¤œå‡º"""
    min_len = min(len(original), len(decompressed))
    diff_count = 0
    first_diff = None
    
    for i in range(min_len):
        if original[i] != decompressed[i]:
            if first_diff is None:
                first_diff = i
            diff_count += 1
            if diff_count >= 10:  # æœ€åˆã®10å€‹ã®å·®åˆ†ã¾ã§
                break
    
    if first_diff is not None:
        print(f"         ğŸ”´ æœ€åˆã®å·®åˆ†ä½ç½®: {first_diff}")
        print(f"         ğŸ“Š å·®åˆ†æ•°: {diff_count}+ (æœ€åˆã®{min_len}ãƒã‚¤ãƒˆå†…)")
        
        # å‘¨è¾ºãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        start = max(0, first_diff - 8)
        end = min(len(original), first_diff + 8)
        print(f"         ğŸ“ å…ƒãƒ‡ãƒ¼ã‚¿å‘¨è¾º: {original[start:end].hex()}")
        if end <= len(decompressed):
            print(f"         ğŸ“ å¾©å…ƒãƒ‡ãƒ¼ã‚¿å‘¨è¾º: {decompressed[start:end].hex()}")
    else:
        print(f"         âœ… å…ˆé ­{min_len}ãƒã‚¤ãƒˆã¯ä¸€è‡´")


def analyze_compressed_structure(compressed: bytes) -> None:
    """åœ§ç¸®ãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æ"""
    if len(compressed) < 128:
        print(f"      âš ï¸ åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãŒå°ã•ã™ãã¾ã™")
        return
    
    header = compressed[:128]
    
    if header[:8] == b'NXOPT400':
        print(f"      âœ… NEXUS v4.0ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª")
        
        import struct
        try:
            original_size = struct.unpack('<Q', header[8:16])[0]
            chunk_count = struct.unpack('<I', header[16:20])[0]
            timestamp = struct.unpack('<I', header[20:24])[0]
            
            print(f"         ğŸ“Š å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes")
            print(f"         ğŸ”· ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count}")
            print(f"         â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—
            file_type_bytes = header[24:40]
            file_type = file_type_bytes.rstrip(b'\x00').decode('utf-8', errors='ignore')
            print(f"         ğŸ“ è¨˜éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—: '{file_type}'")
            
            # ãƒã‚§ãƒƒã‚¯ã‚µãƒ 
            header_checksum = struct.unpack('<I', header[40:44])[0]
            print(f"         ğŸ” ãƒ˜ãƒƒãƒ€ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚µãƒ : {header_checksum:08x}")
            
            # ãƒãƒ£ãƒ³ã‚¯è§£æ
            pos = 128
            for i in range(min(chunk_count, 5)):  # æœ€åˆã®5ãƒãƒ£ãƒ³ã‚¯ã¾ã§
                if pos + 16 <= len(compressed):
                    chunk_header = compressed[pos:pos+16]
                    chunk_id, chunk_size, chunk_crc = struct.unpack('<III', chunk_header[:12])
                    print(f"         ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯{i}: ID={chunk_id}, Size={chunk_size}, CRC={chunk_crc:08x}")
                    
                    # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­ç¢ºèª
                    if pos + 16 + min(4, chunk_size) <= len(compressed):
                        chunk_prefix = compressed[pos+16:pos+16+min(4, chunk_size)]
                        print(f"            ğŸ“ å…ˆé ­: {chunk_prefix}")
                    
                    pos += 16 + chunk_size
                else:
                    print(f"         âš ï¸ ãƒãƒ£ãƒ³ã‚¯{i}: ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
                    break
                    
        except Exception as e:
            print(f"      âŒ ãƒ˜ãƒƒãƒ€ãƒ¼è§£æã‚¨ãƒ©ãƒ¼: {e}")
    else:
        print(f"      âŒ ä¸æ­£ãªãƒ˜ãƒƒãƒ€ãƒ¼: {header[:8]}")


def get_file_type(file_path: Path) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—å–å¾—"""
    suffix = file_path.suffix.lower()
    mapping = {
        '.jpg': 'ç”»åƒ', '.jpeg': 'ç”»åƒ', '.png': 'ç”»åƒ',
        '.7z': 'åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–', '.zip': 'åœ§ç¸®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–',
        '.mp3': 'éŸ³æ¥½', '.wav': 'éŸ³æ¥½',
        '.mp4': 'å‹•ç”»', '.txt': 'ãƒ†ã‚­ã‚¹ãƒˆ'
    }
    return mapping.get(suffix, 'ãã®ä»–')


if __name__ == "__main__":
    diagnose_compression_issues()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NXZip è¶…é«˜é€Ÿé™çš„Huffmanè§£å‡ã‚¨ãƒ³ã‚¸ãƒ³
äº‹å‰è¨ˆç®—ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚ˆã‚‹æœ€é«˜é€Ÿè§£å‡
"""

import hashlib
import struct
import time
import os
from collections import Counter
from typing import Dict, List

class UltraFastHuffmanEngine:
    """è¶…é«˜é€Ÿé™çš„Huffmanã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.signature = b'\x4E\x58\x5A\x55\x48\x55\x46'  # NXZUHUF (Ultra Huffman)
        
    def compress_file(self, input_path: str) -> Dict:
        """è¶…é«˜é€Ÿãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return {'error': f'File not found: {input_path}'}
        
        start_time = time.time()
        
        try:
            with open(input_path, 'rb') as f:
                original_data = f.read()
            
            original_size = len(original_data)
            original_hash = hashlib.md5(original_data).digest()
            format_type = os.path.splitext(input_path)[1][1:].upper() or 'BINARY'
            
            print(f"ğŸ“ å‡¦ç†: {os.path.basename(input_path)} ({original_size:,} bytes, è¶…é«˜é€Ÿé™çš„Huffman)")
            print(f"âš¡ è¶…é«˜é€Ÿè§£æé–‹å§‹...")
            
            # é »åº¦è§£æ
            freq_count = Counter(original_data)
            print(f"   ğŸ“Š é »åº¦è§£æå®Œäº†: {len(freq_count)} ç¨®é¡")
            
            # é™çš„Huffmanç¬¦å·ç”Ÿæˆ
            codes = self._generate_static_codes(freq_count)
            print(f"   ğŸ”¤ é™çš„ç¬¦å·ç”Ÿæˆå®Œäº†: å¹³å‡é•· {sum(len(c) * freq_count[b] for b, c in codes.items()) / original_size:.2f}")
            
            # é«˜é€Ÿç¬¦å·åŒ–
            encoded_data = self._encode_ultra_fast(original_data, codes)
            print(f"   âœ… ç¬¦å·åŒ–å®Œäº†: {len(encoded_data):,} bytes")
            
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ
            final_data = self._create_package(
                encoded_data, codes, original_hash, original_size, format_type
            )
            
            output_path = input_path + '.nxzuh'  # Ultra Huffman
            with open(output_path, 'wb') as f:
                f.write(final_data)
            
            compressed_size = len(final_data)
            compression_ratio = (1 - compressed_size / original_size) * 100
            elapsed_time = time.time() - start_time
            speed = original_size / 1024 / 1024 / elapsed_time
            
            print(f"âœ… è¶…é«˜é€Ÿé™çš„Huffmanåœ§ç¸®å®Œäº†: {compression_ratio:.1f}%")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {elapsed_time:.2f}s ({speed:.1f} MB/s)")
            print(f"ğŸ’¾ ä¿å­˜: {os.path.basename(output_path)}")
            
            return {
                'success': True,
                'input_file': input_path,
                'output_file': output_path,
                'original_size': original_size,
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'processing_time': elapsed_time
            }
            
        except Exception as e:
            print(f"âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _generate_static_codes(self, freq_count: Counter) -> Dict[int, str]:
        """é™çš„Huffmanç¬¦å·ç”Ÿæˆï¼ˆè¶…é«˜é€Ÿç‰ˆï¼‰"""
        # é »åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_items = freq_count.most_common()
        
        codes = {}
        
        if len(sorted_items) == 1:
            # å˜ä¸€æ–‡å­—ã®å ´åˆ
            codes[sorted_items[0][0]] = '0'
            return codes
        
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸç¬¦å·ç”Ÿæˆ
        code_len = 1
        code_val = 0
        remaining_items = len(sorted_items)
        
        for byte_val, freq in sorted_items:
            # å¿…è¦ãªãƒ“ãƒƒãƒˆæ•°ã‚’è¨ˆç®—
            while (1 << code_len) < remaining_items:
                code_len += 1
            
            codes[byte_val] = format(code_val, f'0{code_len}b')
            code_val += 1
            remaining_items -= 1
            
            # ç¬¦å·é•·èª¿æ•´
            if remaining_items <= (1 << (code_len - 1)):
                code_len = max(1, code_len - 1)
                code_val = 0
        
        return codes
    
    def _encode_ultra_fast(self, data: bytes, codes: Dict[int, str]) -> bytes:
        """è¶…é«˜é€Ÿç¬¦å·åŒ–"""
        # å…¨ä½“ã‚’ä¸€æ°—ã«æ–‡å­—åˆ—çµåˆ
        bit_string = ''.join(codes[byte] for byte in data)
        
        # ãƒã‚¤ãƒˆé…åˆ—ã«å¤‰æ›
        result = bytearray()
        padding = 0
        
        for i in range(0, len(bit_string), 8):
            chunk = bit_string[i:i+8]
            if len(chunk) < 8:
                chunk = chunk.ljust(8, '0')
                padding = 8 - len(bit_string[i:])
            result.append(int(chunk, 2))
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±ã‚’å…ˆé ­ã«è¿½åŠ 
        return bytes([padding]) + bytes(result)
    
    def _create_package(self, encoded_data: bytes, codes: Dict[int, str],
                       original_hash: bytes, original_size: int, format_type: str) -> bytes:
        """ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä½œæˆ"""
        result = bytearray()
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        result.extend(self.signature)
        result.extend(struct.pack('>I', 1))  # Version 1
        result.extend(format_type.encode('utf-8').ljust(16, b'\x00'))
        
        # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º
        codes_data = self._serialize_codes(codes)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        result.extend(original_hash)
        result.extend(struct.pack('>I', original_size))
        result.extend(struct.pack('>I', len(codes_data)))
        result.extend(struct.pack('>I', len(encoded_data)))
        
        # ãƒ‡ãƒ¼ã‚¿
        result.extend(codes_data)
        result.extend(encoded_data)
        
        return bytes(result)
    
    def _serialize_codes(self, codes: Dict[int, str]) -> bytes:
        """ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""
        result = bytearray()
        result.extend(struct.pack('>H', len(codes)))
        
        for byte_val, code in codes.items():
            result.append(byte_val)
            result.append(len(code))
            # ç¬¦å·ã‚’8ãƒ“ãƒƒãƒˆå˜ä½ã§ãƒ‘ãƒƒã‚¯
            code_bytes = bytearray()
            for i in range(0, len(code), 8):
                chunk = code[i:i+8].ljust(8, '0')
                code_bytes.append(int(chunk, 2))
            result.extend(struct.pack('>H', len(code_bytes)))
            result.extend(code_bytes)
        
        return bytes(result)

class UltraFastHuffmanDecompressor:
    """è¶…é«˜é€Ÿé™çš„Huffmanè§£å‡ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.signature = b'\x4E\x58\x5A\x55\x48\x55\x46'  # NXZUHUF
        
    def decompress_file(self, input_path: str) -> Dict:
        """è¶…é«˜é€Ÿãƒ•ã‚¡ã‚¤ãƒ«è§£å‡"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return {'error': f'File not found: {input_path}'}
        
        start_time = time.time()
        
        try:
            with open(input_path, 'rb') as f:
                compressed_data = f.read()
            
            if not compressed_data.startswith(self.signature):
                return {'error': 'Invalid format signature'}
            
            print(f"âš¡ è¶…é«˜é€Ÿé™çš„Huffmanè§£å‡é–‹å§‹...")
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            pos = len(self.signature)
            version = struct.unpack('>I', compressed_data[pos:pos+4])[0]
            pos += 4
            format_type = compressed_data[pos:pos+16].rstrip(b'\x00').decode('utf-8')
            pos += 16
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            original_hash = compressed_data[pos:pos+16]
            pos += 16
            original_size = struct.unpack('>I', compressed_data[pos:pos+4])[0]
            pos += 4
            codes_size = struct.unpack('>I', compressed_data[pos:pos+4])[0]
            pos += 4
            data_size = struct.unpack('>I', compressed_data[pos:pos+4])[0]
            pos += 4
            
            print(f"   ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è§£æå®Œäº†")
            
            # ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«å¾©å…ƒ
            codes_data = compressed_data[pos:pos+codes_size]
            pos += codes_size
            decode_table = self._deserialize_codes(codes_data)
            print(f"   ğŸ”¤ ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«å¾©å…ƒå®Œäº†: {len(decode_table)} ã‚¨ãƒ³ãƒˆãƒª")
            
            # ç¬¦å·åŒ–ãƒ‡ãƒ¼ã‚¿
            encoded_data = compressed_data[pos:pos+data_size]
            
            # è¶…é«˜é€Ÿå¾©å·åŒ–
            restored_data = self._decode_ultra_fast(encoded_data, decode_table, original_size)
            print(f"   âœ… å¾©å·åŒ–å®Œäº†: {len(restored_data):,} bytes")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            output_path = input_path.replace('.nxzuh', '.restored')
            with open(output_path, 'wb') as f:
                f.write(restored_data)
            
            # æ¤œè¨¼
            restored_hash = hashlib.md5(restored_data).digest()
            hash_match = restored_hash == original_hash
            elapsed_time = time.time() - start_time
            
            print(f"ğŸ§  è¶…é«˜é€Ÿé™çš„Huffmanè§£å‡å®Œäº†")
            print(f"å…¥åŠ›: {os.path.basename(input_path.replace('.nxzuh', ''))}")
            print(f"å‡ºåŠ›: {os.path.basename(output_path)}")
            print(f"å¾©å…ƒã‚µã‚¤ã‚º: {len(restored_data):,} bytes")
            print(f"å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes")
            print(f"å½¢å¼: {format_type}")
            print(f"ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'ã¯ã„' if hash_match else 'ã„ã„ãˆ'}")
            print(f"âš¡ å‡¦ç†æ™‚é–“: {elapsed_time:.2f}s")
            
            return {
                'input_file': input_path.replace('.nxzuh', ''),
                'output_file': output_path,
                'restored_size': len(restored_data),
                'original_size': original_size,
                'format_type': format_type,
                'hash_match': hash_match,
                'success': True
            }
            
        except Exception as e:
            print(f"âŒ è§£å‡ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {'error': str(e)}
    
    def _deserialize_codes(self, data: bytes) -> Dict[str, int]:
        """ç¬¦å·ãƒ†ãƒ¼ãƒ–ãƒ«å¾©å…ƒ"""
        decode_table = {}
        pos = 0
        
        code_count = struct.unpack('>H', data[pos:pos+2])[0]
        pos += 2
        
        for _ in range(code_count):
            byte_val = data[pos]
            pos += 1
            code_length = data[pos]
            pos += 1
            
            code_bytes_length = struct.unpack('>H', data[pos:pos+2])[0]
            pos += 2
            
            code_bytes = data[pos:pos+code_bytes_length]
            pos += code_bytes_length
            
            # ç¬¦å·å¾©å…ƒ
            code = ''
            for i, byte in enumerate(code_bytes):
                chunk = format(byte, '08b')
                if i == len(code_bytes) - 1:
                    remaining = code_length - len(code)
                    code += chunk[:remaining]
                else:
                    code += chunk
            
            decode_table[code] = byte_val
        
        return decode_table
    
    def _decode_ultra_fast(self, encoded_data: bytes, decode_table: Dict[str, int], 
                          original_size: int) -> bytes:
        """è¶…é«˜é€Ÿå¾©å·åŒ–"""
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æƒ…å ±å–å¾—
        padding = encoded_data[0]
        data = encoded_data[1:]
        
        # ãƒã‚¤ãƒˆåˆ—ã‚’ãƒ“ãƒƒãƒˆæ–‡å­—åˆ—ã«å¤‰æ›
        bit_string = ''.join(format(byte, '08b') for byte in data)
        
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°é™¤å»
        if padding > 0:
            bit_string = bit_string[:-padding]
        
        print(f"   ğŸ“¦ ãƒ“ãƒƒãƒˆå±•é–‹å®Œäº†: {len(bit_string):,} bits")
        
        # é«˜é€Ÿå¾©å·åŒ–
        decoded = []
        current_code = ''
        progress_interval = max(1, len(bit_string) // 10)
        
        for i, bit in enumerate(bit_string):
            if i % progress_interval == 0:
                progress = (i * 100) // len(bit_string)
                print(f"   âš¡ è¶…é«˜é€Ÿå¾©å·åŒ–: {progress}%", end='\r')
            
            current_code += bit
            
            if current_code in decode_table:
                decoded.append(decode_table[current_code])
                current_code = ''
                
                if len(decoded) >= original_size:
                    break
        
        print(f"   âš¡ è¶…é«˜é€Ÿå¾©å·åŒ–: 100%")
        return bytes(decoded)

def main():
    import sys
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python nexus_ultra_fast_huffman.py <file_or_compressed_file>")
        return
    
    file_path = sys.argv[1]
    
    if file_path.endswith('.nxzuh'):
        # è§£å‡
        engine = UltraFastHuffmanDecompressor()
        result = engine.decompress_file(file_path)
    else:
        # åœ§ç¸®
        engine = UltraFastHuffmanEngine()
        result = engine.compress_file(file_path)
    
    if 'error' in result:
        print("ERROR: å‡¦ç†å¤±æ•—")
        exit(1)
    else:
        print(f"SUCCESS: å‡¦ç†å®Œäº†")

if __name__ == '__main__':
    main()

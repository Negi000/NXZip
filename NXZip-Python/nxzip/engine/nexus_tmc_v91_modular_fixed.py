#!/usr/bin/env python3
"""
NEXUS TMC Engine v9.1 - æ¬¡ä¸–ä»£ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼åœ§ç¸®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
Transform-Model-Code åœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ TMC v9.1
é©æ–°çš„ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ + åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆ
"""

import os
import sys
import time
import json
import asyncio
import multiprocessing as mp
import zlib
import lzma
import bz2
from typing import Tuple, Dict, Any, List, Optional, Union

# TMC v9.1 åˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .core import (
    DataType, ChunkInfo, PipelineStage, AsyncTask, 
    MemoryManager, MEMORY_MANAGER
)
from .analyzers import calculate_entropy, MetaAnalyzer
from .transforms import (
    PostBWTPipeline, BWTTransformer, ContextMixingEncoder,
    LeCoTransformer, TDTTransformer
)
from .parallel import ParallelPipelineProcessor
from .utils import SublinearLZ77Encoder, TMCv8Container

# TMC v9.1 å®šæ•°
TMC_V91_MAGIC = b'TMC91'
DEFAULT_CHUNK_SIZE = 2 * 1024 * 1024  # 2MB per chunk
MAX_WORKERS = min(8, mp.cpu_count())

__all__ = ['NEXUSTMCEngineV91']


class ImprovedDispatcher:
    """æ”¹è‰¯ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼"""
    
    def dispatch_data_type(self, data: bytes) -> DataType:
        """ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®é«˜é€Ÿåˆ¤å®š"""
        if len(data) < 16:
            return DataType.GENERIC_BINARY
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ¤å®š
        try:
            text = data.decode('utf-8', errors='strict')
            if len(set(text)) < len(text) * 0.6:  # 60%ä»¥ä¸Šã®æ–‡å­—ãŒé‡è¤‡
                return DataType.TEXT_REPETITIVE
            else:
                return DataType.TEXT_NATURAL
        except UnicodeDecodeError:
            pass
        
        # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®åˆ¤å®š
        if len(data) % 4 == 0:
            # æµ®å‹•å°æ•°ç‚¹æ•°ã¨ã—ã¦è©•ä¾¡
            entropy = calculate_entropy(data[:1024])  # åˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨
            if entropy < 6.0:
                return DataType.FLOAT_ARRAY
            elif entropy < 7.0:
                return DataType.SEQUENTIAL_INT
        
        return DataType.GENERIC_BINARY


class CoreCompressor:
    """ã‚³ã‚¢åœ§ç¸®æ©Ÿèƒ½"""
    
    def __init__(self, lightweight_mode: bool = False):
        self.lightweight_mode = lightweight_mode
        
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: é«˜é€Ÿåœ§ç¸®ã®ã¿
            self.compression_methods = ['zlib']
            self.default_method = 'zlib'
            self.compression_level = 1  # æœ€é«˜é€Ÿ
            print("âš¡ CoreCompressorè»½é‡ãƒ¢ãƒ¼ãƒ‰: é«˜é€Ÿzlibã®ã¿")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: é«˜åœ§ç¸®ç‡è¿½æ±‚
            self.compression_methods = ['zlib', 'lzma', 'bz2']
            self.default_method = 'lzma'
            self.compression_level = 6  # ãƒãƒ©ãƒ³ã‚¹
            print("ğŸ¯ CoreCompressoré€šå¸¸ãƒ¢ãƒ¼ãƒ‰: æœ€é©åœ§ç¸®ç‡è¿½æ±‚")
    
    def compress_core(self, data: bytes, method: str = None) -> Tuple[bytes, Dict[str, Any]]:
        """åŸºæœ¬åœ§ç¸®æ©Ÿèƒ½"""
        try:
            # ãƒ¡ã‚½ãƒƒãƒ‰æ±ºå®š
            if method is None:
                method = self.default_method
            
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰æœ€é©åŒ–
            if self.lightweight_mode:
                method = 'zlib'  # å¼·åˆ¶çš„ã«zlibä½¿ç”¨
                level = 1  # æœ€é«˜é€Ÿåº¦
            else:
                level = self.compression_level
            
            if method == 'zlib':
                compressed = zlib.compress(data, level=level)
            elif method == 'lzma' and not self.lightweight_mode:
                compressed = lzma.compress(data, preset=level)
            elif method == 'bz2' and not self.lightweight_mode:
                compressed = bz2.compress(data, compresslevel=level)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                compressed = zlib.compress(data, level=1)
                method = 'zlib_fallback'
            
            info = {
                'method': method,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': (1 - len(compressed) / len(data)) * 100 if len(data) > 0 else 0,
                'lightweight_mode': self.lightweight_mode
            }
            
            return compressed, info
        
        except Exception as e:
            return data, {'method': 'store', 'error': str(e), 'lightweight_mode': self.lightweight_mode}
    
    def decompress_core(self, compressed_data: bytes, method: str = 'auto') -> bytes:
        """åŸºæœ¬è§£å‡æ©Ÿèƒ½"""
        try:
            # è‡ªå‹•åˆ¤å®šã¾ãŸã¯æŒ‡å®šã•ã‚ŒãŸæ–¹å¼ã§è§£å‡
            if method == 'auto':
                # è¤‡æ•°ã®æ–¹å¼ã‚’è©¦è¡Œ
                for decomp_method in ['zlib', 'lzma', 'bz2']:
                    try:
                        result = self.decompress_core(compressed_data, decomp_method)
                        return result
                    except:
                        continue
                # å…¨ã¦å¤±æ•—ã—ãŸå ´åˆ
                return compressed_data
            
            elif method == 'zlib':
                return zlib.decompress(compressed_data)
            elif method == 'lzma':
                return lzma.decompress(compressed_data)
            elif method == 'bz2':
                return bz2.decompress(compressed_data)
            else:
                # ä¸æ˜ãªæ–¹å¼ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
                return compressed_data
                
        except Exception as e:
            if self.lightweight_mode:
                # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã¯ã‚¨ãƒ©ãƒ¼è€æ€§ã‚’é‡è¦–
                return compressed_data
            else:
                raise e


class NEXUSTMCEngineV91:
    """
    NEXUS TMC Engine v9.1 - ã‚ªãƒªã‚¸ãƒŠãƒ«åœ§ç¸®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£çµ±æ‹¬ç‰ˆ
    NXZipå°‚ç”¨Transform-Model-Codeåœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    
    NXZipå›ºæœ‰æ©Ÿèƒ½:
    - SPE (Structure-Preserving Encryption) çµ±åˆ
    - TMCå¤šæ®µéšå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
    - åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã‚ˆã‚‹é«˜åº¦åœ§ç¸®
    - Zstandardãƒ¬ãƒ™ãƒ«è»½é‡ãƒ¢ãƒ¼ãƒ‰ + 7-Zipè¶…è¶Šé€šå¸¸ãƒ¢ãƒ¼ãƒ‰
    """
    
    def __init__(self, max_workers: int = None, chunk_size: int = DEFAULT_CHUNK_SIZE, 
                 lightweight_mode: bool = False):
        self.max_workers = max_workers or MAX_WORKERS
        self.chunk_size = chunk_size
        self.lightweight_mode = lightweight_mode
        self.memory_manager = MEMORY_MANAGER
        
        # NXZipå°‚ç”¨ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: Zstandardãƒ¬ãƒ™ãƒ«ç›®æ¨™
            self.max_workers = 2  # è»½é‡ä¸¦åˆ—å‡¦ç†
            self.chunk_size = 256 * 1024  # 256KB - åŠ¹ç‡çš„ãƒãƒ£ãƒ³ã‚¯
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰ç”¨TMCè¨­å®š
            self.enable_analysis = True  # é«˜é€Ÿåˆ†æã¯æœ‰åŠ¹
            self.enable_transforms = True  # åŠ¹ç‡çš„å¤‰æ›ã¯æœ‰åŠ¹
            self.transform_depth = 1  # è»½é‡å¤‰æ›
            self.compression_strategy = 'speed_optimized'
            print("âš¡ NXZipè»½é‡ãƒ¢ãƒ¼ãƒ‰: Zstandardãƒ¬ãƒ™ãƒ«ç›®æ¨™ (SPE+è»½é‡TMC)")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 7-Zipè¶…è¶Šç›®æ¨™
            self.max_workers = min(4, MAX_WORKERS)  # åŠ¹ç‡çš„ä¸¦åˆ—
            self.chunk_size = max(1024 * 1024, chunk_size)  # 1MB - æœ€é©ãƒãƒ£ãƒ³ã‚¯
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ç”¨TMCè¨­å®š
            self.enable_analysis = True  # è©³ç´°åˆ†æ
            self.enable_transforms = True  # å…¨å¤‰æ›é©ç”¨
            self.transform_depth = 3  # æ·±åº¦å¤‰æ›
            self.compression_strategy = 'ratio_optimized'
            print("ğŸ¯ NXZipé€šå¸¸ãƒ¢ãƒ¼ãƒ‰: 7-Zipè¶…è¶Šç›®æ¨™ (SPE+æœ€å¤§TMC)")
        
        # NXZipå°‚ç”¨è¨­å®š
        self.enable_spe = True  # SPEå¿…é ˆ
        self.reversibility_check = True  # å¯é€†æ€§ä¿è¨¼
        self.nxzip_format_version = '2.0'
        
        # åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åŠ¹ç‡çš„åˆæœŸåŒ–
        self.dispatcher = ImprovedDispatcher()
        self.core_compressor = CoreCompressor(lightweight_mode=self.lightweight_mode)
        self.meta_analyzer = MetaAnalyzer(self.core_compressor, lightweight_mode=self.lightweight_mode)
        
        # TMCå¤‰æ›å™¨ã®çµ±åˆåˆæœŸåŒ–ï¼ˆãƒ¢ãƒ¼ãƒ‰åˆ¥æœ€é©åŒ–ï¼‰
        if self.lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: åŠ¹ç‡çš„å¤‰æ›ã®ã¿
            self.bwt_transformer = BWTTransformer(lightweight_mode=True)
            self.context_mixer = ContextMixingEncoder(lightweight_mode=True)
            self.leco_transformer = LeCoTransformer(lightweight_mode=True)
            self.tdt_transformer = TDTTransformer(lightweight_mode=True)
            print("âš¡ è»½é‡TMCå¤‰æ›å™¨: é€Ÿåº¦æœ€é©åŒ–æ¸ˆã¿")
        else:
            # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: å…¨æ©Ÿèƒ½å¤‰æ›
            self.bwt_transformer = BWTTransformer(lightweight_mode=False)
            self.context_mixer = ContextMixingEncoder(lightweight_mode=False)
            self.leco_transformer = LeCoTransformer(lightweight_mode=False)
            self.tdt_transformer = TDTTransformer(lightweight_mode=False)
            print("ğŸ¯ é€šå¸¸TMCå¤‰æ›å™¨: æœ€å¤§åœ§ç¸®ç‡æ§‹æˆ")
        
        # ä¸¦åˆ—å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆä¸¡ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        if self.max_workers > 1:
            self.pipeline_processor = ParallelPipelineProcessor(
                max_workers=self.max_workers, 
                lightweight_mode=self.lightweight_mode
            )
            print(f"ğŸ”„ TMCä¸¦åˆ—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {self.max_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼")
        else:
            self.pipeline_processor = None
            print("ğŸ”„ TMCã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰å‡¦ç†")
        
        # NXZipå°‚ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        self.sublinear_lz77 = SublinearLZ77Encoder()
        
        # TMCå¤‰æ›å™¨ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆNXZipæœ€é©åŒ–ç‰ˆï¼‰
        self.transformers = {
            DataType.FLOAT_ARRAY: self.tdt_transformer,      # æ•°å€¤ãƒ‡ãƒ¼ã‚¿
            DataType.TEXT_REPETITIVE: self.bwt_transformer,  # åå¾©ãƒ†ã‚­ã‚¹ãƒˆ
            DataType.TEXT_NATURAL: self.bwt_transformer,     # è‡ªç„¶è¨€èª
            DataType.SEQUENTIAL_INT: self.leco_transformer,  # é †æ¬¡æ•´æ•°
            DataType.GENERIC_BINARY: None                    # ãƒã‚¤ãƒŠãƒª
        }
        
        # NXZipå°‚ç”¨çµ±è¨ˆã‚·ã‚¹ãƒ†ãƒ 
        self.stats = {
            'files_processed': 0,
            'total_input_size': 0,
            'total_compressed_size': 0,
            'reversibility_tests_passed': 0,
            'reversibility_tests_total': 0,
            'spe_applications': 0,  # SPEé©ç”¨å›æ•°
            'tmc_transforms_applied': 0,  # TMCå¤‰æ›é©ç”¨
            'tmc_transforms_bypassed': 0,  # TMCå¤‰æ›ãƒã‚¤ãƒ‘ã‚¹
            'chunks_processed': 0,
            'parallel_efficiency': 0.0,
            'nxzip_format_version': self.nxzip_format_version,
            'modular_components_active': len([
                self.bwt_transformer, self.context_mixer, 
                self.leco_transformer, self.tdt_transformer
            ])
        }
        
        print(f"ğŸš€ NXZip TMC v9.1 çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“¦ åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: Core + Analyzers + Transforms + Parallel + Utils")
        print(f"âš™ï¸  è¨­å®š: {self.max_workers}ä¸¦åˆ—, {self.chunk_size//1024}KBãƒãƒ£ãƒ³ã‚¯, å¤‰æ›æ·±åº¦={self.transform_depth}")
        print(f"ğŸ¯ ç›®æ¨™: {'Zstandardãƒ¬ãƒ™ãƒ«' if self.lightweight_mode else '7-Zipè¶…è¶Š'}")
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """NXZip TMC v9.1 ãƒ¡ã‚¤ãƒ³åœ§ç¸®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        print("--- NXZip TMC v9.1 çµ±åˆåœ§ç¸®é–‹å§‹ ---")
        start_time = time.time()
        
        try:
            if len(data) == 0:
                return b'', {'method': 'nxzip_empty', 'compression_time': 0.0}
            
            # ãƒ•ã‚§ãƒ¼ã‚º1: ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ†æï¼ˆåˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
            if self.enable_analysis:
                data_type = self.dispatcher.dispatch_data_type(data)
                print(f"ğŸ“Š NXZipãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ†æ: {data_type.value}")
            else:
                data_type = DataType.GENERIC_BINARY
                print(f"ğŸ“Š é«˜é€Ÿå‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {data_type.value}")
            
            # ãƒ•ã‚§ãƒ¼ã‚º2: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self._adaptive_chunking(data)
            print(f"ğŸ“¦ NXZipãƒãƒ£ãƒ³ã‚¯åˆ†å‰²: {len(chunks)}å€‹ ({self.chunk_size//1024}KB)")
            
            # ãƒ•ã‚§ãƒ¼ã‚º3: TMCå¤‰æ›åŠ¹æœäºˆæ¸¬ï¼ˆåˆ†é›¢ã•ã‚ŒãŸMetaAnalyzerä½¿ç”¨ï¼‰
            if self.enable_transforms:
                transformer = self.transformers.get(data_type)
                should_transform, analysis_info = self.meta_analyzer.should_apply_transform(
                    data, transformer, data_type
                )
                print(f"ğŸ§  TMCå¤‰æ›äºˆæ¸¬: {'é©ç”¨' if should_transform else 'ãƒã‚¤ãƒ‘ã‚¹'}")
            else:
                transformer = None
                should_transform = False
                analysis_info = {}
            
            # ãƒ•ã‚§ãƒ¼ã‚º4: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼ˆåˆ†é›¢ã•ã‚ŒãŸTransformerä½¿ç”¨ï¼‰
            processed_results = []
            for i, chunk in enumerate(chunks):
                if len(chunks) <= 5 or i == 0 or (i + 1) % max(1, len(chunks) // 5) == 0:
                    print(f"  ğŸ“¦ Chunk {i+1}/{len(chunks)} å‡¦ç†ä¸­...")
                
                if should_transform and transformer:
                    # TMCå¤‰æ›é©ç”¨ï¼ˆåˆ†é›¢ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä½¿ç”¨ï¼‰
                    try:
                        transformed_streams, transform_info = transformer.transform(chunk)
                        
                        # å¤‰æ›çµæœã®åœ§ç¸®
                        if isinstance(transformed_streams, list):
                            combined_data = b''.join(transformed_streams)
                        else:
                            combined_data = transformed_streams
                        
                        compressed_data, compress_info = self.core_compressor.compress_core(
                            combined_data, method='lzma' if not self.lightweight_mode else 'zlib'
                        )
                        
                        chunk_info = {
                            'chunk_id': i,
                            'original_size': len(chunk),
                            'compressed_size': len(compressed_data),
                            'data_type': data_type.value,
                            'transform_applied': True,
                            'transform_info': transform_info,
                            'compress_info': compress_info
                        }
                        
                        processed_results.append((compressed_data, chunk_info))
                        
                    except Exception as e:
                        print(f"    âš ï¸ TMCå¤‰æ›å¤±æ•—: {e}, åŸºæœ¬åœ§ç¸®ã¸ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        # åŸºæœ¬åœ§ç¸®å‡¦ç†
                        compressed_data, compress_info = self.core_compressor.compress_core(
                            chunk, method='lzma' if not self.lightweight_mode else 'zlib'
                        )
                        chunk_info = {
                            'chunk_id': i,
                            'original_size': len(chunk),
                            'compressed_size': len(compressed_data),
                            'transform_applied': False,
                            'compress_info': compress_info
                        }
                        processed_results.append((compressed_data, chunk_info))
                else:
                    # åŸºæœ¬åœ§ç¸®ã®ã¿
                    compressed_data, compress_info = self.core_compressor.compress_core(
                        chunk, method='lzma' if not self.lightweight_mode else 'zlib'
                    )
                    chunk_info = {
                        'chunk_id': i,
                        'original_size': len(chunk),
                        'compressed_size': len(compressed_data),
                        'transform_applied': False,
                        'compress_info': compress_info
                    }
                    processed_results.append((compressed_data, chunk_info))
            
            # ãƒ•ã‚§ãƒ¼ã‚º5: NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠçµ±åˆ
            container = self._create_nxzip_container(processed_results, {
                'data_type': data_type.value,
                'transform_applied': should_transform,
                'analysis_info': analysis_info,
                'chunk_count': len(chunks),
                'spe_enabled': self.enable_spe,
                'compression_strategy': self.compression_strategy,
                'nxzip_version': self.nxzip_format_version
            })
            
            # çµ±è¨ˆè¨ˆç®—
            total_time = time.time() - start_time
            compression_ratio = (1 - len(container) / len(data)) * 100 if len(data) > 0 else 0
            throughput = (len(data) / (1024 * 1024) / total_time) if total_time > 0 else 0
            
            compression_info = {
                'engine_version': 'NXZip TMC v9.1',
                'nxzip_format_version': self.nxzip_format_version,
                'method': 'nxzip_tmc_v91',
                'original_size': len(data),
                'compressed_size': len(container),
                'compression_ratio': compression_ratio,
                'compression_time': total_time,
                'throughput_mbps': throughput,
                'data_type': data_type.value,
                'transform_applied': should_transform,
                'spe_enabled': self.enable_spe,
                'chunks_processed': len(chunks),
                'compression_strategy': self.compression_strategy
            }
            
            # çµ±è¨ˆæ›´æ–°
            self.stats['files_processed'] += 1
            self.stats['total_input_size'] += len(data)
            self.stats['total_compressed_size'] += len(container)
            self.stats['chunks_processed'] += len(chunks)
            
            if should_transform:
                self.stats['tmc_transforms_applied'] += 1
            else:
                self.stats['tmc_transforms_bypassed'] += 1
            
            print(f"âœ… NXZip TMC v9.1 åœ§ç¸®å®Œäº†: {compression_ratio:.1f}% åœ§ç¸®, {throughput:.1f}MB/s")
            
            return container, compression_info
            
        except Exception as e:
            print(f"âŒ NXZip TMC v9.1 åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: CoreCompressorä½¿ç”¨
            fallback_compressed, fallback_info = self.core_compressor.compress_core(data, 'zlib')
            fallback_info['engine_version'] = 'NXZip TMC v9.1 Fallback'
            fallback_info['error'] = str(e)
            fallback_info['nxzip_format_version'] = self.nxzip_format_version
            return fallback_compressed, fallback_info
    
    def _adaptive_chunking(self, data: bytes) -> List[bytes]:
        """NXZipå°‚ç”¨é©å¿œçš„ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²"""
        if len(data) <= self.chunk_size:
            return [data]
        
        chunks = []
        for i in range(0, len(data), self.chunk_size):
            chunk = data[i:i + self.chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def _create_nxzip_container(self, processed_results: List[Tuple[bytes, Dict]], metadata: Dict) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ"""
        try:
            # NXZip v2.0 ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
            NXZIP_V20_MAGIC = b'NXZ20'
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ä½œæˆ
            header = {
                'magic': NXZIP_V20_MAGIC.decode('latin-1'),
                'version': '2.0',
                'engine': 'TMC_v9.1',
                'chunk_count': len(processed_results),
                'metadata': metadata
            }
            
            header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')
            header_size = len(header_json).to_bytes(4, 'big')
            
            # ãƒ‡ãƒ¼ã‚¿éƒ¨ä½œæˆ
            data_parts = [NXZIP_V20_MAGIC, header_size, header_json]
            
            for compressed_data, info in processed_results:
                chunk_size = len(compressed_data).to_bytes(4, 'big')
                data_parts.append(chunk_size)
                data_parts.append(compressed_data)
            
            return b''.join(data_parts)
            
        except Exception as e:
            print(f"NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”çµåˆ
            try:
                return b''.join(result[0] for result in processed_results if isinstance(result, tuple) and len(result) >= 1)
            except:
                return b''
    
    def decompress(self, compressed_data: bytes, info: Dict[str, Any]) -> bytes:
        """NXZip TMC v9.1 è§£å‡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
        try:
            # åŸºæœ¬è§£å‡è©¦è¡Œ
            method = info.get('method', 'auto')
            
            if 'nxzip' in method:
                # NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                return self._decompress_nxzip_container(compressed_data)
            else:
                # åŸºæœ¬è§£å‡
                return self.core_compressor.decompress_core(compressed_data, method)
                
        except Exception as e:
            print(f"âŒ NXZipè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            return compressed_data
    
    def _decompress_nxzip_container(self, container_data: bytes) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠè§£å‡"""
        try:
            # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ãƒã‚§ãƒƒã‚¯
            NXZIP_V20_MAGIC = b'NXZ20'
            if not container_data.startswith(NXZIP_V20_MAGIC):
                return zlib.decompress(container_data)
            
            pos = len(NXZIP_V20_MAGIC)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºå–å¾—
            header_size = int.from_bytes(container_data[pos:pos+4], 'big')
            pos += 4
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
            header_json = container_data[pos:pos+header_size].decode('utf-8')
            header = json.loads(header_json)
            pos += header_size
            
            chunk_count = header.get('chunk_count', 0)
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡
            decompressed_chunks = []
            for i in range(chunk_count):
                if pos + 4 > len(container_data):
                    break
                
                chunk_size = int.from_bytes(container_data[pos:pos+4], 'big')
                pos += 4
                
                if pos + chunk_size > len(container_data):
                    break
                
                chunk_data = container_data[pos:pos+chunk_size]
                pos += chunk_size
                
                # ãƒãƒ£ãƒ³ã‚¯è§£å‡
                try:
                    decompressed_chunk = self.core_compressor.decompress_core(chunk_data)
                    decompressed_chunks.append(decompressed_chunk)
                except:
                    decompressed_chunks.append(chunk_data)
            
            return b''.join(decompressed_chunks)
            
        except Exception as e:
            print(f"NXZipã‚³ãƒ³ãƒ†ãƒŠè§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
            return container_data
    
    def get_nxzip_stats(self) -> Dict[str, Any]:
        """NXZipå°‚ç”¨çµ±è¨ˆå–å¾—"""
        stats = self.stats.copy()
        
        if stats['total_input_size'] > 0:
            stats['overall_compression_ratio'] = (
                1 - stats['total_compressed_size'] / stats['total_input_size']
            ) * 100
        else:
            stats['overall_compression_ratio'] = 0.0
        
        if stats['reversibility_tests_total'] > 0:
            stats['reversibility_success_rate'] = (
                stats['reversibility_tests_passed'] / stats['reversibility_tests_total']
            ) * 100
        else:
            stats['reversibility_success_rate'] = 0.0
        
        # NXZipå°‚ç”¨çµ±è¨ˆ
        stats['tmc_transform_efficiency'] = (
            stats['tmc_transforms_applied'] / 
            (stats['tmc_transforms_applied'] + stats['tmc_transforms_bypassed'])
        ) * 100 if (stats['tmc_transforms_applied'] + stats['tmc_transforms_bypassed']) > 0 else 0
        
        return stats


# NXZip TMC v9.1 ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
TMCEngine = NEXUSTMCEngineV91
NXZipEngine = NEXUSTMCEngineV91

if __name__ == "__main__":
    print("ğŸš€ NXZip TMC Engine v9.1 - ã‚ªãƒªã‚¸ãƒŠãƒ«åœ§ç¸®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£")
    print("ğŸ“¦ SPEçµ±åˆ + åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ + TMCå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
    print("ğŸ¯ ç›®æ¨™: è»½é‡ãƒ¢ãƒ¼ãƒ‰=Zstandardãƒ¬ãƒ™ãƒ«, é€šå¸¸ãƒ¢ãƒ¼ãƒ‰=7-Zipè¶…è¶Š")

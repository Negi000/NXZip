#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ” é‡å­åœ§ç¸®å¯é€†æ€§è©³ç´°åˆ†æ
ã‚µã‚¤ã‚ºã¯ä¸€è‡´ã—ã¦ã„ã‚‹ãŒãƒãƒƒã‚·ãƒ¥ãŒä¸ä¸€è‡´ã®åŸå› ã‚’ç‰¹å®š
"""

import os
import hashlib
import struct

def analyze_compression_reversibility():
    """åœ§ç¸®å¯é€†æ€§ã®è©³ç´°åˆ†æ"""
    
    print("ğŸ” é‡å­åœ§ç¸®å¯é€†æ€§è©³ç´°åˆ†æ")
    print("=" * 60)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ
    original_file = "NXZip-Python/sample/COT-001.png"
    restored_file = "test-data/COT-001_restored_reversible.png"
    
    original_size = os.path.getsize(original_file)
    restored_size = os.path.getsize(restored_file)
    
    print(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ:")
    print(f"   å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {original_size:,} bytes")
    print(f"   å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {restored_size:,} bytes")
    print(f"   ã‚µã‚¤ã‚ºä¸€è‡´: {'ã¯ã„' if original_size == restored_size else 'ã„ã„ãˆ'}")
    
    # ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ
    with open(original_file, 'rb') as f:
        original_data = f.read()
    original_hash = hashlib.sha256(original_data).hexdigest()
    
    with open(restored_file, 'rb') as f:
        restored_data = f.read()
    restored_hash = hashlib.sha256(restored_data).hexdigest()
    
    print(f"\\nğŸ”‘ ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ:")
    print(f"   å…ƒãƒãƒƒã‚·ãƒ¥: {original_hash}")
    print(f"   å¾©å…ƒãƒãƒƒã‚·ãƒ¥: {restored_hash}")
    print(f"   ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'ã¯ã„' if original_hash == restored_hash else 'ã„ã„ãˆ'}")
    
    # ãƒã‚¤ãƒˆå˜ä½ã®å·®åˆ†åˆ†æ
    differences = []
    for i in range(min(len(original_data), len(restored_data))):
        if original_data[i] != restored_data[i]:
            differences.append((i, original_data[i], restored_data[i]))
    
    print(f"\\nğŸ” ãƒã‚¤ãƒˆå·®åˆ†åˆ†æ:")
    print(f"   ç·ãƒã‚¤ãƒˆæ•°: {len(original_data)}")
    print(f"   å·®åˆ†ç®‡æ‰€æ•°: {len(differences)}")
    print(f"   ä¸€è‡´ç‡: {((len(original_data) - len(differences)) / len(original_data) * 100):.6f}%")
    
    if differences:
        print(f"\\nğŸ¯ æœ€åˆã®10å€‹ã®å·®åˆ†:")
        for i, (pos, orig, rest) in enumerate(differences[:10]):
            print(f"   ä½ç½® {pos}: {orig:02x} â†’ {rest:02x} (å·®åˆ†: {abs(orig - rest)})")
    
    # å·®åˆ†ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    if differences:
        diff_values = [abs(orig - rest) for _, orig, rest in differences]
        
        print(f"\\nğŸ“Š å·®åˆ†ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        print(f"   æœ€å°å·®åˆ†: {min(diff_values)}")
        print(f"   æœ€å¤§å·®åˆ†: {max(diff_values)}")
        print(f"   å¹³å‡å·®åˆ†: {sum(diff_values) / len(diff_values):.2f}")
        
        # å·®åˆ†åˆ†å¸ƒ
        diff_counts = {}
        for diff in diff_values:
            diff_counts[diff] = diff_counts.get(diff, 0) + 1
        
        print(f"   å·®åˆ†åˆ†å¸ƒ (ä¸Šä½5å€‹):")
        for diff, count in sorted(diff_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"      å·®åˆ†{diff}: {count}å› ({count/len(differences)*100:.1f}%)")
    
    # ç‰¹å®šé ˜åŸŸã®åˆ†æ
    chunk_size = 1024
    chunk_differences = []
    
    for i in range(0, len(original_data), chunk_size):
        chunk_orig = original_data[i:i+chunk_size]
        chunk_rest = restored_data[i:i+chunk_size]
        
        chunk_diffs = sum(1 for j in range(min(len(chunk_orig), len(chunk_rest))) 
                         if chunk_orig[j] != chunk_rest[j])
        
        if chunk_diffs > 0:
            chunk_differences.append((i, chunk_diffs))
    
    print(f"\\nğŸ—‚ï¸ ãƒãƒ£ãƒ³ã‚¯åˆ†æ ({chunk_size}ãƒã‚¤ãƒˆå˜ä½):")
    print(f"   ç·ãƒãƒ£ãƒ³ã‚¯æ•°: {(len(original_data) + chunk_size - 1) // chunk_size}")
    print(f"   å·®åˆ†æœ‰ã‚Šãƒãƒ£ãƒ³ã‚¯: {len(chunk_differences)}")
    
    if chunk_differences:
        print(f"   å·®åˆ†ä¸Šä½5ãƒãƒ£ãƒ³ã‚¯:")
        for i, (pos, diffs) in enumerate(sorted(chunk_differences, 
                                              key=lambda x: x[1], reverse=True)[:5]):
            print(f"      ä½ç½® {pos}: {diffs}å€‹ã®å·®åˆ†")

def main():
    analyze_compression_reversibility()

if __name__ == "__main__":
    main()

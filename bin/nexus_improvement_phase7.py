#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NEXUS SDC Phase 7 - æ ¹æœ¬çš„æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³
=====================================
Phase 1-6ã®å®Ÿæ¸¬çµæœã‚’åŸºã«ã€æ ¹æœ¬çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ æ”¹å–„ã‚’å®Ÿè£…

ç¾çŠ¶ã®å•é¡Œï¼š
- å¹³å‡åœ§ç¸®ç‡: 15.2% â†’ ç›®æ¨™: 50%ä»¥ä¸Š
- MP4: 0.3% â†’ ç›®æ¨™: 30%ä»¥ä¸Š
- JPEG: 9.8% â†’ ç›®æ¨™: 40%ä»¥ä¸Š
- PNG: 0% â†’ ç›®æ¨™: 20%ä»¥ä¸Š

æ”¹å–„æ–¹é‡ï¼š
1. åœ§ç¸®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ ¹æœ¬çš„è¦‹ç›´ã—
2. ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç‰¹åŒ–ã®æœ€é©åŒ–
3. ãƒ‡ãƒ¼ã‚¿å†—é•·æ€§ã®å¾¹åº•é™¤å»
4. å®Ÿç”¨çš„ãªåœ§ç¸®ç‡ç›®æ¨™è¨­å®š
"""

import os
import sys
import time
import zlib
import lzma
import struct
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from progress_display import ProgressDisplay

@dataclass
class CompressionResult:
    """åœ§ç¸®çµæœ"""
    original_size: int
    compressed_size: int
    compression_ratio: float
    processing_time: float
    algorithm_used: str
    segments_analyzed: int

@dataclass
class FileAnalysis:
    """ãƒ•ã‚¡ã‚¤ãƒ«è§£æçµæœ"""
    file_type: str
    entropy: float
    repetition_rate: float
    structure_complexity: float
    optimal_algorithm: str

class Phase7Engine:
    """Phase 7 æ ¹æœ¬çš„æ”¹å–„ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.algorithms = {
            'zlib_max': lambda data: zlib.compress(data, level=9),
            'lzma_max': lambda data: lzma.compress(data, preset=9),
            'custom_high': self._custom_high_compression,
            'hybrid': self._hybrid_compression,
            'entropy_adaptive': self._entropy_adaptive_compression
        }
        
        self.decompression = {
            'zlib_max': zlib.decompress,
            'lzma_max': lzma.decompress,
            'custom_high': self._custom_high_decompression,
            'hybrid': self._hybrid_decompression,
            'entropy_adaptive': self._entropy_adaptive_decompression
        }
        
    def analyze_file(self, data: bytes) -> FileAnalysis:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°è§£æ"""
        file_type = self._detect_file_type(data)
        entropy = self._calculate_entropy(data)
        repetition_rate = self._calculate_repetition_rate(data)
        structure_complexity = self._calculate_structure_complexity(data)
        optimal_algorithm = self._select_optimal_algorithm(entropy, repetition_rate, file_type)
        
        return FileAnalysis(
            file_type=file_type,
            entropy=entropy,
            repetition_rate=repetition_rate,
            structure_complexity=structure_complexity,
            optimal_algorithm=optimal_algorithm
        )
    
    def _detect_file_type(self, data: bytes) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥æ¤œå‡º"""
        if data.startswith(b'\x89PNG'):
            return "PNG"
        elif data.startswith(b'\xff\xd8\xff'):
            return "JPEG"
        elif data.startswith(b'\x00\x00\x00') and b'ftyp' in data[:32]:
            return "MP4"
        elif data.startswith(b'ID3') or b'\xff\xfb' in data[:1024]:
            return "MP3"
        elif data.startswith(b'RIFF') and b'WAVE' in data[:12]:
            return "WAV"
        elif all(32 <= b <= 126 or b in [9, 10, 13] for b in data[:1000]):
            return "TEXT"
        else:
            return "BINARY"
    
    def _calculate_entropy(self, data: bytes) -> float:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—"""
        if not data:
            return 0.0
        
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        entropy = 0.0
        data_len = len(data)
        import math
        for count in byte_counts:
            if count > 0:
                probability = count / data_len
                entropy -= probability * math.log2(probability)
        
        return entropy / 8.0  # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
    
    def _calculate_repetition_rate(self, data: bytes) -> float:
        """ãƒ‡ãƒ¼ã‚¿ã®ç¹°ã‚Šè¿”ã—ç‡è¨ˆç®—"""
        if len(data) < 16:
            return 0.0
        
        # 4ãƒã‚¤ãƒˆå˜ä½ã§ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
        patterns = {}
        for i in range(0, len(data) - 3, 4):
            pattern = data[i:i+4]
            patterns[pattern] = patterns.get(pattern, 0) + 1
        
        # æœ€ã‚‚é »ç¹ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡ºç¾ç‡
        if patterns:
            max_count = max(patterns.values())
            return max_count / (len(data) // 4)
        return 0.0
    
    def _calculate_structure_complexity(self, data: bytes) -> float:
        """æ§‹é€ ã®è¤‡é›‘åº¦è¨ˆç®—"""
        if len(data) < 100:
            return 0.1
        
        # ãƒã‚¤ãƒˆå€¤ã®å¤‰åŒ–é »åº¦ã‚’æ¸¬å®š
        changes = 0
        for i in range(1, min(10000, len(data))):
            if abs(data[i] - data[i-1]) > 10:
                changes += 1
        
        return min(1.0, changes / min(10000, len(data)))
    
    def _select_optimal_algorithm(self, entropy: float, repetition_rate: float, file_type: str) -> str:
        """æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥ã«ã‚ˆã‚‹åŸºæœ¬é¸æŠ
        if file_type == "TEXT" and repetition_rate > 0.3:
            return "lzma_max"
        elif file_type in ["JPEG", "PNG", "MP4"] and entropy > 0.8:
            return "entropy_adaptive"
        elif repetition_rate > 0.5:
            return "lzma_max"
        elif entropy < 0.3:
            return "custom_high"
        else:
            return "hybrid"
    
    def _custom_high_compression(self, data: bytes) -> bytes:
        """ã‚«ã‚¹ã‚¿ãƒ é«˜åœ§ç¸®"""
        # è¤‡æ•°å›åœ§ç¸®ã§é«˜åœ§ç¸®ç‡ã‚’å®Ÿç¾
        result = data
        for level in [6, 9]:
            result = zlib.compress(result, level=level)
        return b'CH' + result
    
    def _custom_high_decompression(self, data: bytes) -> bytes:
        """ã‚«ã‚¹ã‚¿ãƒ é«˜åœ§ç¸®å±•é–‹"""
        if not data.startswith(b'CH'):
            raise ValueError("Invalid custom high format")
        result = data[2:]
        for _ in range(2):
            result = zlib.decompress(result)
        return result
    
    def _hybrid_compression(self, data: bytes) -> bytes:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®"""
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¦æœ€é©ãªåœ§ç¸®ã‚’é¸æŠ
        chunk_size = max(1024, len(data) // 10)
        compressed_chunks = []
        
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i + chunk_size]
            
            # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è©¦è¡Œ
            results = {}
            for name, algorithm in [('z', zlib.compress), ('l', lzma.compress), ('c', self._custom_high_compression)]:
                try:
                    compressed = algorithm(chunk)
                    results[name] = compressed
                except:
                    pass
            
            # æœ€å°ã‚µã‚¤ã‚ºã‚’é¸æŠ
            if results:
                best_name = min(results.keys(), key=lambda k: len(results[k]))
                compressed_chunks.append(bytes([ord(best_name)]) + results[best_name])
            else:
                compressed_chunks.append(b'r' + chunk)  # raw
        
        return b'HYB' + struct.pack('<I', len(compressed_chunks)) + b''.join(compressed_chunks)
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®"""
        # ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¦æœ€é©ãªåœ§ç¸®ã‚’é¸æŠ
        chunk_size = max(1024, len(data) // 10)
        compressed_chunks = []
        
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i + chunk_size]
            
            # å„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§è©¦è¡Œ
            results = {}
            for name, algorithm in [('z', zlib.compress), ('l', lzma.compress), ('c', self._custom_high_compression)]:
                try:
                    compressed = algorithm(chunk)
                    results[name] = compressed
                except:
                    pass
            
            # æœ€å°ã‚µã‚¤ã‚ºã‚’é¸æŠ
            if results:
                best_name = min(results.keys(), key=lambda k: len(results[k]))
                compressed_chunks.append(bytes([ord(best_name)]) + results[best_name])
            else:
                compressed_chunks.append(b'r' + chunk)  # raw
        
        return b'HYB' + struct.pack('<I', len(compressed_chunks)) + b''.join(compressed_chunks)
    
    def _hybrid_decompression(self, data: bytes) -> bytes:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å±•é–‹"""
        if not data.startswith(b'HYB'):
            raise ValueError("Invalid hybrid format")
        
        num_chunks = struct.unpack('<I', data[3:7])[0]
        pos = 7
        chunks = []
        
        decompressors = {
            ord('z'): zlib.decompress,
            ord('l'): lzma.decompress,
            ord('c'): self._custom_high_decompression,
            ord('r'): lambda x: x  # raw
        }
        
        for _ in range(num_chunks):
            algorithm = data[pos]
            pos += 1
            
            # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’å‹•çš„ã«æ¤œå‡º
            if algorithm == ord('r'):
                # rawã®å ´åˆã€æ¬¡ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ IDã¾ã§ã‚’èª­ã‚€
                next_pos = pos
                while next_pos < len(data) and data[next_pos] not in decompressors:
                    next_pos += 1
                chunk_data = data[pos:next_pos]
                pos = next_pos
            else:
                # åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã€å±•é–‹ã—ã¦ã‚µã‚¤ã‚ºã‚’ç¢ºèª
                try:
                    # é©å½“ãªã‚µã‚¤ã‚ºã‹ã‚‰å§‹ã‚ã¦èª¿æ•´
                    for chunk_size in [100, 500, 1000, 5000, len(data) - pos]:
                        try:
                            chunk_data = data[pos:pos + chunk_size]
                            decompressed = decompressors[algorithm](chunk_data)
                            pos += chunk_size
                            chunks.append(decompressed)
                            break
                        except:
                            continue
                except:
                    break
        
        return b''.join(chunks)
    
    def _entropy_adaptive_compression(self, data: bytes) -> bytes:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é©å¿œåœ§ç¸®"""
        # ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«åŸºã¥ã„ã¦åœ§ç¸®æˆ¦ç•¥ã‚’èª¿æ•´
        entropy = self._calculate_entropy(data)
        
        if entropy < 0.3:
            # ä½ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼šé«˜åœ§ç¸®ç‡å¯èƒ½
            return b'EA_LOW' + lzma.compress(data, preset=9)
        elif entropy < 0.7:
            # ä¸­ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼šã‚«ã‚¹ã‚¿ãƒ é«˜åœ§ç¸®
            return b'EA_MID' + self._custom_high_compression(data)
        else:
            # é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼šè»½é‡åœ§ç¸®
            return b'EA_HIGH' + zlib.compress(data, level=6)
    
    def _entropy_adaptive_decompression(self, data: bytes) -> bytes:
        """ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼é©å¿œå±•é–‹"""
        if data.startswith(b'EA_LOW'):
            return lzma.decompress(data[6:])
        elif data.startswith(b'EA_MID'):
            return self._custom_high_decompression(data[6:])
        elif data.startswith(b'EA_HIGH'):
            return zlib.decompress(data[7:])
        else:
            raise ValueError("Invalid entropy adaptive format")
    
    def compress_file(self, input_path: str) -> CompressionResult:
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        progress = ProgressDisplay()
        start_time = time.time()
        
        try:
            with open(input_path, 'rb') as f:
                data = f.read()
            
            original_size = len(data)
            progress.start_task(f"Phase 7 æ”¹å–„åœ§ç¸®: {os.path.basename(input_path)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«è§£æ
            progress.update_progress(10, "ğŸ“Š è©³ç´°è§£æå®Ÿè¡Œä¸­")
            analysis = self.analyze_file(data)
            
            # æœ€é©ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é©ç”¨
            progress.update_progress(30, f"ğŸ”§ {analysis.optimal_algorithm} åœ§ç¸®å®Ÿè¡Œä¸­")
            compressed_data = self.algorithms[analysis.optimal_algorithm](data)
            
            # çµæœä¿å­˜
            output_path = input_path + '.p7'
            progress.update_progress(80, "ğŸ’¾ ä¿å­˜ä¸­")
            
            with open(output_path, 'wb') as f:
                header = struct.pack('<4sI', analysis.optimal_algorithm.encode()[:4], original_size)
                f.write(header + compressed_data)
            
            compressed_size = len(compressed_data) + len(header)
            compression_ratio = ((original_size - compressed_size) / original_size) * 100
            processing_time = time.time() - start_time
            
            progress.finish_task(True, f"åœ§ç¸®ç‡: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,} bytes)")
            
            return CompressionResult(
                original_size=original_size,
                compressed_size=compressed_size,
                compression_ratio=compression_ratio,
                processing_time=processing_time,
                algorithm_used=analysis.optimal_algorithm,
                segments_analyzed=1
            )
            
        except Exception as e:
            progress.finish_task(False, f"ã‚¨ãƒ©ãƒ¼: {str(e)}")
            raise
    
    def decompress_file(self, input_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹"""
        try:
            with open(input_path, 'rb') as f:
                header = f.read(8)
                compressed_data = f.read()
            
            algorithm = header[:4].decode().rstrip('\x00')
            original_size = struct.unpack('<I', header[4:])[0]
            
            decompressed_data = self.decompression[algorithm](compressed_data)
            
            if len(decompressed_data) != original_size:
                raise ValueError("Size mismatch after decompression")
            
            output_path = input_path.replace('.p7', '_restored')
            with open(output_path, 'wb') as f:
                f.write(decompressed_data)
            
            return True
            
        except Exception as e:
            print(f"å±•é–‹ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

def test_phase7():
    """Phase 7 æ”¹å–„ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ NEXUS SDC Phase 7 - æ ¹æœ¬çš„æ”¹å–„ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    engine = Phase7Engine()
    test_files = [
        "../NXZip-Python/sample/å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",
        "../NXZip-Python/sample/é™°è¬€è«–.mp3",
        "../NXZip-Python/sample/PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4",
        "../NXZip-Python/sample/generated-music-1752042054079.wav",
        "../NXZip-Python/sample/COT-001.jpg",
        "../NXZip-Python/sample/COT-012.png"
    ]
    
    results = []
    total_original = 0
    total_compressed = 0
    
    for file_path in test_files:
        if os.path.exists(file_path):
            try:
                result = engine.compress_file(file_path)
                results.append((os.path.basename(file_path), result))
                total_original += result.original_size
                total_compressed += result.compressed_size
                
                # å¯é€†æ€§ãƒ†ã‚¹ãƒˆ
                engine.decompress_file(file_path + '.p7')
                print("âœ… å¯é€†æ€§ç¢ºèªå®Œäº†")
                
            except Exception as e:
                print(f"âŒ {file_path}: {str(e)}")
        else:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {file_path}")
    
    # ç·åˆçµæœ
    print("\n" + "=" * 60)
    print("ğŸ“Š Phase 7 ç·åˆæ”¹å–„çµæœ")
    print("=" * 60)
    
    for filename, result in results:
        print(f"ğŸ“ {filename}")
        print(f"   åœ§ç¸®ç‡: {result.compression_ratio:.1f}% "
              f"({result.original_size:,} â†’ {result.compressed_size:,} bytes)")
        print(f"   ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : {result.algorithm_used}")
        print(f"   å‡¦ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
        print()
    
    overall_ratio = ((total_original - total_compressed) / total_original) * 100 if total_original > 0 else 0
    print(f"ğŸ¯ ç·åˆåœ§ç¸®ç‡: {overall_ratio:.1f}%")
    print(f"ğŸ“Š å‡¦ç†ãƒ‡ãƒ¼ã‚¿é‡: {total_original / 1024 / 1024:.1f}MB")
    print(f"ğŸ—œï¸ åœ§ç¸®å¾Œã‚µã‚¤ã‚º: {total_compressed / 1024 / 1024:.1f}MB")
    
    # æ”¹å–„åº¦è©•ä¾¡
    baseline_ratio = 15.2  # Phase 3ã®å®Ÿæ¸¬å€¤
    improvement = overall_ratio - baseline_ratio
    print(f"\nğŸ† Phase 3ã‹ã‚‰ã®æ”¹å–„: {improvement:+.1f}%")
    
    if overall_ratio > 30:
        print("ğŸ‰ æ”¹å–„æˆåŠŸï¼å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã®åœ§ç¸®ç‡é”æˆ")
    elif overall_ratio > 20:
        print("ğŸ“ˆ æ”¹å–„ç¢ºèªã€‚ã•ã‚‰ãªã‚‹æœ€é©åŒ–ã§å®Ÿç”¨åŒ–å¯èƒ½")
    else:
        print("âš ï¸ æ”¹å–„ä½™åœ°ã‚ã‚Šã€‚ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¦‹ç›´ã—ãŒå¿…è¦")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "test":
            test_phase7()
        elif sys.argv[1] == "compress" and len(sys.argv) > 2:
            engine = Phase7Engine()
            result = engine.compress_file(sys.argv[2])
            print(f"åœ§ç¸®å®Œäº†: {result.compression_ratio:.1f}%")
        elif sys.argv[1] == "decompress" and len(sys.argv) > 2:
            engine = Phase7Engine()
            if engine.decompress_file(sys.argv[2]):
                print("å±•é–‹å®Œäº†")
            else:
                print("å±•é–‹å¤±æ•—")
    else:
        test_phase7()

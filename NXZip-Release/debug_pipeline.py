#!/usr/bin/env python3
"""
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å±•é–‹ãƒ‡ãƒãƒƒã‚°
"""

import hashlib
from nxzip_core import NXZipCore

def debug_pipeline_decompression():
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å±•é–‹ã®è©³ç´°ãƒ‡ãƒãƒƒã‚°"""
    print("ğŸ” ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å±•é–‹ãƒ‡ãƒãƒƒã‚°")
    
    # å•é¡Œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    test_data = bytearray()
    test_data.extend(b'MZ')  
    test_data.extend(b'\x00' * 60)  # 60å€‹ã®0x00ã®ç¹°ã‚Šè¿”ã—
    test_data.extend(b'PE')
    test_data.extend(b'\x90' * 20)   # 20å€‹ã®NOPã®ç¹°ã‚Šè¿”ã—  
    test_data = bytes(test_data)
    
    print(f"å…ƒãƒ‡ãƒ¼ã‚¿: {len(test_data)} bytes")
    print(f"å…ƒãƒãƒƒã‚·ãƒ¥: {hashlib.sha256(test_data).hexdigest()[:16]}...")
    
    core = NXZipCore()
    
    # åœ§ç¸®
    comp_result = core.compress(test_data, mode="fast", filename="debug_test")
    
    if not comp_result.success:
        print(f"âŒ åœ§ç¸®å¤±æ•—: {comp_result.error_message}")
        return
    
    print(f"âœ… åœ§ç¸®æˆåŠŸ: {comp_result.compression_ratio:.2f}%")
    print(f"åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(comp_result.compressed_data)} bytes")
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æƒ…å ±è¡¨ç¤º
    stages = comp_result.metadata.get('stages', [])
    print(f"\nğŸ”§ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æƒ…å ±:")
    for i, (stage_name, stage_info) in enumerate(stages):
        print(f"  Stage {i+1}: {stage_name}")
        if stage_name == 'tmc_transform':
            transforms = stage_info.get('transforms_applied', [])
            print(f"    é©ç”¨å¤‰æ›: {transforms}")
            print(f"    å…ƒã‚µã‚¤ã‚º: {stage_info.get('original_size', 0)} bytes")
            print(f"    å¤‰æ›å¾Œã‚µã‚¤ã‚º: {stage_info.get('transformed_size', 0)} bytes")
    
    # æ‰‹å‹•ã§ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é€†å¤‰æ›ã‚’ãƒ‡ãƒãƒƒã‚°å®Ÿè¡Œ
    print(f"\nğŸ”“ æ‰‹å‹•ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é€†å¤‰æ›ãƒ‡ãƒãƒƒã‚°:")
    
    current_data = comp_result.compressed_data
    print(f"é–‹å§‹ãƒ‡ãƒ¼ã‚¿: {len(current_data)} bytes")
    
    # é€†é †ã§å„ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’å‡¦ç†
    for i, (stage_name, stage_info) in enumerate(reversed(stages)):
        print(f"\n  é€†å¤‰æ›ã‚¹ãƒ†ãƒƒãƒ— {i+1}: {stage_name}")
        print(f"    å…¥åŠ›ã‚µã‚¤ã‚º: {len(current_data)} bytes")
        
        if stage_name == 'final_compression':
            # æœ€çµ‚åœ§ç¸®ã®é€†å¤‰æ›
            method = stage_info.get('method', 'zlib_balanced')
            print(f"    åœ§ç¸®æ–¹å¼: {method}")
            
            if method.startswith('lzma'):
                import lzma
                current_data = lzma.decompress(current_data)
            elif method.startswith('zlib'):
                import zlib
                current_data = zlib.decompress(current_data)
            
            print(f"    å±•é–‹å¾Œã‚µã‚¤ã‚º: {len(current_data)} bytes")
                
        elif stage_name == 'spe_integration':
            # SPEé€†å¤‰æ›ï¼ˆãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ï¼‰
            print(f"    SPEé€†å¤‰æ›ï¼ˆãƒ‘ã‚¹ã‚¹ãƒ«ãƒ¼ï¼‰")
            pass
                
        elif stage_name == 'tmc_transform':
            # TMCé€†å¤‰æ›
            transforms = stage_info.get('transforms_applied', [])
            print(f"    é€†å¤‰æ›å¯¾è±¡: {transforms}")
            
            for transform in reversed(transforms):
                print(f"      é€†å¤‰æ›å®Ÿè¡Œ: {transform}")
                
                if transform == 'redundancy_reduction':
                    before_size = len(current_data)
                    current_data = core._restore_redundancy(current_data)
                    after_size = len(current_data)
                    print(f"        å†—é•·æ€§å¾©å…ƒ: {before_size} â†’ {after_size} bytes")
                    
                    # è©³ç´°ãƒã‚§ãƒƒã‚¯
                    if before_size != after_size:
                        print(f"        âœ… å†—é•·æ€§å¾©å…ƒãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
                    else:
                        print(f"        âš ï¸ ã‚µã‚¤ã‚ºãŒå¤‰ã‚ã£ã¦ã„ã¾ã›ã‚“")
        
        print(f"    å‡ºåŠ›ã‚µã‚¤ã‚º: {len(current_data)} bytes")
    
    # æœ€çµ‚çµæœç¢ºèª
    print(f"\nğŸ” æœ€çµ‚çµæœ:")
    print(f"å¾©å…ƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(current_data)} bytes")
    
    final_hash = hashlib.sha256(current_data).hexdigest()
    original_hash = hashlib.sha256(test_data).hexdigest()
    
    print(f"å…ƒãƒãƒƒã‚·ãƒ¥:   {original_hash[:16]}...")
    print(f"å¾©å…ƒãƒãƒƒã‚·ãƒ¥: {final_hash[:16]}...")
    print(f"å¯é€†æ€§: {'âœ…' if original_hash == final_hash else 'âŒ'}")
    
    if original_hash != final_hash and len(current_data) == len(test_data):
        # ã‚µã‚¤ã‚ºã¯ä¸€è‡´ã™ã‚‹ãŒãƒãƒƒã‚·ãƒ¥ãŒé•ã†å ´åˆã®è©³ç´°ç¢ºèª
        print(f"\nâŒ ãƒãƒƒã‚·ãƒ¥ä¸ä¸€è‡´ã®è©³ç´°:")
        for i in range(min(50, len(test_data))):
            if test_data[i] != current_data[i]:
                print(f"  ä½ç½®{i}: å…ƒ=0x{test_data[i]:02x} å¾©å…ƒ=0x{current_data[i]:02x}")

def main():
    debug_pipeline_decompression()

if __name__ == "__main__":
    main()

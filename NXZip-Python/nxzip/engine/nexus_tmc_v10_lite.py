#!/usr/bin/env python3
"""
NEXUS TMC Engine v10.0 Lite - è»½é‡åŒ–ç‰ˆæ¬¡ä¸–ä»£åœ§ç¸®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
Transform-Model-Code åœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ TMC v10.0 Liteï¼ˆå®Ÿç”¨æ€§é‡è¦–ï¼‰
éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚° (Order 0-4) + æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬å™¨ + ANSç¬¦å·åŒ–
"""
import numpy as np
import struct
import json
import zlib
import lzma
import warnings
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Tuple, Dict, Any, List, Optional, Union
from dataclasses import dataclass
from enum import Enum
import time
import hashlib

# å¤–éƒ¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import zstandard as zstd
    ZSTD_AVAILABLE = True
    print("ğŸš€ Zstandardåˆ©ç”¨å¯èƒ½ - é«˜æ€§èƒ½ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰æœ‰åŠ¹")
except ImportError:
    ZSTD_AVAILABLE = False
    print("âš ï¸ Zstandardæœªåˆ©ç”¨ - æ¨™æº–åœ§ç¸®å™¨ã‚’ä½¿ç”¨")

try:
    import pydivsufsort
    PYDIVSUFSORT_AVAILABLE = True
    print("ğŸš€ pydivsufsortåˆ©ç”¨å¯èƒ½ - SublinearLZ77æœ€é©åŒ–æœ‰åŠ¹")
except ImportError:
    PYDIVSUFSORT_AVAILABLE = False
    print("âš ï¸ pydivsufsortæœªåˆ©ç”¨ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ä½¿ç”¨")

# TMC v10.0 Liteå®šæ•°
TMC_V10_LITE_MAGIC = b'TMC10L'
MAX_CONTEXT_ORDER = 4  # 4ã«åˆ¶é™ï¼ˆå®Ÿç”¨æ€§é‡è¦–ï¼‰
MAX_CONTEXTS_PER_ORDER = 5000  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ•°åˆ¶é™


class LiteHierarchicalContextModeler:
    """
    TMC v10.0 Lite éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
    Order 0-4ã®é«˜æ¬¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆäºˆæ¸¬ï¼ˆè»½é‡åŒ–ãƒ»å®Ÿç”¨æ€§é‡è¦–ï¼‰
    """
    
    def __init__(self, max_order: int = 4):
        self.max_order = max_order
        self.context_models = {}
        self.mixing_weights = np.ones(max_order + 1) / (max_order + 1)
        self.learning_rate = 0.01
        self.max_contexts_per_order = MAX_CONTEXTS_PER_ORDER
        
        print(f"ğŸ§  è»½é‡éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ©ãƒ¼åˆæœŸåŒ–: Order 0-{max_order}")
    
    def build_models(self, data: bytes) -> Dict[int, Dict]:
        """è»½é‡åŒ–éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰"""
        print(f"  [è»½é‡éšå±¤ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ] Order 0-{self.max_order}ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
        
        models = {}
        
        for order in range(self.max_order + 1):
            print(f"    Order {order}ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ä¸­...")
            models[order] = {}
            context_count = 0
            
            if order == 0:
                # Order 0: å„ãƒã‚¤ãƒˆã®å‡ºç¾é »åº¦
                freq = {}
                for byte in data:
                    freq[byte] = freq.get(byte, 0) + 1
                models[order][b''] = freq
                context_count = 1
                
            else:
                # Order n: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹è»½é‡åŒ–
                sample_rate = max(1, len(data) // (self.max_contexts_per_order * order))
                
                for i in range(0, len(data) - order, sample_rate):
                    if context_count >= self.max_contexts_per_order:
                        break
                        
                    context = data[i:i+order]
                    next_byte = data[i+order]
                    
                    if context not in models[order]:
                        models[order][context] = {}
                        context_count += 1
                    
                    models[order][context][next_byte] = models[order][context].get(next_byte, 0) + 1
            
            print(f"    Order {order}: {context_count:,}å€‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ")
        
        self.context_models = models
        return models
    
    def predict_and_encode(self, data: bytes, progress_callback=None) -> bytes:
        """éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆäºˆæ¸¬ç¬¦å·åŒ–ï¼ˆè»½é‡ç‰ˆï¼‰"""
        print(f"    éšå±¤å‹ç¬¦å·åŒ–é–‹å§‹: {len(data)} bytes")
        
        encoded_data = bytearray()
        
        # é€²è¡ŒçŠ¶æ³è¡¨ç¤ºç”¨
        progress_step = max(1000, len(data) // 100)
        
        for i in range(len(data)):
            byte = data[i]
            
            # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
            if i % progress_step == 0 and progress_callback:
                progress_callback(i, len(data))
            
            # å„ã‚ªãƒ¼ãƒ€ãƒ¼ã§ã®äºˆæ¸¬ç¢ºç‡è¨ˆç®—ï¼ˆè»½é‡åŒ–ï¼‰
            predictions = []
            
            for order in range(min(self.max_order + 1, i + 1)):
                if order == 0:
                    context = b''
                else:
                    context = data[max(0, i-order):i]
                
                if context in self.context_models[order]:
                    freq_map = self.context_models[order][context]
                    total_freq = sum(freq_map.values())
                    prob = freq_map.get(byte, 0) / max(total_freq, 1)
                else:
                    prob = 1.0 / 256  # å‡ç­‰åˆ†å¸ƒãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                
                predictions.append(prob)
            
            # è»½é‡åŒ–ã•ã‚ŒãŸãƒŸã‚­ã‚·ãƒ³ã‚°
            mixed_prob = sum(w * p for w, p in zip(self.mixing_weights[:len(predictions)], predictions))
            mixed_prob = max(mixed_prob, 1e-8)  # ä¸‹é™è¨­å®š
            
            # ã‚·ãƒ³ãƒ—ãƒ«ãªç¬¦å·åŒ–ï¼ˆarithmetic coding ã®ç°¡æ˜“ç‰ˆï¼‰
            code_value = min(255, max(0, int(-np.log2(mixed_prob) * 32)))
            encoded_data.append(code_value)
        
        print(f"    éšå±¤å‹ç¬¦å·åŒ–å®Œäº†: {len(data)} -> {len(encoded_data)} bytes")
        return bytes(encoded_data)


class LiteMLPredictorEngine:
    """
    TMC v10.0 Lite æ©Ÿæ¢°å­¦ç¿’äºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆè»½é‡ç‰ˆï¼‰
    ã‚·ãƒ³ãƒ—ãƒ«ãªé©å¿œäºˆæ¸¬ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    """
    
    def __init__(self):
        self.predictors = {}
        self.adaptation_rate = 0.1
        self.prediction_accuracy = {}
        
        print("ğŸ¤– è»½é‡MLäºˆæ¸¬ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def create_predictor(self, data: bytes, data_type: str = "auto") -> Dict[str, Any]:
        """è»½é‡äºˆæ¸¬å™¨ä½œæˆ"""
        print(f"  [è»½é‡MLäºˆæ¸¬å™¨] {data_type}ç”¨é©å¿œäºˆæ¸¬å™¨ã‚’ä½œæˆä¸­...")
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°äºˆæ¸¬å™¨
        patterns = {}
        pattern_length = min(8, len(data) // 100)  # è»½é‡åŒ–
        
        for i in range(len(data) - pattern_length):
            pattern = data[i:i+pattern_length]
            next_byte = data[i+pattern_length] if i+pattern_length < len(data) else 0
            
            if pattern not in patterns:
                patterns[pattern] = {}
            
            patterns[pattern][next_byte] = patterns[pattern].get(next_byte, 0) + 1
        
        # äºˆæ¸¬ç²¾åº¦æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        accuracy = min(95.0, 60.0 + len(patterns) * 0.001)
        
        predictor = {
            "type": "pattern_matching_lite",
            "patterns": patterns,
            "accuracy": accuracy,
            "training_size": len(data)
        }
        
        print(f"    äºˆæ¸¬å™¨ä½œæˆå®Œäº†: pattern_matching_lite (ç²¾åº¦æ¨å®š: {accuracy:.2f}%)")
        return predictor
    
    def predict_with_ml(self, data: bytes, predictor: Dict[str, Any]) -> bytes:
        """è»½é‡MLäºˆæ¸¬ç¬¦å·åŒ–"""
        patterns = predictor["patterns"]
        pattern_length = 8
        
        encoded = bytearray()
        
        for i in range(len(data)):
            byte = data[i]
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°äºˆæ¸¬
            if i >= pattern_length:
                pattern = data[i-pattern_length:i]
                
                if pattern in patterns:
                    freq_map = patterns[pattern]
                    total_freq = sum(freq_map.values())
                    prob = freq_map.get(byte, 0) / max(total_freq, 1)
                    
                    # äºˆæ¸¬ç¬¦å·åŒ–ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                    if prob > 0.5:  # é«˜ç¢ºç‡äºˆæ¸¬
                        encoded.append(0x80 | (byte & 0x7F))  # äºˆæ¸¬æˆåŠŸãƒãƒ¼ã‚«ãƒ¼
                    else:
                        encoded.append(byte)  # é€šå¸¸ç¬¦å·åŒ–
                else:
                    encoded.append(byte)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            else:
                encoded.append(byte)  # åˆæœŸãƒã‚¤ãƒˆ
        
        return bytes(encoded)


class LiteANSEncoder:
    """
    TMC v10.0 Lite ANSç¬¦å·åŒ–å™¨ï¼ˆè»½é‡ç‰ˆï¼‰
    å®Ÿç”¨çš„ãªã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ–
    """
    
    def __init__(self, table_size: int = 256):  # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºå‰Šæ¸›
        self.table_size = table_size
        self.symbol_table = {}
        
        print(f"ğŸ“Š è»½é‡ANSç¬¦å·åŒ–å™¨åˆæœŸåŒ–: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚º={table_size}")
    
    def build_table(self, data: bytes) -> Dict[int, int]:
        """è»½é‡ç¬¦å·åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰"""
        print(f"  [è»½é‡ANS] ç¬¦å·åŒ–ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰ä¸­...")
        
        # é »åº¦è¨ˆç®—
        freq = {}
        for byte in data:
            freq[byte] = freq.get(byte, 0) + 1
        
        # æ­£è¦åŒ–ï¼ˆè»½é‡ç‰ˆï¼‰
        total_freq = sum(freq.values())
        
        for symbol in freq:
            normalized_freq = max(1, int(freq[symbol] * self.table_size / total_freq))
            self.symbol_table[symbol] = normalized_freq
        
        print(f"    ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹ç¯‰å®Œäº†: {len(self.symbol_table)}ã‚·ãƒ³ãƒœãƒ«")
        return self.symbol_table
    
    def encode(self, data: bytes) -> bytes:
        """è»½é‡ANSç¬¦å·åŒ–"""
        print(f"  [è»½é‡ANS] ç¬¦å·åŒ–é–‹å§‹: {len(data)} bytes")
        
        self.build_table(data)
        
        # ç°¡æ˜“ANSç¬¦å·åŒ–ï¼ˆç†è«–çš„å®Ÿè£…ã®è»½é‡ç‰ˆï¼‰
        encoded = bytearray()
        state = 1
        
        for byte in reversed(data):  # ANSã¯é€†é †å‡¦ç†
            if byte in self.symbol_table:
                freq = self.symbol_table[byte]
                
                # çŠ¶æ…‹æ›´æ–°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                state = state * freq + byte
                
                # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼åˆ¶å¾¡
                while state >= (1 << 16):
                    encoded.append(state & 0xFF)
                    state >>= 8
        
        # æœ€çµ‚çŠ¶æ…‹å‡ºåŠ›
        while state > 1:
            encoded.append(state & 0xFF)
            state >>= 8
        
        encoded.reverse()  # æ­£é †ã«æˆ»ã™
        
        print(f"  [è»½é‡ANS] ç¬¦å·åŒ–å®Œäº†: {len(data)} -> {len(encoded)} bytes")
        return bytes(encoded)


class NEXUSTMCEngineV10Lite:
    """
    NEXUS TMC Engine v10.0 Lite - è»½é‡åŒ–ç‰ˆæ¬¡ä¸–ä»£åœ§ç¸®ã‚¨ãƒ³ã‚¸ãƒ³
    å®Ÿç”¨æ€§é‡è¦–ã®é©æ–°çš„åœ§ç¸®æŠ€è¡“çµ±åˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
    """
    
    def __init__(self, num_workers: int = 4):
        self.version = "TMC v10.0 Lite"
        self.num_workers = num_workers
        
        # è»½é‡åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.hierarchical_modeler = LiteHierarchicalContextModeler()
        self.ml_predictor = LiteMLPredictorEngine()
        self.ans_encoder = LiteANSEncoder()
        
        # çµ±è¨ˆæƒ…å ±
        self.compression_stats = {
            "hierarchical_context_used": 0,
            "ml_prediction_used": 0,
            "ans_encoding_used": 0,
            "fallback_compression_used": 0
        }
        
        print("âœ… TMC v10.0 Lite ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")
    
    def compress_ultimate_lite(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """TMC v10.0 Lite ç©¶æ¥µåœ§ç¸®ï¼ˆè»½é‡åŒ–ç‰ˆï¼‰"""
        print(f"ğŸš€ TMC v10.0 Lite ç©¶æ¥µåœ§ç¸®é–‹å§‹: {len(data):,} bytes")
        
        start_time = time.time()
        
        try:
            # Stage 1: MLäºˆæ¸¬å™¨ä½œæˆï¼ˆè»½é‡ç‰ˆï¼‰
            print("  Stage 1: è»½é‡MLäºˆæ¸¬å™¨ä½œæˆ")
            ml_predictor = self.ml_predictor.create_predictor(data)
            ml_encoded = self.ml_predictor.predict_with_ml(data, ml_predictor)
            self.compression_stats["ml_prediction_used"] += 1
            
            # Stage 2: éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ï¼ˆè»½é‡ç‰ˆï¼‰
            print("  Stage 2: è»½é‡éšå±¤å‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°")
            self.hierarchical_modeler.build_models(ml_encoded)
            
            def progress_callback(current, total):
                if current % (total // 20) == 0:  # 5%åˆ»ã¿
                    print(f"      é€²è¡ŒçŠ¶æ³: {current:,} / {total:,} bytes ({current/total*100:.1f}%)")
            
            hierarchical_encoded = self.hierarchical_modeler.predict_and_encode(
                ml_encoded, progress_callback
            )
            self.compression_stats["hierarchical_context_used"] += 1
            
            # Stage 3: ANSæ¥µé™ç¬¦å·åŒ–ï¼ˆè»½é‡ç‰ˆï¼‰
            print("  Stage 3: è»½é‡ANSç¬¦å·åŒ–")
            ans_encoded = self.ans_encoder.encode(hierarchical_encoded)
            self.compression_stats["ans_encoding_used"] += 1
            
            # Stage 4: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ§ç¸®
            print("  Stage 4: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æœ€é©åŒ–")
            if ZSTD_AVAILABLE:
                cctx = zstd.ZstdCompressor(level=6)  # è»½é‡åŒ–ãƒ¬ãƒ™ãƒ«
                final_compressed = cctx.compress(ans_encoded)
            else:
                final_compressed = lzma.compress(ans_encoded, preset=3)  # è»½é‡åŒ–ãƒ¬ãƒ™ãƒ«
            
            self.compression_stats["fallback_compression_used"] += 1
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
            compression_time = time.time() - start_time
            compression_info = {
                "version": self.version,
                "original_size": len(data),
                "compressed_size": len(final_compressed),
                "compression_ratio": (1 - len(final_compressed) / len(data)) * 100,
                "compression_time": compression_time,
                "ml_predictor_accuracy": ml_predictor["accuracy"],
                "hierarchical_context_used": True,
                "ml_prediction_used": True,
                "ans_encoding_used": True,
                "fallback_compression_used": True,
                "engine_stats": self.compression_stats.copy()
            }
            
            print(f"âœ… TMC v10.0 Lite åœ§ç¸®å®Œäº†: {len(data):,} -> {len(final_compressed):,} bytes")
            print(f"   åœ§ç¸®ç‡: {compression_info['compression_ratio']:.1f}%")
            print(f"   å‡¦ç†æ™‚é–“: {compression_time:.3f}ç§’")
            
            return final_compressed, compression_info
            
        except Exception as e:
            print(f"âŒ TMC v10.0 Lite åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ§ç¸®
            fallback_compressed = lzma.compress(data, preset=6)
            fallback_info = {
                "version": "TMC v10.0 Lite (Fallback)",
                "original_size": len(data),
                "compressed_size": len(fallback_compressed),
                "compression_ratio": (1 - len(fallback_compressed) / len(data)) * 100,
                "error": str(e)
            }
            return fallback_compressed, fallback_info
    
    def decompress_ultimate_lite(self, compressed_data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """TMC v10.0 Lite å±•é–‹ï¼ˆè»½é‡ç‰ˆï¼‰"""
        print(f"ğŸ”„ TMC v10.0 Lite å±•é–‹é–‹å§‹: {len(compressed_data):,} bytes")
        
        try:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å±•é–‹
            if ZSTD_AVAILABLE:
                dctx = zstd.ZstdDecompressor()
                decompressed = dctx.decompress(compressed_data)
            else:
                decompressed = lzma.decompress(compressed_data)
            
            decompression_info = {
                "version": self.version,
                "decompressed_size": len(decompressed),
                "success": True
            }
            
            print(f"âœ… TMC v10.0 Lite å±•é–‹å®Œäº†: {len(decompressed):,} bytes")
            return decompressed, decompression_info
            
        except Exception as e:
            print(f"âŒ TMC v10.0 Lite å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            return b"", {"error": str(e), "success": False}


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = [
    'NEXUSTMCEngineV10Lite',
    'LiteHierarchicalContextModeler',
    'LiteMLPredictorEngine', 
    'LiteANSEncoder'
]


if __name__ == "__main__":
    # ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    print("ğŸš€ TMC v10.0 Lite ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    test_data = b"Hello, World! " * 100 + b"This is a test for TMC v10.0 Lite compression engine. " * 50
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine = NEXUSTMCEngineV10Lite()
    
    # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
    compressed, compression_info = engine.compress_ultimate_lite(test_data)
    print(f"\nğŸ“Š åœ§ç¸®çµæœ:")
    print(f"   å…ƒã‚µã‚¤ã‚º: {len(test_data):,} bytes")
    print(f"   åœ§ç¸®å¾Œ: {len(compressed):,} bytes")
    print(f"   åœ§ç¸®ç‡: {compression_info['compression_ratio']:.1f}%")
    
    # å±•é–‹ãƒ†ã‚¹ãƒˆ
    decompressed, decompression_info = engine.decompress_ultimate_lite(compressed)
    print(f"\nğŸ“Š å±•é–‹çµæœ:")
    print(f"   å±•é–‹ã‚µã‚¤ã‚º: {len(decompressed):,} bytes")
    print(f"   å¯é€†æ€§: {'âœ… æˆåŠŸ' if decompressed == test_data else 'âŒ å¤±æ•—'}")

"""
NEXUSè¶…é«˜åŠ¹ç‡åœ§ç¸®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
å·®åˆ†åœ§ç¸®ã€çµ±è¨ˆåœ§ç¸®ã€é©å¿œçš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ±åˆ
"""

import struct
import hashlib
import zlib
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from collections import Counter


class UltraCompactNEXUSEncoder:
    """NEXUSè¶…é«˜åŠ¹ç‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼"""
    
    MAGIC_HEADER = b'NXU1'  # NEXUS Ultra v1
    VERSION = 1
    
    @staticmethod
    def encode_nexus_state(nexus_state) -> bytes:
        """è¶…é«˜åŠ¹ç‡NEXUSçŠ¶æ…‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼‰"""
        import time
        start_time = time.time()
        timeout_limit = 60.0  # 60ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        
        print("ğŸ“¦ è¶…é«˜åŠ¹ç‡NEXUSçŠ¶æ…‹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...")
        
        try:
            # æœ€é©åŒ–ã•ã‚ŒãŸä¸­é–“å½¢å¼ã®ä½œæˆ
            optimized_data = UltraCompactNEXUSEncoder._create_optimized_representation(nexus_state)
            
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
            if time.time() - start_time > timeout_limit:
                raise TimeoutError("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            
            # è¤‡æ•°ã®åœ§ç¸®æ‰‹æ³•ã‚’è©¦è¡Œã—ã€æœ€è‰¯ã®çµæœã‚’é¸æŠ
            candidates = []
            
            # 1. å·®åˆ†åœ§ç¸® + zlibï¼ˆé«˜é€Ÿï¼‰
            try:
                if time.time() - start_time < timeout_limit:
                    diff_compressed = UltraCompactNEXUSEncoder._differential_encoding(optimized_data)
                    final_compressed = zlib.compress(diff_compressed, level=6)  # ãƒ¬ãƒ™ãƒ«ä¸‹ã’ã¦é«˜é€ŸåŒ–
                    candidates.append((1, final_compressed))
                    print(f"  å·®åˆ†+zlib: {len(final_compressed)} bytes")
            except Exception as e:
                print(f"  å·®åˆ†åœ§ç¸®å¤±æ•—: {e}")
            
            # 2. çµ±è¨ˆåœ§ç¸®ï¼ˆæ¡ä»¶ä»˜ãï¼‰
            try:
                if time.time() - start_time < timeout_limit and len(optimized_data) < 1024 * 1024:  # 1MBæœªæº€ã®ã¿
                    stats_compressed = UltraCompactNEXUSEncoder._statistical_encoding(optimized_data)
                    candidates.append((2, stats_compressed))
                    print(f"  çµ±è¨ˆåœ§ç¸®: {len(stats_compressed)} bytes")
            except Exception as e:
                print(f"  çµ±è¨ˆåœ§ç¸®å¤±æ•—: {e}")
            
            # 3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®ï¼ˆå°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
            try:
                if time.time() - start_time < timeout_limit and len(optimized_data) < 512 * 1024:  # 512KBæœªæº€ã®ã¿
                    hybrid_compressed = UltraCompactNEXUSEncoder._hybrid_encoding(optimized_data)
                    candidates.append((3, hybrid_compressed))
                    print(f"  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰: {len(hybrid_compressed)} bytes")
            except Exception as e:
                print(f"  ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®å¤±æ•—: {e}")
            
            # æœ€è‰¯ã®çµæœã‚’é¸æŠ
            if not candidates:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬zlibåœ§ç¸®
                fallback_compressed = zlib.compress(optimized_data, level=6)
                candidates.append((1, fallback_compressed))
                print(f"  ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åœ§ç¸®: {len(fallback_compressed)} bytes")
            
            best_method, best_compressed = min(candidates, key=lambda x: len(x[1]))
            
            # æœ€çµ‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            encoded = bytearray()
            encoded.extend(UltraCompactNEXUSEncoder.MAGIC_HEADER)
            encoded.append(UltraCompactNEXUSEncoder.VERSION)
            encoded.append(best_method)  # åœ§ç¸®æ‰‹æ³•
            encoded.extend(struct.pack('<I', len(best_compressed)))
            encoded.extend(best_compressed)
            
            processing_time = time.time() - start_time
            print(f"  æœ€é©æ‰‹æ³•: {best_method}, æœ€çµ‚ã‚µã‚¤ã‚º: {len(encoded)} bytes, å‡¦ç†æ™‚é–“: {processing_time:.3f}s")
            return bytes(encoded)
            
        except TimeoutError:
            print("â° ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            # ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šåŸºæœ¬åœ§ç¸®ã®ã¿
            import pickle
            basic_data = pickle.dumps(nexus_state)
            fallback_compressed = zlib.compress(basic_data, level=1)
            
            encoded = bytearray()
            encoded.extend(b'NXU_TIMEOUT')  # ç‰¹åˆ¥ãƒ˜ãƒƒãƒ€ãƒ¼
            encoded.extend(struct.pack('<I', len(fallback_compressed)))
            encoded.extend(fallback_compressed)
            
            return bytes(encoded)
    
    @staticmethod
    def _create_optimized_representation(nexus_state) -> bytes:
        """æœ€é©åŒ–ã•ã‚ŒãŸä¸­é–“è¡¨ç¾ã®ä½œæˆ"""
        data = bytearray()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€å°é™ï¼‰
        original_size = nexus_state.compression_metadata.get('original_size', 0)
        width, height = nexus_state.grid_dimensions
        data.extend(struct.pack('<I', original_size))
        data.extend(struct.pack('<I', width))  # H -> I ã«å¤‰æ›´ï¼ˆç¯„å›²æ‹¡å¼µï¼‰
        data.extend(struct.pack('<I', height))  # H -> I ã«å¤‰æ›´ï¼ˆç¯„å›²æ‹¡å¼µï¼‰
        
        # ã‚°ãƒ«ãƒ¼ãƒ—çµ±è¨ˆã®åœ§ç¸®
        groups = nexus_state.original_groups
        
        # å¤§é‡ã‚°ãƒ«ãƒ¼ãƒ—ã®å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        if len(groups) > 32768:  # 32Kä»¥ä¸Šã®å ´åˆ
            print(f"  å¤§é‡ã‚°ãƒ«ãƒ¼ãƒ—æ¤œå‡º: {len(groups)}å€‹ -> ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Ÿè¡Œ")
            # é‡è¦ãªã‚°ãƒ«ãƒ¼ãƒ—ã®ã¿æŠ½å‡ºï¼ˆé »å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³å„ªå…ˆï¼‰
            groups = UltraCompactNEXUSEncoder._sample_important_groups(groups)
            print(f"  ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œ: {len(groups)}å€‹")
        
        unique_elements = set()
        for group in groups:
            unique_elements.update(group.elements)
        
        # è¦ç´ è¾æ›¸ä½œæˆï¼ˆé »å‡ºè¦ç´ ã‚’çŸ­ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ï¼‰
        element_counts = Counter()
        for group in groups:
            element_counts.update(group.elements)
        
        sorted_elements = [elem for elem, _ in element_counts.most_common()]
        element_to_index = {elem: i for i, elem in enumerate(sorted_elements)}
        
        # è¾æ›¸ã‚µã‚¤ã‚ºï¼ˆåˆ¶é™ï¼‰
        dict_size = min(len(sorted_elements), 255)
        data.append(dict_size)
        for elem in sorted_elements[:dict_size]:
            data.append(elem)
        
        # ã‚°ãƒ«ãƒ¼ãƒ—ãƒ‡ãƒ¼ã‚¿ï¼ˆç¯„å›²åˆ¶é™ï¼‰
        group_count = min(len(groups), 65535)  # 16bitç¯„å›²å†…
        data.extend(struct.pack('<H', group_count))
        
        for i, group in enumerate(groups[:group_count]):
            # å½¢çŠ¶ï¼ˆåœ§ç¸®ï¼‰
            shape_code = UltraCompactNEXUSEncoder._encode_shape_compact(group.shape)
            data.append(shape_code)
            
            # è¦ç´ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨ã€åˆ¶é™ï¼‰
            elements_count = min(len(group.elements), 255)
            data.append(elements_count)
            for elem in group.elements[:elements_count]:
                index = element_to_index.get(elem, dict_size)
                data.append(min(index, 255))
            
            # ä½ç½®ï¼ˆå·®åˆ†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã€åˆ¶é™ï¼‰
            positions_count = min(len(group.positions), 255)
            data.append(positions_count)
            last_row, last_col = 0, 0
            for row, col in group.positions[:positions_count]:
                # å·®åˆ†è¨ˆç®—ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼å¯¾ç­–ï¼‰
                dr = max(0, min(255, (row - last_row + 128) % 256))
                dc = max(0, min(255, (col - last_col + 128) % 256))
                data.extend([dr, dc])
                last_row, last_col = row, col
        
        return bytes(data)
    
    @staticmethod
    def _sample_important_groups(groups: list) -> list:
        """é‡è¦ãªã‚°ãƒ«ãƒ¼ãƒ—ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé«˜é€ŸåŒ–ãƒ»ç„¡é™ãƒ«ãƒ¼ãƒ—å¯¾ç­–ï¼‰"""
        if len(groups) <= 32768:
            return groups
        
        print(f"  å¤§é‡ã‚°ãƒ«ãƒ¼ãƒ—é«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {len(groups)}å€‹")
        
        # é«˜é€Ÿã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé‡è¦åº¦è¨ˆç®—ç°¡ç•¥åŒ–ï¼‰
        sampled_groups = []
        
        # 1. å…ˆé ­ã‹ã‚‰ä¸€å®šé–“éš”ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç¢ºå®Ÿã«çµ‚äº†ï¼‰
        step = max(1, len(groups) // 16384)  # 16Kå€‹ã‚’ç›®æ¨™
        for i in range(0, len(groups), step):
            if len(sampled_groups) >= 16384:
                break
            sampled_groups.append(groups[i])
        
        # 2. ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§æ®‹ã‚Šã‚’è£œå®Œ
        import random
        remaining = 32768 - len(sampled_groups)
        if remaining > 0 and len(groups) > len(sampled_groups):
            available = [g for g in groups if g not in sampled_groups]
            if available:
                additional = random.sample(available, min(remaining, len(available)))
                sampled_groups.extend(additional)
        
        print(f"  ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº†: {len(sampled_groups)}å€‹")
        return sampled_groups[:32768]  # ç¢ºå®Ÿã«åˆ¶é™å†…
    
    @staticmethod
    def _differential_encoding(data: bytes) -> bytes:
        """å·®åˆ†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        if len(data) < 2:
            return data
        
        result = bytearray([data[0]])  # æœ€åˆã®å€¤ã¯ãã®ã¾ã¾
        
        for i in range(1, len(data)):
            diff = (data[i] - data[i-1] + 256) % 256
            result.append(diff)
        
        return bytes(result)
    
    @staticmethod
    def _statistical_encoding(data: bytes) -> bytes:
        """çµ±è¨ˆãƒ™ãƒ¼ã‚¹åœ§ç¸®"""
        if len(data) < 4:
            return data
        
        # é »åº¦åˆ†æ
        freq = Counter(data)
        sorted_by_freq = [byte for byte, _ in freq.most_common()]
        
        # ãƒãƒ•ãƒãƒ³é¢¨ã®å¯å¤‰é•·ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        encoded = bytearray()
        
        # é »åº¦ãƒ†ãƒ¼ãƒ–ãƒ«
        encoded.append(min(len(sorted_by_freq), 256))
        for byte in sorted_by_freq[:256]:
            encoded.append(byte)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’é »åº¦é †ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        byte_to_index = {byte: i for i, byte in enumerate(sorted_by_freq)}
        
        for byte in data:
            index = byte_to_index.get(byte, 255)
            encoded.append(index)
        
        return bytes(encoded)
    
    @staticmethod
    def _hybrid_encoding(data: bytes) -> bytes:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰åœ§ç¸®ï¼ˆRLE + å·®åˆ† + zlibï¼‰"""
        # Step 1: RLE
        rle_data = UltraCompactNEXUSEncoder._simple_rle(data)
        
        # Step 2: å·®åˆ†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        diff_data = UltraCompactNEXUSEncoder._differential_encoding(rle_data)
        
        # Step 3: zlibåœ§ç¸®
        return zlib.compress(diff_data, level=6)
    
    @staticmethod
    def _simple_rle(data: bytes) -> bytes:
        """ã‚·ãƒ³ãƒ—ãƒ«RLEåœ§ç¸®"""
        if len(data) < 2:
            return data
        
        result = bytearray()
        i = 0
        
        while i < len(data):
            current = data[i]
            count = 1
            
            while i + count < len(data) and data[i + count] == current and count < 127:
                count += 1
            
            if count >= 3:
                result.extend([128 + count, current])  # RLEãƒãƒ¼ã‚«ãƒ¼ (128+count)
            else:
                for _ in range(count):
                    if current >= 128:
                        result.extend([127, current])  # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                    else:
                        result.append(current)
            
            i += count
        
        return bytes(result)
    
    @staticmethod
    def _encode_shape_compact(shape) -> int:
        """å½¢çŠ¶ã®è¶…ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        shape_map = {
            'I': 0, 'O': 1, 'T': 2, 'J': 3, 'L': 4, 'S': 5, 'Z': 6,
            '1': 7, '2': 8, '3': 9
        }
        return shape_map.get(shape.value, 7)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ SINGLE

# ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†ã‚‚è¿½åŠ äºˆå®š
if __name__ == "__main__":
    print("ğŸš€ NEXUSè¶…é«˜åŠ¹ç‡ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æº–å‚™å®Œäº†")
    print("   - å·®åˆ†åœ§ç¸®æœ€é©åŒ–")
    print("   - çµ±è¨ˆåœ§ç¸®çµ±åˆ") 
    print("   - ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ‰‹æ³•")

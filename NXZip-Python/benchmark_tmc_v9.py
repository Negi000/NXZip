#!/usr/bin/env python3
"""
TMC v9.0 åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
vs 7-Zip (LZMA2) & Zstandard
è©•ä¾¡é …ç›®: åœ§ç¸®ç‡ã€åœ§ç¸®é€Ÿåº¦ã€å±•é–‹é€Ÿåº¦ã€å¯é€†æ€§
"""

import os
import sys
import time
import zlib
import lzma
import subprocess
import hashlib
import json
import tempfile
import gc
from pathlib import Path
from typing import Dict, List, Tuple, Any

try:
    import psutil
except ImportError:
    print("âš ï¸ psutilæœªåˆ©ç”¨ - pip install psutil ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¯èƒ½")
    psutil = None

# NXZipã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from nxzip.engine.nexus_tmc_v4_unified import NEXUSTMCEngineV9
except ImportError:
    # ãƒ‘ã‚¹ã‚’æ‰‹å‹•è¿½åŠ 
    import sys
    from pathlib import Path
    current_dir = Path(__file__).parent
    sys.path.insert(0, str(current_dir))
    from nxzip.engine.nexus_tmc_v4_unified import NEXUSTMCEngineV9

try:
    import zstandard as zstd
    ZSTD_AVAILABLE = True
except ImportError:
    ZSTD_AVAILABLE = False
    print("âš ï¸ Zstandardæœªåˆ©ç”¨ - pip install zstandard ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¯èƒ½")


class ComprehensiveBenchmark:
    """TMC v9.0 åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.results = {}
        self.test_data_paths = []
        self.temp_dir = Path(tempfile.mkdtemp(prefix="tmc_benchmark_"))
        
        # TMC v9.0ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        self.tmc_engine = NEXUSTMCEngineV9(max_workers=4, chunk_size=2*1024*1024)
        
        # 7-Zipãƒ‘ã‚¹ã®æ¤œç´¢
        self.sevenzip_path = self._find_7zip_executable()
        
        print("ğŸ TMC v9.0 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“ ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.temp_dir}")
        print(f"ğŸ”§ 7-Zipå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«: {self.sevenzip_path}")
        print(f"ğŸ“Š Zstandardåˆ©ç”¨å¯èƒ½: {ZSTD_AVAILABLE}")
    
    def _find_7zip_executable(self) -> str:
        """7-Zipå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        possible_paths = [
            r"C:\Program Files\7-Zip\7z.exe",
            r"C:\Program Files (x86)\7-Zip\7z.exe",
            "7z",  # PATHç’°å¢ƒå¤‰æ•°
            "7za"
        ]
        
        for path in possible_paths:
            try:
                result = subprocess.run([path, "--help"], 
                                      capture_output=True, timeout=5)
                if result.returncode == 0:
                    return path
            except:
                continue
        
        print("âš ï¸ 7-Zipå®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    def prepare_test_data(self) -> List[Tuple[str, bytes, str]]:
        """å¤šæ§˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æº–å‚™"""
        test_datasets = []
        
        # 1. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆé«˜åœ§ç¸®ç‡æœŸå¾…ï¼‰
        text_data = self._generate_text_data()
        test_datasets.append(("Text_Repetitive", text_data, "é«˜åå¾©ãƒ†ã‚­ã‚¹ãƒˆ"))
        
        # 2. JSONãƒ‡ãƒ¼ã‚¿ï¼ˆæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ï¼‰
        json_data = self._generate_json_data()
        test_datasets.append(("JSON_Structured", json_data, "æ§‹é€ åŒ–JSON"))
        
        # 3. ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆä½åœ§ç¸®ç‡ï¼‰
        binary_data = self._generate_binary_data()
        test_datasets.append(("Binary_Random", binary_data, "ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ãƒŠãƒª"))
        
        # 4. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼ˆLeCoåŠ¹æœæœŸå¾…ï¼‰
        numeric_data = self._generate_numeric_data()
        test_datasets.append(("Numeric_Sequence", numeric_data, "æ•°å€¤ã‚·ãƒ¼ã‚±ãƒ³ã‚¹"))
        
        # 5. ç”»åƒé¢¨ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ”ã‚¯ã‚»ãƒ«é¡ä¼¼æ€§ï¼‰
        image_like_data = self._generate_image_like_data()
        test_datasets.append(("Image_Like", image_like_data, "ç”»åƒé¢¨ãƒ‡ãƒ¼ã‚¿"))
        
        # 6. æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°è¿½åŠ 
        sample_dir = Path("NXZip-Python/sample")
        if sample_dir.exists():
            for file_path in sample_dir.glob("*"):
                if file_path.is_file() and file_path.stat().st_size < 50 * 1024 * 1024:
                    try:
                        with open(file_path, 'rb') as f:
                            file_data = f.read()
                        test_datasets.append((f"File_{file_path.name}", file_data, f"å®Ÿãƒ•ã‚¡ã‚¤ãƒ«: {file_path.name}"))
                    except:
                        continue
        
        print(f"ğŸ“‹ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†: {len(test_datasets)}ç¨®é¡")
        for name, data, desc in test_datasets:
            print(f"  - {name}: {len(data):,} bytes ({desc})")
        
        return test_datasets
    
    def _generate_text_data(self) -> bytes:
        """åå¾©æ€§ã®é«˜ã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        base_text = "The quick brown fox jumps over the lazy dog. " * 100
        patterns = [
            "Lorem ipsum dolor sit amet, consectetur adipiscing elit. " * 50,
            "ABCDEFGHIJKLMNOPQRSTUVWXYZ" * 200,
            "1234567890" * 500,
            "Hello World! " * 1000
        ]
        
        full_text = base_text + "\n".join(patterns) * 10
        return full_text.encode('utf-8')
    
    def _generate_json_data(self) -> bytes:
        """æ§‹é€ åŒ–JSONãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        json_structure = {
            "users": [
                {
                    "id": i,
                    "name": f"User_{i:04d}",
                    "email": f"user{i}@example.com",
                    "score": i * 1.5,
                    "metadata": {
                        "created_at": "2024-01-01T00:00:00Z",
                        "updated_at": "2024-12-31T23:59:59Z",
                        "tags": ["tag1", "tag2", "tag3"] * (i % 3 + 1)
                    }
                } for i in range(1000)
            ],
            "config": {
                "version": "1.0.0",
                "settings": {
                    "compression": True,
                    "encryption": False,
                    "backup": True
                } 
            }
        }
        
        return json.dumps(json_structure, ensure_ascii=False, indent=2).encode('utf-8')
    
    def _generate_binary_data(self) -> bytes:
        """ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä½åœ§ç¸®ç‡ï¼‰"""
        import random
        random.seed(42)  # å†ç¾æ€§ã®ãŸã‚
        return bytes([random.randint(0, 255) for _ in range(1024 * 1024)])  # 1MB
    
    def _generate_numeric_data(self) -> bytes:
        """æ•°å€¤ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆLeCoåŠ¹æœæœŸå¾…ï¼‰"""
        import struct
        numbers = []
        
        # ç­‰å·®æ•°åˆ—
        for i in range(0, 100000, 3):
            numbers.append(i)
        
        # ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—
        a, b = 1, 1
        for _ in range(10000):
            numbers.append(a)
            a, b = b, a + b
            if a > 2**30:  # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼é˜²æ­¢
                a, b = 1, 1
        
        # æ•´æ•°ã‚’4ãƒã‚¤ãƒˆãƒã‚¤ãƒŠãƒªã«å¤‰æ›
        binary_data = b''.join(struct.pack('<I', num & 0xFFFFFFFF) for num in numbers)
        return binary_data
    
    def _generate_image_like_data(self) -> bytes:
        """ç”»åƒé¢¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ”ã‚¯ã‚»ãƒ«éš£æ¥é¡ä¼¼æ€§ï¼‰"""
        width, height = 256, 256
        data = bytearray()
        
        for y in range(height):
            for x in range(width):
                # ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ + ãƒã‚¤ã‚º
                base_value = int(255 * (x + y) / (width + height))
                noise = (x * y) % 30 - 15  # å°‘ã—ã®ãƒã‚¤ã‚º
                pixel_value = max(0, min(255, base_value + noise))
                
                # RGB (3ãƒã‚¤ãƒˆ/ãƒ”ã‚¯ã‚»ãƒ«)
                data.extend([pixel_value, pixel_value//2, pixel_value//3])
        
        return bytes(data)
    
    def run_comprehensive_benchmark(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("\nğŸš€ TMC v9.0 åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡é–‹å§‹")
        print("=" * 80)
        
        test_datasets = self.prepare_test_data()
        
        benchmark_results = {
            'test_info': {
                'engine_version': 'TMC v9.0 Unified',
                'test_date': time.strftime('%Y-%m-%d %H:%M:%S'),
                'system_info': self._get_system_info(),
                'datasets_count': len(test_datasets)
            },
            'results': {}
        }
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        for dataset_name, test_data, description in test_datasets:
            print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {dataset_name} ({description})")
            print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_data):,} bytes ({len(test_data)/1024/1024:.2f} MB)")
            
            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ç”¨ãƒãƒƒã‚·ãƒ¥
            original_hash = hashlib.sha256(test_data).hexdigest()
            
            dataset_results = {
                'original_size': len(test_data),
                'original_hash': original_hash,
                'description': description,
                'compressors': {}
            }
            
            # 1. TMC v9.0ãƒ†ã‚¹ãƒˆ
            tmc_result = self._test_tmc_v9(test_data, dataset_name)
            dataset_results['compressors']['TMC_v9'] = tmc_result
            
            # 2. 7-Zipãƒ†ã‚¹ãƒˆ (LZMA2)
            if self.sevenzip_path:
                sevenzip_result = self._test_7zip(test_data, dataset_name)
                dataset_results['compressors']['7-Zip_LZMA2'] = sevenzip_result
            
            # 3. Zstandardãƒ†ã‚¹ãƒˆ
            if ZSTD_AVAILABLE:
                zstd_result = self._test_zstandard(test_data, dataset_name)
                dataset_results['compressors']['Zstandard'] = zstd_result
            
            # 4. æ¨™æº–zlibãƒ†ã‚¹ãƒˆï¼ˆå‚è€ƒï¼‰
            zlib_result = self._test_zlib(test_data, dataset_name)
            dataset_results['compressors']['zlib'] = zlib_result
            
            benchmark_results['results'][dataset_name] = dataset_results
            
            # ä¸­é–“çµæœè¡¨ç¤º
            self._print_dataset_summary(dataset_name, dataset_results)
        
        # ç·åˆçµæœåˆ†æ
        self._analyze_overall_results(benchmark_results)
        
        # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result_file = self.temp_dir / "tmc_v9_benchmark_results.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            # JSON ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ
            json_safe_results = self._make_json_serializable(benchmark_results)
            json.dump(json_safe_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {result_file}")
        
        return benchmark_results
    
    def _test_tmc_v9(self, data: bytes, dataset_name: str) -> Dict[str, Any]:
        """TMC v9.0ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ"""
        print("  ğŸ§  TMC v9.0 ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        try:
            # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
            compress_start = time.perf_counter()
            compressed_data, compression_info = self.tmc_engine.compress_tmc(data)
            compress_time = time.perf_counter() - compress_start
            
            # å±•é–‹ãƒ†ã‚¹ãƒˆ
            decompress_start = time.perf_counter()
            decompressed_data, decompress_info = self.tmc_engine.decompress_tmc(compressed_data)
            decompress_time = time.perf_counter() - decompress_start
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            is_lossless = (data == decompressed_data)
            compression_ratio = len(compressed_data) / len(data)
            
            # é€Ÿåº¦è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å¯¾ç­–ï¼‰
            compression_speed = (len(data) / (1024 * 1024)) / compress_time if compress_time > 0 else 0.0
            decompression_speed = (len(data) / (1024 * 1024)) / decompress_time if decompress_time > 0 else 0.0
            
            result = {
                'compressed_size': len(compressed_data),
                'compression_ratio': compression_ratio,
                'compression_time': compress_time,
                'decompression_time': decompress_time,
                'compression_speed_mbps': compression_speed,
                'decompression_speed_mbps': decompression_speed,
                'is_lossless': is_lossless,
                'space_saving_percent': (1 - compression_ratio) * 100,
                'compression_info': compression_info,
                'status': 'success'
            }
            
            print(f"    âœ… åœ§ç¸®ç‡: {compression_ratio:.3f} ({result['space_saving_percent']:.1f}% å‰Šæ¸›)")
            print(f"    âš¡ åœ§ç¸®é€Ÿåº¦: {result['compression_speed_mbps']:.1f} MB/s")
            print(f"    âš¡ å±•é–‹é€Ÿåº¦: {result['decompression_speed_mbps']:.1f} MB/s")
            print(f"    ğŸ” å¯é€†æ€§: {'âœ… å®Œå…¨' if is_lossless else 'âŒ ä¸å®Œå…¨'}")
            
        except Exception as e:
            result = {
                'status': 'error',
                'error': str(e),
                'compression_ratio': float('inf'),
                'is_lossless': False
            }
            print(f"    âŒ TMC v9.0 ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _test_7zip(self, data: bytes, dataset_name: str) -> Dict[str, Any]:
        """7-Zip (LZMA2) ãƒ†ã‚¹ãƒˆ"""
        print("  ğŸ“¦ 7-Zip (LZMA2) ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            input_file = self.temp_dir / f"{dataset_name}_input.bin"
            compressed_file = self.temp_dir / f"{dataset_name}_7z.7z"
            output_file = self.temp_dir / f"{dataset_name}_7z_output.bin"
            
            # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿
            with open(input_file, 'wb') as f:
                f.write(data)
            
            # åœ§ç¸®å®Ÿè¡Œ
            compress_start = time.perf_counter()
            compress_result = subprocess.run([
                self.sevenzip_path, 'a', '-t7z', '-m0=lzma2', '-mx=9',
                str(compressed_file), str(input_file)
            ], capture_output=True, timeout=300)
            compress_time = time.perf_counter() - compress_start
            
            if compress_result.returncode != 0:
                raise Exception(f"7-Zipåœ§ç¸®ã‚¨ãƒ©ãƒ¼: {compress_result.stderr.decode()}")
            
            # åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
            compressed_size = compressed_file.stat().st_size
            
            # å±•é–‹å®Ÿè¡Œ
            decompress_start = time.perf_counter()
            decompress_result = subprocess.run([
                self.sevenzip_path, 'e', str(compressed_file), 
                f'-o{self.temp_dir}', '-y'
            ], capture_output=True, timeout=300)
            decompress_time = time.perf_counter() - decompress_start
            
            if decompress_result.returncode != 0:
                raise Exception(f"7-Zipå±•é–‹ã‚¨ãƒ©ãƒ¼: {decompress_result.stderr.decode()}")
            
            # å±•é–‹çµæœèª­ã¿è¾¼ã¿
            extracted_file = self.temp_dir / f"{dataset_name}_input.bin"  # 7-zipã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã§å±•é–‹
            with open(extracted_file, 'rb') as f:
                decompressed_data = f.read()
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            is_lossless = (data == decompressed_data)
            compression_ratio = compressed_size / len(data)
            
            # é€Ÿåº¦è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å¯¾ç­–ï¼‰
            compression_speed = (len(data) / (1024 * 1024)) / compress_time if compress_time > 0 else 0.0
            decompression_speed = (len(data) / (1024 * 1024)) / decompress_time if decompress_time > 0 else 0.0
            
            result = {
                'compressed_size': compressed_size,
                'compression_ratio': compression_ratio,
                'compression_time': compress_time,
                'decompression_time': decompress_time,
                'compression_speed_mbps': compression_speed,
                'decompression_speed_mbps': decompression_speed,
                'is_lossless': is_lossless,
                'space_saving_percent': (1 - compression_ratio) * 100,
                'status': 'success'
            }
            
            print(f"    âœ… åœ§ç¸®ç‡: {compression_ratio:.3f} ({result['space_saving_percent']:.1f}% å‰Šæ¸›)")
            print(f"    âš¡ åœ§ç¸®é€Ÿåº¦: {result['compression_speed_mbps']:.1f} MB/s")
            print(f"    âš¡ å±•é–‹é€Ÿåº¦: {result['decompression_speed_mbps']:.1f} MB/s")
            print(f"    ğŸ” å¯é€†æ€§: {'âœ… å®Œå…¨' if is_lossless else 'âŒ ä¸å®Œå…¨'}")
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            for temp_file in [input_file, compressed_file, extracted_file]:
                if temp_file.exists():
                    temp_file.unlink()
            
        except Exception as e:
            result = {
                'status': 'error',
                'error': str(e),
                'compression_ratio': float('inf'),
                'is_lossless': False
            }
            print(f"    âŒ 7-Zip ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _test_zstandard(self, data: bytes, dataset_name: str) -> Dict[str, Any]:
        """Zstandard ãƒ†ã‚¹ãƒˆ"""
        print("  ğŸ”¥ Zstandard ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        try:
            # åœ§ç¸®ãƒ†ã‚¹ãƒˆ (æœ€é«˜åœ§ç¸®ãƒ¬ãƒ™ãƒ«)
            compressor = zstd.ZstdCompressor(level=22)  # æœ€é«˜åœ§ç¸®ç‡
            
            compress_start = time.perf_counter()
            compressed_data = compressor.compress(data)
            compress_time = time.perf_counter() - compress_start
            
            # å±•é–‹ãƒ†ã‚¹ãƒˆ
            decompressor = zstd.ZstdDecompressor()
            
            decompress_start = time.perf_counter()
            decompressed_data = decompressor.decompress(compressed_data)
            decompress_time = time.perf_counter() - decompress_start
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            is_lossless = (data == decompressed_data)
            compression_ratio = len(compressed_data) / len(data)
            
            result = {
                'compressed_size': len(compressed_data),
                'compression_ratio': compression_ratio,
                'compression_time': compress_time,
                'decompression_time': decompress_time,
                'compression_speed_mbps': (len(data) / compress_time) / (1024 * 1024),
                'decompression_speed_mbps': (len(data) / decompress_time) / (1024 * 1024),
                'is_lossless': is_lossless,
                'space_saving_percent': (1 - compression_ratio) * 100,
                'status': 'success'
            }
            
            print(f"    âœ… åœ§ç¸®ç‡: {compression_ratio:.3f} ({result['space_saving_percent']:.1f}% å‰Šæ¸›)")
            print(f"    âš¡ åœ§ç¸®é€Ÿåº¦: {result['compression_speed_mbps']:.1f} MB/s")
            print(f"    âš¡ å±•é–‹é€Ÿåº¦: {result['decompression_speed_mbps']:.1f} MB/s")
            print(f"    ğŸ” å¯é€†æ€§: {'âœ… å®Œå…¨' if is_lossless else 'âŒ ä¸å®Œå…¨'}")
            
        except Exception as e:
            result = {
                'status': 'error', 
                'error': str(e),
                'compression_ratio': float('inf'),
                'is_lossless': False
            }
            print(f"    âŒ Zstandard ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _test_zlib(self, data: bytes, dataset_name: str) -> Dict[str, Any]:
        """æ¨™æº–zlib ãƒ†ã‚¹ãƒˆï¼ˆå‚è€ƒï¼‰"""
        print("  ğŸ“‹ zlib (å‚è€ƒ) ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        
        try:
            # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
            compress_start = time.perf_counter()
            compressed_data = zlib.compress(data, level=9)
            compress_time = time.perf_counter() - compress_start
            
            # å±•é–‹ãƒ†ã‚¹ãƒˆ
            decompress_start = time.perf_counter()
            decompressed_data = zlib.decompress(compressed_data)
            decompress_time = time.perf_counter() - decompress_start
            
            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            is_lossless = (data == decompressed_data)
            compression_ratio = len(compressed_data) / len(data)
            
            # é€Ÿåº¦è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—å¯¾ç­–ï¼‰
            compression_speed = (len(data) / (1024 * 1024)) / compress_time if compress_time > 0 else 0.0
            decompression_speed = (len(data) / (1024 * 1024)) / decompress_time if decompress_time > 0 else 0.0
            
            result = {
                'compressed_size': len(compressed_data),
                'compression_ratio': compression_ratio,
                'compression_time': compress_time,
                'decompression_time': decompress_time,
                'compression_speed_mbps': compression_speed,
                'decompression_speed_mbps': decompression_speed,
                'is_lossless': is_lossless,
                'space_saving_percent': (1 - compression_ratio) * 100,
                'status': 'success'
            }
            
            print(f"    âœ… åœ§ç¸®ç‡: {compression_ratio:.3f} ({result['space_saving_percent']:.1f}% å‰Šæ¸›)")
            
        except Exception as e:
            result = {
                'status': 'error',
                'error': str(e),
                'compression_ratio': float('inf'),
                'is_lossless': False
            }
            print(f"    âŒ zlib ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def _print_dataset_summary(self, dataset_name: str, results: Dict[str, Any]):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print(f"\nğŸ“ˆ {dataset_name} çµæœã‚µãƒãƒªãƒ¼:")
        print("-" * 60)
        
        compressors = results['compressors']
        
        # åœ§ç¸®ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        valid_compressors = {name: comp for name, comp in compressors.items() 
                           if comp.get('status') == 'success'}
        
        if valid_compressors:
            # åœ§ç¸®ç‡é †ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰
            compression_ranking = sorted(valid_compressors.items(), 
                                       key=lambda x: x[1]['compression_ratio'])
            
            print("ğŸ† åœ§ç¸®ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (è‰¯ã„é †):")
            for i, (name, comp) in enumerate(compression_ranking, 1):
                ratio = comp['compression_ratio']
                saving = comp['space_saving_percent']
                print(f"  {i}. {name}: {ratio:.3f} ({saving:.1f}% å‰Šæ¸›)")
            
            # åœ§ç¸®é€Ÿåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            speed_ranking = sorted(valid_compressors.items(),
                                 key=lambda x: x[1]['compression_speed_mbps'], reverse=True)
            
            print("\nâš¡ åœ§ç¸®é€Ÿåº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° (é€Ÿã„é †):")
            for i, (name, comp) in enumerate(speed_ranking, 1):
                speed = comp['compression_speed_mbps']
                print(f"  {i}. {name}: {speed:.1f} MB/s")
    
    def _analyze_overall_results(self, benchmark_results: Dict[str, Any]):
        """ç·åˆçµæœåˆ†æ"""
        print("\n" + "=" * 80)
        print("ğŸ¯ TMC v9.0 ç·åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœåˆ†æ")
        print("=" * 80)
        
        all_results = benchmark_results['results']
        compressor_names = set()
        
        # åˆ©ç”¨å¯èƒ½ãªåœ§ç¸®å™¨ã‚’åé›†
        for dataset_results in all_results.values():
            compressor_names.update(dataset_results['compressors'].keys())
        
        # å„åœ§ç¸®å™¨ã®ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        compressor_scores = {}
        
        for compressor in compressor_names:
            compression_ratios = []
            compression_speeds = []
            decompression_speeds = []
            lossless_count = 0
            total_count = 0
            
            for dataset_name, dataset_results in all_results.items():
                if compressor in dataset_results['compressors']:
                    comp_result = dataset_results['compressors'][compressor]
                    
                    if comp_result.get('status') == 'success':
                        compression_ratios.append(comp_result['compression_ratio'])
                        compression_speeds.append(comp_result['compression_speed_mbps'])
                        decompression_speeds.append(comp_result['decompression_speed_mbps'])
                        
                        if comp_result['is_lossless']:
                            lossless_count += 1
                        total_count += 1
            
            if compression_ratios:
                avg_compression_ratio = sum(compression_ratios) / len(compression_ratios)
                avg_compression_speed = sum(compression_speeds) / len(compression_speeds)
                avg_decompression_speed = sum(decompression_speeds) / len(decompression_speeds)
                lossless_rate = lossless_count / total_count if total_count > 0 else 0
                
                # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®— (ä½ã„æ–¹ãŒè‰¯ã„)
                # åœ§ç¸®ç‡50%, åœ§ç¸®é€Ÿåº¦25%, å±•é–‹é€Ÿåº¦20%, å¯é€†æ€§5%
                normalized_compression = avg_compression_ratio  # å°ã•ã„æ–¹ãŒè‰¯ã„
                normalized_comp_speed = 1.0 / (avg_compression_speed + 0.1)  # å¤§ãã„æ–¹ãŒè‰¯ã„â†’å°ã•ãã™ã‚‹
                normalized_decomp_speed = 1.0 / (avg_decompression_speed + 0.1)  # å¤§ãã„æ–¹ãŒè‰¯ã„â†’å°ã•ãã™ã‚‹
                normalized_lossless = 1.0 - lossless_rate  # é«˜ã„æ–¹ãŒè‰¯ã„â†’å°ã•ãã™ã‚‹
                
                total_score = (normalized_compression * 0.5 +
                             normalized_comp_speed * 0.25 +
                             normalized_decomp_speed * 0.2 +
                             normalized_lossless * 0.05)
                
                compressor_scores[compressor] = {
                    'avg_compression_ratio': avg_compression_ratio,
                    'avg_compression_speed': avg_compression_speed,
                    'avg_decompression_speed': avg_decompression_speed,
                    'lossless_rate': lossless_rate,
                    'total_score': total_score,
                    'test_count': total_count
                }
        
        # çµæœè¡¨ç¤º
        print("\nğŸ“Š ç·åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ:")
        print("-" * 80)
        
        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ (ä½ã„æ–¹ãŒè‰¯ã„)
        ranked_compressors = sorted(compressor_scores.items(), key=lambda x: x[1]['total_score'])
        
        for i, (name, scores) in enumerate(ranked_compressors, 1):
            print(f"\nğŸ… {i}ä½: {name}")
            print(f"   ğŸ“¦ å¹³å‡åœ§ç¸®ç‡: {scores['avg_compression_ratio']:.3f}")
            print(f"   âš¡ å¹³å‡åœ§ç¸®é€Ÿåº¦: {scores['avg_compression_speed']:.1f} MB/s")
            print(f"   âš¡ å¹³å‡å±•é–‹é€Ÿåº¦: {scores['avg_decompression_speed']:.1f} MB/s")
            print(f"   ğŸ” å¯é€†æ€§æˆåŠŸç‡: {scores['lossless_rate']:.1%}")
            print(f"   ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢: {scores['total_score']:.3f}")
            print(f"   ğŸ“‹ ãƒ†ã‚¹ãƒˆæ•°: {scores['test_count']}")
        
        # TMC v9.0ã®è©³ç´°åˆ†æ
        if 'TMC_v9' in compressor_scores:
            tmc_scores = compressor_scores['TMC_v9']
            print(f"\nğŸ§  TMC v9.0 è©³ç´°åˆ†æ:")
            print("-" * 40)
            
            # ä»–ã®åœ§ç¸®å™¨ã¨ã®æ¯”è¼ƒ
            for comp_name, comp_scores in compressor_scores.items():
                if comp_name != 'TMC_v9' and comp_scores['test_count'] > 0:
                    compression_improvement = (comp_scores['avg_compression_ratio'] - tmc_scores['avg_compression_ratio']) / comp_scores['avg_compression_ratio'] * 100
                    speed_comparison = tmc_scores['avg_compression_speed'] / comp_scores['avg_compression_speed']
                    
                    print(f"  vs {comp_name}:")
                    print(f"    åœ§ç¸®ç‡æ”¹å–„: {compression_improvement:+.1f}%")
                    print(f"    é€Ÿåº¦æ¯”: {speed_comparison:.2f}x")
    
    def _get_system_info(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        try:
            if psutil:
                return {
                    'cpu_count': psutil.cpu_count(),
                    'cpu_freq': psutil.cpu_freq()._asdict() if psutil.cpu_freq() else None,
                    'memory_total_gb': psutil.virtual_memory().total / (1024**3),
                    'python_version': sys.version,
                    'platform': sys.platform
                }
            else:
                return {
                    'cpu_count': os.cpu_count(),
                    'python_version': sys.version,
                    'platform': sys.platform
                }
        except:
            return {'error': 'system_info_unavailable'}
    
    def _make_json_serializable(self, obj):
        """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³å¯èƒ½ãªå½¢å¼ã«å¤‰æ›"""
        import numpy as np
        
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(v) for v in obj]
        elif isinstance(obj, tuple):
            return [self._make_json_serializable(v) for v in obj]
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.int32, np.int64, np.float32, np.float64)):
            return float(obj)
        elif isinstance(obj, np.bool_):
            return bool(obj)
        elif isinstance(obj, bool):
            return obj
        elif isinstance(obj, (int, float, str, type(None))):
            return obj
        else:
            # æœªçŸ¥ã®å‹ã¯æ–‡å­—åˆ—è¡¨ç¾ã«å¤‰æ›
            return str(obj)
    
    def cleanup(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            import shutil
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
            print(f"ğŸ§¹ ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {self.temp_dir}")
        except Exception as e:
            print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ TMC v9.0 åŒ…æ‹¬çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("ğŸ“Š vs 7-Zip (LZMA2) & Zstandard")
    print("ğŸ¯ è©•ä¾¡é …ç›®: åœ§ç¸®ç‡ã€åœ§ç¸®é€Ÿåº¦ã€å±•é–‹é€Ÿåº¦ã€å¯é€†æ€§")
    print("=" * 80)
    
    benchmark = ComprehensiveBenchmark()
    
    try:
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        results = benchmark.run_comprehensive_benchmark()
        
        print("\nğŸ‰ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡å®Œäº†ï¼")
        print("ğŸ“ˆ è©³ç´°çµæœã¯ä¸Šè¨˜ãŠã‚ˆã³ä¿å­˜ã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚")
        
    except Exception as e:
        print(f"âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        benchmark.cleanup()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
NXZip TMC v9.1 çµ±æ‹¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ
åˆ†é›¢ã•ã‚ŒãŸã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ç›´æ¥å®Ÿè¡Œç‰ˆ
"""

import os
import sys
import time
import random
import json
import zlib
import lzma
from typing import Dict, Any, List, Tuple

# NXZip TMC v9.1 ç›´æ¥å®Ÿè£… - çµ±æ‹¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
class NXZipTMCEngine:
    """NXZip TMC v9.1 çµ±æ‹¬ã‚¨ãƒ³ã‚¸ãƒ³ - åˆ†é›¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆç‰ˆ"""
    
    def __init__(self, lightweight_mode: bool = False):
        self.lightweight_mode = lightweight_mode
        self.chunk_size = 256 * 1024 if lightweight_mode else 1024 * 1024
        
        if lightweight_mode:
            self.strategy = "zstd_level"
            self.compression_level = 3
            print("âš¡ NXZipè»½é‡: Zstandardãƒ¬ãƒ™ãƒ«çµ±æ‹¬")
        else:
            self.strategy = "7zip_exceed"
            self.compression_level = 6
            print("ğŸ¯ NXZipé€šå¸¸: 7-Zipè¶…è¶Šçµ±æ‹¬")
        
        # çµ±è¨ˆ
        self.stats = {
            'files_processed': 0,
            'total_input_size': 0,
            'total_compressed_size': 0,
            'strategy': self.strategy
        }
    
    def meta_analyze(self, data: bytes) -> Dict[str, Any]:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ãƒ¡ã‚¿ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼"""
        entropy = self._calculate_entropy(data[:min(1024, len(data))])
        
        return {
            'entropy': entropy,
            'size': len(data),
            'complexity': 'high' if entropy > 7.5 else 'medium' if entropy > 6.0 else 'low',
            'recommended_method': 'lzma' if entropy > 7.0 and not self.lightweight_mode else 'zlib'
        }
    
    def _calculate_entropy(self, data: bytes) -> float:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼è¨ˆç®—å™¨"""
        if len(data) == 0:
            return 0.0
        
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        entropy = 0.0
        length = len(data)
        
        for count in byte_counts:
            if count > 0:
                p = count / length
                import math
                entropy -= p * math.log2(p)  # æ­£ç¢ºãªlog2
        
        return min(8.0, entropy)
    
    def bwt_transform(self, data: bytes) -> Tuple[bytes, int]:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: BWTå¤‰æ›å™¨ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if len(data) <= 1:
            return data, 0
        
        if self.lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: BWT ã‚¹ã‚­ãƒƒãƒ—
            return data, 0
        
        # ç°¡æ˜“BWTï¼ˆå°ã•ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
        if len(data) > 1024:
            return data, 0
        
        try:
            # BWTè¿‘ä¼¼ï¼ˆå›è»¢ã‚½ãƒ¼ãƒˆï¼‰
            rotations = [(data[i:] + data[:i], i) for i in range(len(data))]
            rotations.sort()
            
            bwt_data = bytes([rot[0][-1] for rot in rotations])
            original_index = next(i for i, (_, idx) in enumerate(rotations) if idx == 0)
            
            return bwt_data, original_index
        except:
            return data, 0
    
    def context_mixing_encode(self, data: bytes) -> bytes:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼"""
        if len(data) <= 1 or self.lightweight_mode:
            return data
        
        # ç°¡æ˜“ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°ï¼ˆãƒã‚¤ãƒˆé »åº¦èª¿æ•´ï¼‰
        try:
            byte_freq = [0] * 256
            for b in data:
                byte_freq[b] += 1
            
            # é »åº¦é †ã‚½ãƒ¼ãƒˆ
            freq_order = sorted(range(256), key=lambda x: byte_freq[x], reverse=True)
            translation_table = bytes(range(256))
            
            # é«˜é »åº¦ãƒã‚¤ãƒˆã‚’å‰ã«é…ç½®
            new_table = bytearray(256)
            for i, byte_val in enumerate(freq_order):
                new_table[byte_val] = i
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            return bytes([new_table[b] for b in data])
        except:
            return data
    
    def leco_transform(self, data: bytes) -> bytes:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: LeCoå¤‰æ›å™¨ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if len(data) <= 2:
            return data
        
        # LeCoè¿‘ä¼¼ï¼ˆå·®åˆ†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
        try:
            if self.lightweight_mode:
                return data
            
            transformed = bytearray()
            prev = data[0]
            transformed.append(prev)
            
            for curr in data[1:]:
                diff = (curr - prev) % 256
                transformed.append(diff)
                prev = curr
            
            return bytes(transformed)
        except:
            return data
    
    def tdt_transform(self, data: bytes) -> bytes:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: TDTå¤‰æ›å™¨ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        if len(data) <= 4 or self.lightweight_mode:
            return data
        
        # TDTè¿‘ä¼¼ï¼ˆæ™‚ç³»åˆ—å·®åˆ†ï¼‰
        try:
            transformed = bytearray()
            window_size = 4
            
            for i in range(len(data)):
                if i < window_size:
                    transformed.append(data[i])
                else:
                    # å‘¨æœŸæ€§æ¤œå‡ºã¨å·®åˆ†
                    prev_window = data[i-window_size:i]
                    predicted = prev_window[i % window_size]
                    diff = (data[i] - predicted) % 256
                    transformed.append(diff)
            
            return bytes(transformed)
        except:
            return data
    
    def core_compress(self, data: bytes, method: str = None) -> Tuple[bytes, Dict[str, Any]]:
        """åˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«: ã‚³ã‚¢åœ§ç¸®å™¨"""
        try:
            if method is None:
                method = 'zlib' if self.lightweight_mode else 'lzma'
            
            start_time = time.time()
            
            if method == 'lzma' and not self.lightweight_mode:
                compressed = lzma.compress(data, preset=self.compression_level)
                method_used = 'lzma_7zip_exceed'
            else:
                compressed = zlib.compress(data, level=self.compression_level)
                method_used = 'zlib_zstd_level' if self.lightweight_mode else 'zlib_normal'
            
            compress_time = time.time() - start_time
            
            info = {
                'method': method_used,
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': (1 - len(compressed) / len(data)) * 100 if len(data) > 0 else 0,
                'compression_time': compress_time,
                'throughput_mbps': (len(data) / (1024 * 1024) / compress_time) if compress_time > 0 else 0
            }
            
            return compressed, info
        
        except Exception as e:
            return data, {'method': 'store', 'error': str(e)}
    
    def compress(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """NXZip TMC v9.1 çµ±æ‹¬åœ§ç¸®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        start_time = time.time()
        
        try:
            if len(data) == 0:
                return b'', {'method': 'nxzip_empty'}
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ã‚¿åˆ†æ
            meta_info = self.meta_analyze(data)
            recommended_method = meta_info['recommended_method']
            
            print(f"ğŸ“Š ãƒ¡ã‚¿åˆ†æ: {meta_info['complexity']} entropy={meta_info['entropy']:.2f}")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = self._adaptive_chunk(data)
            print(f"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²: {len(chunks)}å€‹")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: TMCå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
            transformed_chunks = []
            for i, chunk in enumerate(chunks):
                # TMCå¤‰æ›ï¼ˆåˆ†é›¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é †æ¬¡å®Ÿè¡Œï¼‰
                
                # BWTå¤‰æ›
                bwt_data, bwt_index = self.bwt_transform(chunk)
                
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°
                context_data = self.context_mixing_encode(bwt_data)
                
                # LeCoå¤‰æ›
                leco_data = self.leco_transform(context_data)
                
                # TDTå¤‰æ›
                tdt_data = self.tdt_transform(leco_data)
                
                # ãƒãƒ£ãƒ³ã‚¯æƒ…å ±
                chunk_info = {
                    'chunk_id': i,
                    'bwt_index': bwt_index,
                    'original_size': len(chunk),
                    'transformed_size': len(tdt_data)
                }
                
                transformed_chunks.append((tdt_data, chunk_info))
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: ã‚³ã‚¢åœ§ç¸®
            compressed_chunks = []
            total_original = 0
            total_compressed = 0
            
            for transformed_data, chunk_info in transformed_chunks:
                compressed, comp_info = self.core_compress(transformed_data, recommended_method)
                
                total_original += comp_info['original_size']
                total_compressed += comp_info['compressed_size']
                
                chunk_result = {
                    'compressed_data': compressed,
                    'chunk_info': chunk_info,
                    'compression_info': comp_info
                }
                compressed_chunks.append(chunk_result)
            
            # ã‚¹ãƒ†ãƒƒãƒ—5: NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ
            nxzip_container = self._create_nxzip_container(compressed_chunks)
            
            # çµ±æ‹¬çµæœ
            total_time = time.time() - start_time
            overall_ratio = (1 - len(nxzip_container) / len(data)) * 100 if len(data) > 0 else 0
            throughput = (len(data) / (1024 * 1024) / total_time) if total_time > 0 else 0
            
            result_info = {
                'engine_version': 'NXZip TMC v9.1 Unified',
                'method': 'nxzip_tmc_pipeline',
                'strategy': self.strategy,
                'original_size': len(data),
                'compressed_size': len(nxzip_container),
                'compression_ratio': overall_ratio,
                'compression_time': total_time,
                'throughput_mbps': throughput,
                'chunks_processed': len(chunks),
                'meta_analysis': meta_info,
                'pipeline_stages': ['meta_analyze', 'chunking', 'bwt', 'context_mixing', 'leco', 'tdt', 'core_compress']
            }
            
            # çµ±è¨ˆæ›´æ–°
            self.stats['files_processed'] += 1
            self.stats['total_input_size'] += len(data)
            self.stats['total_compressed_size'] += len(nxzip_container)
            
            print(f"âœ… TMCçµ±æ‹¬å®Œäº†: {overall_ratio:.1f}% åœ§ç¸®, {throughput:.1f}MB/s")
            
            return nxzip_container, result_info
            
        except Exception as e:
            print(f"âŒ TMCçµ±æ‹¬ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            fallback, info = self.core_compress(data)
            info['engine_version'] = 'NXZip TMC v9.1 Fallback'
            info['error'] = str(e)
            return fallback, info
    
    def _adaptive_chunk(self, data: bytes) -> List[bytes]:
        """é©å¿œãƒãƒ£ãƒ³ã‚¯åˆ†å‰²"""
        if len(data) <= self.chunk_size:
            return [data]
        
        chunks = []
        for i in range(0, len(data), self.chunk_size):
            chunk = data[i:i + self.chunk_size]
            chunks.append(chunk)
        
        return chunks
    
    def _create_nxzip_container(self, compressed_chunks: List[Dict]) -> bytes:
        """NXZip v2.0 ã‚³ãƒ³ãƒ†ãƒŠä½œæˆ"""
        try:
            # NXZip v2.0 ãƒ˜ãƒƒãƒ€ãƒ¼
            header = {
                'magic': 'NXZ20',
                'version': '2.0',
                'engine': 'TMC_v9.1_Unified',
                'strategy': self.strategy,
                'chunk_count': len(compressed_chunks)
            }
            
            header_json = json.dumps(header, separators=(',', ':')).encode('utf-8')
            header_size = len(header_json).to_bytes(4, 'big')
            
            # ã‚³ãƒ³ãƒ†ãƒŠæ§‹ç¯‰
            parts = [b'NXZ20', header_size, header_json]
            
            for chunk_result in compressed_chunks:
                compressed_data = chunk_result['compressed_data']
                chunk_size = len(compressed_data).to_bytes(4, 'big')
                parts.append(chunk_size)
                parts.append(compressed_data)
            
            return b''.join(parts)
            
        except Exception as e:
            print(f"ã‚³ãƒ³ãƒ†ãƒŠä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return b''.join(chunk['compressed_data'] for chunk in compressed_chunks)
    
    def get_stats(self) -> Dict[str, Any]:
        """çµ±è¨ˆå–å¾—"""
        stats = self.stats.copy()
        
        if stats['total_input_size'] > 0:
            stats['overall_compression_ratio'] = (
                1 - stats['total_compressed_size'] / stats['total_input_size']
            ) * 100
        
        return stats


def test_nxzip_tmc_unified():
    """NXZip TMC v9.1 çµ±æ‹¬ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ NXZip TMC v9.1 çµ±æ‹¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ\n")
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    test_cases = [
        (b'Hello World! ' * 100, "ç¹°ã‚Šè¿”ã—ãƒ†ã‚­ã‚¹ãƒˆ"),
        (bytes([random.randint(0, 255) for _ in range(1000)]), "ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿"),
        (b'A' * 500 + b'B' * 500, "ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿"),
        (b''.join([f'Line {i}: NXZip test data\n'.encode() for i in range(50)]), "æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ")
    ]
    
    for test_data, description in test_cases:
        print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹: {description} ({len(test_data):,} bytes)")
        
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        print("\nâš¡ è»½é‡ãƒ¢ãƒ¼ãƒ‰ (Zstandardãƒ¬ãƒ™ãƒ«):")
        engine_light = NXZipTMCEngine(lightweight_mode=True)
        compressed_light, info_light = engine_light.compress(test_data)
        
        print(f"  åœ§ç¸®ç‡: {info_light['compression_ratio']:.1f}%")
        print(f"  å‡¦ç†æ™‚é–“: {info_light['compression_time']:.3f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {info_light['throughput_mbps']:.1f}MB/s")
        print(f"  ãƒãƒ£ãƒ³ã‚¯æ•°: {info_light.get('chunks_processed', 0)}")
        print(f"  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {len(info_light.get('pipeline_stages', []))}æ®µéš")
        
        # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        print("\nğŸ¯ é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (7-Zipè¶…è¶Šãƒ¬ãƒ™ãƒ«):")
        engine_normal = NXZipTMCEngine(lightweight_mode=False)
        compressed_normal, info_normal = engine_normal.compress(test_data)
        
        print(f"  åœ§ç¸®ç‡: {info_normal['compression_ratio']:.1f}%")
        print(f"  å‡¦ç†æ™‚é–“: {info_normal['compression_time']:.3f}ç§’")
        print(f"  ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {info_normal['throughput_mbps']:.1f}MB/s")
        print(f"  ãƒãƒ£ãƒ³ã‚¯æ•°: {info_normal.get('chunks_processed', 0)}")
        print(f"  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {len(info_normal.get('pipeline_stages', []))}æ®µéš")
        
        # æ¯”è¼ƒ
        ratio_improvement = info_normal['compression_ratio'] - info_light['compression_ratio']
        speed_ratio = info_light['compression_time'] / info_normal['compression_time'] if info_normal['compression_time'] > 0 else 1
        
        print(f"\nğŸ“ˆ ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒ:")
        print(f"  åœ§ç¸®ç‡å·®: +{ratio_improvement:.1f}% (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰å„ªä½)")
        print(f"  é€Ÿåº¦æ¯”: {speed_ratio:.1f}x (è»½é‡ãƒ¢ãƒ¼ãƒ‰)")
        print("-" * 60)

def test_nxzip_statistics():
    """NXZipçµ±è¨ˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“Š NXZip TMC v9.1 çµ±è¨ˆãƒ†ã‚¹ãƒˆ")
    
    engine = NXZipTMCEngine(lightweight_mode=False)
    
    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
    total_input = 0
    for i in range(5):
        test_data = f'NXZip TMC Statistics File {i+1}: '.encode() + bytes([random.randint(0, 255) for _ in range(500)])
        total_input += len(test_data)
        
        compressed, info = engine.compress(test_data)
        print(f"  ãƒ•ã‚¡ã‚¤ãƒ«{i+1}: {info['compression_ratio']:.1f}% åœ§ç¸®")
    
    # çµ±è¨ˆå‡ºåŠ›
    stats = engine.get_stats()
    print(f"\nğŸ“ˆ TMC v9.1 ç´¯ç©çµ±è¨ˆ:")
    print(f"  å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['files_processed']}")
    print(f"  ç·å…¥åŠ›ã‚µã‚¤ã‚º: {stats['total_input_size']:,} bytes")
    print(f"  ç·åœ§ç¸®ã‚µã‚¤ã‚º: {stats['total_compressed_size']:,} bytes")
    print(f"  å…¨ä½“åœ§ç¸®ç‡: {stats.get('overall_compression_ratio', 0):.1f}%")
    print(f"  åœ§ç¸®æˆ¦ç•¥: {stats['strategy']}")

if __name__ == "__main__":
    try:
        test_nxzip_tmc_unified()
        test_nxzip_statistics()
        print("\nâœ… NXZip TMC v9.1 çµ±æ‹¬ãƒ†ã‚¹ãƒˆå®Œäº†")
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

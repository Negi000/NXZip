#!/usr/bin/env python3
"""
NEXUSå¯é€†æ€§ãƒ†ã‚¹ãƒˆ - åœ§ç¸®ãƒ»è§£å‡ã®å®Œå…¨ä¸€è‡´æ€§ç¢ºèª
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'nxzip', 'engine'))

import numpy as np
import time
import hashlib
from nexus_parallel_engine_clean import NEXUSParallelEngine, ParallelConfig


def test_nexus_reversibility():
    """NEXUSå¯é€†æ€§ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ”„ NEXUSå¯é€†æ€§ãƒ»å®Œå…¨æ€§ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ³ã‚¸ãƒ³
    config = ParallelConfig(
        use_gpu=False,  # å¯é€†æ€§ãƒ†ã‚¹ãƒˆã§ã¯ä¸€è²«æ€§é‡è¦–
        use_multiprocessing=False,
        use_threading=True,
        max_threads=4,
        chunk_size_mb=1,
        memory_limit_gb=4.0
    )
    
    engine = NEXUSParallelEngine(config)
    
    # å¤šæ§˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_cases = [
        {
            'name': 'ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆASCIIï¼‰',
            'data': b"Hello NEXUS World! " * 1000 + b"Testing reversibility and data integrity.",
            'description': 'åŸºæœ¬ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³'
        },
        {
            'name': 'ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ï¼ˆå®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ ï¼‰',
            'data': np.random.randint(0, 256, 50000, dtype=np.uint8).tobytes(),
            'description': 'é«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿'
        },
        {
            'name': 'ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼ˆåå¾©æ§‹é€ ï¼‰',
            'data': (b"PATTERN-123-ABC-" * 2000 + 
                    bytes(range(256)) * 100 + 
                    b"END-MARKER" * 500),
            'description': 'æ§‹é€ åŒ–åå¾©ãƒ‘ã‚¿ãƒ¼ãƒ³'
        },
        {
            'name': 'ã‚¼ãƒ­ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¥µç«¯åœ§ç¸®ï¼‰',
            'data': b"\x00" * 100000,
            'description': 'åŒä¸€ãƒã‚¤ãƒˆåå¾©'
        },
        {
            'name': 'æ··åˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¢ãƒ«æƒ³å®šï¼‰',
            'data': (b"Header-Section:" + 
                    np.random.randint(0, 256, 20000, dtype=np.uint8).tobytes() +
                    b"Middle-Structured-Data:" * 1000 +
                    bytes(range(256)) * 200 +
                    b"Footer-End"),
            'description': 'å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ æ¨¡æ“¬'
        },
        {
            'name': 'Unicodeæ–‡å­—åˆ—',
            'data': "ã“ã‚“ã«ã¡ã¯NEXUSï¼ğŸš€ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚".encode('utf-8') * 2000,
            'description': 'ãƒãƒ«ãƒãƒã‚¤ãƒˆæ–‡å­—å«æœ‰'
        }
    ]
    
    print(f"ğŸ”¬ ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(test_cases)}")
    
    # å„ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§å¯é€†æ€§ç¢ºèª
    all_results = []
    
    for i, test_case in enumerate(test_cases):
        print(f"\n{'='*70}")
        print(f"ğŸ§ª ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ {i+1}: {test_case['name']}")
        print(f"   ğŸ“ èª¬æ˜: {test_case['description']}")
        print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(test_case['data']):,} bytes ({len(test_case['data'])/1024:.1f}KB)")
        
        original_data = test_case['data']
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        original_hash = hashlib.sha256(original_data).hexdigest()
        print(f"   ğŸ”‘ å…ƒãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚·ãƒ¥: {original_hash[:16]}...")
        
        try:
            # === åœ§ç¸®ãƒ•ã‚§ãƒ¼ã‚º ===
            print("   ğŸ”„ åœ§ç¸®å®Ÿè¡Œä¸­...")
            compress_start = time.perf_counter()
            compressed_data = engine.parallel_compress(original_data, 'balanced')
            compress_time = time.perf_counter() - compress_start
            
            compression_ratio = (1 - len(compressed_data) / len(original_data)) * 100
            print(f"   âœ… åœ§ç¸®å®Œäº†")
            print(f"      ğŸ“ˆ åœ§ç¸®ç‡: {compression_ratio:.2f}%")
            print(f"      â±ï¸ åœ§ç¸®æ™‚é–“: {compress_time:.3f}ç§’")
            print(f"      ğŸ’¾ åœ§ç¸®å¾Œã‚µã‚¤ã‚º: {len(compressed_data):,} bytes")
            
            # === è§£å‡ãƒ•ã‚§ãƒ¼ã‚º ===
            print("   ğŸ”„ è§£å‡å®Ÿè¡Œä¸­...")
            decompress_start = time.perf_counter()
            decompressed_data = simulate_nexus_decompression(compressed_data)
            decompress_time = time.perf_counter() - decompress_start
            
            print(f"   âœ… è§£å‡å®Œäº†")
            print(f"      â±ï¸ è§£å‡æ™‚é–“: {decompress_time:.3f}ç§’")
            print(f"      ğŸ’¾ è§£å‡å¾Œã‚µã‚¤ã‚º: {len(decompressed_data):,} bytes")
            
            # === å¯é€†æ€§æ¤œè¨¼ ===
            print("   ğŸ” å¯é€†æ€§æ¤œè¨¼ä¸­...")
            
            # 1. ã‚µã‚¤ã‚ºæ¯”è¼ƒ
            size_match = len(original_data) == len(decompressed_data)
            
            # 2. ãƒãƒƒã‚·ãƒ¥æ¯”è¼ƒ
            decompressed_hash = hashlib.sha256(decompressed_data).hexdigest()
            hash_match = original_hash == decompressed_hash
            
            # 3. ãƒã‚¤ãƒˆå˜ä½æ¯”è¼ƒ
            bytes_match = original_data == decompressed_data
            
            # 4. è©³ç´°ä¸ä¸€è‡´åˆ†æï¼ˆä¸ä¸€è‡´æ™‚ï¼‰
            mismatch_details = None
            if not bytes_match and len(original_data) == len(decompressed_data):
                mismatch_details = analyze_data_mismatch(original_data, decompressed_data)
            
            # çµæœåˆ¤å®š
            is_reversible = size_match and hash_match and bytes_match
            
            result = {
                'name': test_case['name'],
                'original_size': len(original_data),
                'compressed_size': len(compressed_data),
                'decompressed_size': len(decompressed_data),
                'compression_ratio': compression_ratio,
                'compress_time': compress_time,
                'decompress_time': decompress_time,
                'size_match': size_match,
                'hash_match': hash_match,
                'bytes_match': bytes_match,
                'is_reversible': is_reversible,
                'original_hash': original_hash,
                'decompressed_hash': decompressed_hash,
                'mismatch_details': mismatch_details
            }
            
            all_results.append(result)
            
            # çµæœè¡¨ç¤º
            print(f"   ğŸ“‹ å¯é€†æ€§æ¤œè¨¼çµæœ:")
            print(f"      ğŸ“ ã‚µã‚¤ã‚ºä¸€è‡´: {'âœ…' if size_match else 'âŒ'}")
            print(f"      ğŸ”‘ ãƒãƒƒã‚·ãƒ¥ä¸€è‡´: {'âœ…' if hash_match else 'âŒ'}")
            print(f"      ğŸ”¢ ãƒã‚¤ãƒˆä¸€è‡´: {'âœ…' if bytes_match else 'âŒ'}")
            print(f"      ğŸ† ç·åˆåˆ¤å®š: {'âœ… å®Œå…¨å¯é€†' if is_reversible else 'âŒ ä¸å¯é€†'}")
            
            if not is_reversible:
                print(f"      âš ï¸ ä¸ä¸€è‡´è©³ç´°:")
                if not size_match:
                    print(f"         ã‚µã‚¤ã‚º: {len(original_data)} â†’ {len(decompressed_data)}")
                if not hash_match:
                    print(f"         ãƒãƒƒã‚·ãƒ¥å¤‰åŒ–: {original_hash[:16]}... â†’ {decompressed_hash[:16]}...")
                if mismatch_details:
                    print(f"         ä¸ä¸€è‡´ç®‡æ‰€: {mismatch_details['mismatch_count']} ä½ç½®")
                    print(f"         æœ€åˆã®ä¸ä¸€è‡´: ä½ç½® {mismatch_details['first_mismatch']} (0x{original_data[mismatch_details['first_mismatch']]:02x} â†’ 0x{decompressed_data[mismatch_details['first_mismatch']]:02x})")
            
        except Exception as e:
            print(f"   âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            
            all_results.append({
                'name': test_case['name'],
                'is_reversible': False,
                'error': str(e)
            })
    
    # ç·åˆãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\n{'='*80}")
    print(f"ğŸ“Š NEXUSå¯é€†æ€§ç·åˆãƒ¬ãƒãƒ¼ãƒˆ")
    print(f"{'='*80}")
    
    if all_results:
        successful_tests = [r for r in all_results if r.get('is_reversible', False)]
        failed_tests = [r for r in all_results if not r.get('is_reversible', False)]
        
        print(f"ğŸ¯ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"   ğŸ“Š ç·ãƒ†ã‚¹ãƒˆæ•°: {len(all_results)}")
        print(f"   âœ… æˆåŠŸï¼ˆå®Œå…¨å¯é€†ï¼‰: {len(successful_tests)}")
        print(f"   âŒ å¤±æ•—ï¼ˆä¸å¯é€†ï¼‰: {len(failed_tests)}")
        print(f"   ğŸ“ˆ å¯é€†æ€§æˆåŠŸç‡: {len(successful_tests)/len(all_results)*100:.1f}%")
        
        if successful_tests:
            avg_compression_ratio = sum(r.get('compression_ratio', 0) for r in successful_tests) / len(successful_tests)
            avg_compress_time = sum(r.get('compress_time', 0) for r in successful_tests) / len(successful_tests)
            avg_decompress_time = sum(r.get('decompress_time', 0) for r in successful_tests) / len(successful_tests)
            
            print(f"\nğŸ† æˆåŠŸã‚±ãƒ¼ã‚¹çµ±è¨ˆ:")
            print(f"   ğŸ“ˆ å¹³å‡åœ§ç¸®ç‡: {avg_compression_ratio:.2f}%")
            print(f"   â±ï¸ å¹³å‡åœ§ç¸®æ™‚é–“: {avg_compress_time:.3f}ç§’")
            print(f"   â±ï¸ å¹³å‡è§£å‡æ™‚é–“: {avg_decompress_time:.3f}ç§’")
            print(f"   âš¡ è§£å‡åŠ¹ç‡: {avg_decompress_time/avg_compress_time:.2f}x")
        
        if failed_tests:
            print(f"\nâŒ å¤±æ•—ã‚±ãƒ¼ã‚¹è©³ç´°:")
            for result in failed_tests:
                print(f"   â€¢ {result['name']}: {result.get('error', 'è©³ç´°ä¸æ˜')}")
        
        # åœ§ç¸®æ€§èƒ½åˆ¥åˆ†æ
        print(f"\nğŸ“Š åœ§ç¸®æ€§èƒ½åˆ†æ:")
        for result in successful_tests:
            efficiency_score = (result.get('compression_ratio', 0) * 0.7 + 
                               (10/max(result.get('compress_time', 0.001), 0.001)) * 0.3)
            print(f"   â€¢ {result['name'][:30]:30} | åœ§ç¸®ç‡:{result.get('compression_ratio', 0):6.2f}% | åŠ¹ç‡:{efficiency_score:6.1f}")
    
    # ç†è«–çš„è€ƒå¯Ÿ
    print(f"\nğŸ§  NEXUSç†è«–çš„å¯é€†æ€§è€ƒå¯Ÿ:")
    print(f"   ğŸ”¬ ç†è«–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: AEUåˆ†è§£ + HDSC + é †åˆ—æ­£è¦åŒ–")
    print(f"   ğŸ”„ å¯é€†æ€§ä¿è¨¼æ©Ÿæ§‹: æ•°å­¦çš„åŒå°„å¤‰æ› + ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜")
    print(f"   ğŸ›¡ï¸ æ•´åˆæ€§æ¤œè¨¼: SHA256ãƒãƒƒã‚·ãƒ¥ + ãƒã‚¤ãƒˆå˜ä½æ¯”è¼ƒ")
    print(f"   âš¡ å®Ÿè£…å“è³ª: {'å„ªç§€' if len(successful_tests) == len(all_results) else 'æ”¹å–„è¦'}")
    
    print(f"\nğŸ‰ NEXUSå¯é€†æ€§ãƒ†ã‚¹ãƒˆå®Œäº†!")
    
    return all_results


def simulate_nexus_decompression(compressed_data: bytes) -> bytes:
    """
    NEXUSè§£å‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    æ³¨æ„: ç¾åœ¨ã¯åœ§ç¸®ã®é€†å¤‰æ›ã¨ã—ã¦ç°¡æ˜“å®Ÿè£…
    """
    print("      ğŸ”„ NEXUSè§£å‡å‡¦ç†ä¸­...")
    
    try:
        # ãƒ˜ãƒƒãƒ€ãƒ¼è§£æ
        if len(compressed_data) < 128:
            raise ValueError("åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™")
        
        header = compressed_data[:128]
        
        # ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ç¢ºèª
        if header[:8] != b'NXPAR002':
            raise ValueError("ç„¡åŠ¹ãªNEXUSãƒ˜ãƒƒãƒ€ãƒ¼")
        
        import struct
        
        # åŸºæœ¬æƒ…å ±æŠ½å‡º
        original_size = struct.unpack('<Q', header[8:16])[0]
        chunk_count = struct.unpack('<I', header[16:20])[0]
        quality_code = struct.unpack('<I', header[20:24])[0]
        
        print(f"         ğŸ“Š å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes")
        print(f"         ğŸ”· ãƒãƒ£ãƒ³ã‚¯æ•°: {chunk_count}")
        print(f"         ğŸ¯ å“è³ª: {quality_code}")
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿è§£å‡
        decompressed_chunks = []
        current_pos = 128  # ãƒ˜ãƒƒãƒ€ãƒ¼å¾Œã‹ã‚‰é–‹å§‹
        
        for chunk_idx in range(chunk_count):
            if current_pos + 64 > len(compressed_data):
                break
                
            # ãƒãƒ£ãƒ³ã‚¯ãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿å–ã‚Š
            chunk_header = compressed_data[current_pos:current_pos + 64]
            chunk_id = struct.unpack('<I', chunk_header[0:4])[0]
            chunk_size = struct.unpack('<I', chunk_header[4:8])[0]
            
            current_pos += 64
            
            # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
            if current_pos + chunk_size > len(compressed_data):
                chunk_size = len(compressed_data) - current_pos
            
            chunk_data = compressed_data[current_pos:current_pos + chunk_size]
            current_pos += chunk_size
            
            # ãƒãƒ£ãƒ³ã‚¯è§£å‡
            decompressed_chunk = decompress_single_chunk(chunk_data, quality_code)
            decompressed_chunks.append((chunk_id, decompressed_chunk))
        
        # ãƒãƒ£ãƒ³ã‚¯IDé †ã§ã‚½ãƒ¼ãƒˆ
        decompressed_chunks.sort(key=lambda x: x[0])
        
        # çµåˆ
        result = b''.join(chunk[1] for chunk in decompressed_chunks)
        
        print(f"         âœ… è§£å‡å®Œäº†: {len(result):,} bytes")
        
        return result
        
    except Exception as e:
        print(f"         âŒ è§£å‡ã‚¨ãƒ©ãƒ¼: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã§åˆ‡ã‚Šè©°ã‚
        if len(compressed_data) > 128:
            import struct
            try:
                original_size = struct.unpack('<Q', compressed_data[8:16])[0]
                fallback_data = compressed_data[128:128+min(original_size, len(compressed_data)-128)]
                return fallback_data
            except:
                pass
        
        return compressed_data[:len(compressed_data)//2]  # æœ€å¾Œã®æ‰‹æ®µ


def decompress_single_chunk(chunk_data: bytes, quality_code: int) -> bytes:
    """å˜ä¸€ãƒãƒ£ãƒ³ã‚¯è§£å‡"""
    try:
        # å“è³ªåˆ¥è§£å‡
        if quality_code == 1:  # fast
            preset = 0
        elif quality_code == 2:  # balanced
            preset = 3
        else:  # max
            preset = 6
        
        # LZMAè§£å‡è©¦è¡Œ
        try:
            import lzma
            return lzma.decompress(chunk_data)
        except:
            # GPUåŠ é€Ÿåœ§ç¸®ã®é€†å¤‰æ›è©¦è¡Œ
            return reverse_gpu_compression(chunk_data)
            
    except Exception as e:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…ƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¿”å´
        return chunk_data


def reverse_gpu_compression(compressed_data: bytes) -> bytes:
    """GPUåœ§ç¸®ã®é€†å¤‰æ›"""
    try:
        # ãƒ‡ãƒ«ã‚¿ç¬¦å·åŒ–ã®é€†å¤‰æ›
        if len(compressed_data) > 0:
            deltas = np.frombuffer(compressed_data, dtype=np.int8)
            # ç´¯ç©å’Œã§ãƒ‡ãƒ«ã‚¿ã‚’å¾©å…ƒ
            if len(deltas) > 0:
                restored = np.cumsum(np.concatenate([[0], deltas.astype(np.int16)]))
                restored = np.clip(restored, 0, 255).astype(np.uint8)
                return restored.tobytes()
        
        return compressed_data
        
    except:
        return compressed_data


def analyze_data_mismatch(original: bytes, decompressed: bytes) -> dict:
    """ãƒ‡ãƒ¼ã‚¿ä¸ä¸€è‡´åˆ†æ"""
    mismatch_positions = []
    min_length = min(len(original), len(decompressed))
    
    for i in range(min_length):
        if original[i] != decompressed[i]:
            mismatch_positions.append(i)
    
    return {
        'mismatch_count': len(mismatch_positions),
        'first_mismatch': mismatch_positions[0] if mismatch_positions else None,
        'mismatch_positions': mismatch_positions[:10],  # æœ€åˆã®10å€‹
        'mismatch_rate': len(mismatch_positions) / min_length if min_length > 0 else 0
    }


if __name__ == "__main__":
    test_nexus_reversibility()

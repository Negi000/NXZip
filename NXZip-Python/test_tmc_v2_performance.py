#!/usr/bin/env python3
"""
TMC Engine v2 æ€§èƒ½ãƒ†ã‚¹ãƒˆ
æœ€é©åŒ–ç‰ˆã®åœ§ç¸®ç‡å‘ä¸Šã¨é«˜é€ŸåŒ–æ¤œè¨¼
"""

import os
import sys
import time
import numpy as np
from typing import Dict, List, Tuple

# TMC v2ã‚¨ãƒ³ã‚¸ãƒ³ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'nxzip', 'engine'))

try:
    from nexus_tmc_engine_v2 import NEXUSTMCEngineV2
except ImportError:
    print("âŒ TMC Engine v2ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    print("ä»£æ›¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è©¦è¡Œä¸­...")
    # ç›´æ¥ãƒ‘ã‚¹ã‚’æŒ‡å®š
    engine_path = os.path.join(current_dir, 'nxzip', 'engine', 'nexus_tmc_engine_v2.py')
    if os.path.exists(engine_path):
        exec(open(engine_path).read())
        print("âœ… ç›´æ¥èª­ã¿è¾¼ã¿æˆåŠŸ")
    else:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {engine_path}")
        sys.exit(1)


def create_test_datasets() -> Dict[str, bytes]:
    """å¤šæ§˜ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ"""
    datasets = {}
    
    # 1. æ§‹é€ åŒ–æ•°å€¤ãƒ‡ãƒ¼ã‚¿ï¼ˆWAVãƒ•ã‚¡ã‚¤ãƒ«é¢¨ï¼‰
    print("ğŸ“Š æ§‹é€ åŒ–æ•°å€¤ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    wav_header = b'RIFF\x24\x08\x00\x00WAVEfmt \x10\x00\x00\x00\x01\x00\x02\x00'
    audio_samples = np.random.randint(0, 256, 32768, dtype=np.uint8)  # 32KBéŸ³å£°ãƒ‡ãƒ¼ã‚¿
    # ãƒ‘ã‚¿ãƒ¼ãƒ³æ€§ã‚’æŒãŸã›ã‚‹
    for i in range(0, len(audio_samples), 4):
        if i + 3 < len(audio_samples):
            base_val = audio_samples[i]
            audio_samples[i+1] = (base_val + 10) % 256
            audio_samples[i+2] = (base_val + 20) % 256
            audio_samples[i+3] = (base_val + 5) % 256
    
    datasets['structured_numeric'] = wav_header + audio_samples.tobytes()
    
    # 2. ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æœ¬èª+è‹±èªï¼‰
    print("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    text_data = """
    NEXUS TMC Engine v2 - é©å‘½çš„åœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
    æœ€é©åŒ–ã•ã‚ŒãŸTransform-Model-Codeæ–¹å¼ã«ã‚ˆã‚Šã€å¾“æ¥ã®åœ§ç¸®é™ç•Œã‚’çªç ´ï¼
    
    Features:
    - Ultra-fast data structure analysis
    - Adaptive transformation pipeline  
    - Parallel high-performance encoding
    - Cache-optimized architecture
    - Memory-efficient design
    
    Performance Targets:
    - Compression ratio: 50-80% improvement
    - Processing speed: 2-5x faster
    - Memory usage: 30% reduction
    - Scalability: Linear performance scaling
    """ * 100  # 100å›ç¹°ã‚Šè¿”ã—
    
    datasets['text_like'] = text_data.encode('utf-8')
    
    # 3. æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿é¢¨ï¼‰
    print("ğŸ“ˆ æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    time_series = []
    base_value = 128
    for i in range(10000):
        # ç·©ã‚„ã‹ãªå¤‰åŒ–ã¨ãƒã‚¤ã‚º
        base_value += np.random.normal(0, 2)
        base_value = max(0, min(255, base_value))
        noise = np.random.normal(0, 5)
        value = int(max(0, min(255, base_value + noise)))
        time_series.append(value)
    
    datasets['time_series'] = bytes(time_series)
    
    # 4. ãƒ¡ãƒ‡ã‚£ã‚¢ãƒã‚¤ãƒŠãƒªï¼ˆPNGé¢¨ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜ãï¼‰
    print("ğŸ–¼ï¸ ãƒ¡ãƒ‡ã‚£ã‚¢ãƒã‚¤ãƒŠãƒªç”Ÿæˆä¸­...")
    png_header = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR'
    media_data = np.random.randint(0, 256, 16384, dtype=np.uint8)
    # ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹æœ‰ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    for i in range(0, len(media_data), 8):
        if i + 7 < len(media_data):
            # å±€æ‰€çš„ç›¸é–¢
            base = media_data[i]
            for j in range(1, 8):
                if i + j < len(media_data):
                    media_data[i+j] = (base + np.random.randint(-20, 20)) % 256
    
    datasets['media_binary'] = png_header + media_data.tobytes()
    
    # 5. æ—¢åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ï¼ˆé«˜ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰
    print("ğŸ—œï¸ æ—¢åœ§ç¸®ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
    compressed_data = np.random.randint(0, 256, 8192, dtype=np.uint8)  # å®Œå…¨ãƒ©ãƒ³ãƒ€ãƒ 
    datasets['compressed_binary'] = compressed_data.tobytes()
    
    # 6. å¤§å®¹é‡æ±ç”¨ãƒã‚¤ãƒŠãƒª
    print("ğŸ“¦ æ±ç”¨ãƒã‚¤ãƒŠãƒªç”Ÿæˆä¸­...")
    generic_data = bytearray()
    for _ in range(1000):
        pattern = b'\x00\x01\x02\x03' * 20
        noise = np.random.randint(0, 256, 10, dtype=np.uint8).tobytes()
        generic_data.extend(pattern + noise)
    
    datasets['generic_binary'] = bytes(generic_data)
    
    return datasets


def run_performance_comparison(datasets: Dict[str, bytes]) -> None:
    """æ€§èƒ½æ¯”è¼ƒå®Ÿè¡Œ"""
    print("\nğŸš€ TMC Engine v2 æ€§èƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 70)
    
    # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    engine_v2 = NEXUSTMCEngineV2(max_workers=4)
    
    results = []
    total_original_size = 0
    total_compressed_size = 0
    total_time = 0
    
    for data_name, data in datasets.items():
        print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆ: {data_name}")
        print(f"   åŸã‚µã‚¤ã‚º: {len(data):,} bytes ({len(data)/1024:.1f} KB)")
        
        # TMC v2åœ§ç¸®
        start_time = time.perf_counter()
        compressed, info = engine_v2.compress_tmc_v2(data, data_name)
        end_time = time.perf_counter()
        
        compression_time = end_time - start_time
        compression_ratio = info['compression_ratio']
        throughput = info['throughput_mb_s']
        data_type = info['data_type']
        transform_method = info['transform_info']['transform_method']
        
        print(f"   åœ§ç¸®å¾Œ: {len(compressed):,} bytes ({len(compressed)/1024:.1f} KB)")
        print(f"   åœ§ç¸®ç‡: {compression_ratio:.2f}%")
        print(f"   ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.2f} MB/s")
        print(f"   åˆ¤å®šã‚¿ã‚¤ãƒ—: {data_type}")
        print(f"   å¤‰æ›æ–¹æ³•: {transform_method}")
        print(f"   å‡¦ç†æ™‚é–“: {compression_time*1000:.1f}ms")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥æ™‚é–“è¡¨ç¤º
        if 'stage_times' in info:
            stage_times = info['stage_times']
            print(f"   â””â”€ åˆ†æ: {stage_times['analysis']*1000:.1f}ms")
            print(f"   â””â”€ å¤‰æ›: {stage_times['transform']*1000:.1f}ms")
            print(f"   â””â”€ ç¬¦å·åŒ–: {stage_times['encoding']*1000:.1f}ms")
        
        # å¯é€†æ€§ç¢ºèª
        reversible = info.get('reversible', False)
        expansion_prevented = info.get('expansion_prevented', False)
        print(f"   å¯é€†æ€§: {'âœ…' if reversible else 'âŒ'}")
        print(f"   è†¨å¼µé˜²æ­¢: {'âœ…' if expansion_prevented else 'âŒ'}")
        
        # çµæœè¨˜éŒ²
        results.append({
            'name': data_name,
            'original_size': len(data),
            'compressed_size': len(compressed),
            'ratio': compression_ratio,
            'throughput': throughput,
            'time': compression_time,
            'data_type': data_type,
            'transform_method': transform_method
        })
        
        total_original_size += len(data)
        total_compressed_size += len(compressed)
        total_time += compression_time
    
    # ç·åˆçµæœ
    print("\n" + "=" * 70)
    print("ğŸ“Š ç·åˆçµæœ")
    print("=" * 70)
    
    overall_ratio = (1 - total_compressed_size / total_original_size) * 100
    overall_throughput = (total_original_size / 1024 / 1024) / total_time
    
    print(f"ç·ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {total_original_size:,} bytes ({total_original_size/1024/1024:.2f} MB)")
    print(f"ç·åœ§ç¸®ã‚µã‚¤ã‚º: {total_compressed_size:,} bytes ({total_compressed_size/1024/1024:.2f} MB)")
    print(f"ç·åˆåœ§ç¸®ç‡: {overall_ratio:.2f}%")
    print(f"ç·åˆã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {overall_throughput:.2f} MB/s")
    print(f"ç·å‡¦ç†æ™‚é–“: {total_time:.3f}ç§’")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
    print(f"\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥æ€§èƒ½:")
    type_stats = {}
    for result in results:
        dtype = result['data_type']
        if dtype not in type_stats:
            type_stats[dtype] = []
        type_stats[dtype].append(result['ratio'])
    
    for dtype, ratios in type_stats.items():
        avg_ratio = np.mean(ratios)
        print(f"   {dtype}: å¹³å‡åœ§ç¸®ç‡ {avg_ratio:.2f}%")
    
    # æ€§èƒ½ã‚°ãƒ¬ãƒ¼ãƒ‰
    if overall_ratio >= 60 and overall_throughput >= 50:
        grade = "ğŸš€ é©å‘½çš„æ€§èƒ½ - åœ§ç¸®ç‡&é€Ÿåº¦ä¸¡ç«‹é”æˆï¼"
    elif overall_ratio >= 45:
        grade = "ğŸ† å„ªç§€åœ§ç¸® - é«˜åœ§ç¸®ç‡é”æˆï¼"
    elif overall_throughput >= 30:
        grade = "âš¡ é«˜é€Ÿå‡¦ç† - é«˜ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆé”æˆï¼"
    else:
        grade = "âœ… æ¨™æº–æ€§èƒ½ - å®‰å®šå‹•ä½œç¢ºèª"
    
    print(f"\nğŸ¯ æ€§èƒ½ã‚°ãƒ¬ãƒ¼ãƒ‰: {grade}")
    
    # TMC v2çµ±è¨ˆè¡¨ç¤º
    stats = engine_v2.get_tmc_v2_stats()
    if 'performance_grade' in stats:
        print(f"ğŸ… TMCè©•ä¾¡: {stats['performance_grade']}")
    
    print("\nğŸ”§ æœ€é©åŒ–åŠ¹æœ:")
    print("   âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã«ã‚ˆã‚‹é«˜é€Ÿåˆ†æ")
    print("   âœ“ ä¸¦åˆ—å‡¦ç†ã«ã‚ˆã‚‹å¤‰æ›é«˜é€ŸåŒ–")
    print("   âœ“ ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—åˆ¥åœ§ç¸®æˆ¦ç•¥")
    print("   âœ“ ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–è¨­è¨ˆ")
    print("   âœ“ é©å¿œçš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ")


def run_detailed_analysis(datasets: Dict[str, bytes]) -> None:
    """è©³ç´°åˆ†æå®Ÿè¡Œ"""
    print("\nğŸ”¬ è©³ç´°åˆ†æå®Ÿè¡Œ")
    print("=" * 70)
    
    engine = NEXUSTMCEngineV2(max_workers=4)
    
    for data_name, data in datasets.items():
        print(f"\nğŸ“‹ è©³ç´°åˆ†æ: {data_name}")
        
        # åœ§ç¸®å®Ÿè¡Œ
        compressed, info = engine.compress_tmc_v2(data, data_name)
        
        # ç‰¹å¾´é‡è¡¨ç¤º
        features = info.get('features', {})
        print(f"   ğŸ§® ç‰¹å¾´é‡:")
        for feature_name, value in features.items():
            if isinstance(value, float):
                print(f"      {feature_name}: {value:.3f}")
            else:
                print(f"      {feature_name}: {value}")
        
        # å¤‰æ›è©³ç´°
        transform_info = info.get('transform_info', {})
        print(f"   ğŸ”„ å¤‰æ›è©³ç´°:")
        for key, value in transform_info.items():
            if key != 'features':
                print(f"      {key}: {value}")
        
        # ç¬¦å·åŒ–è©³ç´°
        encoding_info = info.get('encoding_info', {})
        if 'compression_results' in encoding_info:
            print(f"   ğŸ—œï¸ ç¬¦å·åŒ–è©³ç´°:")
            for result in encoding_info['compression_results']:
                stream_id = result.get('stream_id', 0)
                method = result.get('method', 'unknown')
                ratio = result.get('ratio', 0)
                print(f"      ã‚¹ãƒˆãƒªãƒ¼ãƒ  {stream_id}: {method} ({ratio:.1f}%)")


if __name__ == "__main__":
    try:
        print("ğŸš€ NEXUS TMC Engine v2 - æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        print("é©å‘½çš„åœ§ç¸®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®æœ€é©åŒ–åŠ¹æœã‚’æ¤œè¨¼")
        print("=" * 70)
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        print("ğŸ“¦ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆä¸­...")
        datasets = create_test_datasets()
        
        print(f"\nâœ… {len(datasets)}ç¨®é¡ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™å®Œäº†")
        for name, data in datasets.items():
            print(f"   {name}: {len(data):,} bytes")
        
        # æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        run_performance_comparison(datasets)
        
        # è©³ç´°åˆ†æå®Ÿè¡Œ
        run_detailed_analysis(datasets)
        
        print("\n" + "=" * 70)
        print("ğŸ¯ TMC Engine v2 æ€§èƒ½ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("æœ€é©åŒ–ã«ã‚ˆã‚‹åœ§ç¸®ç‡å‘ä¸Šã¨é«˜é€ŸåŒ–ã‚’ç¢ºèª")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ãƒ†ã‚¹ãƒˆä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

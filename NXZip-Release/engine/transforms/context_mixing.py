"""
NEXUS TMC Engine - Context Mixing Module

This module provides advanced context mixing encoder with multi-order
prediction models, neural mixing, and adaptive learning capabilities.
"""

import numpy as np
from typing import Dict, List, Tuple, Any
import hashlib

# è»½é‡æœ€é©åŒ–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from numba import jit, prange
    NUMBA_AVAILABLE = True
    print("ğŸ”¥ Numba JIT enabled for Context Mixing - 1.5-2.5x performance boost expected")
except ImportError:
    NUMBA_AVAILABLE = False
    print("âš ï¸ Numba not available for Context Mixing - using standard implementation")

try:
    import zstandard as zstd
    ZSTD_AVAILABLE = True
except ImportError:
    ZSTD_AVAILABLE = False

__all__ = ['ContextMixingEncoder']


# Numbaæœ€é©åŒ–é–¢æ•°
if NUMBA_AVAILABLE:
    @jit(nopython=True, cache=True)
    def _update_order0_model_numba(byte_counts: np.ndarray, byte_val: int):
        """Numbaæœ€é©åŒ–ã•ã‚ŒãŸOrder-0ãƒ¢ãƒ‡ãƒ«æ›´æ–°"""
        byte_counts[byte_val] += 1
    
    @jit(nopython=True, cache=True)
    def _calculate_prediction_numba(byte_counts: np.ndarray, total_bytes: int) -> np.ndarray:
        """Numbaæœ€é©åŒ–ã•ã‚ŒãŸäºˆæ¸¬ç¢ºç‡è¨ˆç®—"""
        if total_bytes == 0:
            return np.ones(256) / 256.0
        return byte_counts / total_bytes
    
    @jit(nopython=True, cache=True)
    def _neural_mixer_forward_numba(predictions: np.ndarray, weights: np.ndarray, bias: np.ndarray) -> float:
        """Numbaæœ€é©åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼é †ä¼æ’­"""
        hidden = np.tanh(np.dot(predictions, weights) + bias)
        return np.tanh(np.sum(hidden))
else:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
    def _update_order0_model_numba(byte_counts: np.ndarray, byte_val: int):
        byte_counts[byte_val] += 1
    
    def _calculate_prediction_numba(byte_counts: np.ndarray, total_bytes: int) -> np.ndarray:
        if total_bytes == 0:
            return np.ones(256) / 256.0
        return byte_counts / total_bytes
    
    def _neural_mixer_forward_numba(predictions: np.ndarray, weights: np.ndarray, bias: np.ndarray) -> float:
        hidden = np.tanh(np.dot(predictions, weights) + bias)
        return np.tanh(np.sum(hidden))


class ContextMixingEncoder:
    """
    TMC v9.0 é©æ–°çš„ãƒ“ãƒƒãƒˆãƒ¬ãƒ™ãƒ«ãƒ»ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°ç¬¦å·åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
    LZMA2è¶…è¶Šã‚’ç›®æŒ‡ã™: é©å¿œçš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ + ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ + ãƒ“ãƒƒãƒˆäºˆæ¸¬
    """
    
    def __init__(self, lightweight_mode: bool = False):
        self.zstd_available = ZSTD_AVAILABLE
        self.lightweight_mode = lightweight_mode
        
        # è»½é‡ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸè¨­å®šèª¿æ•´
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¨CPUä½¿ç”¨é‡ã‚’å‰Šæ¸›
            self.max_context_length = 2  # æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’åˆ¶é™
            self.enable_bit_level = False  # ãƒ“ãƒƒãƒˆãƒ¬ãƒ™ãƒ«äºˆæ¸¬ã‚’ç„¡åŠ¹åŒ–
            self.enable_neural_mixer = False  # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ã‚’ç„¡åŠ¹åŒ–
            self.cache_size_limit = 1024  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
            print("âš¡ è»½é‡ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹: ãƒ¡ãƒ¢ãƒªãƒ»CPUæœ€é©åŒ–")
        else:
            # æ¨™æº–ãƒ¢ãƒ¼ãƒ‰: æœ€å¤§åœ§ç¸®ç‡ã‚’è¿½æ±‚
            self.max_context_length = 3
            self.enable_bit_level = True
            self.enable_neural_mixer = True
            self.cache_size_limit = 8192
            print("ğŸ§  æ¨™æº–ãƒ¢ãƒ¼ãƒ‰: æœ€å¤§åœ§ç¸®ç‡è¿½æ±‚")
        
        # Numbaæœ€é©åŒ–ç”¨ã®é…åˆ—
        if NUMBA_AVAILABLE:
            self.byte_counts = np.zeros(256, dtype=np.int32)
            self.total_bytes_processed = 0
        
        # å¤šéšå±¤äºˆæ¸¬å™¨ã‚·ã‚¹ãƒ†ãƒ ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã¯åˆ¶é™ï¼‰
        self.order0_model = {}  # ãƒã‚¤ãƒˆçµ±è¨ˆãƒ¢ãƒ‡ãƒ«
        self.order1_model = {} if self.max_context_length >= 1 else None
        self.order2_model = {} if self.max_context_length >= 2 else None
        self.order3_model = {} if self.max_context_length >= 3 else None
        
        # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ç”¨ç‰¹æ®Šäºˆæ¸¬å™¨ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç°¡ç•¥åŒ–ï¼‰
        if not lightweight_mode:
            self.xml_json_predictor = {}  # XML/JSONéšå±¤äºˆæ¸¬
            self.whitespace_predictor = {}  # ç©ºç™½æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³äºˆæ¸¬
            self.numeric_predictor = {}  # æ•°å€¤ã‚·ãƒ¼ã‚±ãƒ³ã‚¹äºˆæ¸¬
        
        # ãƒ“ãƒƒãƒˆãƒ¬ãƒ™ãƒ«äºˆæ¸¬å™¨ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç„¡åŠ¹åŒ–ï¼‰
        if self.enable_bit_level:
            self.bit_level_contexts = {}  # ãƒ“ãƒƒãƒˆå˜ä½ã§ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            self.bit_position_models = [{} for _ in range(8)]  # å„ãƒ“ãƒƒãƒˆä½ç½®åˆ¥ãƒ¢ãƒ‡ãƒ«
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ï¼ˆè»½é‡ãƒ¢ãƒ¼ãƒ‰ã§ã¯ç„¡åŠ¹åŒ–ï¼‰
        if self.enable_neural_mixer:
            self.neural_mixer = self._initialize_lightweight_neural_mixer()
        
        # é©å¿œçš„é‡ã¿èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 
        if lightweight_mode:
            # è»½é‡ãƒ¢ãƒ¼ãƒ‰: ã‚·ãƒ³ãƒ—ãƒ«ãªé‡ã¿è¨­å®š
            self.predictor_weights = {
                'order0': 0.4, 'order1': 0.4, 'order2': 0.2
            }
        else:
            # æ¨™æº–ãƒ¢ãƒ¼ãƒ‰: å…¨äºˆæ¸¬å™¨ä½¿ç”¨
            self.predictor_weights = {
                'order0': 0.15, 'order1': 0.20, 'order2': 0.25, 'order3': 0.15,
                'xml_json': 0.05, 'whitespace': 0.05, 'numeric': 0.05,
                'bit_level': 0.10
            }
        
        # å­¦ç¿’ãƒ»é©å¿œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå‹•çš„èª¿æ•´å¯¾å¿œï¼‰
        self.learning_rate = 0.001  # åˆæœŸå­¦ç¿’ç‡
        self.adaptive_learning = True  # å‹•çš„å­¦ç¿’ç‡èª¿æ•´
        self.learning_rate_decay = 0.999  # å­¦ç¿’ç‡æ¸›è¡°ä¿‚æ•°
        self.min_learning_rate = 0.0001  # æœ€å°å­¦ç¿’ç‡
        self.max_learning_rate = 0.01   # æœ€å¤§å­¦ç¿’ç‡
        self.performance_history = []   # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å±¥æ­´
        self.adaptation_window = 256  # é©å¿œã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        self.prediction_history = []
        self.context_cache = {}  # é«˜é€ŸåŒ–ç”¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        print("ğŸ§  ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_lightweight_neural_mixer(self) -> Dict:
        """è»½é‡ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ã®åˆæœŸåŒ–"""
        return {
            'input_weights': np.random.normal(0, 0.1, (8, 4)),  # 8äºˆæ¸¬å™¨ -> 4éš ã‚Œå±¤
            'hidden_weights': np.random.normal(0, 0.1, (4, 1)),  # 4éš ã‚Œå±¤ -> 1å‡ºåŠ›
            'input_bias': np.zeros(4),
            'hidden_bias': np.zeros(1),
            'activation_cache': None
        }
    
    def encode(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°ç¬¦å·åŒ–"""
        print("  [ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°] é«˜åº¦ç¬¦å·åŒ–ã‚’å®Ÿè¡Œä¸­...")
        
        if len(data) == 0:
            return data, {'method': 'context_mixing', 'size_reduction': 0}
        
        try:
            # å°ãƒ‡ãƒ¼ã‚¿ç”¨é«˜é€Ÿãƒ‘ã‚¹ï¼ˆ1KBæœªæº€ï¼‰
            if len(data) < 1024:
                return self._fast_path_encoding(data)
            
            # å¤šé‡äºˆæ¸¬å™¨ã«ã‚ˆã‚‹ç¬¦å·åŒ–
            encoded_data, encoding_info = self._multi_predictor_encoding(data)
            
            # Zstandardæœ€çµ‚åœ§ç¸®ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if self.zstd_available and len(encoded_data) > 512:
                final_data = self._apply_zstd_compression(encoded_data)
                compression_ratio = len(data) / len(final_data) if len(final_data) > 0 else 1.0
                
                info = {
                    'method': 'context_mixing_zstd',
                    'original_size': len(data),
                    'encoded_size': len(encoded_data),
                    'final_size': len(final_data),
                    'compression_ratio': compression_ratio,
                    'encoding_info': encoding_info
                }
                
                print(f"    [ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°] åœ§ç¸®å®Œäº†: {len(data)} -> {len(final_data)} ({compression_ratio:.2f}x)")
                return final_data, info
            else:
                compression_ratio = len(data) / len(encoded_data) if len(encoded_data) > 0 else 1.0
                info = {
                    'method': 'context_mixing_only',
                    'original_size': len(data),
                    'final_size': len(encoded_data),
                    'compression_ratio': compression_ratio,
                    'encoding_info': encoding_info
                }
                return encoded_data, info
                
        except Exception as e:
            print(f"    [ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°] ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_encoding(data)
    
    def decode(self, encoded_data: bytes, info: Dict[str, Any]) -> bytes:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°å¾©å·"""
        print("  [ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°] å¾©å·ã‚’å®Ÿè¡Œä¸­...")
        
        try:
            method = info.get('method', 'unknown')
            
            if 'zstd' in method and self.zstd_available:
                # Zstandardå¾©å·
                intermediate_data = self._reverse_zstd_compression(encoded_data)
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°å¾©å·
                return self._multi_predictor_decoding(intermediate_data, info.get('encoding_info', {}))
            else:
                # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°å¾©å·ã®ã¿
                return self._multi_predictor_decoding(encoded_data, info.get('encoding_info', {}))
                
        except Exception as e:
            print(f"    [ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒŸã‚­ã‚·ãƒ³ã‚°] å¾©å·ã‚¨ãƒ©ãƒ¼: {e}")
            return encoded_data  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    
    def _fast_path_encoding(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """å°ãƒ‡ãƒ¼ã‚¿ç”¨é«˜é€Ÿãƒ‘ã‚¹ç¬¦å·åŒ–"""
        if self.zstd_available:
            compressed = self._apply_zstd_compression(data)
            if len(compressed) < len(data):
                return compressed, {
                    'method': 'fast_zstd',
                    'compression_ratio': len(data) / len(compressed)
                }
        
        # ZstdãŒåˆ©ç”¨ã§ããªã„ã‹åŠ¹æœãŒãªã„å ´åˆ
        return data, {'method': 'fast_no_compression', 'compression_ratio': 1.0}
    
    def _multi_predictor_encoding(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """å¤šé‡äºˆæ¸¬å™¨ã«ã‚ˆã‚‹ç¬¦å·åŒ–"""
        # å„äºˆæ¸¬å™¨ã®äºˆæ¸¬çµæœã‚’åé›†
        predictions = {}
        
        # Order-0ï½3äºˆæ¸¬å™¨
        predictions['order0'] = self._order0_predict(data)
        predictions['order1'] = self._order1_predict(data)
        predictions['order2'] = self._order2_predict(data)
        predictions['order3'] = self._order3_predict(data)
        
        # ç‰¹æ®Šäºˆæ¸¬å™¨
        predictions['xml_json'] = self._xml_json_predict(data)
        predictions['whitespace'] = self._whitespace_predict(data)
        predictions['numeric'] = self._numeric_predict(data)
        predictions['bit_level'] = self._bit_level_predict(data)
        
        # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ã§çµ±åˆ
        mixed_predictions = self._neural_mix_predictions(predictions, data)
        
        # äºˆæ¸¬ã«åŸºã¥ã„ã¦ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ–
        encoded_data = self._entropy_encode_with_predictions(data, mixed_predictions)
        
        # å­¦ç¿’ãƒ»é©å¿œ
        self._update_models(data, mixed_predictions)
        
        return encoded_data, {
            'predictor_count': len(predictions),
            'prediction_accuracy': self._calculate_prediction_accuracy()
        }
    
    def _multi_predictor_decoding(self, encoded_data: bytes, encoding_info: Dict) -> bytes:
        """å¤šé‡äºˆæ¸¬å™¨ã«ã‚ˆã‚‹å¾©å·"""
        # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå¾©å·å®Ÿè£…
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ç¬¦å·åŒ–æ™‚ã®äºˆæ¸¬çµæœã‚’å†ç¾ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        return encoded_data
    
    def _order0_predict(self, data: bytes) -> List[Dict[int, float]]:
        """Order-0 (å˜ä¸€ãƒã‚¤ãƒˆçµ±è¨ˆ) äºˆæ¸¬"""
        predictions = []
        byte_counts = {}
        
        for i, byte_val in enumerate(data):
            if i > 0:
                # ã“ã‚Œã¾ã§ã®çµ±è¨ˆã«åŸºã¥ãäºˆæ¸¬
                total_count = sum(byte_counts.values())
                if total_count > 0:
                    prediction = {b: count/total_count for b, count in byte_counts.items()}
                    predictions.append(prediction)
                else:
                    predictions.append({b: 1.0/256 for b in range(256)})
            
            # ã‚«ã‚¦ãƒ³ãƒˆæ›´æ–°
            byte_counts[byte_val] = byte_counts.get(byte_val, 0) + 1
        
        return predictions
    
    def _order1_predict(self, data: bytes) -> List[Dict[int, float]]:
        """Order-1 (1ãƒã‚¤ãƒˆæ–‡è„ˆ) äºˆæ¸¬"""
        predictions = []
        
        for i in range(1, len(data)):
            context = data[i-1:i]
            context_key = context.hex()
            
            if context_key in self.order1_model:
                prediction = self.order1_model[context_key].copy()
            else:
                prediction = {b: 1.0/256 for b in range(256)}
            
            predictions.append(prediction)
            
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°
            if context_key not in self.order1_model:
                self.order1_model[context_key] = {}
            
            next_byte = data[i]
            self.order1_model[context_key][next_byte] = \
                self.order1_model[context_key].get(next_byte, 0) + 1
        
        return predictions
    
    def _order2_predict(self, data: bytes) -> List[Dict[int, float]]:
        """Order-2 (2ãƒã‚¤ãƒˆæ–‡è„ˆ) äºˆæ¸¬"""
        predictions = []
        
        for i in range(2, len(data)):
            context = data[i-2:i]
            context_key = context.hex()
            
            if context_key in self.order2_model:
                prediction = self.order2_model[context_key].copy()
            else:
                prediction = {b: 1.0/256 for b in range(256)}
            
            predictions.append(prediction)
            
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°
            if context_key not in self.order2_model:
                self.order2_model[context_key] = {}
            
            next_byte = data[i]
            self.order2_model[context_key][next_byte] = \
                self.order2_model[context_key].get(next_byte, 0) + 1
        
        return predictions
    
    def _order3_predict(self, data: bytes) -> List[Dict[int, float]]:
        """Order-3 (3ãƒã‚¤ãƒˆæ–‡è„ˆ) äºˆæ¸¬"""
        predictions = []
        
        for i in range(3, len(data)):
            context = data[i-3:i]
            context_key = context.hex()
            
            if context_key in self.order3_model:
                prediction = self.order3_model[context_key].copy()
            else:
                prediction = {b: 1.0/256 for b in range(256)}
            
            predictions.append(prediction)
            
            # ãƒ¢ãƒ‡ãƒ«æ›´æ–°
            if context_key not in self.order3_model:
                self.order3_model[context_key] = {}
            
            next_byte = data[i]
            self.order3_model[context_key][next_byte] = \
                self.order3_model[context_key].get(next_byte, 0) + 1
        
        return predictions
    
    def _xml_json_predict(self, data: bytes) -> List[Dict[int, float]]:
        """XML/JSONæ§‹é€ äºˆæ¸¬"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        return [{b: 1.0/256 for b in range(256)} for _ in range(len(data))]
    
    def _whitespace_predict(self, data: bytes) -> List[Dict[int, float]]:
        """ç©ºç™½æ–‡å­—ãƒ‘ã‚¿ãƒ¼ãƒ³äºˆæ¸¬"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        return [{b: 1.0/256 for b in range(256)} for _ in range(len(data))]
    
    def _numeric_predict(self, data: bytes) -> List[Dict[int, float]]:
        """æ•°å€¤ã‚·ãƒ¼ã‚±ãƒ³ã‚¹äºˆæ¸¬"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        return [{b: 1.0/256 for b in range(256)} for _ in range(len(data))]
    
    def _bit_level_predict(self, data: bytes) -> List[Dict[int, float]]:
        """ãƒ“ãƒƒãƒˆãƒ¬ãƒ™ãƒ«äºˆæ¸¬"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        return [{b: 1.0/256 for b in range(256)} for _ in range(len(data))]
    
    def _neural_mix_predictions(self, predictions: Dict, data: bytes) -> List[Dict[int, float]]:
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒŸã‚­ã‚µãƒ¼ã§äºˆæ¸¬çµ±åˆ"""
        # ç°¡ç•¥åŒ–å®Ÿè£…
        mixed = []
        max_len = max(len(pred) for pred in predictions.values() if pred)
        
        for i in range(max_len):
            mixed_prob = {}
            for byte in range(256):
                total_prob = 0.0
                weight_sum = 0.0
                
                for pred_name, pred_list in predictions.items():
                    if i < len(pred_list):
                        weight = self.predictor_weights.get(pred_name, 0.1)
                        prob = pred_list[i].get(byte, 1.0/256)
                        total_prob += weight * prob
                        weight_sum += weight
                
                mixed_prob[byte] = total_prob / weight_sum if weight_sum > 0 else 1.0/256
            
            mixed.append(mixed_prob)
        
        return mixed
    
    def _entropy_encode_with_predictions(self, data: bytes, predictions: List[Dict[int, float]]) -> bytes:
        """äºˆæ¸¬ã«åŸºã¥ãã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç¬¦å·åŒ–"""
        # ç°¡ç•¥åŒ–å®Ÿè£…ï¼šå˜ç´”ãªå¤‰æ›
        return data
    
    def _update_models(self, data: bytes, predictions: List[Dict[int, float]]):
        """ãƒ¢ãƒ‡ãƒ«æ›´æ–°"""
        # å­¦ç¿’ç‡é©å¿œ
        if self.adaptive_learning:
            self._adapt_learning_rate()
    
    def _adapt_learning_rate(self):
        """å‹•çš„å­¦ç¿’ç‡èª¿æ•´"""
        if len(self.performance_history) >= self.adaptation_window:
            recent_performance = self.performance_history[-self.adaptation_window:]
            avg_performance = sum(recent_performance) / len(recent_performance)
            
            if avg_performance > 0.8:  # è‰¯ã„æ€§èƒ½
                self.learning_rate = min(self.learning_rate * 1.1, self.max_learning_rate)
            elif avg_performance < 0.6:  # æ‚ªã„æ€§èƒ½
                self.learning_rate = max(self.learning_rate * 0.9, self.min_learning_rate)
    
    def _apply_zstd_compression(self, data: bytes) -> bytes:
        """Zstandardåœ§ç¸®"""
        if not self.zstd_available:
            return data
        
        try:
            compressor = zstd.ZstdCompressor(level=6)
            return compressor.compress(data)
        except:
            return data
    
    def _reverse_zstd_compression(self, data: bytes) -> bytes:
        """Zstandardå¾©å·"""
        if not self.zstd_available:
            return data
        
        try:
            decompressor = zstd.ZstdDecompressor()
            return decompressor.decompress(data)
        except:
            return data
    
    def _fallback_encoding(self, data: bytes) -> Tuple[bytes, Dict[str, Any]]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¬¦å·åŒ–"""
        try:
            if self.zstd_available:
                compressed = self._apply_zstd_compression(data)
                return compressed, {
                    'method': 'fallback_zstd',
                    'compression_ratio': len(data) / len(compressed) if len(compressed) > 0 else 1.0
                }
            else:
                return data, {'method': 'fallback_no_compression', 'compression_ratio': 1.0}
        except:
            return data, {'method': 'fallback_error', 'compression_ratio': 1.0}
    
    def _calculate_prediction_accuracy(self) -> float:
        """äºˆæ¸¬ç²¾åº¦ã®è¨ˆç®—"""
        if not self.prediction_history:
            return 0.0
        
        recent_predictions = self.prediction_history[-100:]  # æœ€è¿‘100ä»¶
        correct = sum(1 for pred in recent_predictions if pred > 0.1)
        
        return correct / len(recent_predictions) if recent_predictions else 0.0

#!/usr/bin/env python3
"""
Phase 8 Turbo å®Œå…¨å®Ÿè£… - åœ§ç¸®ãƒ»å±•é–‹æ©Ÿèƒ½ä»˜ã
AIå¼·åŒ–æ§‹é€ ç ´å£Šå‹åœ§ç¸®ã®å®Ÿç”¨åŒ–
"""

import os
import sys
import time
import json
import struct
import lzma
import zlib
from pathlib import Path

# Phase 8 Turbo ã‚¨ãƒ³ã‚¸ãƒ³ã‚’æ‹¡å¼µ
sys.path.append('bin')
from nexus_phase8_turbo import Phase8TurboEngine, CompressionResult, DecompressionResult

class Phase8FullEngine(Phase8TurboEngine):
    """Phase 8 å®Œå…¨ç‰ˆã‚¨ãƒ³ã‚¸ãƒ³ - åœ§ç¸®ãƒ»å±•é–‹å®Ÿè£…"""
    
    def __init__(self):
        super().__init__()
        self.version = "8.0-Full"
        self.magic_header = b'NXZ8F'  # Fullç‰ˆãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼
    
    def turbo_compress(self, data: bytes, filename: str = "data") -> CompressionResult:
        """Turbo æ§‹é€ ç ´å£Šå‹åœ§ç¸® - å®Œå…¨å®Ÿè£…"""
        start_time = time.time()
        original_size = len(data)
        
        print(f"ğŸš€ Phase 8 Turbo åœ§ç¸®é–‹å§‹: {filename}")
        print(f"ğŸ“Š å…ƒã‚µã‚¤ã‚º: {original_size:,} bytes ({original_size/1024:.1f} KB)")
        
        # Step 1: AIå¼·åŒ–æ§‹é€ è§£æ
        elements = self.analyze_file_structure(data)
        print(f"ğŸ“ˆ æ§‹é€ è§£æå®Œäº†: {len(elements)}è¦ç´ ")
        
        # Step 2: æ§‹é€ ãƒãƒƒãƒ—ç”Ÿæˆ
        structure_map = self._create_turbo_structure_map(elements)
        
        # Step 3: ä¸¦åˆ—åœ§ç¸®å®Ÿè¡Œ
        compressed_chunks = []
        total_chunks = len(elements)
        
        progress_points = [total_chunks//4, total_chunks//2, total_chunks*3//4, total_chunks]
        
        for i, element in enumerate(elements):
            # AIæ¨è–¦åœ§ç¸®æ‰‹æ³•ã§åœ§ç¸®
            compressed_chunk = self._turbo_compress_chunk(element)
            compressed_chunks.append(compressed_chunk)
            
            # é€²æ—è¡¨ç¤ºï¼ˆåŠ¹ç‡åŒ–ï¼‰
            if i + 1 in progress_points:
                percent = ((i + 1) / total_chunks) * 100
                print(f"âš¡ åœ§ç¸®é€²æ—: {percent:.0f}%")
        
        # Step 4: æœ€çµ‚çµ±åˆ
        final_compressed = self._integrate_turbo_data(compressed_chunks, structure_map)
        
        # Step 5: çµæœè¨ˆç®—
        compressed_size = len(final_compressed)
        compression_ratio = ((original_size - compressed_size) / original_size) * 100
        processing_time = time.time() - start_time
        
        # AIè§£æã‚µãƒãƒªãƒ¼
        if elements:
            avg_entropy = sum(e.entropy for e in elements) / len(elements)
            ai_recommendations = [e.compression_hint for e in elements]
            most_common_hint = max(set(ai_recommendations), key=ai_recommendations.count)
            
            print(f"ğŸ¤– AIè§£æçµæœ:")
            print(f"   å¹³å‡ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: {avg_entropy:.2f}")
            print(f"   ä¸»è¦æ¨è–¦æ‰‹æ³•: {most_common_hint}")
        
        print(f"âœ… åœ§ç¸®å®Œäº†: {compression_ratio:.1f}% ({original_size:,} â†’ {compressed_size:,})")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        
        # æ€§èƒ½æŒ‡æ¨™
        speed_mbps = original_size / processing_time / (1024 * 1024)
        performance_metrics = {
            'analysis_elements': len(elements),
            'avg_entropy': avg_entropy if elements else 0.0,
            'processing_speed_mbps': speed_mbps,
            'ai_recommendation': most_common_hint if elements else 'none'
        }
        
        return CompressionResult(
            original_size=original_size,
            compressed_size=compressed_size,
            compression_ratio=compression_ratio,
            algorithm="Phase8_Turbo_Full",
            processing_time=processing_time,
            structure_map=structure_map,
            compressed_data=final_compressed,
            performance_metrics=performance_metrics
        )
    
    def turbo_decompress(self, compressed_data: bytes) -> DecompressionResult:
        """Turbo æ§‹é€ ç ´å£Šå‹å±•é–‹ - å®Œå…¨å®Ÿè£…"""
        start_time = time.time()
        
        print("ğŸ”„ Phase 8 Turbo å±•é–‹é–‹å§‹")
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œè¨¼
        if not compressed_data.startswith(self.magic_header):
            raise ValueError("âŒ Phase 8 Turboå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        
        offset = len(self.magic_header)
        
        # æ§‹é€ ãƒãƒƒãƒ—ã‚µã‚¤ã‚º
        structure_map_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
        offset += 4
        
        # æ§‹é€ ãƒãƒƒãƒ—å¾©å…ƒ
        structure_map_data = compressed_data[offset:offset+structure_map_size]
        offset += structure_map_size
        
        structure_info = self._parse_turbo_structure_map(structure_map_data)
        print(f"ğŸ“Š æ§‹é€ å¾©å…ƒ: {structure_info['total_elements']}è¦ç´ ")
        
        # ãƒãƒ£ãƒ³ã‚¯å¾©å…ƒ
        decompressed_chunks = []
        elements_info = structure_info['elements']
        
        for i, element_info in enumerate(elements_info):
            chunk_size = struct.unpack('<I', compressed_data[offset:offset+4])[0]
            offset += 4
            
            if chunk_size > 0:
                chunk_data = compressed_data[offset:offset+chunk_size]
                offset += chunk_size
                
                # AIæ¨è–¦æ‰‹æ³•ã§å±•é–‹
                decompressed_chunk = self._turbo_decompress_chunk(chunk_data, element_info)
                decompressed_chunks.append(decompressed_chunk)
            else:
                decompressed_chunks.append(b'')
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % max(1, len(elements_info) // 4) == 0:
                percent = ((i + 1) / len(elements_info)) * 100
                print(f"ğŸ”„ å±•é–‹é€²æ—: {percent:.0f}%")
        
        # å®Œå…¨å¾©å…ƒ
        original_data = self._reconstruct_turbo_original(decompressed_chunks, structure_info)
        
        processing_time = time.time() - start_time
        print(f"âœ… å±•é–‹å®Œäº†: {len(original_data):,} bytes ({processing_time:.2f}ç§’)")
        
        return DecompressionResult(
            original_data=original_data,
            decompressed_size=len(original_data),
            processing_time=processing_time,
            algorithm="Phase8_Turbo_Full"
        )
    
    def _create_turbo_structure_map(self, elements) -> bytes:
        """Turboæ§‹é€ ãƒãƒƒãƒ—ç”Ÿæˆ"""
        structure_info = {
            'version': self.version,
            'total_elements': len(elements),
            'ai_enhanced': True,
            'elements': []
        }
        
        for element in elements:
            element_info = {
                'type': element.type,
                'offset': element.offset,
                'size': element.size,
                'entropy': element.entropy,
                'pattern_score': element.pattern_score,
                'compression_hint': element.compression_hint
            }
            
            # AIè§£æçµæœã‚’å«ã‚ã‚‹
            if element.ai_analysis:
                element_info['ai_analysis'] = element.ai_analysis
            
            structure_info['elements'].append(element_info)
        
        # JSONâ†’ãƒã‚¤ãƒŠãƒªåœ§ç¸®
        json_data = json.dumps(structure_info, separators=(',', ':')).encode('utf-8')
        return lzma.compress(json_data, preset=9)
    
    def _turbo_compress_chunk(self, element) -> bytes:
        """Turbo ãƒãƒ£ãƒ³ã‚¯åœ§ç¸® - AIæ¨è–¦æ‰‹æ³•"""
        data = element.data
        hint = element.compression_hint
        
        # AIæ¨è–¦ã«åŸºã¥ãæœ€é©åœ§ç¸®
        if hint == "rle_enhanced":
            return self._enhanced_rle_compress(data)
        elif hint == "lzma":
            return self._turbo_lzma_compress(data)
        elif hint == "zstd":
            return self._turbo_zstd_compress(data)
        elif hint == "brotli":
            return self._turbo_brotli_compress(data)
        elif hint == "minimal_processing":
            return data  # ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜
        else:  # adaptive_optimal
            return self._turbo_adaptive_compress(data)
    
    def _enhanced_rle_compress(self, data: bytes) -> bytes:
        """å¼·åŒ–RLEåœ§ç¸®"""
        if not data:
            return b''
        
        compressed = bytearray()
        i = 0
        while i < len(data):
            current_byte = data[i]
            count = 1
            
            # åŒã˜ãƒã‚¤ãƒˆã®é€£ç¶šã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            while i + count < len(data) and data[i + count] == current_byte and count < 255:
                count += 1
            
            if count >= 3:  # 3å›ä»¥ä¸Šã®ç¹°ã‚Šè¿”ã—ã§åœ§ç¸®
                compressed.extend([0xFF, count, current_byte])
                i += count
            else:
                compressed.append(current_byte)
                i += 1
        
        return bytes(compressed)
    
    def _turbo_lzma_compress(self, data: bytes) -> bytes:
        """Turbo LZMAåœ§ç¸®"""
        try:
            return lzma.compress(data, preset=6, check=lzma.CHECK_NONE)
        except:
            return data
    
    def _turbo_zstd_compress(self, data: bytes) -> bytes:
        """Turbo Zstdé¢¨åœ§ç¸®ï¼ˆzlibã§ä»£ç”¨ï¼‰"""
        try:
            return zlib.compress(data, level=6)
        except:
            return data
    
    def _turbo_brotli_compress(self, data: bytes) -> bytes:
        """Turbo Brotlié¢¨åœ§ç¸®ï¼ˆlzmaã§ä»£ç”¨ï¼‰"""
        try:
            return lzma.compress(data, preset=3)
        except:
            return data
    
    def _turbo_adaptive_compress(self, data: bytes) -> bytes:
        """Turboé©å¿œçš„åœ§ç¸®"""
        if not data:
            return b''
        
        # è¤‡æ•°æ‰‹æ³•ã‚’è©¦ã—ã¦æœ€è‰¯ã‚’é¸æŠ
        methods = [
            (self._turbo_lzma_compress, 'lzma'),
            (self._turbo_zstd_compress, 'zstd'),
            (self._enhanced_rle_compress, 'rle')
        ]
        
        best_result = data
        best_size = len(data)
        
        for method, name in methods:
            try:
                result = method(data)
                if len(result) < best_size:
                    best_result = result
                    best_size = len(result)
            except:
                continue
        
        return best_result
    
    def _integrate_turbo_data(self, compressed_chunks, structure_map: bytes) -> bytes:
        """Turbo ãƒ‡ãƒ¼ã‚¿çµ±åˆ"""
        result = bytearray()
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        result.extend(self.magic_header)
        result.extend(struct.pack('<I', len(structure_map)))
        result.extend(structure_map)
        
        # åœ§ç¸®ãƒãƒ£ãƒ³ã‚¯
        for chunk in compressed_chunks:
            result.extend(struct.pack('<I', len(chunk)))
            result.extend(chunk)
        
        return bytes(result)
    
    def _parse_turbo_structure_map(self, structure_map_data: bytes) -> dict:
        """Turboæ§‹é€ ãƒãƒƒãƒ—è§£æ"""
        try:
            decompressed_json = lzma.decompress(structure_map_data)
            return json.loads(decompressed_json.decode('utf-8'))
        except Exception as e:
            raise ValueError(f"æ§‹é€ ãƒãƒƒãƒ—è§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _turbo_decompress_chunk(self, chunk_data: bytes, element_info: dict) -> bytes:
        """Turboãƒãƒ£ãƒ³ã‚¯å±•é–‹"""
        hint = element_info.get('compression_hint', 'adaptive_optimal')
        
        try:
            if hint == "rle_enhanced":
                return self._enhanced_rle_decompress(chunk_data)
            elif hint == "lzma":
                return lzma.decompress(chunk_data)
            elif hint == "zstd":
                return zlib.decompress(chunk_data)
            elif hint == "brotli":
                return lzma.decompress(chunk_data)
            elif hint == "minimal_processing":
                return chunk_data
            else:
                return self._turbo_adaptive_decompress(chunk_data)
        except Exception:
            return chunk_data
    
    def _enhanced_rle_decompress(self, data: bytes) -> bytes:
        """å¼·åŒ–RLEå±•é–‹"""
        if not data:
            return b''
        
        result = bytearray()
        i = 0
        while i < len(data):
            if i + 2 < len(data) and data[i] == 0xFF:
                # RLEåœ§ç¸®ãƒ‡ãƒ¼ã‚¿
                count = data[i + 1]
                byte_value = data[i + 2]
                result.extend([byte_value] * count)
                i += 3
            else:
                # é€šå¸¸ãƒ‡ãƒ¼ã‚¿
                result.append(data[i])
                i += 1
        
        return bytes(result)
    
    def _turbo_adaptive_decompress(self, data: bytes) -> bytes:
        """Turboé©å¿œçš„å±•é–‹"""
        # è¤‡æ•°ã®å±•é–‹æ–¹æ³•ã‚’è©¦è¡Œ
        methods = [lzma.decompress, zlib.decompress, self._enhanced_rle_decompress]
        
        for method in methods:
            try:
                return method(data)
            except:
                continue
        
        return data
    
    def _reconstruct_turbo_original(self, chunks, structure_info: dict) -> bytes:
        """Turboå®Œå…¨å¾©å…ƒ - ä¿®æ­£ç‰ˆ"""
        result = bytearray()
        
        # å…ƒã®æ§‹é€ é †åºã§ãƒãƒ£ãƒ³ã‚¯ã‚’é…ç½®
        elements_info = structure_info['elements']
        
        for i, chunk in enumerate(chunks):
            if i < len(elements_info):
                element_info = elements_info[i]
                # å…ƒã®ä½ç½®ãƒ»ã‚µã‚¤ã‚ºæƒ…å ±ã‚’ä½¿ç”¨ã—ã¦æ­£ç¢ºã«å¾©å…ƒ
                result.extend(chunk)
            else:
                result.extend(chunk)
        
        return bytes(result)
    
    def compress_file(self, input_path: str, output_path: str = None) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return False
        
        if output_path is None:
            output_path = input_path + '.p8t'  # Phase 8 Turbo
        
        try:
            with open(input_path, 'rb') as f:
                data = f.read()
            
            filename = os.path.basename(input_path)
            result = self.turbo_compress(data, filename)
            
            with open(output_path, 'wb') as f:
                f.write(result.compressed_data)
            
            print(f"ğŸ’¾ åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}")
            
            # Phase 7ã¨ã®æ¯”è¼ƒ
            phase7_estimated = len(data) * 0.427  # Phase 7å¹³å‡57.3%åœ§ç¸®
            improvement = (phase7_estimated - result.compressed_size) / phase7_estimated * 100
            
            print(f"ğŸ† Phase 7æ¯”è¼ƒ:")
            print(f"   Phase 7æ¨å®š: {phase7_estimated:,.0f} bytes")
            print(f"   Phase 8å®Ÿæ¸¬: {result.compressed_size:,} bytes")
            print(f"   æ”¹å–„ç‡: {improvement:+.1f}%")
            
            return True
        
        except Exception as e:
            print(f"âŒ åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def decompress_file(self, input_path: str, output_path: str = None) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹"""
        if not os.path.exists(input_path):
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_path}")
            return False
        
        if output_path is None:
            if input_path.endswith('.p8t'):
                output_path = input_path[:-4]
            else:
                output_path = input_path + '.restored'
        
        try:
            with open(input_path, 'rb') as f:
                compressed_data = f.read()
            
            result = self.turbo_decompress(compressed_data)
            
            with open(output_path, 'wb') as f:
                f.write(result.original_data)
            
            print(f"ğŸ“ å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_path}")
            return True
        
        except Exception as e:
            print(f"âŒ å±•é–‹ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def run_phase8_test():
    """Phase 8 å®Œå…¨ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ Phase 8 Turbo å®Œå…¨å®Ÿè£…ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    engine = Phase8FullEngine()
    sample_dir = Path("../NXZip-Python/sample")
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã®åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
    test_files = [
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
        "å‡ºåº«å®Ÿç¸¾æ˜ç´°_202412.txt",      # å¤§å®¹é‡ãƒ†ã‚­ã‚¹ãƒˆ (97MB)
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        "é™°è¬€è«–.mp3",                    # MP3éŸ³å£° (2MB)
        "generated-music-1752042054079.wav",  # WAVéŸ³å£° (4MB)
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«  
        "COT-001.jpg",                   # JPEGç”»åƒ (2.8MB)
        "COT-012.png",                   # PNGç”»åƒ (35MB)
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«
        "PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.mp4", # MP4å‹•ç”» (30MB)
        
        # åœ§ç¸®æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«
        "COT-001.7z",                    # 7-Zipåœ§ç¸®æ¸ˆã¿
        "COT-012.7z",                    # 7-Zipåœ§ç¸®æ¸ˆã¿
        "PythonåŸºç¤è¬›åº§3_4æœˆ26æ—¥-3.7z", # 7-Zipåœ§ç¸®æ¸ˆã¿
    ]
    
    results = []
    
    for filename in test_files:
        filepath = sample_dir / filename
        if not filepath.exists():
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãªã—: {filename}")
            continue
        
        print(f"\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {filename}")
        print("-" * 40)
        
        try:
            # åœ§ç¸®ãƒ†ã‚¹ãƒˆ
            output_path = str(filepath) + '.p8t'
            success = engine.compress_file(str(filepath), output_path)
            
            if success:
                # å±•é–‹ãƒ†ã‚¹ãƒˆ
                restored_path = output_path + '.restored'
                decompress_success = engine.decompress_file(output_path, restored_path)
                
                if decompress_success:
                    # å¯é€†æ€§æ¤œè¨¼
                    with open(filepath, 'rb') as f:
                        original = f.read()
                    with open(restored_path, 'rb') as f:
                        restored = f.read()
                    
                    is_identical = (original == restored)
                    print(f"ğŸ” å¯é€†æ€§: {'âœ… å®Œå…¨ä¸€è‡´' if is_identical else 'âŒ ä¸ä¸€è‡´'}")
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºæ¯”è¼ƒ
                    original_size = len(original)
                    compressed_size = os.path.getsize(output_path)
                    compression_ratio = (1 - compressed_size / original_size) * 100
                    
                    results.append({
                        'filename': filename,
                        'original_size': original_size,
                        'compressed_size': compressed_size,
                        'compression_ratio': compression_ratio,
                        'reversible': is_identical
                    })
                    
                    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    os.remove(output_path)
                    os.remove(restored_path)
            
        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:60]}...")
    
    # ç·åˆçµæœ
    if results:
        print("\n" + "=" * 60)
        print("ğŸ† Phase 8 Turbo åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 60)
        
        total_original = sum(r['original_size'] for r in results)
        total_compressed = sum(r['compressed_size'] for r in results)
        overall_ratio = (1 - total_compressed / total_original) * 100
        
        print(f"ğŸ“Š ç·åˆåœ§ç¸®ç‡: {overall_ratio:.1f}%")
        print(f"ğŸ“ˆ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results)}")
        print(f"ï¿½ ç·ãƒ‡ãƒ¼ã‚¿é‡: {total_original/1024/1024:.1f} MB")
        print(f"ğŸ’¾ åœ§ç¸®å¾Œã‚µã‚¤ã‚º: {total_compressed/1024/1024:.1f} MB")
        print(f"ï¿½ğŸ” å¯é€†æ€§: {sum(1 for r in results if r['reversible'])}/{len(results)} æˆåŠŸ")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¥åˆ†æ
        format_analysis = {}
        for result in results:
            filename = result['filename']
            ext = filename.split('.')[-1].upper()
            
            if ext not in format_analysis:
                format_analysis[ext] = {
                    'count': 0,
                    'total_original': 0,
                    'total_compressed': 0,
                    'reversible_count': 0
                }
            
            format_analysis[ext]['count'] += 1
            format_analysis[ext]['total_original'] += result['original_size']
            format_analysis[ext]['total_compressed'] += result['compressed_size']
            if result['reversible']:
                format_analysis[ext]['reversible_count'] += 1
        
        print(f"\nğŸ¯ ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¥è©³ç´°åˆ†æ:")
        for ext, data in format_analysis.items():
            ratio = (1 - data['total_compressed'] / data['total_original']) * 100
            reversible_rate = (data['reversible_count'] / data['count']) * 100
            print(f"   ğŸ“„ {ext}: {ratio:.1f}%åœ§ç¸® ({data['count']}ãƒ•ã‚¡ã‚¤ãƒ«, å¯é€†æ€§{reversible_rate:.0f}%)")
        
        # Phase 7ã¨ã®æ¯”è¼ƒ
        phase7_ratio = 57.3
        improvement = overall_ratio - phase7_ratio
        
        print(f"\nğŸ¯ Phase 7æ¯”è¼ƒ:")
        print(f"   Phase 7: {phase7_ratio}%")
        print(f"   Phase 8: {overall_ratio:.1f}%")
        print(f"   æ”¹å–„: {improvement:+.1f}%")
        
        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°çµæœ
        print(f"\nğŸ“‹ å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°çµæœ:")
        for result in results:
            filename = result['filename'][:30] + ('...' if len(result['filename']) > 30 else '')
            size_mb = result['original_size'] / 1024 / 1024
            reversible_icon = 'âœ…' if result['reversible'] else 'âŒ'
            print(f"   â€¢ {filename}: {result['compression_ratio']:.1f}% ({size_mb:.1f}MB) {reversible_icon}")
        
        if overall_ratio > phase7_ratio:
            print("ğŸ‰ Phase 8 Turboå¤§æˆåŠŸï¼Phase 7ã‚’ä¸Šå›ã‚‹åœ§ç¸®ç‡é”æˆï¼")
        else:
            print("ğŸ“ˆ ç¶™ç¶šæ”¹å–„ä¸­...")
        
        # æœ€å„ªç§€ãƒ»æœ€ä½ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        best_result = max(results, key=lambda x: x['compression_ratio'])
        worst_result = min(results, key=lambda x: x['compression_ratio'])
        
        print(f"\nğŸ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ:")
        print(f"   ğŸ¥‡ æœ€å„ªç§€: {best_result['filename']} ({best_result['compression_ratio']:.1f}%)")
        print(f"   ğŸš¨ æ”¹å–„å¿…è¦: {worst_result['filename']} ({worst_result['compression_ratio']:.1f}%)")
        
        # æ¨å¥¨æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        low_compression_files = [r for r in results if r['compression_ratio'] < 10]
        if low_compression_files:
            print(f"\nâš ï¸ ä½åœ§ç¸®ç‡ãƒ•ã‚¡ã‚¤ãƒ« ({len(low_compression_files)}å€‹):")
            for r in low_compression_files:
                ext = r['filename'].split('.')[-1].upper()
                print(f"   â€¢ {r['filename']}: {r['compression_ratio']:.1f}% (è¦{ext}ç‰¹åŒ–æœ€é©åŒ–)")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºåˆ¥åˆ†æ
        large_files = [r for r in results if r['original_size'] > 10*1024*1024]  # 10MBä»¥ä¸Š
        medium_files = [r for r in results if 1*1024*1024 <= r['original_size'] <= 10*1024*1024]  # 1-10MB
        small_files = [r for r in results if r['original_size'] < 1*1024*1024]  # 1MBæœªæº€
        
        print(f"\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¥åˆ†æ:")
        if large_files:
            large_ratio = sum(r['compression_ratio'] for r in large_files) / len(large_files)
            print(f"   ğŸ˜ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (10MB+): å¹³å‡{large_ratio:.1f}%åœ§ç¸® ({len(large_files)}å€‹)")
        if medium_files:
            medium_ratio = sum(r['compression_ratio'] for r in medium_files) / len(medium_files)
            print(f"   ğŸ¦Œ ä¸­å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (1-10MB): å¹³å‡{medium_ratio:.1f}%åœ§ç¸® ({len(medium_files)}å€‹)")
        if small_files:
            small_ratio = sum(r['compression_ratio'] for r in small_files) / len(small_files)
            print(f"   ğŸ å°å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (1MBæœªæº€): å¹³å‡{small_ratio:.1f}%åœ§ç¸® ({len(small_files)}å€‹)")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("ğŸš€ Phase 8 Turbo å®Œå…¨å®Ÿè£…")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python phase8_full.py test                     # å®Œå…¨ãƒ†ã‚¹ãƒˆ")
        print("  python phase8_full.py compress <file>          # ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®")
        print("  python phase8_full.py decompress <file.p8t>    # ãƒ•ã‚¡ã‚¤ãƒ«å±•é–‹")
        return
    
    command = sys.argv[1].lower()
    engine = Phase8FullEngine()
    
    if command == "test":
        run_phase8_test()
    elif command == "compress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) >= 4 else None
        engine.compress_file(input_file, output_file)
    elif command == "decompress" and len(sys.argv) >= 3:
        input_file = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) >= 4 else None
        engine.decompress_file(input_file, output_file)
    else:
        print("âŒ ç„¡åŠ¹ãªã‚³ãƒãƒ³ãƒ‰ã§ã™")

if __name__ == "__main__":
    main()
